c11b301bcda123711f678754647bef7b9b17f760,2023-01-26T02:50:44Z,https://github.com/pytorch/pytorch/commit/c11b301bcda123711f678754647bef7b9b17f760,"[NVFUSER] refactor nvfuser build (#89621)  This PR is the first step towards refactors the build for nvfuser in order to have the coegen being a standalone library.  Contents inside this PR: 1. nvfuser code base has been moved to `./nvfuser`, from `./torch/csrc/jit/codegen/cuda/`, except for registration code for integration (interface.h/interface.cpp) 2. splits the build system so nvfuser is generating its own `.so` files. Currently there are:     - `libnvfuser_codegen.so`, which contains the integration, codegen and runtime system of nvfuser     - `nvfuser.so`, which is nvfuser's python API via pybind. Python frontend is now exposed via `nvfuser._C.XXX` instead of `torch._C._nvfuser` 3. nvfuser cpp tests is currently being compiled into `nvfuser_tests` 4. cmake is refactored so that:     - nvfuser now has its own `CMakeLists.txt`, which is under `torch/csrc/jit/codegen/cuda/`.     - nvfuser backend code is not compiled inside `libtorch_cuda_xxx` any more     - nvfuser is added as a subdirectory under `./CMakeLists.txt` at the very end after torch is built.     - since nvfuser has dependency on torch, the registration of nvfuser at runtime is done via dlopen (`at::DynamicLibrary`). This avoids circular dependency in cmake, which will be a nightmare to handle. For details, look at `torch/csrc/jit/codegen/cuda/interface.cpp::LoadingNvfuserLibrary`  Future work that's scoped in following PR: - Currently since nvfuser codegen has dependency on torch, we need to refactor that out so we can move nvfuser into a submodule and not rely on dlopen to load the library. @malfet - Since we moved nvfuser into a cmake build, we effectively disabled bazel build for nvfuser. This could impact internal workload at Meta, so we need to put support back. cc'ing @vors  Pull Request resolved: https://github.com/pytorch/pytorch/pull/89621 Approved by: https://github.com/davidberard98",1,Tease Apart Inheritance,,
42aab9b1f03713757d7c027b23f1113ea80f73ad,2020-11-17T00:06:00Z,https://github.com/tensorflow/tensorflow/commit/42aab9b1f03713757d7c027b23f1113ea80f73ad,Simplify the stack walking in deprecation.py. Remove dependency on tf_stack.PiperOrigin-RevId: 342742350Change-Id: Ie976e0e45062361d4349a2d72a7941c221fb98be,1,Expression,,
76a08f796c560a109d8d58d75c55d38cdb8b8cd6,2020-10-26T20:12:13Z,https://github.com/tensorflow/tensorflow/commit/76a08f796c560a109d8d58d75c55d38cdb8b8cd6,Remove usage of internal ops.numpy_text by forking it into Keras.PiperOrigin-RevId: 339102563Change-Id: Ic21e266529dcd44e2a2199bbd0391beef4444a79,1,Expression,,
88c2594048b70e7a77b3b235d0a8b29665599cb7,2020-07-31T08:19:03Z,https://github.com/tensorflow/tensorflow/commit/88c2594048b70e7a77b3b235d0a8b29665599cb7,"Replace x.eval() with self.evaluate() in tests.It makes the line V2 compatible$ sed -i ""s/\([a-z][._a-z0-9]*\).eval()/self.evaluate(\1)/"" ./third_party/tensorflow/python/kernel_tests/*.pyAnd some manual cleaning.PiperOrigin-RevId: 324169377Change-Id: I36a8d92c28a46e5a05fb32bdb634a84081951d88",1,Expression,,
dd472f98f5681769d1206bab93dee59f53575bd6,2020-07-31T07:54:04Z,https://github.com/tensorflow/tensorflow/commit/dd472f98f5681769d1206bab93dee59f53575bd6,"Replace `x.initializer.run()` with `self.evaluate(x.initializer)` in tests.This change makes the line V2 compatible.sed -i ""s/\([_a-z0-9]*\).initializer.run()/self.evaluate(\1.initializer)/"" ./third_party/tensorflow/python/kernel_tests/*.pyPiperOrigin-RevId: 324166739Change-Id: Icf6213784063de295f0bf7b69a847e5f3820a752",1,Expression,,
0f6544c932fb6739641c7fe2438401891b1a8b70,2020-07-27T23:18:13Z,https://github.com/tensorflow/tensorflow/commit/0f6544c932fb6739641c7fe2438401891b1a8b70,Remove the usage of TF private API init_ops._compute_fans from Keras.PiperOrigin-RevId: 323463488Change-Id: If0c71609a7ac111651abf9b3ebd46bc790fe993d,1,Expression,,
15691d14b471a5f794360e4ec4060f48d8f80d15,2020-06-22T13:46:12Z,https://github.com/tensorflow/tensorflow/commit/15691d14b471a5f794360e4ec4060f48d8f80d15,Replace deprecated np.asscalar with .item(),1,Expression,,
2624f6c405e12012c8cdd90594fbc4ea573a2d91,2020-06-22T13:44:17Z,https://github.com/tensorflow/tensorflow/commit/2624f6c405e12012c8cdd90594fbc4ea573a2d91,Replace deprecated numpy.ndarray.tostring() with tobytes(),1,Expression,,
c05bb4efcaf53d4cbc315ef6d12de822f2557a13,2018-08-22T10:13:37Z,https://github.com/tensorflow/tensorflow/commit/c05bb4efcaf53d4cbc315ef6d12de822f2557a13,CLN: replace safe_div method by div_no_nan,1,Expression,,
d4091eec522e41093e6e10601af79c75bee14c80,2017-12-22T23:50:19Z,https://github.com/tensorflow/tensorflow/commit/d4091eec522e41093e6e10601af79c75bee14c80,"Replaces custom _lengths_to_masks function with the official, more efficient sequence_mask function that supersedes it.PiperOrigin-RevId: 179971521",1,Expression,,
b4d5181fe674a9ab3a9decd38db08314ddf6b5a0,2017-02-03T16:57:42Z,https://github.com/tensorflow/tensorflow/commit/b4d5181fe674a9ab3a9decd38db08314ddf6b5a0,Refactors head to use metrics rather than metric spec and bunch of other cleanups.Change: 146479561,1,Expression,,
de8838042fb34e53a511f25b4613611fc368beeb,2016-08-19T17:38:28Z,https://github.com/tensorflow/tensorflow/commit/de8838042fb34e53a511f25b4613611fc368beeb,"Removes dependency from `image_ops` to `tf.contrib`.This change removes the import of `is_tensor()` function from`tf.contrib.framework...`, and replaces it with a more specificprivate function in image_ops.py.In general non-contrib code should not depend on contrib code.Change: 130767383",1,Expression,,
128d759bd31d4624387c89f544c478e2cbe306ca,2016-06-10T06:26:54Z,https://github.com/tensorflow/tensorflow/commit/128d759bd31d4624387c89f544c478e2cbe306ca,Refactor: use `is_tensor`,1,Expression,,
9f0f0adaabf1bc83edf06359482b169e6c5f4455,2022-03-30T18:59:10Z,https://github.com/keras-team/keras/commit/9f0f0adaabf1bc83edf06359482b169e6c5f4455,"Remove external calls to `_gather_saveables_for_checkpoint.`  Trackables are switching to using `_serialize_to_tensors` and `_restore_from_tensors`, so use this helper method for gathering saveables.  PiperOrigin-RevId: 438361482",1,Expression,,
af70910ffc1d8a3591bfea76728029e100e92a7b,2022-03-09T05:56:38Z,https://github.com/keras-team/keras/commit/af70910ffc1d8a3591bfea76728029e100e92a7b,Remove use of TrackableSaver in Keras.  These two calls are equivalent:  ``` saver = TrackableSaver(ObjectGraphView(obj)) saver.save(path) saver.restore(path) ```  ``` ckpt = tf.train.Checkpoint(root=obj) ckpt.write(path) ckpt.read(path) ``` PiperOrigin-RevId: 433390949,1,Expression,,
b0d33577387bb0397492d0ee0af5b0d15d7c8385,2021-08-20T23:33:48Z,https://github.com/keras-team/keras/commit/b0d33577387bb0397492d0ee0af5b0d15d7c8385,"Update keras RNG logic to use tf.random.Generator if possible.  This change also update the RNG behavior for initializer. The seeded initializer will no longer produce same random value across multiple calls. Instead, it will produce different value, and multiple initializer created with same seed will produce same sequences. This change will the make the seeded initializer behavior align between v1 and v2.  Keras was using stateful RNG op in various place when seed is not provided. The recommended approach in v2 is using tf.random.Generator which can be treat as a variable (seed) with stateless RNG op. This change make sure we use this new approach when seed is provided in v2, and also leave a flag to enforce the new approach, which has not been turn on yet. The new approach will be turned on when all the internal tests are fixed. V1 graph mode, the behavior is not change.  PiperOrigin-RevId: 392092094",1,Expression,,
9295efb21686b4ea5a55dfa1944c4e30bd27794e,2017-04-25T01:23:09Z,https://github.com/keras-team/keras/commit/9295efb21686b4ea5a55dfa1944c4e30bd27794e,Simplify the deep dream example,1,Expression,,
c81713367e3e97f13dd584ae8e48b79615951437,2017-02-24T01:49:05Z,https://github.com/keras-team/keras/commit/c81713367e3e97f13dd584ae8e48b79615951437,Refactor locally connected layer code.,1,Expression,,
c269e3cd8fed713fb54d2971319df0bfe6e1bf10,2022-10-07T23:05:45Z,https://github.com/keras-team/keras/commit/c269e3cd8fed713fb54d2971319df0bfe6e1bf10,Move serialization-related logic in utils/generic_utils.py to saving/legacy/serialization.py.  PiperOrigin-RevId: 479688207,1,Expression,,
192a11d49cae9dee6b978970aa1535de465b2469,2022-12-20T23:15:30Z,https://github.com/pytorch/pytorch/commit/192a11d49cae9dee6b978970aa1535de465b2469,refactor the dfs cyclic search from recursion to iterative approach (#91042)  Follow up on PR #86511  Python's 1000 limit on recursion depth is not practical for us to run cyclic check on larger graphs. This refactor avoids that issue. Pull Request resolved: https://github.com/pytorch/pytorch/pull/91042 Approved by: https://github.com/kit1980,1,Expression,,
35b6cdc2ebca2e6a7db980c0353809ee559950d6,2019-07-17T17:12:38Z,https://github.com/pytorch/pytorch/commit/35b6cdc2ebca2e6a7db980c0353809ee559950d6,"Rewriting hypothesis_utils (#22830)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/22830Separating the tensor generation and the generation of the quantization parameters- Introducing hypothesis filter `assume_not_overflowing`, which makes sure that the generated tensor and qparams play well with each other. **Note: This is an expensive filter!**- `qtensor` -> Renameed to `tensor`- `qtensor_conv` -> Renamed to `tensor_conv2d`- The tensors don't return the quantization parameters anymore, use `qparams` for it- The `dtypes` argument is just a quantized dtype now.- The enforcement for zero_point is predefined as before. As before, if set to `None` the zero_point will be sampled. However, if `None`, you can override sampling with `zero_point_min` and `zero_point_max`- Scale sampling can also be overriden using `scale_min` and `scale_max`Reviewed By: jerryzh168Differential Revision: D16234314fbshipit-source-id: 5b538a5aa9772b7add4f2ce5eff6fd0decd48f8e",1,Expression,API Refactoring,
4d753b50451607b3314f827993df7e5527f0c0a7,2023-02-20T07:28:04Z,https://github.com/pytorch/pytorch/commit/4d753b50451607b3314f827993df7e5527f0c0a7,"[WIP][dynamo] simplify module_key creation logic (#94945)  After some thoughts, I find it difficult to come up with a robust naming convention that satisfies the following constraints at the same time: 1. the new name should be a valid nn.Moule attribute (as required by minifier and it's a good thing to have in general) 2. it can cover various cases such as GetItemSource, GetAttrSource 3. it's easy to recover the original path 4. robust to users' naming scheme.  Thanks to @yanboliang for pointing out the original access path is preserved in Source, now we just need to add an additonal value source.name() to node.meta[""nn_module_stack""]  to get the access path in original module.  We also address some TODO in quantization, which relies on the original naming convention in nn_module_stack.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/94945 Approved by: https://github.com/jansel, https://github.com/yanboliang",1,Expression,,
4f50fdc2a35bad776d0353d42cd97f451dc52bde,2021-05-15T16:51:33Z,https://github.com/pytorch/pytorch/commit/4f50fdc2a35bad776d0353d42cd97f451dc52bde,"fx quant: refactor observer insertion  Summary: tl;dr; rewrites the FX graph mode quantization observer insertion to be easier to understand and extend. The key conceptual difference from before is: * before: for each node, observers are always inserted to the output of the current node, even if they are needed for the next node. This is hard to reason about. * after: for each node, observers are inserted to the inputs (if needed, as calculated by the dtype of the argument and dtype of current node) and to the output (if needed for the type of pattern and qconfig).  There is no knowledge of future nodes needed to insert observers for the current node.  This allows us to significantly simplify various things: * all new observers needed for a node are inserted together.  This makes it easier to understand and debug things.  We add an invariant that node X will never change any observers inserted by any preceding or subsequent node, so to debug an issue the user can just understand what is happening for node X, without having to understand what happens before or after it. * all the state tracking of activation_post_process_map and activation_post_process_indices are removed, instead observers are looked up by graph traversals * since there is no longer a need for overlapping graph passes which mutate each other's interemediate state, it is easier to understand what the rules are for inserting observers, and to create new rules in the future.  Test Plan: ``` # all OSS tests pass python test/test_quantization.py TestQuantizeFx python test/test_quantization.py TestQuantizeFxOps ```  Imported from OSS  Differential Revision: D28241864  Reviewed By: jerryzh168  Pulled By: vkuzo  fbshipit-source-id: 950d58972d26362808564cc0a2dfb30413a3734d",1,Expression,,
60cadd0bd185d02a08cb4a62c4d14a9da6255dee,2021-08-17T17:52:28Z,https://github.com/pytorch/pytorch/commit/60cadd0bd185d02a08cb4a62c4d14a9da6255dee,"[fx2trt] Refactor linear op to use mm + add  Summary: Previously linear is translated to fully_connected which only works when weight is a constant, this diff changes that to mm + add so that the weight can be an ITensor so that we can have the weight - quantize - dequantize pattern in the produced TensorRT network  Test Plan: buck run mode/opt caffe2/torch/fb/fx2trt:test_linear  Reviewed By: 842974287  Differential Revision: D30294751  fbshipit-source-id: 596fbd4c81caef8df41a002a2e14fbf22d9d2a80",1,Expression,,
86363e1d8e9625889fb5977730ae5ab893fb1ac5,2018-08-15T20:21:12Z,https://github.com/pytorch/pytorch/commit/86363e1d8e9625889fb5977730ae5ab893fb1ac5,"Move RNN implementations to C++ (#10481)Summary:This is the first of two changes that are supposed to improve how we handle RNNs in the JIT. They still get traced as `PythonOp`s, but now it will be much easier to actually expose them to the JIT as e.g. `aten::lstm`, and ignore the Python interpreter entirely. This needs some symbolic adjustments that will be part of a second PR.Even when we fix symbolics, there will still be a bit of a problem with statefulness of the cuDNN API (we need a mutable cache for the dropout state, but our IR has no way of representing that).zdevito ezyangPull Request resolved: https://github.com/pytorch/pytorch/pull/10481Reviewed By: ezyangDifferential Revision: D9341113Pulled By: apaszkefbshipit-source-id: 0ae30ead72a1b12044b7c12369d11e5ca8ec30b5",1,Expression,,
8b2a9f81cc7cab9cb49cd2c96b9304a3f9313fca,2023-05-20T03:34:20Z,https://github.com/pytorch/pytorch/commit/8b2a9f81cc7cab9cb49cd2c96b9304a3f9313fca,[dynamo] Minor refactor to use is_allowed to decide inlining of NNModule methods (#101910)  Fixes #101609  Pull Request resolved: https://github.com/pytorch/pytorch/pull/101910 Approved by: https://github.com/yanboliang,1,Expression,,
96487d0d1f638ae9c665dcd3d4b79e7e2a976f59,2023-05-14T19:03:16Z,https://github.com/pytorch/pytorch/commit/96487d0d1f638ae9c665dcd3d4b79e7e2a976f59,Refactor after_dynamo to have a CLI interface too. (#101220)  Signed-off-by: Edward Z. Yang <ezyang@meta.com>  Pull Request resolved: https://github.com/pytorch/pytorch/pull/101220 Approved by: https://github.com/anijain2305,1,Expression,,
a029422cae70b019222c00558da5437020550173,2021-06-18T20:31:43Z,https://github.com/pytorch/pytorch/commit/a029422cae70b019222c00558da5437020550173,"[quant][graphmode][fx][refactor] Change the env map to add dtype as a key (#60054)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/60054  Previously env in convert is Dict[str, Tuple[Node, torch.dtype]], that is, at a given time each node can only have one dtype, this causes a problem for the following case: ``` class M(torch.nn.Module):         def __init__(self):             super().__init__()             self.conv = nn.Conv2d(1, 1, 1)          def forward(self, x):             x = self.conv(x)             x1 = x.expand_as(x)             x2 = torch.add(x, x1)             return x2  def forward(self, x):     x = self.activation_post_process_0(x)     x = self.conv(x)     x = self.activation_post_process_1(x)     x1 = x.expand_as(x)     x1 = self.activation_post_process_2(x1)     x2 = torch.add(x, x1)     x2 = self.activation_post_process_3(x2)     return x2  def forward(self, x):     x = torch.quantize_per_tensor(x, ...)     x = self.conv(x). # quantized conv     x = torch.dequantize(x)     x1 = x.expand_as(x)     x1 = torch.quantize_per_tensor(x1, ...)     # Error: x is dequantized     x2 = torch.ops.quantized.add(x, x1)     return x2  Currently we have a env that is a map from node name of the observed graph to the Node in the quantized graph, here the problem is that following a quantized operator conv, we have two operators, one is expecting float input (expand_as), the other is expecting quantized input (quantized add), and in the quantized graph, ideally, expand_as should consume the dequantized output, and quantized add should consume the quantized output:  quantized_conv - dequantize - expand_as   \ ------- quantized_add  But currently in env, each node needs to either be quantized or not quantized. Therefore we will need to change env to include dtype as well: env: Dict[str, Dict[dtype, Node]], e.g. {‘x? {torch.float: dequantized_node, torch.quint8: quantized_node}} And when we load from the env, we will need to provide the dtype of the Node that we want to load as well. We can have a separate pass to figure out this information for each node. ```  Test Plan: python test/test_quantization.py TestQuantizeFx python test/test_quantization.py TestQuantizeFxOps  Imported from OSS  Reviewed By: vkuzo  Differential Revision: D29149408  fbshipit-source-id: c9e4b7d65444ab6a6f573929bae1db5037629892",1,Expression,,
b109083098541cda315473f0a389b07bdb70118d,2023-04-04T03:18:24Z,https://github.com/pytorch/pytorch/commit/b109083098541cda315473f0a389b07bdb70118d,[quant][pt2e][refactor] Remove `backend_config` from `_maybe_insert_input_observers_for_node` (#98094)  Summary: The goal is to remove the need to use backend_config when pt2e flow code call this function  Test Plan: python test/test_quantization.py TestQuantizeFx  Reviewers:  Subscribers:  Tasks:  Tags: Pull Request resolved: https://github.com/pytorch/pytorch/pull/98094 Approved by: https://github.com/jcaip,1,Expression,,
b59075eced1cfe3961deb1c57ab305f7eefded14,2021-03-04T03:17:28Z,https://github.com/pytorch/pytorch/commit/b59075eced1cfe3961deb1c57ab305f7eefded14,"[Gradient Compression] Refactor tensor grouping in PowerSGD (#52981)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/52981No need to create a hard boundary between rank-1 tensors and high-rank tensors, since some high-rank tensors will not be compressed if the compression cannot save enough bandwidth, according to `_should_compress` function.Therefore, refactor and simplify the tensor grouping logic, which addresses the comment in https://github.com/pytorch/pytorch/pull/52541#discussion_r580867311ghstack-source-id: 122997032Test Plan:waitforbuildbotAlready LGTMed by PowerSGD paper author.Ads1x (completed):https://www.internalfb.com/intern/tupperware/details/job/?handle=priv3_global%2Fmast_hpc%2Ftsm_hpc-wayi_ads_10x_POWER_SGD_gpu8_2021-02-28_15-29.trainer&tatwTabs=tasks&task_id=0&task_tab=TASK_LOGSDetectron2:1) Before refactoring:f254353864Accuracy: 39.972Overall training speed: 67498 iterations in 6:15:42 (0.3340 s / it)2) After refactoring:f254353380Accuracy: 39.944Overall training speed: 67498 iterations in 6:09:41 (0.3286 s / it)Reviewed By: rohan-varmaDifferential Revision: D26713689fbshipit-source-id: 12cfcb65feaa2a2d94e3c7793073031f13828305",1,Expression,,
d0bb8fdc64898229e2f695dee2812172325dd96b,2023-05-22T08:37:12Z,https://github.com/pytorch/pytorch/commit/d0bb8fdc64898229e2f695dee2812172325dd96b,"Revert ""[dynamo] Minor refactor to use is_allowed to decide inlining of NNModule methods (#101910)""  This reverts commit 8b2a9f81cc7cab9cb49cd2c96b9304a3f9313fca.  Reverted https://github.com/pytorch/pytorch/pull/101910 on behalf of https://github.com/DanilBaibak due to Break internal build ([comment](https://github.com/pytorch/pytorch/pull/101910#issuecomment-1556782524))",1,Expression,,
dca208b525653d64a6c89527975d1840e2cf6142,2017-05-02T01:52:58Z,https://github.com/pytorch/pytorch/commit/dca208b525653d64a6c89527975d1840e2cf6142,"Refactor test_sparse to reduce boilerplate. (#1421)* Refactor test_sparse to reduce boilerplate.Instead of manually creating a helper function, threading an is_cudaparameter around, and creating a test method for CUDA and non-CUDAvariants, we take a different approach:- There is now some new member variables initialized in setUp which  control the aspects of how we carry out the test; at the moment,  it's just whether or not we are using CUDA or not.  This means  you don't have to pass is_cuda around, or do a conditional to  get the triplet of constructors you need.  I'll note that I am not a big fan of member variables in test  objects, but these are (intended to be) immutable so I think  it should be OK.- Instead of manually defining test_foo and test_foo_cuda, we now  have a new TestCudaSparse class which overrides setUp (from above)  to swap in the CUDA implementation.  Way less boilerplate, and NO  metaprogramming needed.  If you need to opt out of CUDA testing, there is a new cpu_only  decorator you can use.Signed-off-by: Edward Z. Yang <ezyang@fb.com>",1,Expression,,
f45213a2765a8dc57c90e8c1496722a2236cfd68,2016-08-31T18:12:30Z,https://github.com/pytorch/pytorch/commit/f45213a2765a8dc57c90e8c1496722a2236cfd68,"Simplify nn.Container and nn.Sequential - nn.Container.modules is just a python list and used by nn.Sequential - Every module in nn.Sequential has a name. This fixes Module.type() - nn.Sequential constructor accepts either a list or an OrderedDict. With a   list, the modules are named ""0"", ""1"", ""2"", ...",1,Expression,,
f9446cb15ab7b76ff756d0e1b5993b062aa41714,2020-10-20T22:51:57Z,https://github.com/pytorch/pytorch/commit/f9446cb15ab7b76ff756d0e1b5993b062aa41714,[quant][refactor] Remove register api and rename get_*_mapping to get_default_*_mapping (#46337)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/46337We plan to pass around the mappings instead of using global registration api to keepthe mappings local to the transformations user is performingTest Plan: Imported from OSSReviewed By: vkuzoDifferential Revision: D24317436fbshipit-source-id: 81569b88f05eeeaa9595447e482a12827aeb961f,1,Expression,,
5dbb8f52dc5c9902503b0b686f25916321a0ebbd,2023-09-07T11:01:27Z,https://github.com/scikit-learn/scikit-learn/commit/5dbb8f52dc5c9902503b0b686f25916321a0ebbd,ENH replace loss module Gradient boosting (#26278),1,Expression,,
cb15a82e6439feda50b0605d70ce6d06c2eac7fd,2023-09-06T15:06:31Z,https://github.com/scikit-learn/scikit-learn/commit/cb15a82e6439feda50b0605d70ce6d06c2eac7fd,MAINT: Remove np.in1d and np.trapz usages (#27140)  Co-authored-by: Loïc Estève <loic.esteve@ymail.com>,1,Expression,,
1abc9ad7a61271f1a60c8c1cf7601aaa60ec8891,2023-09-06T07:16:55Z,https://github.com/scikit-learn/scikit-learn/commit/1abc9ad7a61271f1a60c8c1cf7601aaa60ec8891,MAINT replace obj and grad in sigmoid calibration with private loss module (#27185),1,Expression,,
789c0680f62970a00c9868ab38caea3e410e3a34,2023-04-27T09:26:03Z,https://github.com/scikit-learn/scikit-learn/commit/789c0680f62970a00c9868ab38caea3e410e3a34,MNT Remove deprecated pandas.api.types.is_sparse (#26287),1,Expression,,
a790c09fbab756c42b676c1f7d193d01956f35db,2023-04-13T11:44:26Z,https://github.com/scikit-learn/scikit-learn/commit/a790c09fbab756c42b676c1f7d193d01956f35db,MAINT remove deprecated is_categorical_dtype (#26156),1,Expression,,
f702e97907b69ebf47dc26398737fca7dd57faa2,2022-11-18T10:31:01Z,https://github.com/scikit-learn/scikit-learn/commit/f702e97907b69ebf47dc26398737fca7dd57faa2,MAINT: Replace np.find_common_type with np.result_type. (#24858),1,Expression,,
99262c06c02375ce9579638d0f37ee1ce61807c8,2022-03-18T20:14:07Z,https://github.com/scikit-learn/scikit-learn/commit/99262c06c02375ce9579638d0f37ee1ce61807c8,MNT remove sparse_lsqr from utils.fixes (#22894),1,Expression,,
a794c58692a1f3e7a85a42d8c7f7ddd5fcf18baa,2022-03-14T11:25:35Z,https://github.com/scikit-learn/scikit-learn/commit/a794c58692a1f3e7a85a42d8c7f7ddd5fcf18baa,MNT Replace if_delegate_has_method with available_if in ensemble and semi_supervised (#20545)  Co-authored-by: Guillaume Lemaitre <g.lemaitre58@gmail.com> Co-authored-by: Jérémie du Boisberranger <34657725+jeremiedbb@users.noreply.github.com>,1,Expression,,
f12987de98152659f9279b635ccf9c150597274a,2022-03-13T20:13:45Z,https://github.com/scikit-learn/scikit-learn/commit/f12987de98152659f9279b635ccf9c150597274a,MNT Replace if_delegate_has_method with available_if in feature_selection (#20593)  Co-authored-by: Guillaume Lemaitre <g.lemaitre58@gmail.com> Co-authored-by: Jérémie du Boisberranger <34657725+jeremiedbb@users.noreply.github.com>,1,Expression,,
9f96d42e3966ec0ac778132bf1192ba36f413006,2022-02-01T22:09:38Z,https://github.com/scikit-learn/scikit-learn/commit/9f96d42e3966ec0ac778132bf1192ba36f413006,ENH Replaced RandomState.rand with equivalent uniform (#22327),1,Expression,,
254ea8c453cd2100ade07644648f1f00392611a6,2022-01-28T20:49:34Z,https://github.com/scikit-learn/scikit-learn/commit/254ea8c453cd2100ade07644648f1f00392611a6,ENH Replaced RandomState with Generator compatible calls (#22271),1,Expression,,
4e974e0d5e0b9e4aeaf83ab5b2f6381c5e122c6f,2022-01-11T20:02:41Z,https://github.com/scikit-learn/scikit-learn/commit/4e974e0d5e0b9e4aeaf83ab5b2f6381c5e122c6f,ENH Replace loss module HGBT (#20811),1,Expression,,
02e2a113e6cc63854f08349e054d4a3b3e045cb4,2021-04-09T10:04:54Z,https://github.com/scikit-learn/scikit-learn/commit/02e2a113e6cc63854f08349e054d4a3b3e045cb4,"TST replace assert_raises by pytest.raises in test_least_angle, test_omp, test_test_theil_sen (#19406)  Co-authored-by: Olivier Grisel <olivier.grisel@gmail.com> Co-authored-by: Olivier Grisel <olivier.grisel@ensta.org> Co-authored-by: Guillaume Lemaitre <g.lemaitre58@gmail.com> Co-authored-by: Chiara Marmo <cmarmo@users.noreply.github.com>",1,Expression,,
114616d9f6ce9eba7c1aacd3d4a254f868010e25,2021-03-23T17:09:05Z,https://github.com/scikit-learn/scikit-learn/commit/114616d9f6ce9eba7c1aacd3d4a254f868010e25,TST Replace assert_warns in covariance/tests (#19757),1,Expression,,
f2773e840a0fcc9dd673cdd0da82dc43299a713b,2021-03-08T18:03:56Z,https://github.com/scikit-learn/scikit-learn/commit/f2773e840a0fcc9dd673cdd0da82dc43299a713b,TST replace assert_raise_* by pytest.raises in tests/test_multioutput.py (#19618)  Co-authored-by: Alihan Zihna <a.zihna@ckhgbdp.onmicrosoft.com>,1,Expression,,
5c0bbb0a4a4e674ba8017e3cdc664e0b7c7c8dc0,2021-03-02T11:14:26Z,https://github.com/scikit-learn/scikit-learn/commit/5c0bbb0a4a4e674ba8017e3cdc664e0b7c7c8dc0,TST replaces assert_raise* by pytest.raises in model_selection (#19592)  Co-authored-by: Cycks <sikolia.wycliffe@gmail.com>,1,Expression,,
72db93cc40884f42e05e4290d6ab63713d0075c9,2021-03-01T17:07:56Z,https://github.com/scikit-learn/scikit-learn/commit/72db93cc40884f42e05e4290d6ab63713d0075c9,TST replaces assert_raises* by pytest.raises in model_selection/tests/test_split.py (#19585)  Co-authored-by: Cycks <sikolia.wycliffe@gmail.com>,1,Expression,,
0df7abfc87fd7aa875d0ee5ad133c455b2ded423,2021-02-27T15:01:46Z,https://github.com/scikit-learn/scikit-learn/commit/0df7abfc87fd7aa875d0ee5ad133c455b2ded423,TST replace asert_warns by pytest.warns in compose/tests (#19492)  Co-authored-by: Olivier Grisel <olivier.grisel@gmail.com> Co-authored-by: Olivier Grisel <olivier.grisel@ensta.org>,1,Expression,,
1000d0a61be311542e01d56f6745178307406395,2021-02-22T15:25:34Z,https://github.com/scikit-learn/scikit-learn/commit/1000d0a61be311542e01d56f6745178307406395,TST replace assert_raise with pytest.raises in test_base.py (#19500)  Co-authored-by: Alihan Zihna <a.zihna@ckhgbdp.onmicrosoft.com>,1,Expression,,
c3eb5eda0fe08d3c0341031a23211b89721ae3a8,2021-02-22T08:54:31Z,https://github.com/scikit-learn/scikit-learn/commit/c3eb5eda0fe08d3c0341031a23211b89721ae3a8,TST replace assert_raise_* by pytest.raises in neighbors module (#19388)  Co-authored-by: SteveKola <kolawolesteven99@gmail.com> Co-authored-by: Olivier Grisel <olivier.grisel@ensta.org>,1,Expression,,
b5e55f79fdfcb0f41f0cfb279e54a123822bca43,2021-02-19T10:44:09Z,https://github.com/scikit-learn/scikit-learn/commit/b5e55f79fdfcb0f41f0cfb279e54a123822bca43,TST replace assert_warns* by pytest.warns in model_selection/tests (#19458),1,Expression,,
321799971be8ede64d4603c93687becd5701d30f,2021-02-18T15:50:27Z,https://github.com/scikit-learn/scikit-learn/commit/321799971be8ede64d4603c93687becd5701d30f,TST Replace the use of assert_warns messages in cluster/tests/ module (#19437),1,Expression,,
cc13313b26852169dff3fdf80c40008c233ce40f,2021-02-18T15:43:54Z,https://github.com/scikit-learn/scikit-learn/commit/cc13313b26852169dff3fdf80c40008c233ce40f,TST remove assert_warns in feature_extraction/tests/ module (#19439),1,Expression,,
dac560551c5767d9a8608f86e3f253e706026189,2021-02-12T19:52:23Z,https://github.com/scikit-learn/scikit-learn/commit/dac560551c5767d9a8608f86e3f253e706026189,TST replace assert_raise_* by pytest.raises in linear_model (#19440),1,Expression,,
c61dcff5118a6cbd984c5e53bd3ae22628b3ba8a,2021-02-11T13:16:55Z,https://github.com/scikit-learn/scikit-learn/commit/c61dcff5118a6cbd984c5e53bd3ae22628b3ba8a,TST replace assert_raise_* by pytest.raises in ensemble module (#19399)  Co-authored-by: feras-oughali <oughali.feras@gmail.com> Co-authored-by: hassanalsawadi <alsawadi.h@mozn.sa> Co-authored-by: Guillaume Lemaitre <g.lemaitre58@gmail.com>,1,Expression,,
a8d6361fe0dea3b313cd7621a7c75c4b24a974f5,2021-02-11T10:45:44Z,https://github.com/scikit-learn/scikit-learn/commit/a8d6361fe0dea3b313cd7621a7c75c4b24a974f5,TST replace assert_warns* by pytest.warns in module svm/tests (#19424)  Co-authored-by: Shivam <shivam@ellipsishealth.com> Co-authored-by: Guillaume Lemaitre <g.lemaitre58@gmail.com>,1,Expression,,
7f5ee92beddb6f56fcc633d142718bcf0a4bb735,2021-02-11T10:45:15Z,https://github.com/scikit-learn/scikit-learn/commit/7f5ee92beddb6f56fcc633d142718bcf0a4bb735,TST replace assert_warns* by pytest.warns in ensemble/tests (#19425)  Co-authored-by: Guillaume Lemaitre <g.lemaitre58@gmail.com>,1,Expression,,
bd67f12b07c3532436dc61d09a8461fba69ac7b4,2021-02-07T11:04:56Z,https://github.com/scikit-learn/scikit-learn/commit/bd67f12b07c3532436dc61d09a8461fba69ac7b4,TST replace assert_raises with the pytest.raises context manager in dummy module (#19372),1,Expression,,
e230778f6f1f24de1aa694b52fa9411a1e5c3197,2021-02-07T10:14:30Z,https://github.com/scikit-learn/scikit-learn/commit/e230778f6f1f24de1aa694b52fa9411a1e5c3197,TST replace assert_raises* by pytest.raises in dummy module (#19386),1,Expression,,
a952fbb10e9be8ebe3ca2ff60bf458f51ab2a721,2021-02-06T10:52:14Z,https://github.com/scikit-learn/scikit-learn/commit/a952fbb10e9be8ebe3ca2ff60bf458f51ab2a721,MAINT Remove the use of assert_raises* in model_selection/tests/test_search (#19371),1,Expression,,
88be2abb7b7f7450dc569e0065e672a0676e4130,2021-01-31T00:52:16Z,https://github.com/scikit-learn/scikit-learn/commit/88be2abb7b7f7450dc569e0065e672a0676e4130,Simplify computation of radius to match BIRCH more closely (#19251)  Co-authored-by: Olivier Grisel <olivier.grisel@ensta.org>,1,Expression,,
cb49ad475155ed482829bb1a0278a5e19b9ca17c,2020-04-19T00:14:22Z,https://github.com/scikit-learn/scikit-learn/commit/cb49ad475155ed482829bb1a0278a5e19b9ca17c,MNT removed _safe_tags utility (#16950),1,Expression,,
a5b689429d519038ed9de07c13cdbde7b83c767e,2020-01-28T06:30:19Z,https://github.com/scikit-learn/scikit-learn/commit/a5b689429d519038ed9de07c13cdbde7b83c767e,MAINT/EXA replaced deprecated NavigationToolbar2TkAgg (#16187),1,Expression,,
12196dab9b1b42f7526eedb6b7b18e04cd3286d2,2019-11-20T08:12:53Z,https://github.com/scikit-learn/scikit-learn/commit/12196dab9b1b42f7526eedb6b7b18e04cd3286d2,"MNT replaced check_consistent_length, etc with _check_sample_weight in BaseGradientBoosting (#15478)",1,Expression,,
fa98a72dcca91920e5e807fdc1ce5b54486ad652,2018-11-28T01:16:26Z,https://github.com/scikit-learn/scikit-learn/commit/fa98a72dcca91920e5e807fdc1ce5b54486ad652,MNT Replaced all occurrences of assert_true and assert_false with assert (#12588),1,Expression,,
6f9a8dfd54bbd77b13962bb1e2b207197f4f2918,2018-07-04T23:13:48Z,https://github.com/scikit-learn/scikit-learn/commit/6f9a8dfd54bbd77b13962bb1e2b207197f4f2918,MNT replace log with log1p (#11424),1,Expression,,
3dab1c4fcc2e34aff69e2c2361620e982820fce4,2018-04-03T13:15:53Z,https://github.com/scikit-learn/scikit-learn/commit/3dab1c4fcc2e34aff69e2c2361620e982820fce4,Replace inner1d by standard numpy constructs. (#10880)  numpy.core.umath_tests has been moved to private modules in numpy 1.15.0.dev.,1,Expression,,
0c2264da191e03a82e6ce0f95e66738b9f42a9c4,2016-09-19T10:46:42Z,https://github.com/scikit-learn/scikit-learn/commit/0c2264da191e03a82e6ce0f95e66738b9f42a9c4,replace RandomizedPCA by new API in remaining documentation,1,Expression,,
f69f895eee47a88a4f3b1201961c5ba9c55dd831,2015-10-24T06:18:29Z,https://github.com/scikit-learn/scikit-learn/commit/f69f895eee47a88a4f3b1201961c5ba9c55dd831,remove _balance_weights,1,Expression,,
7fe71c18ab3d542a396c9fb33a6ced81b3cc0ca9,2015-10-21T19:37:24Z,https://github.com/scikit-learn/scikit-learn/commit/7fe71c18ab3d542a396c9fb33a6ced81b3cc0ca9,as_float_array removed,1,Expression,,
752b6b86a9c7f7557db13b7e888a41fb9ae2e525,2015-10-19T16:04:55Z,https://github.com/scikit-learn/scikit-learn/commit/752b6b86a9c7f7557db13b7e888a41fb9ae2e525,TST Replace call to deepcopy() by clone(),1,Expression,,
f75c98b872d6aa70c158211f2179e90b0f649b4b,2015-02-01T02:27:29Z,https://github.com/scikit-learn/scikit-learn/commit/f75c98b872d6aa70c158211f2179e90b0f649b4b,refactor forests & trees class_weight calc,1,Expression,,
b088c2add71e27954f97e950ec4ce1dc283ca008,2014-07-22T14:57:40Z,https://github.com/scikit-learn/scikit-learn/commit/b088c2add71e27954f97e950ec4ce1dc283ca008,Replaced helper function _phi by special.expit,1,Expression,,
24af95a211086cf032d263e0f2ed57b63e06c2f4,2013-10-12T18:27:51Z,https://github.com/scikit-learn/scikit-learn/commit/24af95a211086cf032d263e0f2ed57b63e06c2f4,"ENH refactor squared-norms computation to extmath  k-means can now use the memory-efficient dense implementation from metrics.pairwise, while pairwise can use the fast sparse implementation from k-means.",1,Expression,,
5a320d703b1585aa6477fba1ecd1a35ad75fd6c4,2012-09-08T21:08:07Z,https://github.com/scikit-learn/scikit-learn/commit/5a320d703b1585aa6477fba1ecd1a35ad75fd6c4,COSMIT replace useless safe_sparse_dot in chi2 with np.dot,1,Expression,,
0f96c26de6171a996094a00d2126575c0a457fba,2023-02-16T16:32:32Z,https://github.com/huggingface/transformers/commit/0f96c26de6171a996094a00d2126575c0a457fba,refactor: Make direct_transformers_import util (#21652)  * refactor: Make direct_import util  * edit direct import fn  * add docstring  * make import function specific to transformers only  * edit doc string,1,Expression,,
5f2791c7c1f69992aa75ed81bc8818803ac21788,2021-07-15T16:59:48Z,https://github.com/huggingface/transformers/commit/5f2791c7c1f69992aa75ed81bc8818803ac21788,Replace specific tokenizer in log message by AutoTokenizer (#12745),1,Expression,,
47ca0eaaac5b993da1a22e190f8c938aa647d73b,2021-01-04T18:00:08Z,https://github.com/huggingface/transformers/commit/47ca0eaaac5b993da1a22e190f8c938aa647d73b,replace apex.normalization.FusedLayerNorm with torch.nn.LayerNorm (#9386),1,Expression,,
dbbd6c7500dded778706326c7a1e402cffe97eb8,2019-04-12T14:07:58Z,https://github.com/huggingface/transformers/commit/dbbd6c7500dded778706326c7a1e402cffe97eb8,"Replaced some randints with cleaner randranges, and added a helpful error for users whose corpus is just one giant document.",1,Expression,,
c991e30c96ace1565604b429de22e36ed6b1e7bd,2023-03-09T15:38:29Z,https://github.com/scikit-learn/scikit-learn/commit/c991e30c96ace1565604b429de22e36ed6b1e7bd,ENH simplify alpha_grid expression for ElasticNetCV (#25794),1,Simplify Logic,,
7cc0177f8e8e958b6291433274a07cc67f933985,2020-06-24T14:51:51Z,https://github.com/scikit-learn/scikit-learn/commit/7cc0177f8e8e958b6291433274a07cc67f933985,MNT Replaces numpy alias with builtin typse (#17687)  * MNT Replaces numpy alias with builtin typse  * STY Lint error,1,Simplify Logic,,
c3835442e50077d32b1b5f9771e7c6b7b999bbfc,2020-06-09T09:10:31Z,https://github.com/scikit-learn/scikit-learn/commit/c3835442e50077d32b1b5f9771e7c6b7b999bbfc,remove int() (#17539),1,Simplify Logic,,
c393bdc6dde1e2826002a6d2529f068a8376a7e9,2019-12-26T12:02:31Z,https://github.com/scikit-learn/scikit-learn/commit/c393bdc6dde1e2826002a6d2529f068a8376a7e9,EXA/MAINT Simplify code in manifold learning example (#15949),1,Simplify Logic,,
f80180564bd5c7dbd91c38d4bad81deb1808020c,2019-10-18T18:04:00Z,https://github.com/scikit-learn/scikit-learn/commit/f80180564bd5c7dbd91c38d4bad81deb1808020c,MNT Simplify module deprecation procedures with automatic tests (#15294),1,Simplify Logic,,
d508c22e78d3a2f139f6a579f1c43ade71ab20e0,2019-04-23T13:55:44Z,https://github.com/scikit-learn/scikit-learn/commit/d508c22e78d3a2f139f6a579f1c43ade71ab20e0,MNT Minor clean up in OneVsRestClassifier (#13675),1,Simplify Logic,,
a547311b5faae0809b8935e1f1d00ff901109f84,2019-03-01T00:32:57Z,https://github.com/scikit-learn/scikit-learn/commit/a547311b5faae0809b8935e1f1d00ff901109f84,MNT Replace externals.six.integer_types with int (#13342),1,Simplify Logic,,
89f5488c6a6d286a4d058e6f54ef96e4375d9901,2019-02-13T11:54:41Z,https://github.com/scikit-learn/scikit-learn/commit/89f5488c6a6d286a4d058e6f54ef96e4375d9901,MNT Remove useless operation in feature_importance_ (#13155),1,Simplify Logic,,
d300f406aeeac439b4212558f208ce5a9613a1d5,2019-01-10T21:27:06Z,https://github.com/scikit-learn/scikit-learn/commit/d300f406aeeac439b4212558f208ce5a9613a1d5,MAINT Simplify super() calls (#12812),1,Simplify Logic,,
362cb3bcabad2ec5d9d0c29ea1ec69558a64d76b,2018-11-11T01:05:34Z,https://github.com/scikit-learn/scikit-learn/commit/362cb3bcabad2ec5d9d0c29ea1ec69558a64d76b,TST autoreplace assert_true(...==...) with plain assert (#12547),1,Simplify Logic,,
0a7a1db8c7ebd01c98e26289dd89b5e1d707630f,2015-09-16T22:24:29Z,https://github.com/scikit-learn/scikit-learn/commit/0a7a1db8c7ebd01c98e26289dd89b5e1d707630f,removed list around sorted,1,Simplify Logic,,
6a3365d67d7bc5a779289145fd3c58f21a217282,2015-05-21T10:51:08Z,https://github.com/scikit-learn/scikit-learn/commit/6a3365d67d7bc5a779289145fd3c58f21a217282,ENH use astype to avoid unnecessary copy,1,Simplify Logic,,
54d68d247f902c54ed63a656d41e22943bfcdf67,2015-02-03T02:37:25Z,https://github.com/scikit-learn/scikit-learn/commit/54d68d247f902c54ed63a656d41e22943bfcdf67,remove inplace multiplication in ridge,1,Simplify Logic,,
ec663e6cf0ba1e9c70c68642c31b7b30230afc6f,2014-10-13T11:44:15Z,https://github.com/scikit-learn/scikit-learn/commit/ec663e6cf0ba1e9c70c68642c31b7b30230afc6f,COSMIT: Another slicing syntax cleanup,1,Simplify Logic,,
222cb87af1a4e94f8f1bf2b56225375bb6051c7f,2014-08-05T19:31:07Z,https://github.com/scikit-learn/scikit-learn/commit/222cb87af1a4e94f8f1bf2b56225375bb6051c7f,Remove outer for loop in dense case predict,1,Simplify Logic,,
b80b0ea2d31a31f2252e7a7fcdd7f6569ece9af4,2014-03-02T11:07:02Z,https://github.com/scikit-learn/scikit-learn/commit/b80b0ea2d31a31f2252e7a7fcdd7f6569ece9af4,STY Simplify and avoided numpy warnings in imputation,1,Simplify Logic,,
551625fad7d3371f667995a12a33db7f48b17e7d,2013-10-13T22:15:31Z,https://github.com/scikit-learn/scikit-learn/commit/551625fad7d3371f667995a12a33db7f48b17e7d,"MAINT simplify f_oneway in feature selection  reduce(lambda x, y: x + y, s) == sum(s), always.",1,Simplify Logic,,
c7c4d53d84f6e3e4bbd80c623061c9a90e8c0464,2013-01-07T14:31:05Z,https://github.com/scikit-learn/scikit-learn/commit/c7c4d53d84f6e3e4bbd80c623061c9a90e8c0464,COSMIT simplify unique_labels in sklearn.metrics,1,Simplify Logic,,
b2e6e19e4d175dd56e91cedf1848044148c11654,2012-08-29T20:26:23Z,https://github.com/scikit-learn/scikit-learn/commit/b2e6e19e4d175dd56e91cedf1848044148c11654,Minor cleanup of StratifiedShuffleSplit,1,Simplify Logic,,
f5de79a91cf6e954774f6c4b9827c243dbb9e242,2012-03-27T08:40:50Z,https://github.com/scikit-learn/scikit-learn/commit/f5de79a91cf6e954774f6c4b9827c243dbb9e242,Removed unneeded numpy.array call in test Added NearestCentroid to 20 newsgroups example,1,Simplify Logic,,
7b81afdebaa227ed9c151f173bec290fe59a0a74,2011-09-06T13:43:35Z,https://github.com/scikit-learn/scikit-learn/commit/7b81afdebaa227ed9c151f173bec290fe59a0a74,ENH: `np.fill_diagonal` replaced with more portable code. Added an explanatory comment.,1,Simplify Logic,,
c1bacaef2482a64b260b8418fe648a5f551198f6,2011-07-29T23:00:16Z,https://github.com/scikit-learn/scikit-learn/commit/c1bacaef2482a64b260b8418fe648a5f551198f6,more clarity,1,Simplify Logic,,
42a891e3e0424963636336e6090966aea09f0ccb,2011-04-05T23:15:45Z,https://github.com/scikit-learn/scikit-learn/commit/42a891e3e0424963636336e6090966aea09f0ccb,ENH: More accurate and clean numeric code in PCA,1,Simplify Logic,,
96cc02b51b60b71bce2ca38e23f8e1f920b6c626,2021-12-02T13:13:42Z,https://github.com/huggingface/transformers/commit/96cc02b51b60b71bce2ca38e23f8e1f920b6c626,change tf.math.divide with int(/) to remove dim_per_head from the TF graph (#14600)  Co-authored-by: yis <yis@graphcore.ai>,1,Simplify Logic,,
9261c7f771fccfa2a2cb78ae544adef2f6eb402b,2020-01-07T10:46:44Z,https://github.com/huggingface/transformers/commit/9261c7f771fccfa2a2cb78ae544adef2f6eb402b,Remove f-string device creation on PyTorch GPU pipelines.  Signed-off-by: Morgan Funtowicz <morgan@huggingface.co>,1,Simplify Logic,,
901e9b8eda2fe88af717f960ddc05cac1803679b,2020-10-22T14:41:41Z,https://github.com/huggingface/transformers/commit/901e9b8eda2fe88af717f960ddc05cac1803679b,Remove the else branch adding 0 to the hidden state if token_type_embeds is None. (#7977)  Signed-off-by: Morgan Funtowicz <funtowiczmo@gmail.com>,1,Separate Statement,,
365ccd0af20586aac9ca5312995584981db4dae4,2019-12-25T22:17:24Z,https://github.com/huggingface/transformers/commit/365ccd0af20586aac9ca5312995584981db4dae4,make if statements cleaner for prepare_inputs_for_generation,1,Separate Statement,,
3b1fdd9c822c2724c6141bb923923986ec6f8ed6,2016-09-21T19:46:35Z,https://github.com/tensorflow/tensorflow/commit/3b1fdd9c822c2724c6141bb923923986ec6f8ed6,Refactor DNNClassifier implementation from inheritance to composition.Change: 133862709,1,Replace Subclass with Delegate,,
c07399cef4bc60cb1d5b71cb5fb421dbf6ec1496,2016-08-30T16:45:48Z,https://github.com/tensorflow/tensorflow/commit/c07399cef4bc60cb1d5b71cb5fb421dbf6ec1496,Refactor LinearClassifier implementation from inheritance to composition.Change: 131719982,1,Replace Subclass with Delegate,,
bcd4b72897f520a5dba07b2d25c485afd09da9fb,2015-10-19T16:07:11Z,https://github.com/scikit-learn/scikit-learn/commit/bcd4b72897f520a5dba07b2d25c485afd09da9fb,REFACTOR Remove theta_ attribute from GPR and GPC  It can be accessed instead via kernel_.theta,1,Replace Primitive with Object,,
3e8ca8cad698ee76c73d28b6b04c5b872af491c0,2014-03-09T11:55:54Z,https://github.com/scikit-learn/scikit-learn/commit/3e8ca8cad698ee76c73d28b6b04c5b872af491c0,Vectorization of theilsen._modweiszfeld_step  Replaced the for-loop in linear_model.theilsen._modweiszfeld_step by array operations as suggested by jnothman,1,Replace Loop with Pipeline,,
29bdb88368e319acb0cbe145021427d37a3507c9,2020-11-20T18:59:06Z,https://github.com/huggingface/transformers/commit/29bdb88368e319acb0cbe145021427d37a3507c9,Vectorize RepetitionPenaltyLogitsProcessor to improve performance (#8598)  * refactored exisiting nested loops to vectorized implementation  * replaced explicit indexing with torch.where  * modifying score for previous input_ids only,1,Replace Loop with Pipeline,,
93e63459afbffc2d2b09a253762b186595073680,2019-07-29T18:04:46Z,https://github.com/tensorflow/tensorflow/commit/93e63459afbffc2d2b09a253762b186595073680,Removed explicit context._context assignment in .../eager:ops_testPiperOrigin-RevId: 260537267,1,Replace Inline Code with Function Call,,
011c1faeb4429cd9ae4332a32be662254b706688,2017-02-11T01:04:30Z,https://github.com/keras-team/keras/commit/011c1faeb4429cd9ae4332a32be662254b706688,Learning_phase refactoring.,1,Replace Inline Code with Function Call,Rename Variable,
59648f337bd75eca955d442526aa8cf993458421,2015-01-24T15:16:45Z,https://github.com/scikit-learn/scikit-learn/commit/59648f337bd75eca955d442526aa8cf993458421,Simplify rescaling.,1,Replace Inline Code with Function Call,,
58cca47c16149e43d1b516623d59e3c5d97f695e,2020-07-03T18:27:49Z,https://github.com/huggingface/transformers/commit/58cca47c16149e43d1b516623d59e3c5d97f695e,[cleanup] TF T5 tests only init t5-base once. (#5410),1,Replace Exception with Assert,,
3ee88c592939029e4db28d42e5c2d24cc3106fa9,2022-01-21T00:23:59Z,https://github.com/keras-team/keras/commit/3ee88c592939029e4db28d42e5c2d24cc3106fa9,"Create a class that delegates LossScaleOptimizer creation to the right subclass depending on the inner optimizer's type.  To avoid name confusion and massive code changes, we are creating a BaseLossScaleOptimizer class that delegates object creation to LSO or LSOV3 based on the type of inner optimizer. The BaseLossScaleOptimizer will be exported as tf.keras.mixed_precision.LossScaleOptimizer so that type check on tf.keras.mixed_precision.LossScaleOptimizer would pass for both LossScaleOptimizer and LossScaleOptimizerV3.  PiperOrigin-RevId: 423184717",1,Replace Constructor with Factory Method,,
b746fed16482a4f11f0fdaa514fda807e138ff7f,2021-08-11T18:15:57Z,https://github.com/pytorch/pytorch/commit/b746fed16482a4f11f0fdaa514fda807e138ff7f,[Pytorch Edge] Move RuntimeCompatibilityInfo Factory Method (#63005)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/63005  Realized I forgot to move the Runtime half of these functions be within the struct.  Test Plan: ci  Reviewed By: pavithranrao  Differential Revision: D30205521  fbshipit-source-id: ccd87d7d78450dd0dd23ba493bbb9d87be4640a5,1,Replace Constructor with Factory Function,,
ea0927b2523e1e684f7064e8f0289d6e81456a67,2021-12-22T19:31:13Z,https://github.com/keras-team/keras/commit/ea0927b2523e1e684f7064e8f0289d6e81456a67,Keras Metric: Override default behavior of `Metric.__deepcopy__()` so `update_state` is invoked on the right instance.  PiperOrigin-RevId: 417856176,1,Replace Conditional with Polymorphism,,
c9daa18100c5f11e90c55609602d9ba75673a7da,2021-02-04T19:12:52Z,https://github.com/keras-team/keras/commit/c9daa18100c5f11e90c55609602d9ba75673a7da,Use distribute_utils.is_distributed_variable instead checking the class  This is part of the effort to refactor distributed variable. This makes the refactor transparent to mixed_precision.  PiperOrigin-RevId: 355668004,1,Replace Conditional with Polymorphism,,
e0fefdae0cae9c97f318fca9717467f7faf071d9,2017-08-07T00:11:37Z,https://github.com/keras-team/keras/commit/e0fefdae0cae9c97f318fca9717467f7faf071d9,refactor the function - _convert_string_dtype (#7540),1,Replace Conditional with Polymorphism,Extract Variable,
2a5c22a6aa615b2f69322458d82939aba4b6f55c,2020-05-06T17:29:31Z,https://github.com/scikit-learn/scikit-learn/commit/2a5c22a6aa615b2f69322458d82939aba4b6f55c,Delegate choice of final model to sub class in LinearModelCV  (#17099)  * init  * flake8 error by vscode autoformatting  * remove returns  * get_model > get_estimator  * cosmit Tom + autoformat on save error again,1,Replace Conditional with Polymorphism,,
01c40db4f8d814f8069a32581644181e29402d38,2020-07-20T14:44:10Z,https://github.com/huggingface/transformers/commit/01c40db4f8d814f8069a32581644181e29402d38,[cleanup] squad processor (#5868),1,Replace Conditional with Method,,
d40656e5799dfd22e96b8bab217638b2934a6894,2018-07-19T15:48:43Z,https://github.com/keras-team/keras/commit/d40656e5799dfd22e96b8bab217638b2934a6894,Refactoring: Used the function `normalize_data_format` to remove some code. (#10690)  * Used the function `normalize_data_format` to remove some code. Moved the implementation to keras/backend/common.py.  * Changed all conv_utils.normalize_data_format into K.normalize_data_format,1,Replace Conditional with Function Call,,
d18c564548104c862892a1f73423e333f11f7ce2,2018-07-18T17:59:14Z,https://github.com/keras-team/keras/commit/d18c564548104c862892a1f73423e333f11f7ce2,Refactoring: Simplified some if-else by creating a function similar to `to_list`. (#10679)  * Refactoring: Simplified some if-else by creating a function similar to `to_list`.  * Changed the name and the description of `first_or_list`.,1,Replace Conditional with Function Call,,
c8df8f147158d012245de8c0fc062401507df4ad,2020-08-29T01:46:11Z,https://github.com/tensorflow/tensorflow/commit/c8df8f147158d012245de8c0fc062401507df4ad,PSv2: Replace an assert with a more informative ValueError.PiperOrigin-RevId: 329046260Change-Id: Ifdad03e35b12dfbbd70feedcd9f96f9e20b202d2,1,Replace Assert with Exception,,
73e2faa6c2fe087b450e4e52debfa6321b9b0abd,2022-11-29T16:34:08Z,https://github.com/huggingface/transformers/commit/73e2faa6c2fe087b450e4e52debfa6321b9b0abd,Replace assert statements with raise exceptions (#20478)  * replace assert statements with exceptions  * made conditions more readable,1,Replace Assert with Exception,,
667ccea72235504ab7876024e4f8c113ca62190f,2022-11-28T15:06:25Z,https://github.com/huggingface/transformers/commit/667ccea72235504ab7876024e4f8c113ca62190f,Replace assertion with ValueError exceptions in run_image_captioning_flax.py (#20365)  * replace 4 asserts with ValueError exception for control flow  * Update examples/flax/image-captioning/run_image_captioning_flax.py  Co-authored-by: Sanchit Gandhi <93869735+sanchit-gandhi@users.noreply.github.com>  * Update examples/flax/image-captioning/run_image_captioning_flax.py  Co-authored-by: Sanchit Gandhi <93869735+sanchit-gandhi@users.noreply.github.com>  * reformatted file  * uninstalled trasformers and applied make style  Co-authored-by: Bibi <Bibi@katies-mac.local> Co-authored-by: Sanchit Gandhi <93869735+sanchit-gandhi@users.noreply.github.com>,1,Replace Assert with Exception,,
98122794d45b124b7e9ef75d58686a4f156156bd,2022-11-28T14:44:03Z,https://github.com/huggingface/transformers/commit/98122794d45b124b7e9ef75d58686a4f156156bd,Replace assertions with value errors on distilbert model (#20463)  * Changed assert into 7-8 exceptions  * updated syntax error  * updated error  * updated file (Co-autho: Batese2001)  * Successful test on test_modeling_distilbert.py   Successful raising errors and exceptions on the revised code in test_modeling_distilbert.py .  Co-credit: @batese2001  * Delete test_modeling_distilbert.ipynb  * Update modeling_distilbert.py  * Successful raising of exceptions with the conditions that are contrary to defined condition that asserts statements (Co-author: Batese2001)  * Successful raising of exceptions with the conditions that are contrary to defined condition that asserts statements (Co-author: Batese2001)  * committing the reformatted distilbert model  * reformatted distilbert model  * reformatted distilbert model  * reformatted distilbert model  * reformatted distilbert model with black  * Changed comments that explain better about raising exceptions for not having the even number of multi heads  * Changed comments that explain better about raising exceptions for not having the even number of multi heads  * changed based on the feedback  * Changed line 833 based on the suggestion made from @younesbelkada  * Changed line 833 based on the suggestion made from @younesbelkada draft2  * reformatted file  * Update src/transformers/models/distilbert/modeling_distilbert.py  * Update src/transformers/models/distilbert/modeling_distilbert.py  Co-authored-by: Younes Belkada <49240599+younesbelkada@users.noreply.github.com>,1,Replace Assert with Exception,,
04cddaf402591e9f5bdb5f116a111d829a0ce4f4,2021-12-29T15:09:54Z,https://github.com/huggingface/transformers/commit/04cddaf402591e9f5bdb5f116a111d829a0ce4f4,refactor: replace `assert` with `ValueError` (#14970),1,Replace Assert with Exception,,
4469010c1be3a94f74d6448497051468f617baf2,2021-10-28T21:17:43Z,https://github.com/huggingface/transformers/commit/4469010c1be3a94f74d6448497051468f617baf2,Replace assertions with RuntimeError exceptions (#14186),1,Replace Assert with Exception,,
e5b8ffb848024a709f796180de9adca5c3233440,2021-10-27T16:19:10Z,https://github.com/huggingface/transformers/commit/e5b8ffb848024a709f796180de9adca5c3233440,Replace assert of data/data_collator.py by ValueError (#14131)  * Replace assert of data_collator.py by ValueError  * Replace assert of data_collator.py by ValueError,1,Replace Assert with Exception,,
ebd48c6de544e22dd4c5743fb27039bf24b811e1,2021-10-26T21:14:29Z,https://github.com/huggingface/transformers/commit/ebd48c6de544e22dd4c5743fb27039bf24b811e1,Replace assertions with ValueError exception (#14142)  Updated masked-language modeling examples in pytorch with convention defined by #12789,1,Replace Assert with Exception,,
9f3aa46f45d10fde9c8b1514eaa383b69e78c180,2021-10-26T16:59:58Z,https://github.com/huggingface/transformers/commit/9f3aa46f45d10fde9c8b1514eaa383b69e78c180,Add Unispeech & Unispeech-SAT (#13963)  * unispeech  * add copy from  * remove hubert copy from  * finish for today  * add unispeech-sat  * adapt more  * up  * up  * up  * up  * add modeling  * add tests  * up  * up  * finish  * up  * Apply suggestions from code review  * up  * up  * Apply suggestions from code review  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * up  * up  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>,1,Replace Assert with Exception,,
fa4abdb3ea8860827e985dcbb59bf72ecb01b9eb,2021-10-22T11:45:32Z,https://github.com/huggingface/transformers/commit/fa4abdb3ea8860827e985dcbb59bf72ecb01b9eb,Replace assertions with valueError Exeptions (#14117)  * Replace assertions with valueError Exeptions  * Reformatted,1,Replace Assert with Exception,,
7af55d3a1ca72787bf79b8dcfe05557d8234763c,2021-10-21T19:31:00Z,https://github.com/huggingface/transformers/commit/7af55d3a1ca72787bf79b8dcfe05557d8234763c,Replace assertion with ValueError exception (#14098),1,Replace Assert with Exception,,
3187228206cce052c5df0a8643fe85d2fd50e6a0,2021-10-21T11:32:27Z,https://github.com/huggingface/transformers/commit/3187228206cce052c5df0a8643fe85d2fd50e6a0,Replace assertions with ValueError exceptions (#14061)  * Replace assertions with ValueError exceptions  * Format error messages as suggested,1,Replace Assert with Exception,,
a43d9352a999da4fa8d96d0d48daf962e179e096,2021-10-20T11:43:45Z,https://github.com/huggingface/transformers/commit/a43d9352a999da4fa8d96d0d48daf962e179e096,replace assert with exception in src/transformers/utils/model_pararallel_utils.py (#14072)  * replace assert with exception in src/transformers/utils/model_parallel_utils.py  * fix some code style  * fix typo  Co-authored-by: skpig <1900012999@pku.edu.cn>,1,Replace Assert with Exception,,
cde0c750af2fae6848ed3ee8be381b4f1230ecd0,2021-10-16T00:28:13Z,https://github.com/huggingface/transformers/commit/cde0c750af2fae6848ed3ee8be381b4f1230ecd0,Replace assertions with ValueError exceptions (#14018)  * Replace assertions with ValueError exceptions  * Change length check for a more explicit one,1,Replace Assert with Exception,,
47489a6974574c3b6a550be4da65325525965c45,2021-10-15T19:56:07Z,https://github.com/huggingface/transformers/commit/47489a6974574c3b6a550be4da65325525965c45,Fix: replace asserts statements with exception (#14029),1,Replace Assert with Exception,,
a5be95413f99ada138f9d396eb4bd6a7216f640a,2021-10-14T12:57:12Z,https://github.com/huggingface/transformers/commit/a5be95413f99ada138f9d396eb4bd6a7216f640a,Replace assertion with ValueError exception (#14006),1,Replace Assert with Exception,,
3499728dc47b87b8ca74ec7f43c62049e8279611,2021-10-11T17:58:09Z,https://github.com/huggingface/transformers/commit/3499728dc47b87b8ca74ec7f43c62049e8279611,"Replace assert by ValueError of src/transformers/models/electra/modeling_{electra,tf_electra}.py and all other models that had copies (#13955)  * Replace all assert by ValueError in src/transformers/models/electra  * Reformat with black to pass check_code_quality test  * Change some assert to ValueError of modeling_bert & modeling_tf_albert  * Change some assert in multiples models  * Change multiples models assertion to ValueError in order to validate   check_code_style test and models template test.  * Black reformat  * Change some more asserts in multiples models  * Change assert to ValueError in modeling_layoutlm.py to fix copy error in code_style_check  * Add proper message to ValueError in modeling_tf_albert.py  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * Simplify logic in models/bert/modeling_bert.py  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * Add ValueError message to models/convbert/modeling_tf_convbert.py  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * Add error message for ValueError to modeling_tf_electra.py  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * Simplify logic in models/tapas/modeling_tapas.py  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * Simplify logic in models/electra/modeling_electra.py  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * Add ValueError message in src/transformers/models/bert/modeling_tf_bert.py  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * Simplify logic in src/transformers/models/rembert/modeling_rembert.py  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * Simplify logic in src/transformers/models/albert/modeling_albert.py  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>",1,Replace Assert with Exception,,
3c0c699ffd7f434451b1e2a483aa7458633b35cc,2021-10-11T08:59:16Z,https://github.com/huggingface/transformers/commit/3c0c699ffd7f434451b1e2a483aa7458633b35cc,Raise ValueError instead of asserts in src/transformers/benchmark/benchmark.py (#13951)  * Raise ValueError exception instead of assert  * Remove f unnecessary f-strings  * Remove unused f-strings,1,Replace Assert with Exception,,
319beb64eb5f8d1f302160d2bd5bbbc7272b8896,2021-10-07T13:09:01Z,https://github.com/huggingface/transformers/commit/319beb64eb5f8d1f302160d2bd5bbbc7272b8896,#12789 Replace assert statements with exceptions (#13909)  * #12789 Replace assert statements with exceptions  * fix-copies: made copy changes to utils_qa.py in examples/pytorch/question-answering and examples/tensorflow/question-answering  * minor refactor for clarity,1,Replace Assert with Exception,,
9f58becc8dfd46c6e71d88baf7749cc4d7bff0ad,2021-10-06T03:02:44Z,https://github.com/huggingface/transformers/commit/9f58becc8dfd46c6e71d88baf7749cc4d7bff0ad,Replace assert statements with exceptions (#13871),1,Replace Assert with Exception,,
7af7d7ce05271118e595d4c01c40a72741121a64,2021-10-05T22:08:48Z,https://github.com/huggingface/transformers/commit/7af7d7ce05271118e595d4c01c40a72741121a64,fix: replace asserts by error (#13894),1,Replace Assert with Exception,,
b9c6a976949681113c8686215ebdef4de53b3d2f,2021-09-01T08:03:48Z,https://github.com/huggingface/transformers/commit/b9c6a976949681113c8686215ebdef4de53b3d2f,Add the `AudioClassificationPipeline` (#13342)  * Add the audio classification pipeline  * Remove autoconfig exception  * Mark ffmpeg test as slow  * Rearrange pipeline tests  * Add small test  * Replace asserts with ValueError,1,Replace Assert with Exception,,
225de5ccbbd392735013fb1b1b5604ff80cab3ad,2021-08-25T16:14:03Z,https://github.com/huggingface/transformers/commit/225de5ccbbd392735013fb1b1b5604ff80cab3ad,Replace assert statement with if condition and ValueError (#13263),1,Replace Assert with Exception,,
81009b7a5c5cb183a9275c15bf347bdc988b02c4,2021-04-13T14:33:52Z,https://github.com/huggingface/transformers/commit/81009b7a5c5cb183a9275c15bf347bdc988b02c4,Replace error by warning when loading an architecture in another (#11207)  * Replace error by warning when loading an architecture in another  * Style  * Style again  * Add a test  * Adapt old test,1,Replace Assert with Exception,,
2a8115f0838a8fd6de5465658a3afd0868456b58,2021-04-06T16:24:15Z,https://github.com/huggingface/transformers/commit/2a8115f0838a8fd6de5465658a3afd0868456b58,[WIP] GPT Neo cleanup (#10985)  * better names  * add attention mixin  * all slow tests in one class  * make helper methods static so we can test  * add local attention tests  * better names  * doc  * apply review suggestions,1,Replace Assert with Exception,,
3279b1ae661518c5e29b2dfe07fde974fce02ea4,2020-11-20T21:24:31Z,https://github.com/tensorflow/tensorflow/commit/3279b1ae661518c5e29b2dfe07fde974fce02ea4,"[XLA:Python] Change import paths in xla_client to use relative paths to simplify jaxlib build rules.Currently we need to rewrite this path using sed as part of a jaxlib build, but if we make the path relative, we don't need the rewrite.PiperOrigin-RevId: 343553404Change-Id: I8c282966adff436a0486846a6e47188699f3ea38",1,Replace Absolute with Relative,,
633e5e89f78718c1d7be9b83c3dc0eda43bf7ac1,2023-03-02T08:45:42Z,https://github.com/huggingface/transformers/commit/633e5e89f78718c1d7be9b83c3dc0eda43bf7ac1,[Refactor] Relative imports wherever we can (#21880)  * initial commit  * update  * second batch  * style  * fix imports  * fix relative import on pipeline,1,Replace Absolute with Relative,,
fa9e953c6fa165056110bdd598a8d8b1b9c4c807,2022-01-20T15:25:03Z,https://github.com/keras-team/keras/commit/fa9e953c6fa165056110bdd598a8d8b1b9c4c807,"Update callbacks_test.py  refactoring code with List Comprehension which is more pythonic, concise and efficient",1,Repalce Loop with Pipeline,,
c050b13bb61729ee900161bfa41289e51e45ffe1,2021-02-11T23:12:55Z,https://github.com/tensorflow/tensorflow/commit/c050b13bb61729ee900161bfa41289e51e45ffe1,"Make CategoryEncoding a stateless layerRename max_tokens->num_tokens, drop tf-idf output, drop adapt use case.IntegerLookup should be a more appropriate choice when the number of tokens is unknown.PiperOrigin-RevId: 357068012Change-Id: Ic508c2bcceb5b2aa149a920ff52315c683a9aabf",1,Rename Variable,,
f23830c990f02a92c58c78b5c9f5f39ecae08fca,2021-02-09T18:36:35Z,https://github.com/tensorflow/tensorflow/commit/f23830c990f02a92c58c78b5c9f5f39ecae08fca,rename op_or_dataset to iterable,1,Rename Variable,,
ed5b87cd0b3a5267582c147c47a9fdb068cef962,2021-02-09T08:48:11Z,https://github.com/tensorflow/tensorflow/commit/ed5b87cd0b3a5267582c147c47a9fdb068cef962,rename dataset with op,1,Rename Variable,,
28602b108452fa6d6fabe4486381081c45c603d5,2021-01-11T16:26:45Z,https://github.com/tensorflow/tensorflow/commit/28602b108452fa6d6fabe4486381081c45c603d5,"NFC: Replace ""toco"" with ""converter"" in loggings.The testing is for both MLIR-based and TOCO based converters.Calling these ""toco"" is confusingPiperOrigin-RevId: 351158814Change-Id: If659d97a2b38feee980d9533db83e73b6798e2d1",1,Rename Variable,,
edc252f6ec7e09f7bc5c984ce2a760ce23e0beb3,2020-09-28T16:41:19Z,https://github.com/tensorflow/tensorflow/commit/edc252f6ec7e09f7bc5c984ce2a760ce23e0beb3,MultiProcessRunner: String replacement of `list_stdout` -> `return_output`.PiperOrigin-RevId: 334176159Change-Id: I4b6d625a294dfbf469885b16658c8cd066d3bf26,1,Rename Variable,,
e96a7098f1fb3efede53c153aff2f25eb5bdcbd9,2020-09-28T15:48:04Z,https://github.com/tensorflow/tensorflow/commit/e96a7098f1fb3efede53c153aff2f25eb5bdcbd9,MultiProcessRunner: String replacement: stream_stdout->stream_output.PiperOrigin-RevId: 334165921Change-Id: I523b80b211cc0517d6d1cc4fd9447e0509b0f441,1,Rename Variable,,
108d82902294684d4eff3d693e5ca70c210cb142,2020-09-22T08:11:36Z,https://github.com/tensorflow/tensorflow/commit/108d82902294684d4eff3d693e5ca70c210cb142,Do not create unnecessary intermediate lists in tf.nest,1,Rename Variable,,
bf0764d49138a770dbadebf9cfc3c56aa8ef641d,2020-09-01T18:36:01Z,https://github.com/tensorflow/tensorflow/commit/bf0764d49138a770dbadebf9cfc3c56aa8ef641d,TFLite (tools): renamed xxd_output_to_bytearray to xxd_output_to_bytes,1,Rename Variable,Rename Method,
f8c14ec741b08d8b9920d3fcd016b974f7adb2b0,2020-06-24T19:14:00Z,https://github.com/tensorflow/tensorflow/commit/f8c14ec741b08d8b9920d3fcd016b974f7adb2b0,Rename `_var_policy` to `policy` to remove the redundant `var`.PiperOrigin-RevId: 318114143Change-Id: Iac5d11f990154111b49049f4db33220753cab362,1,Rename Variable,,
609a60b44bbf934b31a1dce4f0aa84e731b83c35,2020-06-15T23:41:09Z,https://github.com/tensorflow/tensorflow/commit/609a60b44bbf934b31a1dce4f0aa84e731b83c35,Refactor AutoCastVariable tests to rely on strategy_combinations,1,Rename Variable,,
0c296013f624e35232570b5ffd1575b77a6a0d93,2020-06-13T02:05:23Z,https://github.com/tensorflow/tensorflow/commit/0c296013f624e35232570b5ffd1575b77a6a0d93,rename the pass the hoist_discard,1,Rename Variable,,
761d850ac6456aed93ab250ff49af3f0a6a62960,2020-06-03T16:56:39Z,https://github.com/tensorflow/tensorflow/commit/761d850ac6456aed93ab250ff49af3f0a6a62960,Renamed option with the prefix EXPERIMENTAL_.Change-Id: Idb84736507d5c07ebdf182b8a15d55906d0d7fc0,1,Rename Variable,,
3e31be22cfcd22e7fced904df4c5be014b7d24b7,2020-05-08T01:46:23Z,https://github.com/tensorflow/tensorflow/commit/3e31be22cfcd22e7fced904df4c5be014b7d24b7,"Make regularizers API more consistent.API change (backwards compatible): rename argument `l` in aliases `l1()` and `l2()` to `l1` and `l2` respectively. `l` argument name still works and takes priority over the default value, if passed by name.API addition: add `L1` and `L2` classes (previously named `l1` and `l2`). Aliases `l1` and `l2` still work.Not an actual API change, but nevertheless reflect in golden API files: refactor `l1` and `l2` functions into classes `L1` and `L2`. This makes them consistent with the rest of the API and removes the need for deserialization special cases.PiperOrigin-RevId: 310478018Change-Id: I46d433a2149a97615ca311932c070ab23e8adae2",1,Rename Variable,,
5b630e8624b2a57ad70db6dde8ba504b1f962cfe,2020-04-05T13:51:30Z,https://github.com/tensorflow/tensorflow/commit/5b630e8624b2a57ad70db6dde8ba504b1f962cfe,"Internal cleanup: consolidate the function transformations in a single file, and name it accordingly.PiperOrigin-RevId: 304887346Change-Id: I8049bf59d22e8677dc832d22c222b7e994e50c67",1,Rename Variable,,
f0ee69ee30bcc65631e80768e47932bb871d640e,2020-03-26T00:21:29Z,https://github.com/tensorflow/tensorflow/commit/f0ee69ee30bcc65631e80768e47932bb871d640e,"Make some ""experimental"" feature flag privateAnd also removes all the related api documentation.PiperOrigin-RevId: 303006102Change-Id: Id135e802e6007e98f30e48a8232a51f7150c7aaa",1,Rename Variable,,
75ae7742abc027b001a5f3d7c020bb4504cc0f78,2020-03-24T20:28:21Z,https://github.com/tensorflow/tensorflow/commit/75ae7742abc027b001a5f3d7c020bb4504cc0f78,"Rename all_reduce_sum_gradients to experimental_aggregate_gradientsFor some strategies we don't do all reduce, so all_reduce_sum_gradients can bemisleading. The parameter is also changed to experimental because of issues withCentralStorageStrategy.PiperOrigin-RevId: 302734837Change-Id: Ic30e2f81ab61eef568ee68e5752015f950117d47",1,Rename Variable,,
b76fdc4d454d2de37b33413d4526dba9ef27532b,2020-03-18T20:42:07Z,https://github.com/tensorflow/tensorflow/commit/b76fdc4d454d2de37b33413d4526dba9ef27532b,Replace  arg with,1,Rename Variable,,
0d64ea5b718930691daa03a88ce2607f8228a1e6,2020-01-17T23:23:15Z,https://github.com/tensorflow/tensorflow/commit/0d64ea5b718930691daa03a88ce2607f8228a1e6,Keras: Simplify recurrent state updates,1,Rename Variable,,
4b7f4c1f09a9e0b221a25049af676183a43e1f2b,2020-01-02T23:45:29Z,https://github.com/tensorflow/tensorflow/commit/4b7f4c1f09a9e0b221a25049af676183a43e1f2b,"Rename `seed` to `shuffle_seed` to better indicate use, and add a test for it.PiperOrigin-RevId: 287907717Change-Id: I4f1649ab669058d036a3a076a87024803640eb32",1,Rename Variable,,
d74412af53590e18a07d8cc5cfb042efbf42fd73,2019-12-17T18:51:47Z,https://github.com/tensorflow/tensorflow/commit/d74412af53590e18a07d8cc5cfb042efbf42fd73,"[XLA:Python] Refactor Device and DeviceState class.* Remove all device_ordinals from the local_client.h API. Instead, change APIs to expect a Device object.* Rename DeviceState to LocalDeviceState, which perhaps better clarifies its role: it hold objects pertaining to a locally-attached device.* Make the LocalDeviceState owned by Device.PiperOrigin-RevId: 286013320Change-Id: Icd006a7bc35ae0e14caf32965274468379dea923",1,Rename Variable,,
5c6542df275ea6fe4cff628e063f9d690a9bf4cc,2019-12-13T18:52:42Z,https://github.com/tensorflow/tensorflow/commit/5c6542df275ea6fe4cff628e063f9d690a9bf4cc,"[XLA:Python] Refactor Device and DeviceState class.* Remove all device_ordinals from the local_client.h API. Instead, change APIs to expect a Device object.* Rename DeviceState to LocalDeviceState, which perhaps better clarifies its role: it hold objects pertaining to a locally-attached device.* Make the LocalDeviceState owned by Device.PiperOrigin-RevId: 285430281Change-Id: Ic26ba6f0df24dcae604d27fd07f79cf7fa6b22f8",1,Rename Variable,,
9a4295cb3d7e8121e40b27ba9b6158d43e550bda,2019-12-13T15:16:10Z,https://github.com/tensorflow/tensorflow/commit/9a4295cb3d7e8121e40b27ba9b6158d43e550bda,"[XLA:Python] Refactor Device and DeviceState class.* Remove all device_ordinals from the local_client.h API. Instead, change APIs to expect a Device object.* Rename DeviceState to LocalDeviceState, which perhaps better clarifies its role: it hold objects pertaining to a locally-attached device.* Make the LocalDeviceState owned by Device.PiperOrigin-RevId: 285394262Change-Id: I8a4f14bb03be31c4667c85e7d39a4ebcee4c6f40",1,Rename Variable,,
e08ae8459886595aafeec694a49fa8fd4bd23025,2019-12-11T08:06:59Z,https://github.com/tensorflow/tensorflow/commit/e08ae8459886595aafeec694a49fa8fd4bd23025,"Pass experimental_relax_shapes to instance methods...decorated with `tf.function`.Currently the `experimental_relax_shapes` is not passed,so the instance methods ignore this argument.Fixes #34905.Note that the `experimental_relax_shapes` was named differently in`def_function.Function` and `function.Function`, so the onein `def_function` was renamed to start with underscore. It is a privatefield, so it should be fine.",1,Rename Variable,,
82ffe368896b5f360aa7afcdf613beff49a22bbe,2019-11-15T23:54:49Z,https://github.com/tensorflow/tensorflow/commit/82ffe368896b5f360aa7afcdf613beff49a22bbe,rename variables,1,Rename Variable,,
ef15e65bca6713fda4923410b3f7e15cd85d90f9,2019-10-24T00:53:45Z,https://github.com/tensorflow/tensorflow/commit/ef15e65bca6713fda4923410b3f7e15cd85d90f9,Move the init file content to API gen build rule.The final leftover piece is keras.layer.PiperOrigin-RevId: 276390172Change-Id: Ie2efc73e9b987df15fb8085f82b8369eca8ce664,1,Rename Variable,,
5367cbe18f38ab5cac4fce2f5f0b24dde2590473,2019-10-17T22:42:46Z,https://github.com/tensorflow/tensorflow/commit/5367cbe18f38ab5cac4fce2f5f0b24dde2590473,Rename experimental_enable_mlir_converter to experimental_new_converterPiperOrigin-RevId: 275354472Change-Id: I76bb7f87c0958212ea8e47e0d175182f00ad3c13,1,Rename Variable,,
8b1e044236073b458a3b2d6b75c9f92358968a79,2019-10-07T23:52:45Z,https://github.com/tensorflow/tensorflow/commit/8b1e044236073b458a3b2d6b75c9f92358968a79,[XLA:Python] Plumb Devices through to more places.* PyLocalBuffer.make_tuple() overload that takes Device* PyLocalExecutable.local_devices()* Replace PyLocalExecutable::device_ordinals_ with local_devices_PiperOrigin-RevId: 273408185,1,Rename Variable,,
84ec37fb58ebea5fdeeb870c5e68b86b89dc6dd6,2019-09-23T20:55:09Z,https://github.com/tensorflow/tensorflow/commit/84ec37fb58ebea5fdeeb870c5e68b86b89dc6dd6,Remove use of target_ops.PiperOrigin-RevId: 270753282,1,Rename Variable,,
fa2440f749bd70d39eaeec970f9b6bf0470b396b,2019-09-14T00:52:28Z,https://github.com/tensorflow/tensorflow/commit/fa2440f749bd70d39eaeec970f9b6bf0470b396b,Reduce usage of ObjectIdentityDictionaryWe will be recommending to users to use experimental_ref() in order tohash tensors & variables. We should do the same internally.PiperOrigin-RevId: 269016891,1,Rename Variable,,
649155b7447ca9f58896ab05fcf7e561af4345b5,2019-09-12T16:42:51Z,https://github.com/tensorflow/tensorflow/commit/649155b7447ca9f58896ab05fcf7e561af4345b5,[tf.data] Have `dataset_ops.Dataset` alias DatasetV1 or DatasetV2 depending on TensorFlow version so that internal TensorFlow uses of the symbol do not return dataset objects that expose V1 APIs (e.g. make_one_shot_iterator) in TF 2.0.PiperOrigin-RevId: 268704083,1,Rename Variable,,
b2ba7c7176c462342e0614811fa05f9701a1ba40,2019-08-07T09:34:24Z,https://github.com/tensorflow/tensorflow/commit/b2ba7c7176c462342e0614811fa05f9701a1ba40,Renamed icfo->gates in lstm_ops.ccThis is needed in order to generalize BlockLSTM and LSTMBlockCell to ICFO/IFCOgate order. Extracted into a separate change to minimize the diff of the main one.PiperOrigin-RevId: 262094818,1,Rename Variable,,
960a225b72a8c6615b0296e1e2bfcf7e4a25d27f,2019-07-31T23:41:07Z,https://github.com/tensorflow/tensorflow/commit/960a225b72a8c6615b0296e1e2bfcf7e4a25d27f,Remove element in list based on id instead of ==PiperOrigin-RevId: 261024062,1,Rename Variable,,
c7933ce9f3f25e592bef5f9a243ac72c5fd76cd1,2019-07-30T19:06:33Z,https://github.com/tensorflow/tensorflow/commit/c7933ce9f3f25e592bef5f9a243ac72c5fd76cd1,Renames the `run_distributed` flag to `experimental_run_tf_function` and modifies the tests generated by the keras_all_modes decorator to better reflect that.PiperOrigin-RevId: 260767064,1,Rename Variable,,
461582c2242247dfaa2e02135ca33a92da05056a,2019-07-29T22:56:51Z,https://github.com/tensorflow/tensorflow/commit/461582c2242247dfaa2e02135ca33a92da05056a,"Refactor forward/backward function selection and execution so there's one call siteShifts around internal ConcreteFunction symbols a bit, which breaks some disable=protected-access users (a sin of which I am completely blameless personally). I've switched to public interfaces as much as possible, although _call_flat is still a not-completely-private-to-internal-code thing for mapped captures.I've tried to avoid many functional changes, although record_operation may end up running in a few places where it didn't before and backward function caching is slightly tweaked.My ulterior motive is that I want to special-case function forwardprop, but that requires intercepting function calls after we decide what the forward function is going to output. Before this CL there were three-ish call sites where that logic would need to have gone (two called record_operation, one with not quite all of its side outputs...).PiperOrigin-RevId: 260598474",1,Rename Variable,,
022fa6c7500e5a828b49688bf1e499e466e35eb3,2019-07-18T23:09:43Z,https://github.com/tensorflow/tensorflow/commit/022fa6c7500e5a828b49688bf1e499e466e35eb3,"Test run_distributed=True path in Keras dist-strat tests.This effectively replaces the cloning=False tests.  The cloning argument doesn't have an effect anymore and is completely removed in the change # 258789323.Mechanically this change is done by recursive rename of ""cloning"" to ""run_distributed"" in _test.py files followed by pyformatting the changed lines.PiperOrigin-RevId: 258864940",1,Rename Variable,,
9db44da9316633cf4859cbd4cb46ce5505e41ca1,2019-07-02T18:10:43Z,https://github.com/tensorflow/tensorflow/commit/9db44da9316633cf4859cbd4cb46ce5505e41ca1,"[tf.data] Exposing dataset / iterator element type specification in the public API as `element_spec`.This CL renames the pre-existing `_element_structure` property of tf.data datasets and iterators to `element_spec`, thus exposing it in the public API.PiperOrigin-RevId: 256201202",1,Rename Variable,,
38df5d8ef43e884674f22670dbfd19ec26782f17,2019-06-30T17:14:23Z,https://github.com/tensorflow/tensorflow/commit/38df5d8ef43e884674f22670dbfd19ec26782f17,"Reduce the verbosity of error message raised when failing to parse the source of lambda function, and move the details to the logs.Fixes #30149.PiperOrigin-RevId: 255844488",1,Rename Variable,,
0754009ba3f399636caecfb8399937ec088c7b4d,2019-06-25T20:02:05Z,https://github.com/tensorflow/tensorflow/commit/0754009ba3f399636caecfb8399937ec088c7b4d,variable name changed import tf removedChanged offsets_variable to offsets and import tensorflow as tf removed,1,Rename Variable,,
b79af7bd609421fabb8c882c21ce18350584687b,2019-06-11T22:25:49Z,https://github.com/tensorflow/tensorflow/commit/b79af7bd609421fabb8c882c21ce18350584687b,Follow batch renormalization paper more closely1) Doesn't do moment mixing between inference and renorm moving averages2) Initializes renorm variance to 1.0 instead of 0.0 to more closely match the inference mode moving average3) Removes early training correction to mean/variance which leads to very slight positive bias later in trainingPiperOrigin-RevId: 252711154,1,Rename Variable,,
65b507e8a14f625e7d3f9870ab0816f56bf83f49,2019-06-11T20:08:38Z,https://github.com/tensorflow/tensorflow/commit/65b507e8a14f625e7d3f9870ab0816f56bf83f49,"Replace training tensor argument with python boolean. Required for TFLite, which does not yet support control flow ops.This also adds a class that ensures that all layer call functions are traced with the same inputs, and with training set to both True&False.PiperOrigin-RevId: 252682485",1,Rename Variable,,
53027266f023d56d20102dd56e80e913724826e7,2019-05-28T17:44:19Z,https://github.com/tensorflow/tensorflow/commit/53027266f023d56d20102dd56e80e913724826e7,Tensor tracer refactor.PiperOrigin-RevId: 250316061,1,Rename Variable,,
2cb745ef1e0b4082a618c81274fca39be0cb4fc6,2019-05-15T22:55:09Z,https://github.com/tensorflow/tensorflow/commit/2cb745ef1e0b4082a618c81274fca39be0cb4fc6,Remove epsilon as variable.PiperOrigin-RevId: 248422472,1,Rename Variable,,
e905b8b447977a62dfaa2538052dd9be5c7172ef,2019-05-07T23:30:52Z,https://github.com/tensorflow/tensorflow/commit/e905b8b447977a62dfaa2538052dd9be5c7172ef,Refactoring the keras compile() by consolidating internal fields.PiperOrigin-RevId: 247113640,1,Rename Variable,,
f8b5947349fc2084c18619df20fba963a9a87aa0,2019-04-11T16:53:20Z,https://github.com/tensorflow/tensorflow/commit/f8b5947349fc2084c18619df20fba963a9a87aa0,s/source/input on the argument name of v2 strings.splitPiperOrigin-RevId: 243088260,1,Rename Variable,,
66a0c2a8ab7662be546de5c5f297d7ed995d64bf,2019-03-30T14:50:11Z,https://github.com/tensorflow/tensorflow/commit/66a0c2a8ab7662be546de5c5f297d7ed995d64bf,Replaced contrib v2 optimizers with keras v2 optimizers.PiperOrigin-RevId: 241134872,1,Rename Variable,,
aef2d88445cef2e9567a9274562d8d2147b20dc5,2019-03-22T23:28:46Z,https://github.com/tensorflow/tensorflow/commit/aef2d88445cef2e9567a9274562d8d2147b20dc5,Rename `ignore_toco_errors ` to `ignore_converter_errors`.PiperOrigin-RevId: 239886513,1,Rename Variable,,
89a949ec78154a65cac0bda8b528d2741ad1e96b,2019-02-08T19:12:24Z,https://github.com/tensorflow/tensorflow/commit/89a949ec78154a65cac0bda8b528d2741ad1e96b,Rename variable for more clarityPiperOrigin-RevId: 233092472,1,Rename Variable,,
13d91f621a2bbb630ba354281e9e93181b73e7b6,2019-02-04T14:16:24Z,https://github.com/tensorflow/tensorflow/commit/13d91f621a2bbb630ba354281e9e93181b73e7b6,Rename event_shape_only to innermost_dims,1,Rename Variable,,
634eefa5c48c0b90cafaceb55ad00186e3ece6ce,2019-01-24T21:54:32Z,https://github.com/tensorflow/tensorflow/commit/634eefa5c48c0b90cafaceb55ad00186e3ece6ce,Refactoring transformer constructors to take a transformer.Context.1. Make converter.EntityContext inherit from transformer.Context.2. Move converter.Base.ctx to transformer.Base.ctx (replacing transformer.Base.transformer_ctx.)PiperOrigin-RevId: 230784642,1,Rename Variable,Rename Method,
c43361b59b913f13d42ab6fa8f434f1fe221c208,2019-01-23T23:48:27Z,https://github.com/tensorflow/tensorflow/commit/c43361b59b913f13d42ab6fa8f434f1fe221c208,Rename task_index to task_id in cluster resolvers.PiperOrigin-RevId: 230618484,1,Rename Variable,,
baad4e65fc8c4e5313e70bfd9fe0240cd0972842,2018-11-20T22:21:31Z,https://github.com/tensorflow/tensorflow/commit/baad4e65fc8c4e5313e70bfd9fe0240cd0972842,Remove some `num_gpus` and `auto_shard_dataset` from CoreMirroredStrategy.PiperOrigin-RevId: 222306139,1,Rename Variable,,
36035b92300e2183357c70b18b5400e656bf958b,2018-11-16T19:54:10Z,https://github.com/tensorflow/tensorflow/commit/36035b92300e2183357c70b18b5400e656bf958b,"A round of moving some DistributionStrategy libraries from contrib tocore (just implementations, not public APIs):  * cross_tower_ops -> cross_device_ops  * cross_tower_utils -> cross_device_utils  * input_ops (and test)  * shared_variable_creator (and test)  * valuesAlso:  * BUILD clean up  * renaming cross_tower -> cross_device in a number of places.PiperOrigin-RevId: 221828945",1,Rename Variable,Rename Method,
cfdfcc311c10eacad1c9a6506c53987372b132f3,2018-11-15T12:27:12Z,https://github.com/tensorflow/tensorflow/commit/cfdfcc311c10eacad1c9a6506c53987372b132f3,Rename `ReplicaContext.replica_id` to `replica_id_in_sync_group`.PiperOrigin-RevId: 221602399,1,Rename Variable,,
4baf08902bb99d3478e9e87688c78fa2d793db8c,2018-11-09T19:43:54Z,https://github.com/tensorflow/tensorflow/commit/4baf08902bb99d3478e9e87688c78fa2d793db8c,Rename PerDevice -> PerReplica in distribution strategies.PiperOrigin-RevId: 220838587,1,Rename Variable,,
0474b806cb5c69c99b58df27f0476f64f85d4fac,2018-11-08T20:02:32Z,https://github.com/tensorflow/tensorflow/commit/0474b806cb5c69c99b58df27f0476f64f85d4fac,"Rename experimental_autograph to autograph. Still disabled by default in both defun and tf.function, until we add support for lambda conversions.PiperOrigin-RevId: 220678074",1,Rename Variable,,
fb3bcc39a5801eed9923765ada7992d3696ad9a4,2018-11-01T23:31:00Z,https://github.com/tensorflow/tensorflow/commit/fb3bcc39a5801eed9923765ada7992d3696ad9a4,Rename flex_ops -> select_tf_ops in Toco flagsPiperOrigin-RevId: 219719783,1,Rename Variable,,
9a1a8af2735d09a198a0b97c2fbc1693da28bdc3,2018-10-25T21:55:17Z,https://github.com/tensorflow/tensorflow/commit/9a1a8af2735d09a198a0b97c2fbc1693da28bdc3,Step 1 of rename `cross_tower_ops` -> `cross_device_ops` in`MirroredStrategy.__init__()`.PiperOrigin-RevId: 218755068,1,Rename Variable,,
ce2e925493cead88de6546ad2754d953694d91c3,2018-10-02T18:26:45Z,https://github.com/tensorflow/tensorflow/commit/ce2e925493cead88de6546ad2754d953694d91c3,Rename the variable name from  to  to avoid the built-in,1,Rename Variable,,
6aebb0866718cae2c921e875f3fd74573ee9acc8,2018-09-14T15:29:15Z,https://github.com/tensorflow/tensorflow/commit/6aebb0866718cae2c921e875f3fd74573ee9acc8,global_step/sec renamed to global_steps/secPiperOrigin-RevId: 212986442,1,Rename Variable,,
f4de1e737c914618e6fcefac5918fe73945ef9fb,2018-09-12T00:39:28Z,https://github.com/tensorflow/tensorflow/commit/f4de1e737c914618e6fcefac5918fe73945ef9fb,"Rename ""_periods"" private property in ARModel with ""_periodicities"" to make it more accurate.PiperOrigin-RevId: 212555968",1,Rename Variable,,
0f1b3bcf48eaaca4dccdf2d3208b0305b1c6056b,2018-08-27T20:46:16Z,https://github.com/tensorflow/tensorflow/commit/0f1b3bcf48eaaca4dccdf2d3208b0305b1c6056b,Misc clean up tpu.pyPiperOrigin-RevId: 210423935,1,Rename Variable,,
68a5b0357d21b8b38e467f25bc445f0e8b6c414d,2018-08-01T20:19:31Z,https://github.com/tensorflow/tensorflow/commit/68a5b0357d21b8b38e467f25bc445f0e8b6c414d,Refactored the multi_worker_test_base:1) move some common utils to this test base2) rename task_index to task_idPiperOrigin-RevId: 206981192,1,Rename Variable,,
4f456bc6f19d667a6d32a7459742b3139e8fe617,2018-07-29T14:52:44Z,https://github.com/tensorflow/tensorflow/commit/4f456bc6f19d667a6d32a7459742b3139e8fe617,CLN: clean codes,1,Rename Variable,,
e8c44d765146d228ee88e46b1e1f1e8fb3894818,2018-07-13T15:30:49Z,https://github.com/tensorflow/tensorflow/commit/e8c44d765146d228ee88e46b1e1f1e8fb3894818,"rename arguments from seq_dim to seq_axis, batch_dim to batch_axis in _reverse(...) function",1,Rename Variable,,
eaa78c17269b97991355974d7a26d650de76bbcd,2018-05-16T15:35:29Z,https://github.com/tensorflow/tensorflow/commit/eaa78c17269b97991355974d7a26d650de76bbcd,Resolved inconsistency with shape inference for tf.reduce_join when passing non-Tensor values.Removed deprecated arguments in tf.reduce_join test.PiperOrigin-RevId: 196832183,1,Rename Variable,,
b50f6325143486eb82b5654f8794f0771b54dd4d,2018-05-02T02:05:39Z,https://github.com/tensorflow/tensorflow/commit/b50f6325143486eb82b5654f8794f0771b54dd4d,"Minor refactor: establish some operator naming conventions and apply them, so that the interface is a bit more consistent.PiperOrigin-RevId: 195034691",1,Rename Variable,Rename Method,
91bf5524560c5bc0783b43717156c7dbb6f798f5,2018-04-04T22:06:08Z,https://github.com/tensorflow/tensorflow/commit/91bf5524560c5bc0783b43717156c7dbb6f798f5,Rename `distribute` to `train_distribute` parameter in `RunConfig` to clarify that its purpose is only for training.PiperOrigin-RevId: 191654161,1,Rename Variable,,
1a9663e9e06075c5b5f8984bb95b36f3458edccf,2018-03-29T21:17:16Z,https://github.com/tensorflow/tensorflow/commit/1a9663e9e06075c5b5f8984bb95b36f3458edccf,boosted_trees: post-submit clean up - non-public objects are renamed. - is_single_machine is set properly when run_config is not populated properly (i.e. empty).PiperOrigin-RevId: 190984693,1,Rename Variable,,
5324b75ceb5751938d6a7f59c2fc1793933d38ad,2018-03-27T20:15:46Z,https://github.com/tensorflow/tensorflow/commit/5324b75ceb5751938d6a7f59c2fc1793933d38ad,Remove unneeded _ in gen_array_opsSigned-off-by: Yong Tang <yong.tang.github@outlook.com>,1,Rename Variable,,
f176a611605bb26b17ef16d096e66d9d9ab2bda9,2018-03-01T19:59:14Z,https://github.com/tensorflow/tensorflow/commit/f176a611605bb26b17ef16d096e66d9d9ab2bda9,Refactor training part of the Keras engine.Also add support for sample/class weights with eager execution.Structure before:engine/training.pyengine/training_eager.pyAfter:engine/training.pyengine/training_arrays.pyengine/training_eager.pyengine/training_generator.pyengine/training_utils.pyAll new files are about 500 lines long. training.py is now 1700 lines long (about 1000 lines of logic). It was previously 3000 lines long.PiperOrigin-RevId: 187511923,1,Rename Variable,,
7f06d633e58ba37cbf654c1371135100260f20d8,2018-02-14T12:02:15Z,https://github.com/tensorflow/tensorflow/commit/7f06d633e58ba37cbf654c1371135100260f20d8,"effective_sample_size kwarg change (same default behavior).* rename max_lags --> filter_beyond_lag* rename max_lags_threshold --> filter_threshold* Users can use both filters, and they combine in an ""OR"" manner* None ==> turn off a filter.PiperOrigin-RevId: 185666926",1,Rename Variable,,
95a8af24058c168ce8a5327451e1cfcbc56461eb,2018-01-29T20:12:41Z,https://github.com/tensorflow/tensorflow/commit/95a8af24058c168ce8a5327451e1cfcbc56461eb,"Ensure that non-recursive conversion is identity transformation wrt all types of function calls by only failing on unresolved symbols if they're needed.Simplify code structure all around. Remove the awkward activity analysis that deemed a function parameter as ""modified"". Consolidate activity analysis by tracking function parameters and returned symbols separately. Strengthen the type inference a little by using more interpret-like constructs.PiperOrigin-RevId: 183705547",1,Rename Variable,,
ffdae0a35785337bd10fed289d3998ba0e7c014b,2018-01-24T17:15:32Z,https://github.com/tensorflow/tensorflow/commit/ffdae0a35785337bd10fed289d3998ba0e7c014b,Rename internal field.PiperOrigin-RevId: 183093901,1,Rename Variable,,
ff49f7b1c5b2c152ad9ac9c22a2baa4f353c2995,2018-01-16T19:10:58Z,https://github.com/tensorflow/tensorflow/commit/ff49f7b1c5b2c152ad9ac9c22a2baa4f353c2995,"Internal API to optionally compile a template's function into a graph function.(1) Adds a function `make_template_internal` that takes an optional keywordargument `create_graph_function_` that controls whether or not `func_` iscompiled into and executed as a graph function.(2) Exposes `make_template_internal` as `tfe.make_template`, so users maywrite something like`compiled = tfe.make_template(""my_op"", func, create_graph_function_=True)`to obtain a templatized version of func that is executed as a graphfunction.(3) Simplifies the implementation of (Eager)Template's _call_func and __call__methods in a minor way.PiperOrigin-RevId: 182082866",1,Rename Variable,,
c72bb9754152577de6393879ba38dcfdf583477d,2017-12-05T18:17:45Z,https://github.com/tensorflow/tensorflow/commit/c72bb9754152577de6393879ba38dcfdf583477d,nn_impl.py cleanup: used keepdims instead of deprecated keep_dims.PiperOrigin-RevId: 177972555,1,Rename Variable,,
10581c8afee392f2455acb700ece8217a3a19a4b,2017-11-17T04:50:28Z,https://github.com/tensorflow/tensorflow/commit/10581c8afee392f2455acb700ece8217a3a19a4b,Rename global_step -> step in contrib/summary APISince it's more succinct and the API doesn't actually care if the provided stepis the one true global step.PiperOrigin-RevId: 176063779,1,Rename Variable,,
466040ca83a29d9842c4f44b56f51e99a16083dc,2017-11-17T02:39:43Z,https://github.com/tensorflow/tensorflow/commit/466040ca83a29d9842c4f44b56f51e99a16083dc,Renaming feature_id to dimension_id in dense float splitPiperOrigin-RevId: 176055428,1,Rename Variable,,
e4cb8d93775bb9f47e1a632d984495debbbe1b37,2017-11-07T17:21:12Z,https://github.com/tensorflow/tensorflow/commit/e4cb8d93775bb9f47e1a632d984495debbbe1b37,Renames sparse_precision_at_k to precision_at_k and sparse_average_precision_at_k to average_precision_at_k.Also fixes some line wrapping.PiperOrigin-RevId: 174865470,1,Rename Variable,,
80374a7b47dddb591f711b6240ea0896fbe90d29,2017-10-27T22:59:46Z,https://github.com/tensorflow/tensorflow/commit/80374a7b47dddb591f711b6240ea0896fbe90d29,"Breaking change: Rename `tf.contrib.distributions.Independent` parameter from`reduce_batch_ndims` to `reinterpreted_batch_ndims`. Also change default;`reinterpreted_batch_ndims` default has semantics of `tf.layers.flatten`, i.e.,all batch dimensions except the first (batch axis 0) are interpretted as beingpart of the event.PiperOrigin-RevId: 173729585",1,Rename Variable,,
4d70239f0e090f2a455605c7e348415705f3656f,2017-10-04T17:28:22Z,https://github.com/tensorflow/tensorflow/commit/4d70239f0e090f2a455605c7e348415705f3656f,Replace the contrib FC with core FC  in canned Estimator docstring.PiperOrigin-RevId: 171027602,1,Rename Variable,,
5d5975bab087894e78bf2be1e9195a29e6fe7fe7,2017-08-28T07:09:55Z,https://github.com/tensorflow/tensorflow/commit/5d5975bab087894e78bf2be1e9195a29e6fe7fe7,CLN: rename ordered_dict_x => ordered_dict_data,1,Rename Variable,,
159062982894be94609780a05e236b4c8cdfe1cf,2017-08-23T15:58:54Z,https://github.com/tensorflow/tensorflow/commit/159062982894be94609780a05e236b4c8cdfe1cf,Rename shard_dimensions to batch_axis.PiperOrigin-RevId: 166207345,1,Rename Variable,,
b3c3a1c5720fd8122ef425b2c9b9081967a16d21,2017-05-25T16:13:04Z,https://github.com/tensorflow/tensorflow/commit/b3c3a1c5720fd8122ef425b2c9b9081967a16d21,"Refactor session.py to reference input Tensors/Operations directly instead of their namesThis is a step towards switching to the new session API, which expects the corresponding C objects instead of names.PiperOrigin-RevId: 157114094",1,Rename Variable,,
7c561e09c05100fe68f00d66a2d27d1b490ee74e,2017-05-01T23:11:37Z,https://github.com/tensorflow/tensorflow/commit/7c561e09c05100fe68f00d66a2d27d1b490ee74e,Explain when callables passed to tf.cond & tf.while_loop are run.Rename the parameters to tf.cond.Change: 154774725,1,Rename Variable,,
891de62d0266113b067267ece48ea448665a5fbe,2017-04-27T16:59:05Z,https://github.com/tensorflow/tensorflow/commit/891de62d0266113b067267ece48ea448665a5fbe,[tf contrib seq2seq] Minor cleanups to beam search decoder.Change: 154435114,1,Rename Variable,,
eabdedd1ae712e587546f4b460954e1b80dad92d,2017-02-23T00:22:03Z,https://github.com/tensorflow/tensorflow/commit/eabdedd1ae712e587546f4b460954e1b80dad92d,Refactor doc generator to extract class ReferenceResolver.Change: 148284712,1,Rename Variable,,
2d759d55a6873ad4d551a597857f1ab2d9cdce43,2017-02-22T18:03:04Z,https://github.com/tensorflow/tensorflow/commit/2d759d55a6873ad4d551a597857f1ab2d9cdce43,Speeding up and refactoring contrib/training_test.pyChange: 148232625,1,Rename Variable,,
9fe33c2d5f961b5bd9111ef93ab271e931eb0422,2017-02-10T20:49:33Z,https://github.com/tensorflow/tensorflow/commit/9fe33c2d5f961b5bd9111ef93ab271e931eb0422,BREAKING CHANGE: Rename MVN usage of Greek and refactor to use`bijector.AffineLinearOperator`.Change: 147187653,1,Rename Variable,,
e26f9cddbd47b4139711c8a03871158943a989e5,2017-02-01T21:57:20Z,https://github.com/tensorflow/tensorflow/commit/e26f9cddbd47b4139711c8a03871158943a989e5,"Rename training_scaffold to scaffold. First step to use scaffold in all actions: training, evaluation, inference, serving.Change: 146285386",1,Rename Variable,,
53bdaa9233a14a62be616cfdd6e143b4deab5b6e,2017-01-23T21:19:42Z,https://github.com/tensorflow/tensorflow/commit/53bdaa9233a14a62be616cfdd6e143b4deab5b6e,Handle non-tensor args.Rename `target` arg to `labels`.Use asserts with more descriptive failure messages.Change: 145325723,1,Rename Variable,,
aa4c188ff8b25577df6f1ed31e273403114750c2,2017-01-17T22:04:17Z,https://github.com/tensorflow/tensorflow/commit/aa4c188ff8b25577df6f1ed31e273403114750c2,"Rename `weights` in `Dense` layer to `kernel`, and add base layer aliases for `(non_)trainable_weights`.Change: 144752883",1,Rename Variable,,
901f6508ecb290278d94481d63dd9177a7c1d55d,2017-01-19T22:35:51Z,https://github.com/tensorflow/tensorflow/commit/901f6508ecb290278d94481d63dd9177a7c1d55d,"BREAKING CHANGE: Rename instances of ""std"" to ""stddev"".Change: 145010945",1,Rename Variable,,
0662eabf9d6d670bd9a741ea3a3eb0c9f0005850,2017-01-17T22:04:17Z,https://github.com/tensorflow/tensorflow/commit/0662eabf9d6d670bd9a741ea3a3eb0c9f0005850,"Rename `weights` in `Dense` layer to `kernel`, and add base layer aliases for `(non_)trainable_weights`.Change: 144752883",1,Rename Variable,,
dac3cf87e6fd2fd80ebc05c1d21bec9ca992041d,2017-01-13T01:18:45Z,https://github.com/tensorflow/tensorflow/commit/dac3cf87e6fd2fd80ebc05c1d21bec9ca992041d,Remove unnecessary control dependencies.Change: 144392019,1,Rename Variable,,
be270ecb79c8548a0caddf67908189e6169b1472,2017-01-11T17:35:14Z,https://github.com/tensorflow/tensorflow/commit/be270ecb79c8548a0caddf67908189e6169b1472,"Deprecate tf.neg, tf.mul, tf.sub (and remove math_ops.{neg,mul,sub} usagestf.negative, tf.multiply, tf.subtract are the new names- Also enabled deprecation warning (to be completely removed by friday)Change: 144215355",1,Rename Variable,,
b79d37b19bc692635d52b5273a9b922a5c24c225,2016-12-08T23:17:34Z,https://github.com/tensorflow/tensorflow/commit/b79d37b19bc692635d52b5273a9b922a5c24c225,Final breaking change of SparseTensor.shape -> SparseTensor.dense_shape rename.Removing shape property from SparseTensor.Change: 141490813,1,Rename Variable,,
e1cb0920c8f5d1639faa692ef04c2eee65296c93,2016-12-08T23:07:42Z,https://github.com/tensorflow/tensorflow/commit/e1cb0920c8f5d1639faa692ef04c2eee65296c93,Final breaking change of SparseTensor.shape -> SparseTensor.dense_shape rename.Removing shape property from SparseTensor.Change: 141489556,1,Rename Variable,,
056c0877adbc6ce21842f0bcdc6bb62e18f15a03,2016-12-08T22:25:47Z,https://github.com/tensorflow/tensorflow/commit/056c0877adbc6ce21842f0bcdc6bb62e18f15a03,Final breaking change of SparseTensor.shape -> SparseTensor.dense_shape rename.Removing shape property from SparseTensor.Change: 141484042,1,Rename Variable,,
e824de5ce5c652746a62eb513c0f5ed10a6372a3,2016-12-01T23:17:31Z,https://github.com/tensorflow/tensorflow/commit/e824de5ce5c652746a62eb513c0f5ed10a6372a3,SparseTensor.shape -> SparseTensor.dense_shape part 1... wherein the flawed protagonist adds temporary support for *both* versionsof the property so that a followup change can perform the rename.A final change will then remove the old `shape`.Requires adding an iterator for SparseTensorValue because some folks use itstuple iterable property.Change: 140784809,1,Rename Variable,,
83cef3f1f4ce4177c5bcf38b6a24e920dc12fba7,2016-12-01T01:39:34Z,https://github.com/tensorflow/tensorflow/commit/83cef3f1f4ce4177c5bcf38b6a24e920dc12fba7,Rename more argument names to be consistent with NumPy.Create temporary dummy arguments with old names at the end in preparation fordeprecation.Change: 140675930,1,Rename Variable,,
60b563f274e71b3f5de06d56e338489ff9ae3a69,2016-11-30T23:34:54Z,https://github.com/tensorflow/tensorflow/commit/60b563f274e71b3f5de06d56e338489ff9ae3a69,Move properties in Layer to read-only; add output_size property.Change: 140661470,1,Rename Variable,,
fd9fa066ea42d1210e9aa961230959ee9fc4b214,2016-11-22T00:53:47Z,https://github.com/tensorflow/tensorflow/commit/fd9fa066ea42d1210e9aa961230959ee9fc4b214,Renamed 'hashed_embedding_x' as 'scattered_embedding_x' to eliminate confusion.Change: 139849495,1,Rename Variable,,
a571fc91c3360b53b343d189481af77bb378a099,2016-11-15T20:01:10Z,https://github.com/tensorflow/tensorflow/commit/a571fc91c3360b53b343d189481af77bb378a099,Renamed variable bias to pre_activation (#5613),1,Rename Variable,,
6dba9924198aba18535f0b131beae281aa7ef2f7,2016-11-10T16:11:10Z,https://github.com/tensorflow/tensorflow/commit/6dba9924198aba18535f0b131beae281aa7ef2f7,"Refactors dynamic_rnn_estimator to use a model_fn and Estimator, rather than inheriting from BaseEstimator.Also adds the capability to predict probabilities.Change: 138761836",1,Rename Variable,,
4f50a5f58b82b3628975897bb8cfd7f0123ac803,2016-10-31T21:30:47Z,https://github.com/tensorflow/tensorflow/commit/4f50a5f58b82b3628975897bb8cfd7f0123ac803,Refactor LinearRegressor from inheritance to composition.Change: 137749798,1,Rename Variable,,
27cb0773412df75ebede70092c3fc28d96e0d2c0,2016-10-29T00:31:58Z,https://github.com/tensorflow/tensorflow/commit/27cb0773412df75ebede70092c3fc28d96e0d2c0,Rename targets to labels for naming consistency.Change: 137572074,1,Rename Variable,,
48ebbb8c7247b492cdff12306c4a0381ae099830,2016-10-11T16:30:39Z,https://github.com/tensorflow/tensorflow/commit/48ebbb8c7247b492cdff12306c4a0381ae099830,Renames all `DistributionTensor` to `StochasticTensor`Change: 135804717,1,Rename Variable,,
932840a29f4655eeb3bf1dfc54bf4c405842ba07,2016-10-01T00:30:59Z,https://github.com/tensorflow/tensorflow/commit/932840a29f4655eeb3bf1dfc54bf4c405842ba07,Rename variables filename generated by SavedModel.Change: 134847453,1,Rename Variable,,
a080485a5d6833f24db211c7d770fe46398eea13,2016-09-28T19:24:29Z,https://github.com/tensorflow/tensorflow/commit/a080485a5d6833f24db211c7d770fe46398eea13,Simplify and speed up shape inference code in tf.contrib.distributions.Categorical.Change: 134566685,1,Rename Variable,,
858c1709cbe48d429caab3b9340bffb595234f44,2016-08-18T21:50:40Z,https://github.com/tensorflow/tensorflow/commit/858c1709cbe48d429caab3b9340bffb595234f44,"Rename Tensor ""summary_op"" to ""summary"" in the 101 tutorial (#3877)* ""summary_op"" -> ""summary"" in tutorial code""summary_op"" is a Tensor, so it's incorrectly labeled as an op. This change renames it to ""summary"", and makes the corresponding changes in the explanation.* Rename Tensor ""summary_op"" to ""summary"" in tutorial""summary_op"" is a Tensor, so it's incorrectly labeled as an op. This change renames it to ""summary"", and makes the corresponding changes in the explanation.",1,Rename Variable,,
3485f56c407f52cfccff482152d6a4e7c8e1e2c4,2016-07-13T20:14:25Z,https://github.com/tensorflow/tensorflow/commit/3485f56c407f52cfccff482152d6a4e7c8e1e2c4,Rename ellipse to ellipsis to avoid confusionTESTED:  - passed opensource_build  - passed non-prefailing unit testsChange: 127350891,1,Rename Variable,,
36ab34a39bbf56c190899f9819fe10ebd8fe7b2d,2016-06-11T09:04:03Z,https://github.com/tensorflow/tensorflow/commit/36ab34a39bbf56c190899f9819fe10ebd8fe7b2d,Refactored a few resizing opsNew function added: `_assert`Run time checks added: `pad_to_bounding_box` `crop_to_bounding_box` `resize_with_crop_or_pad`,1,Rename Variable,,
f412579ec4fe1fff1ea6ee58c6f0e9f81c8840c2,2016-03-31T11:32:45Z,https://github.com/tensorflow/tensorflow/commit/f412579ec4fe1fff1ea6ee58c6f0e9f81c8840c2,"clean up _propagate, better way to reuse variables, don't depends on input and output of the cell, updated tests",1,Rename Variable,,
fbe67738bd2f16563d152ca0bd87429d5f0b4478,2016-03-25T18:47:15Z,https://github.com/tensorflow/tensorflow/commit/fbe67738bd2f16563d152ca0bd87429d5f0b4478,Move some clipping operations to the same devices as the variables.  This reduces unnecessary copying.Change: 118224298,1,Rename Variable,,
4bc8285bb65da03862f4131bf7b4df6fe32de560,2016-03-22T20:47:57Z,https://github.com/tensorflow/tensorflow/commit/4bc8285bb65da03862f4131bf7b4df6fe32de560,Code cleanups as per style conventions.Change: 117859536,1,Rename Variable,,
b49474d2794a86b4f4e27aefb0998e1c7734135b,2016-03-21T22:58:37Z,https://github.com/tensorflow/tensorflow/commit/b49474d2794a86b4f4e27aefb0998e1c7734135b,"Rename RunOutputs -> RunMetadata proto.Reason: it can be confusing to have session.run(ops, run_outputs=...) as users might get confused that run_outputs contains the outputs of the ops that are passed.Or in the C++ API it is even more confusing since we have Session.Run(..., std::vector<Tensor>* outputs, RunOutputs* run_outputs)Change: 117764542",1,Rename Variable,,
201b37589f0dbbdf938eaf5c0d1c40d416032698,2016-02-29T12:01:07Z,https://github.com/tensorflow/tensorflow/commit/201b37589f0dbbdf938eaf5c0d1c40d416032698,replaced an unused parameter with `_`,1,Rename Variable,,
6f2fd6647f9c55be95ee5ca9124cad9b22c072a7,2016-02-08T21:57:00Z,https://github.com/tensorflow/tensorflow/commit/6f2fd6647f9c55be95ee5ca9124cad9b22c072a7,Rename the parameter of wrapper function consistently with its docs and the original one.This fixes the mismatch between parameter variable `dev` andits documentation `device_name_or_function`.,1,Rename Variable,,
4f07837840756dba221eb1d150325d7bc61f654a,2015-12-17T01:56:35Z,https://github.com/tensorflow/tensorflow/commit/4f07837840756dba221eb1d150325d7bc61f654a,"s/name/scope/ so it does not collide with the ""name"" param, and remove unused import.Change: 110411627",1,Rename Variable,,
0d6e2f2a424fccf3ef98ea8a03b5b5e708c03d84,2023-02-09T01:42:14Z,https://github.com/keras-team/keras/commit/0d6e2f2a424fccf3ef98ea8a03b5b5e708c03d84,renaming a couple variables correctly this time,1,Rename Variable,,
41fe49bfaaace3bc482bac7a2598c5db8d4385c0,2023-01-25T07:25:54Z,https://github.com/keras-team/keras/commit/41fe49bfaaace3bc482bac7a2598c5db8d4385c0,"formatted, renamed 'cell' to '{layer}_cell', changed to self.assertEqual using lists",1,Rename Variable,,
70f7fb6789e1a7e030737a46847b24b892965e4e,2022-07-03T14:08:35Z,https://github.com/keras-team/keras/commit/70f7fb6789e1a7e030737a46847b24b892965e4e,"Rename ignore_index to ignore_label, update docs",1,Rename Variable,,
372515ca4540d99eece842ab0b56d13eedf37b7c,2021-08-24T22:51:17Z,https://github.com/keras-team/keras/commit/372515ca4540d99eece842ab0b56d13eedf37b7c,"Rename references to ""K"" as ""backend"" for consistency.  PiperOrigin-RevId: 392765629",1,Rename Variable,,
644b84faad19794bcd309634af2320fc2c436fee,2021-06-20T20:35:06Z,https://github.com/keras-team/keras/commit/644b84faad19794bcd309634af2320fc2c436fee,Rename parameter & docstrings,1,Rename Variable,,
be8468411ab57083a83214ea3593be7917165404,2021-06-18T05:15:05Z,https://github.com/keras-team/keras/commit/be8468411ab57083a83214ea3593be7917165404,PR #43417: Fixes #42872: map_to_outputs_names always returns a copy  Imported from GitHub PR https://github.com/tensorflow/tensorflow/pull/43417  This PR always returns a copy to ensure that any change made to `struct` after calling this function does not propagate to the original `struct` which leads to undesired behavior. The PR fixes #42872 (code snipped to reproduce the bug also present there) Copybara import of the project:  -- 3002ea588650ac59233220f87cef7b7eb56d52a2 by C. Wick <wick.chr@gmail.com>:  Fixes #42872: map_to_outputs_names always returns a copy  PiperOrigin-RevId: 380115199,1,Rename Variable,,
36098bf0d7ca1e8285f63963130877746dc2809d,2019-06-25T17:28:53Z,https://github.com/keras-team/keras/commit/36098bf0d7ca1e8285f63963130877746dc2809d,Rename lr to learning_rate in optimizers,1,Rename Variable,,
33902e53eb7312fbf2f17b7b700bdb7683441a24,2018-10-04T17:14:36Z,https://github.com/keras-team/keras/commit/33902e53eb7312fbf2f17b7b700bdb7683441a24,Refactor keras/engine/training.py and keras/engine/training_arrays.py (#11226)  Make fit_loop function easy to read and understand.,1,Rename Variable,,
5aa3f044a2c530ddfaefb82e17fe5aa22a8570dd,2017-12-14T19:05:38Z,https://github.com/keras-team/keras/commit/5aa3f044a2c530ddfaefb82e17fe5aa22a8570dd,"Rename ""nb_classes"" to ""num_classes"" (#8787)",1,Rename Variable,,
370065795e2c8a1c5cc9f14a0e8fdaa7a27d46d3,2017-11-15T05:55:09Z,https://github.com/keras-team/keras/commit/370065795e2c8a1c5cc9f14a0e8fdaa7a27d46d3,Rename classes=>num_classes (#8489),1,Rename Variable,,
3fa689f1daca66e5ae98a43796b40be402e56531,2017-10-24T22:26:13Z,https://github.com/keras-team/keras/commit/3fa689f1daca66e5ae98a43796b40be402e56531,"Rename random_seed => seed (#8235)  Rename random_seed => seed for consistency with the rest of the code. Maybe resolves https://github.com/fchollet/keras/issues/8227, although maybe GeneratorEnqueuer.seed should be eliminated altogether, because currently it's not used anywhere in Keras code.",1,Rename Variable,,
035c814b13b6fa64ae9eb7f0264ce8a0ac84264f,2017-10-20T18:36:48Z,https://github.com/keras-team/keras/commit/035c814b13b6fa64ae9eb7f0264ce8a0ac84264f,Rename X=>x (#8194),1,Rename Variable,,
a45b0704a4ce75b85ae8d58210a816f2791105b7,2017-10-12T21:14:46Z,https://github.com/keras-team/keras/commit/a45b0704a4ce75b85ae8d58210a816f2791105b7,Rename num_class => num_classes (#8127),1,Rename Variable,,
ef4f0adffcc1f3ed9307e237411d53beae0d567f,2017-10-12T18:46:32Z,https://github.com/keras-team/keras/commit/ef4f0adffcc1f3ed9307e237411d53beae0d567f,Rename num_class => num_classes (#8120),1,Rename Variable,,
52592d45a5fb15c76445d7c7f2e14e33168ad3fd,2017-07-31T05:13:12Z,https://github.com/keras-team/keras/commit/52592d45a5fb15c76445d7c7f2e14e33168ad3fd,Replace the reserved word `input` with `inputs` (#7474),1,Rename Variable,,
fa3b17cd9622cad0f34da4ed6c3d69515033ee86,2016-11-10T01:33:31Z,https://github.com/keras-team/keras/commit/fa3b17cd9622cad0f34da4ed6c3d69515033ee86,Minor code cleanup,1,Rename Variable,,
8a717f5b6c709cfd521548fc525f2c20c2b6b78f,2016-05-16T18:08:00Z,https://github.com/keras-team/keras/commit/8a717f5b6c709cfd521548fc525f2c20c2b6b78f,rename z_log_sigma to z_log_std to match z_mean (which is not z_mu) (#2729),1,Rename Variable,,
da57a530f985e1eccd8dd3899614ac4dd5c78928,2016-04-30T23:38:23Z,https://github.com/keras-team/keras/commit/da57a530f985e1eccd8dd3899614ac4dd5c78928,"""total_loss"" -> ""loss""",1,Rename Variable,,
cd2e36392c93f86ade4bad04a8fb339546ac8ae8,2016-02-04T01:52:05Z,https://github.com/keras-team/keras/commit/cd2e36392c93f86ade4bad04a8fb339546ac8ae8,"Rename ""params"" to ""trainable_weights""",1,Rename Variable,,
b864fa974b00e63a200568667ce151eba8204ebd,2015-12-08T14:06:01Z,https://github.com/keras-team/keras/commit/b864fa974b00e63a200568667ce151eba8204ebd,Renamed local variables in graph model test to fit into test_models.py,1,Rename Variable,,
c1a43df9bbddca535a3847b382b38b2048c864bd,2023-02-09T01:36:41Z,https://github.com/keras-team/keras/commit/c1a43df9bbddca535a3847b382b38b2048c864bd,simplifying some logic and renaming a couple variables,1,Rename Variable,Expression,
0ff700abccc71ceb0794ddc8e77945e178f10599,2017-10-20T18:01:30Z,https://github.com/keras-team/keras/commit/0ff700abccc71ceb0794ddc8e77945e178f10599,Simplify by using sparse_categorical_crossentropy (#8202),1,Rename Variable,,
f5e4c9cff9882331fa0332ff4b26155620454ea1,2022-01-28T06:00:28Z,https://github.com/keras-team/keras/commit/f5e4c9cff9882331fa0332ff4b26155620454ea1,Copy text utils from keras_preprocessing directly into core keras  PiperOrigin-RevId: 424783358,1,Rename Variable,,
66f2613416787a4746c14243d92672b275d82123,2017-02-06T22:46:22Z,https://github.com/keras-team/keras/commit/66f2613416787a4746c14243d92672b275d82123,Refactor theano backend conv postprocessing,1,Rename Variable,,
60927c5d5235422bf674ef2a9b94db58d02e5858,2021-10-07T06:31:17Z,https://github.com/keras-team/keras/commit/60927c5d5235422bf674ef2a9b94db58d02e5858,Refactored code based on PR comments.,1,Rename Variable,,
0577043d940ddb207bda0befab8fd66fc6704b3b,2023-05-15T23:15:01Z,https://github.com/pytorch/pytorch/commit/0577043d940ddb207bda0befab8fd66fc6704b3b,"Rename minpybind namespace from py to mpy (#101410)  Signed-off-by: Edward Z. Yang <ezyang@meta.com> Pull Request resolved: https://github.com/pytorch/pytorch/pull/101410 Approved by: https://github.com/Skylion007, https://github.com/zou3519",1,Rename Variable,,
17e7079aa2caabddf900f154b5c8032fdebcce34,2019-09-05T22:07:11Z,https://github.com/pytorch/pytorch/commit/17e7079aa2caabddf900f154b5c8032fdebcce34,"rename 'mobile' to 'static_dispatch' (#25695)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/25695Rename codegen variables to better reflect its semantics.As we are going to change other parts of codegen for mobile build, e.g.autograd, it would be more clear to use more specific names instead ofcalling everything 'mobile'.Test Plan: - will check CIDifferential Revision: D17202732Pulled By: ljk53fbshipit-source-id: b2953c0914f25f9a1de00be89a09a6372cc5b614",1,Rename Variable,,
2037746e8d156aec2cd20475485a7c0ae8c40cde,2023-01-23T15:56:48Z,https://github.com/pytorch/pytorch/commit/2037746e8d156aec2cd20475485a7c0ae8c40cde,"[inductor] Rename aot_inductor_debug to aot_eager_decomp_partition (#92314)  Summary: To make the naming more explicit,   aot eager + decomposition + min_cut partition  Pull Request resolved: https://github.com/pytorch/pytorch/pull/92314 Approved by: https://github.com/mlazos",1,Rename Variable,,
2076a2ffa7b12a7c0bb41ddd9e3b038662f56120,2023-06-14T16:14:49Z,https://github.com/pytorch/pytorch/commit/2076a2ffa7b12a7c0bb41ddd9e3b038662f56120,[DDP] Rename state_dict var to ddp_state (#103282)  This name is confusing in the context that it is just a dictionary used to pass state to DDP backward pass.  Differential Revision: [D46580516](https://our.internmc.facebook.com/intern/diff/D46580516/) Pull Request resolved: https://github.com/pytorch/pytorch/pull/103282 Approved by: https://github.com/awgu,1,Rename Variable,,
21ad978d4f071dbd4092f1ead07fe42a13deea2b,2021-07-07T22:27:16Z,https://github.com/pytorch/pytorch/commit/21ad978d4f071dbd4092f1ead07fe42a13deea2b,"[sparsity] rename `sparsity_pattern` to `sparse_block_shape` (#59898)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/59898  In `weight_norm_sparsifier`, the name of the argument `sparsity_pattern` is not intuitive for an argument describing the shape of the sparse block. It has been changed to `sparse_block_shape`.  Test Plan: `buck test mode/dev-nosan //caffe2/test:ao -- TestWeightNormSparsifier` https://pxl.cl/1LhRM  Reviewed By: z-a-f  Differential Revision: D29077045  fbshipit-source-id: 0cf9c5387d41ca8e839ee050d71f4fe477374143",1,Rename Variable,,
31888b2e7749e4082a151151bb7010d1d28f2183,2020-10-08T23:11:18Z,https://github.com/pytorch/pytorch/commit/31888b2e7749e4082a151151bb7010d1d28f2183,"[quant][pyper] Rename the sparse argument for embedding_bag ops (#46003)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/46003sparse is confusing because itt is used in training for sparse gradientsTest Plan: Imported from OSSReviewed By: radkris-git, qizzzhDifferential Revision: D24178248fbshipit-source-id: 0a2b595f3873d33b2ce25839b6eee31d2bfd3b0d",1,Rename Variable,,
31d136c81f8e6921f30abcdcff8bddb3f5054671,2021-06-08T17:04:20Z,https://github.com/pytorch/pytorch/commit/31d136c81f8e6921f30abcdcff8bddb3f5054671,[DDP] Rename the member divFactor_ as div_factor for naming consistency in reducer (#59523)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/59523  Should use snake case instead of camel case for the consistency. ghstack-source-id: 130759655  Test Plan: buck test mode/dev-nosan caffe2/test/distributed:distributed_nccl_fork -- test_ddp_grad_div_uneven_inputs  Reviewed By: cbalioglu  Differential Revision: D28922896  fbshipit-source-id: e04298284a78b2e71b562f790a878731962f873a,1,Rename Variable,,
344abd56f913329a877f3e840fb2b9f3f06700e6,2020-10-22T23:46:44Z,https://github.com/pytorch/pytorch/commit/344abd56f913329a877f3e840fb2b9f3f06700e6,"[CI][IOS] Rename the IOS_VERSION (#46645)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/46645### SummaryThe IOS_VERSION should be renamed to XCODE_VERSION### Test- CircleCITest Plan: Imported from OSSReviewed By: seemethere, linbinyuDifferential Revision: D24459598Pulled By: xta0fbshipit-source-id: 9dcba973cc57aa44f8fd4151daf5d89c8da61c67",1,Rename Variable,,
3a12b16fb01ea3a37fd2b709ce67041850306ef9,2023-02-10T08:19:41Z,https://github.com/pytorch/pytorch/commit/3a12b16fb01ea3a37fd2b709ce67041850306ef9,"Renamed passes to options in torch.compile (#94500)  @jansel expressed a preference for this (as most of our options are *not* passes), and I agree. I also think that `fullgraph` could be changed, but I don't know what I'd change it to. I considered `strict`, but some folks objected to that.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/94500 Approved by: https://github.com/voznesenskym, https://github.com/soumith, https://github.com/jansel",1,Rename Variable,,
3b7c05b11b4d80923521755d7c4041a5bfed114f,2020-07-17T18:27:07Z,https://github.com/pytorch/pytorch/commit/3b7c05b11b4d80923521755d7c4041a5bfed114f,"[JIT] Replace uses of ""blacklist"" in gen_unboxing_wrappers.py (#41454)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/41454**Test Plan**Continuous integration (if this file is still used).**Fixes**This commit partially addresses #41443.Test Plan: Imported from OSSReviewed By: eellisonDifferential Revision: D22544271Pulled By: SplitInfinityfbshipit-source-id: 84a4d552745fe5163b2e3200103c3b1f2a9ffb2a",1,Rename Variable,,
4d494986af5201a0c487a9b7f3c68cfa6c4e28d0,2022-12-13T14:45:18Z,https://github.com/pytorch/pytorch/commit/4d494986af5201a0c487a9b7f3c68cfa6c4e28d0,"[functorch] Refactor life handle storage (#90317)  A ""life handle"" is a pointer-to-boolean that says whether or not a TensorWrapper is alive. A TensorWrapper is alive if we are currently inside of its corresponding transform. An Interpreter is alive if we are currently inside of its corresponding transform. I.e., for vmap(f)(x), the BatchedTensor(x, level=1) is alive inside of the execution of f; and the corresponding VmapInterpreter is alive inside of f.  Previously, there was a global map of level to life handle. It is possible to get into a state where we have multiple levels that refer to different Interpreters (if the implementation of an operator calls into functorch) and that messes up the global map.  This PR changes it so that - every Interpreter holds a life handle that says if it is alive - to construct a TensorWrapper, one must either (a) directly pass it a life handle, or (b) one must create the TensorWrapper when the corresponding Interpreter is on the stack (and we will automatically grab the life handle by indexing into the DynamicLayerStack with the level)  (a) is more robust so I changed most of our C++ callsites to do that. (b) feels a bit hacky to me, but it seems fine for now: - It'll raise a nice error message if the interpreter isn't on the stack - all of our Python callsites already follow this convention (we construct TensorWrappers after pushing the Interpreter onto the stack).  The alternative to (b) is that we always do (a), which we can do in the future if (b) runs us into any problems.  Test Plan: - all functorch tests Pull Request resolved: https://github.com/pytorch/pytorch/pull/90317 Approved by: https://github.com/samdow",1,Rename Variable,,
4f09461d24f2e10fe4157b77bb9f0c2afb7ee542,2017-04-19T17:06:46Z,https://github.com/pytorch/pytorch/commit/4f09461d24f2e10fe4157b77bb9f0c2afb7ee542,Rename sparse tensor contiguous() to coalesce(),1,Rename Variable,,
4f4e3a0f15d4d3df7e3a3783eef0b89d615ded15,2020-07-17T18:27:07Z,https://github.com/pytorch/pytorch/commit/4f4e3a0f15d4d3df7e3a3783eef0b89d615ded15,"[JIT] Replace uses of ""whitelist"" in jit/_script.py (#41458)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/41458**Test Plan**Continuous integration.**Fixes**This commit partially fixes #41443.Test Plan: Imported from OSSReviewed By: suoDifferential Revision: D22544273Pulled By: SplitInfinityfbshipit-source-id: 8148e5338f90a5ef19177cf68bf36b56926d5a6c",1,Rename Variable,,
5095332ab9ee8671c7daf4a9e16a78659316965f,2021-03-04T13:34:18Z,https://github.com/pytorch/pytorch/commit/5095332ab9ee8671c7daf4a9e16a78659316965f,"Minor cleanup of interpolate microbenchmarkSummary: Minor cleanup, addresses comments from https://www.internalfb.com/diff/D26780116 (https://github.com/pytorch/pytorch/commit/1559fa6a5c10705d5b1380ad782f3f602e263acc)Test Plan:```? vision buck run //caffe2/benchmarks/operator_benchmark/pt:interpolate_test -- --tag_filter shortParsing buck files: finished in 0.6 secBuilding: finished in 6.2 sec (100%) 10951/10951 jobs, 0 updated  Total time: 6.9 sec/data/users/nicolashug/fbsource/fbcode/buck-out/dev/gen/caffe2/benchmarks/operator_benchmark/pt/interpolate_test#link-tree/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses  import imp# ----------------------------------------# PyTorch/Caffe2 Operator Micro-benchmarks# ----------------------------------------# Tag : short# Benchmarking PyTorch: interpolate# Mode: Eager# Name: interpolate_input_size(1,3,60,40)_output_size(24,24)_channels_lastTrue_modenearest# Input: input_size: (1, 3, 60, 40), output_size: (24, 24), channels_last: True, mode: nearestForward Execution Time (us) : 1346.156# Benchmarking PyTorch: interpolate# Mode: Eager# Name: interpolate_input_size(1,3,60,40)_output_size(24,24)_channels_lastTrue_modelinear# Input: input_size: (1, 3, 60, 40), output_size: (24, 24), channels_last: True, mode: linearForward Execution Time (us) : 1283.784# Benchmarking PyTorch: interpolate# Mode: Eager# Name: interpolate_input_size(1,3,60,40)_output_size(24,24)_channels_lastTrue_modebicubic# Input: input_size: (1, 3, 60, 40), output_size: (24, 24), channels_last: True, mode: bicubicForward Execution Time (us) : 4769.578# Benchmarking PyTorch: interpolate# Mode: Eager# Name: interpolate_input_size(1,3,60,40)_output_size(24,24)_channels_lastFalse_modenearest# Input: input_size: (1, 3, 60, 40), output_size: (24, 24), channels_last: False, mode: nearestForward Execution Time (us) : 982.910# Benchmarking PyTorch: interpolate# Mode: Eager# Name: interpolate_input_size(1,3,60,40)_output_size(24,24)_channels_lastFalse_modelinear# Input: input_size: (1, 3, 60, 40), output_size: (24, 24), channels_last: False, mode: linearForward Execution Time (us) : 1182.191# Benchmarking PyTorch: interpolate# Mode: Eager# Name: interpolate_input_size(1,3,60,40)_output_size(24,24)_channels_lastFalse_modebicubic# Input: input_size: (1, 3, 60, 40), output_size: (24, 24), channels_last: False, mode: bicubicForward Execution Time (us) : 3545.873# Benchmarking PyTorch: interpolate# Mode: Eager# Name: interpolate_input_size(1,3,600,400)_output_size(240,240)_channels_lastTrue_modenearest# Input: input_size: (1, 3, 600, 400), output_size: (240, 240), channels_last: True, mode: nearestForward Execution Time (us) : 34373.955# Benchmarking PyTorch: interpolate# Mode: Eager# Name: interpolate_input_size(1,3,600,400)_output_size(240,240)_channels_lastTrue_modelinear# Input: input_size: (1, 3, 600, 400), output_size: (240, 240), channels_last: True, mode: linearForward Execution Time (us) : 42248.109# Benchmarking PyTorch: interpolate# Mode: Eager# Name: interpolate_input_size(1,3,600,400)_output_size(240,240)_channels_lastTrue_modebicubic# Input: input_size: (1, 3, 600, 400), output_size: (240, 240), channels_last: True, mode: bicubicForward Execution Time (us) : 405944.286...```Reviewed By: fmassaDifferential Revision: D26782757fbshipit-source-id: 2039e1e6b4fea2b56bb4bcf2a017476f928e4928",1,Rename Variable,,
51ff9ce9974b32ba77dd00241a3dc6357f76ba82,2023-04-13T03:21:06Z,https://github.com/pytorch/pytorch/commit/51ff9ce9974b32ba77dd00241a3dc6357f76ba82,"[Replicate] Simplify code a bit (#98889)  Simplifies the code, such as making self.modules not a list and only a single module.  Differential Revision: [D44899281](https://our.internmc.facebook.com/intern/diff/D44899281/) Pull Request resolved: https://github.com/pytorch/pytorch/pull/98889 Approved by: https://github.com/mrshenli, https://github.com/yhcharles",1,Rename Variable,,
52a970bac9ead58fa4a9c380c7d1b07311eb7e0b,2020-10-22T16:01:06Z,https://github.com/pytorch/pytorch/commit/52a970bac9ead58fa4a9c380c7d1b07311eb7e0b,"Minor cleaning of `test_cuda.py` (#46617)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/46617Sort includes, fix deprecated test warningTest Plan:```buck run mode/dev-nosan //caffe2/test:cuda```Reviewed By: drdarshanDifferential Revision: D24429247fbshipit-source-id: 65f53d7c904032e5c8f8ca45d1d2bb437358ffdd",1,Rename Variable,Remove Dead Code,
5936faee7eb13dbd219d61b576bbc6b884d97073,2021-04-06T20:40:04Z,https://github.com/pytorch/pytorch/commit/5936faee7eb13dbd219d61b576bbc6b884d97073,"[NNAPI] Rename local variable (#54698)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/54698""mf"" was short for memory format, but the concept that this variablerepresents was renamed to ""dim_order"", so rename the variable.Test Plan: Unit testReviewed By: axitkhuranaDifferential Revision: D27536793Pulled By: dreissfbshipit-source-id: 2b31c70da1ff221a7833e67486690fa606f01dea",1,Rename Variable,,
5a3b4dacad897c9f4dd8fe8c3725dff1d6388449,2023-01-16T02:38:10Z,https://github.com/pytorch/pytorch/commit/5a3b4dacad897c9f4dd8fe8c3725dff1d6388449,[FSDP][BE] Rename `prefixed_param_names` -> `fqns` for consolidation (#92028)  Closes https://github.com/pytorch/pytorch/issues/90961. Pull Request resolved: https://github.com/pytorch/pytorch/pull/92028 Approved by: https://github.com/zhaojuanmao,1,Rename Variable,,
6016e4c707a14f2e540baa2f6bf1d068a62740cf,2023-01-22T04:53:03Z,https://github.com/pytorch/pytorch/commit/6016e4c707a14f2e540baa2f6bf1d068a62740cf,[quant][fx][refactor] Rename modules to named_modules (#92575)  Summary: att  Test Plan: python test/test_quantization.py TestQuantizeFx  Reviewers:  Subscribers:  Tasks:  Tags: Pull Request resolved: https://github.com/pytorch/pytorch/pull/92575 Approved by: https://github.com/jcaip,1,Rename Variable,,
607d720be154a44ddb5db20bee4999971cf967f5,2021-07-30T06:10:03Z,https://github.com/pytorch/pytorch/commit/607d720be154a44ddb5db20bee4999971cf967f5,Remove an unused variable  Summary: This is set but never used  Test Plan: NFC  Reviewed By: smeenai  Differential Revision: D30000830  fbshipit-source-id: 702d6f7b844b52bfe696725a6b0a055d494b739a,1,Rename Variable,,
673c25d45a522f2804546de90478b9d844db01fc,2022-12-16T12:16:08Z,https://github.com/pytorch/pytorch/commit/673c25d45a522f2804546de90478b9d844db01fc,[FSDP][Easy] Rename `entry` -> `fsdp_module` to be more descriptive (#90864)  I started refactoring unit tests to use `_get_fsdp_states()` instead of `FullyShardedDataParallel.fsdp_modules()` but realized we should not do that for now. This is just a change I made while doing that. `entry` is not descriptive. Let us explicitly say `fsdp_module`. `for fsdp_module in FSDP.fsdp_modules(module)` is a proper idiom. Pull Request resolved: https://github.com/pytorch/pytorch/pull/90864 Approved by: https://github.com/rohan-varma,1,Rename Variable,,
6df87b2e9bbd63fd4ead973a9b9b858613d09dde,2023-04-18T00:45:39Z,https://github.com/pytorch/pytorch/commit/6df87b2e9bbd63fd4ead973a9b9b858613d09dde,"Rename sym_shapes logger to dynamic (#99335)  This matches the logging with the user facing UX dynamic=True, rather than a new abbreviation that shows up no where else in the codebase.  Signed-off-by: Edward Z. Yang <ezyang@meta.com> Pull Request resolved: https://github.com/pytorch/pytorch/pull/99335 Approved by: https://github.com/Skylion007, https://github.com/mlazos, https://github.com/voznesenskym",1,Rename Variable,,
90977e10ed764c756d36dffeceb78b7104c13687,2021-07-30T01:04:01Z,https://github.com/pytorch/pytorch/commit/90977e10ed764c756d36dffeceb78b7104c13687,Remove an unused variable  Summary: This is defined and then set once but never actually used. Kill it here.  Test Plan: NFC  Reviewed By: smeenai  Differential Revision: D29994983  fbshipit-source-id: 0cb7383b3ec95f1aeed5210974bc95060cf10be5,1,Rename Variable,,
911b8b1bfcfb9371276e3b530e7e04408045bb74,2021-03-25T18:47:54Z,https://github.com/pytorch/pytorch/commit/911b8b1bfcfb9371276e3b530e7e04408045bb74,[package] rename PackageExporter.external to PacakgeExporter.extern_modules (#54601)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/54601This make it consistent with PackageImporter and the on-disk format.Test Plan: Imported from OSSReviewed By: LilyjjoDifferential Revision: D27296915Pulled By: suofbshipit-source-id: a9bc615b1952b6cc4dcba31d4a33932b1fa1a2aa,1,Rename Variable,,
929b91a24d7c78483cf9c0dc434810e640d06a2c,2021-02-10T06:14:11Z,https://github.com/pytorch/pytorch/commit/929b91a24d7c78483cf9c0dc434810e640d06a2c,"ns_eager: rename Logger I/O var names to logger_cls (#51359)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/51359`Logger` is the name of the base Logger class.  It's confusing thatit is also used as a variable name, which can represent this classor its subclasses.  Renaming to `logger_cls` to make it clearer.Test Plan:```python test/test_quantization.py TestEagerModeNumericSuite```Imported from OSSReviewed By: supriyarDifferential Revision: D26149577fbshipit-source-id: a9c12f9446f66e5c683ab054b2a94aeb0cf9cc8a",1,Rename Variable,,
962f3f4864b3e989e3342a6b64112162759102af,2019-01-17T21:39:07Z,https://github.com/pytorch/pytorch/commit/962f3f4864b3e989e3342a6b64112162759102af,Refactor _jit_internal (#16058)Summary:Use qualified names in `jit/__init__.py` to avoid polluting that namespacePull Request resolved: https://github.com/pytorch/pytorch/pull/16058Differential Revision: D13718745Pulled By: driazatifbshipit-source-id: 19d150569c8374541250a961f24f70c3f523de03,1,Rename Variable,,
9fa0e403d6d8dab27662d26abee0fd54d95fdf71,2017-05-07T16:41:16Z,https://github.com/pytorch/pytorch/commit/9fa0e403d6d8dab27662d26abee0fd54d95fdf71,Replace retain_variables with retain_graph,1,Rename Variable,,
a3a32c1be02cf7ea4b5a8928450f6bd3702548d9,2023-06-14T16:14:50Z,https://github.com/pytorch/pytorch/commit/a3a32c1be02cf7ea4b5a8928450f6bd3702548d9,"[DDP] Rename num_iterations -> num_forward_calls (#103283)  This more accurately represents what we're counting. At iteration is a forward + backward call, but here we're just counting forward calls. This makes things less confusing in future diffs where we support DDP static graph multiple forwards.  Differential Revision: [D46580601](https://our.internmc.facebook.com/intern/diff/D46580601/) Pull Request resolved: https://github.com/pytorch/pytorch/pull/103283 Approved by: https://github.com/awgu",1,Rename Variable,,
a53cde09b522d1b05e806f61fe7349b924722ed2,2017-06-05T16:39:37Z,https://github.com/pytorch/pytorch/commit/a53cde09b522d1b05e806f61fe7349b924722ed2,Rename masked_copy_ to masked_scatter_,1,Rename Variable,,
a6f60cf4f0caf5422c4a46920cbe96d1276fda09,2021-05-03T18:34:23Z,https://github.com/pytorch/pytorch/commit/a6f60cf4f0caf5422c4a46920cbe96d1276fda09,[12/n] Rename last_keep_alives to last_heartbeats in _RendezvousState (#57141)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/57141Per feedback this PR renames `last_keep_alives` to `last_heartbeats` in `_RendezvousState`.ghstack-source-id: 127629442Test Plan: Run the updated unit tests.Reviewed By: tierexDifferential Revision: D28058948fbshipit-source-id: 0db12eac56a47a426a7a48fb5c93ac6a08b0d22e,1,Rename Variable,,
a7749ae177aa84c60815c869a20772fab7693293,2023-01-04T18:32:49Z,https://github.com/pytorch/pytorch/commit/a7749ae177aa84c60815c869a20772fab7693293,"[reland] rename DisableTorchFunction to DisableTorchFunctionSubclass (#88218) (#89221)  Summary: First half of #87990. This doesn't change any of the behavior and is just a rename  #88218 got reverted for internal breakages. This is the reland of started from internal  Differential Revision: D41268423  LaMa Project: L1098534  Pull Request resolved: https://github.com/pytorch/pytorch/pull/89221 Approved by: https://github.com/meliy-meyada, https://github.com/zou3519",1,Rename Variable,,
adc21c6db278829797161ff23a92e40068f0db5c,2020-10-05T18:41:12Z,https://github.com/pytorch/pytorch/commit/adc21c6db278829797161ff23a92e40068f0db5c,"Rename jobs and cli switches for testing GraphExecutor configurations to something a little bit more sensical. (#45715)Summary:Rename jobs for testing GraphExecutor configurations to something a little bit more sensical.Pull Request resolved: https://github.com/pytorch/pytorch/pull/45715Reviewed By: ezyang, anjali411Differential Revision: D24114344Pulled By: Krovatkinfbshipit-source-id: 89e5f54aaebd88f8c5878e060e983c6f1f41b9bb",1,Rename Variable,,
afaad94fed963e93552cc12b4b2dd6de21c11e3e,2017-06-07T20:22:34Z,https://github.com/pytorch/pytorch/commit/afaad94fed963e93552cc12b4b2dd6de21c11e3e,Rename autograd keepdim tests that now default to True.,1,Rename Variable,,
b1472a173a7627092bdbba2b34fbb301e9169a7b,2017-01-25T00:19:32Z,https://github.com/pytorch/pytorch/commit/b1472a173a7627092bdbba2b34fbb301e9169a7b,don't hardcode outputs order to work only for lstm + don't pass blob names for parametersSummary:In this diff I stop passing parameters by name and also remove hardcoded output ids which were there specifically for LSTM to work. It also allows to avoid using recurrent_sizes in the backward pass (for forward this is done in D4427688)Using similar technic it should be simple enough to eliminate blob name passing at all. Then we can fix scoping. These can be done in a next diff.Reviewed By: urikzDifferential Revision: D4444614fbshipit-source-id: 3580a76365502b9f2f09e3d8b7e78084ca739f00,1,Rename Variable,,
b2da9fd2207c62fd0c99c53c1b3451ba86e9db0b,2018-03-25T13:24:32Z,https://github.com/pytorch/pytorch/commit/b2da9fd2207c62fd0c99c53c1b3451ba86e9db0b,"[distributions] Rename .params to .arg_constraints, fix logic (#5989)",1,Rename Variable,,
b9049a7f1144d01c51c0f68d982f3d5d4fa910fc,2023-03-28T01:46:43Z,https://github.com/pytorch/pytorch/commit/b9049a7f1144d01c51c0f68d982f3d5d4fa910fc,"[FSDP][6/N] Rename param/module name helpers for clarity (#97666)  This is an easy PR. It has some remaining local changes that I had that I felt clarified naming. - `_param_fqns` -> `_param_name_infos` since it returns a tuple of `fqn, param_name, module_name`, not only `fqn`. (similarly for `_shared_param_fqns` -> `_shared_param_name_infos`) - nit: `parameter_module_names` -> `param_module_names` for consistency since we almost never fully spell out `parameter`. (similarly for `shared_parameter_module_names` -> `shared_param_module_names`) - nit: `full_fqn` -> `fqn_from_global_root` Pull Request resolved: https://github.com/pytorch/pytorch/pull/97666 Approved by: https://github.com/rohan-varma",1,Rename Variable,,
bbe33532aec4c3c31b5b88f8a18a3e905009b378,2023-02-08T10:41:10Z,https://github.com/pytorch/pytorch/commit/bbe33532aec4c3c31b5b88f8a18a3e905009b378,Rename DynamicShapeVariable to SymNodeVariable cause thats what it is (#94152)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/94152 Approved by: https://github.com/ezyang,1,Rename Variable,,
bc92444b34dfbe38419a1c8dbea9a7fc3284abe2,2022-12-30T22:49:17Z,https://github.com/pytorch/pytorch/commit/bc92444b34dfbe38419a1c8dbea9a7fc3284abe2,"Rename `torchtriton` (#91539)  to `pytorch-triton` Pull Request resolved: https://github.com/pytorch/pytorch/pull/91539 Approved by: https://github.com/seemethere, https://github.com/soumith",1,Rename Variable,,
d56adb1b54c8dba3d13ecae93f81c945325bc1c7,2023-04-21T16:58:35Z,https://github.com/pytorch/pytorch/commit/d56adb1b54c8dba3d13ecae93f81c945325bc1c7,"[quant][pt2e][refactor] Cleanup the logic for deciding whether to insert observer/fq or not (#99220)  Summary: Previously we have two places we need to decide whether to insert observer or fake quantizer or not: (1) input arguments of a node (2) output of a node, and right now we have separate code to do this in this PR, the logic is unified in `_needs_obs_or_fq` helper function that takes the target_dtype and is_dynamic from previous output and target_dtype and is_dynamic for the current Tensor we are looking at  let's use an example for conv node: ``` conv = convolution(input, weight, bias, ...) ```  let's say we have `input_node` object for argument `input`, and `conv_node` for `conv` node in the graph  (1) input arguments, e.g. `input` the target_dtype/is_dynamic from previous output is the node that produces `input`, we get this from input_node.meta[""target_dtype_info""][""output_act_obs_or_fq""]  the taregt_dtype/is_dynamic for the current argument `input`, comes from conv_node.meta[""target_dtype_info""][""input_act_obs_or_fq""] similarly for weight it comes from conv_node.meta[""target""][""weightobs_or_fq""] etc.  (2) output for conv node the target_dtype/is_dynamic from previous output will be the floating point output from the fp32 convolution operator, so it is hardcoded to be (torch.float, False), however, technically we should get this from node.meta[""val""], but since the current code base is shared by fx graph mode quantization and pytorch 2.0 export quantization, we cannot do that, we can revisit after we decide to deprecate fx graph mode quantization  the target_dtype/is_dynamic for the current output comes from conv_node.meta[""target_dtype_info""][""output_act_obs_or_fq""]  there is one caveat here about dynamic quantization, that is explained in the comment, so I won't repeat here  Note: also fixed some places in `_get_arg_target_dtype_as_input_to_node` and `_get_arg_target_is_dynamic_as_input_to_node` to make sure ""not specified"" == specifying a fp32 placeholder observer as well  Next: we can merge the two get target dtype and get is_dynamic function to reduce code duplication  Test Plan: python test/test_quantization.py TestQuantizeFx python test/test_quantization.py TestQuantizeFxOps python test/test_quantization.py TestQuantizeFxModels python test/test_quantization.py TestQuantizePT2E python test/test_quantization.py TestQuantizePT2EModels  Reviewers:  Subscribers:  Tasks:  Tags:  Differential Revision: [D45167585](https://our.internmc.facebook.com/intern/diff/D45167585) Pull Request resolved: https://github.com/pytorch/pytorch/pull/99220 Approved by: https://github.com/kimishpatel",1,Rename Variable,,
d9a7c758e1e9c4f08091a64e01b937dfd8c1e50d,2021-03-27T18:50:04Z,https://github.com/pytorch/pytorch/commit/d9a7c758e1e9c4f08091a64e01b937dfd8c1e50d,Rename linalg.det test so that it generates a valid method name (#54704)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/54704See https://github.com/pytorch/pytorch/issues/54607Signed-off-by: Edward Z. Yang <ezyang@fb.com>Test Plan: Imported from OSSReviewed By: mruberryDifferential Revision: D27338809Pulled By: ezyangfbshipit-source-id: 52a246a8b8743b8a887403c02df6271ba6db3617,1,Rename Variable,,
d9d50f80c7f162c9c6c6d95c0b51f9e6fd8fccee,2017-06-10T16:33:26Z,https://github.com/pytorch/pytorch/commit/d9d50f80c7f162c9c6c6d95c0b51f9e6fd8fccee,Rename arguments to distributed collectives,1,Rename Variable,,
db6bd9d60bc62afec8beb1428a1afdb8837e2e79,2020-09-01T18:40:33Z,https://github.com/pytorch/pytorch/commit/db6bd9d60bc62afec8beb1428a1afdb8837e2e79,"rename input argunment `interested-folder` to `interest-only` -- be consistent with other arguments (#43889)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/438891. rename input argunment `interested-folder` to `interest-only` -- be consistent with `run-only`, `coverage-only` and be shortedTest Plan: Test on devserver and linux docker.Reviewed By: malfetDifferential Revision: D23417338fbshipit-source-id: ce9711e75ca3a1c30801ad6bd1a620f3b06819c5",1,Rename Variable,,
ddd916c21010c69b6015edd419d62f28664373a7,2021-08-03T17:12:16Z,https://github.com/pytorch/pytorch/commit/ddd916c21010c69b6015edd419d62f28664373a7,"[quant][refactor] Return the models in checkGraphModeFxOp for further checking (#62487)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/62487  checkGraphModeFxOp is our utility test function to quantize a given model with FX Graph Mode Quantization and checks whether the result model contains expected ops, previously it only returns a result on the sample data for the quantized model, this PR chagnes it to return prepared, quantized, quantized_reference models together with the result for quantized models.  Test Plan: python test/test_quantization.py TestQuantizeFx python test/test_quantization.py TestQuantizeFxOps  Imported from OSS  Reviewed By: iramazanli  Differential Revision: D30053981  fbshipit-source-id: 31fbce48d138261d0b00ba24e1427fd0c6208990",1,Rename Variable,,
e9d7d37ad0a920a763bbabf13ea3ba7fbd3e939d,2020-12-16T01:12:01Z,https://github.com/pytorch/pytorch/commit/e9d7d37ad0a920a763bbabf13ea3ba7fbd3e939d,[FX] Rename Node._uses and refactor Node.all_input_nodes (#49415)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/49415Test Plan: Imported from OSSReviewed By: zdevitoDifferential Revision: D25565341Pulled By: jamesr66afbshipit-source-id: 2290ab62572632788809ba16319578bf0c0260ee,1,Rename Variable,,
f9d2600ce207adba16e161aa24de321bfa137abe,2023-02-02T17:20:25Z,https://github.com/pytorch/pytorch/commit/f9d2600ce207adba16e161aa24de321bfa137abe,[Dynamo] Rename `GuardBuilder.guarded_code` -> `check_fn_manager` (#93934)  I was reading Dynamo code to learn and thought to clarify this naming to remove the `TODO`.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/93934 Approved by: https://github.com/ezyang,1,Rename Variable,,
bc10677fcb3d67c5da8ee5d5db4cb661e9079f2d,2019-05-28T19:19:22Z,https://github.com/pytorch/pytorch/commit/bc10677fcb3d67c5da8ee5d5db4cb661e9079f2d,Some name and variable cleanup (#20861)Summary:As a part of https://github.com/pytorch/pytorch/pull/20580 I noticed that we had some unusual variable naming in `summary.py`. This cleans it up and also removes some variables that weren't being used.I'll wait until we have an `add_custom_scalars` test to land this.cc lanpa natalialunovaPull Request resolved: https://github.com/pytorch/pytorch/pull/20861Differential Revision: D15503420Pulled By: orionrfbshipit-source-id: 86d105a346198a1ca543d1c5d297804402ab5a0c,1,Rename Variable,,
c1fa74b2d7606c38bd17e7cb0001b5cff80550ee,2020-07-09T19:31:27Z,https://github.com/pytorch/pytorch/commit/c1fa74b2d7606c38bd17e7cb0001b5cff80550ee,[quant][refactor] test_only_eval_fn (#41078)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/41078Test Plan: Imported from OSSDifferential Revision: D22420699fbshipit-source-id: cf105cd41d83036df65c6bb3147cc14aaf755897,1,Rename Variable,,
e4c9d75008f5a8d5cd44c6b4e24d1e90bb81c598,2019-03-07T18:06:17Z,https://github.com/pytorch/pytorch/commit/e4c9d75008f5a8d5cd44c6b4e24d1e90bb81c598,"- refactoring serialization of ONNX initializers to be name-based (#17420)Summary:Currently, serialization of model parameters in ONNX export depends on the order in which they are stored in a container (`list` on Python side and `std::vector` on C++ side). This has worked fine till now, but if we need to do any pass on that graph that mutates the parameter list, then strictly order-based serialization may not work.This PR is the first in a set to bring in more passes (such as constant folding) related to ONNX export. This PR lays the groundwork by moving the serialization in ONNX export from order-based to name based approach, which is more amenable to some of the passes.houseroad - As discussed this change uses a map for export, and removes the code from `export.cpp` that relies on the order to compute initializer names.Pull Request resolved: https://github.com/pytorch/pytorch/pull/17420Differential Revision: D14361993Pulled By: houseroadfbshipit-source-id: da93e945d55755c126de06641f35df87d1648cc4",1,Rename Variable,,
ea6c738c8aa05cc6725633ce9567ebe3ae349a95,2019-04-19T13:58:41Z,https://github.com/pytorch/pytorch/commit/ea6c738c8aa05cc6725633ce9567ebe3ae349a95,Rename 'not_differentiable' to 'non_differentiable'. (#19272)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/19272ghimport-source-id: 755e91efa68c5a1c4377a6853f21b3eee3f8cab5Differential Revision: D15003381Pulled By: gchananfbshipit-source-id: 54db27c5c5e65acf65821543db3217de9dd9bdb5,1,Rename Variable,,
0e8565d1d57cfb7f8d1e2c2aa25d824de4c95002,2022-12-30T06:56:44Z,https://github.com/pytorch/pytorch/commit/0e8565d1d57cfb7f8d1e2c2aa25d824de4c95002,[FSDP][optim_state_dict][8/N] Enable fully_shard optim state_dict save and load (#91234)  **What does this PR do?** This PR refactor `_optim_utils.py` to use `_FSDPState` instead of `FullyShardedDataParallel` class. This change enables the support of optim state_dict for `fully_shard`. Pull Request resolved: https://github.com/pytorch/pytorch/pull/91234 Approved by: https://github.com/rohan-varma,1,Rename Variable,Rename Method,
267641a245ce85094fc02e14812d0fe4025c4129,2020-12-11T02:12:21Z,https://github.com/pytorch/pytorch/commit/267641a245ce85094fc02e14812d0fe4025c4129,"Rename positional and kwarg_only to have flat prefix (#49042)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/49042I want the names positional and kwarg_only to give the unflatrepresentation (e.g., preserving TensorOptionsArguments in thereturned Union).  So I regret my original naming choice whenI moved grouping to model.  This renames them to have flat_ prefixand also adds a flat_non_out argument for cases where you justwant to look at non-out arguments.Signed-off-by: Edward Z. Yang <ezyang@fb.com>Test Plan: Imported from OSSReviewed By: H-HuangDifferential Revision: D25455884Pulled By: ezyangfbshipit-source-id: f923f8881267a3e3e8e9521519412f7cc25034fc",1,Rename Variable,Rename Method,
65d42c9996b6b9778fa2d57352a8d81557d7eb07,2023-05-04T11:37:29Z,https://github.com/scikit-learn/scikit-learn/commit/65d42c9996b6b9778fa2d57352a8d81557d7eb07,MAINT refactor scorer using _get_response_values (#26037)  Co-authored-by: Jérémie du Boisberranger <34657725+jeremiedbb@users.noreply.github.com> Co-authored-by: Adrin Jalali <adrin.jalali@gmail.com>,1,Rename Variable,Rename Method,
19da1e2030f02d28a9f6b95edc94c5812444e9e6,2023-04-02T13:02:04Z,https://github.com/scikit-learn/scikit-learn/commit/19da1e2030f02d28a9f6b95edc94c5812444e9e6,API Replace `n_iter` in `Bayesian Ridge` and `ARDRegression` (#25697)  Co-authored-by: Guillaume Lemaitre <g.lemaitre58@gmail.com>,1,Rename Variable,,
d926ff130f423681681a2c7d420a5a460e88a619,2023-03-02T09:52:07Z,https://github.com/scikit-learn/scikit-learn/commit/d926ff130f423681681a2c7d420a5a460e88a619,MAINT remove np.product and inf/nan aliases in favor of canonical names (#25741),1,Rename Variable,Rename Method,
4acd91d88198c52e457d355018f07dbde7700b56,2023-02-06T15:12:11Z,https://github.com/scikit-learn/scikit-learn/commit/4acd91d88198c52e457d355018f07dbde7700b56,"MAINT Clean-up comments and rename variables in `_middle_term_sparse_sparse_{32, 64}` (#25449)  Co-authored-by: Julien Jerphanion <git@jjerphan.xyz>",1,Rename Variable,,
205f3b76ef8500c90c346c6c6fb6f4e589368278,2022-12-15T08:02:56Z,https://github.com/scikit-learn/scikit-learn/commit/205f3b76ef8500c90c346c6c6fb6f4e589368278,MAINT Remove `_arr` suffixes from `_binary_tree` (#25106)    Co-authored-by: Julien Jerphanion <git@jjerphan.xyz> Co-authored-by: Olivier Grisel <olivier.grisel@ensta.org>,1,Rename Variable,,
7134e4183cc427b7ff95ed40ce8912312f9983d6,2022-09-16T11:46:53Z,https://github.com/scikit-learn/scikit-learn/commit/7134e4183cc427b7ff95ed40ce8912312f9983d6,API Rename OneHotEncoder option sparse to sparse_output (#24412)  Co-authored-by: Christian Lorentzen <lorentzen.ch@gmail.com> Co-authored-by: Jérémie du Boisberranger <34657725+jeremiedbb@users.noreply.github.com>,1,Rename Variable,,
306608e622bb3fb55095a97405b9ef0f1ad901d9,2022-09-09T09:21:31Z,https://github.com/scikit-learn/scikit-learn/commit/306608e622bb3fb55095a97405b9ef0f1ad901d9,MAINT rename and deprecate `base_estimator` in favor of `estimator` in ensemble classes (#23819)  Co-authored-by: Adrian Trujillo Duron <adrian.td96@gmail.com> Co-authored-by: Guillaume Lemaitre <g.lemaitre58@gmail.com>,1,Rename Variable,,
b4053e258c74f3dc765fa8a53e44342ad31ee218,2022-04-14T19:35:23Z,https://github.com/scikit-learn/scikit-learn/commit/b4053e258c74f3dc765fa8a53e44342ad31ee218,MNT Removes _linear_loss attribute in GLMs (#23126),1,Rename Variable,,
7811a3a4789f5a252e99708e7bd45445f78839e4,2022-03-31T17:45:34Z,https://github.com/scikit-learn/scikit-learn/commit/7811a3a4789f5a252e99708e7bd45445f78839e4,Rename triage team to contributor experience team (#22970),1,Rename Variable,,
1c24595c74e0bea246737b19f8fdfc8a1ffa2282,2022-01-06T18:12:44Z,https://github.com/scikit-learn/scikit-learn/commit/1c24595c74e0bea246737b19f8fdfc8a1ffa2282,MAINT rename base_estimator to estimator in RANSACRegressor (#22062),1,Rename Variable,,
8c4589b23c6481f978d4cfab511f25b77a805f13,2021-04-15T06:32:22Z,https://github.com/scikit-learn/scikit-learn/commit/8c4589b23c6481f978d4cfab511f25b77a805f13,ENH Scalable MiniBatchKMeans plus cln / fixes / refactoring (#17622),1,Rename Variable,,
be4c1d1fee6ee3ec40935283f9e1ab22ebce27cf,2021-01-12T14:30:36Z,https://github.com/scikit-learn/scikit-learn/commit/be4c1d1fee6ee3ec40935283f9e1ab22ebce27cf,MNT Replace PDF build by ZIP of the HTML (#17564),1,Rename Variable,Rename Method,
0e6d415c517aa65528cfa0c189745de50e4c6565,2020-11-11T11:37:18Z,https://github.com/scikit-learn/scikit-learn/commit/0e6d415c517aa65528cfa0c189745de50e4c6565,MNT deprecate attributes in Partial Least Squares module (#18768)  * deprecate attributes  * add test  * add remove test note  * remove classes from ignored sets  * replace abbreviations with full words for improved readability  * make entry in whats_new,1,Rename Variable,,
521b3f289ae7181440781af65045ca0483d0a421,2020-09-30T10:35:46Z,https://github.com/scikit-learn/scikit-learn/commit/521b3f289ae7181440781af65045ca0483d0a421,MNT Minor refactoring _fit_and_predict (#18471),1,Rename Variable,,
5a33360ebb84c5f89035417c5aee042dab235127,2020-06-23T09:12:01Z,https://github.com/scikit-learn/scikit-learn/commit/5a33360ebb84c5f89035417c5aee042dab235127,TST replace Boston in test_gradient_boosting.py (#16937)  Co-authored-by: Guillaume Lemaitre <g.lemaitre58@gmail.com>,1,Rename Variable,Rename Method,
129588c2db1da8d6ee26deab35689872b1e1e289,2020-06-16T11:54:23Z,https://github.com/scikit-learn/scikit-learn/commit/129588c2db1da8d6ee26deab35689872b1e1e289,MNT refactor tests for datasets (#17599)  * MNT refactor tests for datasets  * PEP8  * remove partial,1,Rename Variable,Rename Method,
c573d80031ca9d563c259d5e05d33c9630ab2a7b,2020-03-03T20:52:43Z,https://github.com/scikit-learn/scikit-learn/commit/c573d80031ca9d563c259d5e05d33c9630ab2a7b,BLD Removes post from release on website (#16624),1,Rename Variable,,
db6c12fc117500a751799a3082d1503b65183920,2019-11-13T09:34:28Z,https://github.com/scikit-learn/scikit-learn/commit/db6c12fc117500a751799a3082d1503b65183920,MNT require scipy in setup.py (#15597)  * require scipy in setup  * refactor code,1,Rename Variable,Rename Method,
8e81490d83917412a79999f7c9001516fb3d2554,2019-09-09T17:45:36Z,https://github.com/scikit-learn/scikit-learn/commit/8e81490d83917412a79999f7c9001516fb3d2554,CLN Rename p to power parameter in mean_tweedie_deviance (#14852),1,Rename Variable,,
a1df5c7fed5983b9d6adff4fcc006df85838eb9a,2019-06-26T08:25:58Z,https://github.com/scikit-learn/scikit-learn/commit/a1df5c7fed5983b9d6adff4fcc006df85838eb9a,TST refactor test for PCA (#14138),1,Rename Variable,Rename Method,
eade48eaa2d7fe5dff669febbad619a244361dd3,2019-06-24T17:43:50Z,https://github.com/scikit-learn/scikit-learn/commit/eade48eaa2d7fe5dff669febbad619a244361dd3,TST refactor test_truncated_svd (#14140),1,Rename Variable,Rename Method,
d91b0f324bd320399351af22e21f6e796a25b75e,2019-06-13T09:05:26Z,https://github.com/scikit-learn/scikit-learn/commit/d91b0f324bd320399351af22e21f6e796a25b75e,MNT refactor naive Bayes tests (#14064),1,Rename Variable,Rename Method,
13981bdce97ab2dd49b6b8707f3f27b5c148b9c0,2019-05-05T15:27:55Z,https://github.com/scikit-learn/scikit-learn/commit/13981bdce97ab2dd49b6b8707f3f27b5c148b9c0,STY Remove variable renaming (#13731),1,Rename Variable,,
0f09297cdecad703d8cae6c4fd20252fbaf74a24,2019-02-26T16:53:38Z,https://github.com/scikit-learn/scikit-learn/commit/0f09297cdecad703d8cae6c4fd20252fbaf74a24,ENH: simplify transform for uniform output in QuantileTransformer (#12827),1,Rename Variable,,
2912e3afa27ce39ed92291e1d19854c7ec644fbf,2018-10-27T09:56:54Z,https://github.com/scikit-learn/scikit-learn/commit/2912e3afa27ce39ed92291e1d19854c7ec644fbf,"TST Parametrize, refactor and add new kmeans tests (#12432)",1,Rename Variable,Rename Method,
5b29ae6d2c7198eb9287b881392e5e38f86869eb,2018-06-22T07:56:41Z,https://github.com/scikit-learn/scikit-learn/commit/5b29ae6d2c7198eb9287b881392e5e38f86869eb,MNT: Rename variable `n_samples` to `n_features` (#11344),1,Rename Variable,,
7f0e433183dcfc0d6fb5bc5e18bd2bec39e48701,2018-02-12T16:54:18Z,https://github.com/scikit-learn/scikit-learn/commit/7f0e433183dcfc0d6fb5bc5e18bd2bec39e48701,Remove _pilutil usages from examples (#10527)  Use scikit-image and scipy instead where appropriate.,1,Rename Variable,,
58ff9b8600777166a234f96e418834d3328d1cea,2017-12-20T21:10:22Z,https://github.com/scikit-learn/scikit-learn/commit/58ff9b8600777166a234f96e418834d3328d1cea,ENH Remove check_array for X in DummyRegressor/DummyClassifier and replace X.shape[0] with _num_samples (#9835),1,Rename Variable,Rename Method,
26653db63783be19b41e5c5fe0f94396f4efb445,2017-06-26T10:32:35Z,https://github.com/scikit-learn/scikit-learn/commit/26653db63783be19b41e5c5fe0f94396f4efb445,Rename clf to reg,1,Rename Variable,,
cee48cdf8f67bca9408855d2cd5a20fabec60155,2016-10-08T01:27:41Z,https://github.com/scikit-learn/scikit-learn/commit/cee48cdf8f67bca9408855d2cd5a20fabec60155,removed cv_ prefix (#6252),1,Rename Variable,,
3e12412e053ba5a3e565d5b643f3ded2ef573041,2016-09-12T19:05:28Z,https://github.com/scikit-learn/scikit-learn/commit/3e12412e053ba5a3e565d5b643f3ded2ef573041,ENH rename algorithm to solver in MLP for consistency,1,Rename Variable,,
f02fce89956c875f37119185f6f95a42fb2fb2f9,2016-09-12T13:04:15Z,https://github.com/scikit-learn/scikit-learn/commit/f02fce89956c875f37119185f6f95a42fb2fb2f9,ENH rename l-bfgs to lbfgs in MLP for the sake of consistency,1,Rename Variable,,
35bb1c6ce2aa15baa804e4e0ecce85feb499d003,2016-09-07T16:27:30Z,https://github.com/scikit-learn/scikit-learn/commit/35bb1c6ce2aa15baa804e4e0ecce85feb499d003,Merge pull request #7324 from raghavrv/rename_results_  ENH/MNT results_ --> cv_results; test_mean_score --> mean_test_score et al.,1,Rename Variable,,
e2648b18e568b112c9bcecee4e3ff76972ee19fb,2016-08-30T12:30:18Z,https://github.com/scikit-learn/scikit-learn/commit/e2648b18e568b112c9bcecee4e3ff76972ee19fb,classes parameter renamed to labels in hamming_loss(),1,Rename Variable,,
13f68c93b889fb20730f24ec6c9fa74d4c0e43cf,2016-06-17T23:44:51Z,https://github.com/scikit-learn/scikit-learn/commit/13f68c93b889fb20730f24ec6c9fa74d4c0e43cf,Simplifying imports and test,1,Rename Variable,,
4f580e60bb31cf5bd669646cd395a200b7bf2ecb,2015-10-19T15:28:52Z,https://github.com/scikit-learn/scikit-learn/commit/4f580e60bb31cf5bd669646cd395a200b7bf2ecb,"Deprecate residues_ in LinearRegression  Residues can be empty if the rank of X does not satisfy the conditions described in scipy.linalg.lstsq documentation. As residues are not that useful (i.e. we're not doing stat testing), this property is deprecated and will be removed in sklearn 0.19.",1,Rename Variable,,
26d33232424a3ec29a52bb018cb4873d9b85d0e5,2015-08-26T10:45:02Z,https://github.com/scikit-learn/scikit-learn/commit/26d33232424a3ec29a52bb018cb4873d9b85d0e5,Remove redundant p variable,1,Rename Variable,,
e50aaba7dc06cbeec11cc6237111556577780b5d,2015-08-17T04:25:14Z,https://github.com/scikit-learn/scikit-learn/commit/e50aaba7dc06cbeec11cc6237111556577780b5d,"""nonnegative"" -> ""positive"" + cleanup",1,Rename Variable,,
d75f8ccb2fe22ae5cf4e415992779df0cfecbcbe,2015-08-17T04:16:12Z,https://github.com/scikit-learn/scikit-learn/commit/d75f8ccb2fe22ae5cf4e415992779df0cfecbcbe,"""nonnegative"" -> ""positive"" + cleanup",1,Rename Variable,,
4ac6a90a82e4a8d7b5338c18ae8a16559c98ba10,2015-08-13T21:10:24Z,https://github.com/scikit-learn/scikit-learn/commit/4ac6a90a82e4a8d7b5338c18ae8a16559c98ba10,ENH: split LDA's n_iter_ into n_iter_ and n_batch_iter_  Fixes #5107.,1,Rename Variable,,
3396087038704cbb1eccb2eef4154a51b6f6c85a,2015-06-15T06:17:28Z,https://github.com/scikit-learn/scikit-learn/commit/3396087038704cbb1eccb2eef4154a51b6f6c85a,Update plot_ols.py  Minor/trivial NumPy slicing refactor,1,Rename Variable,,
cc84db3775f8eb0e72f65dff810628dee656bc80,2015-05-28T07:12:48Z,https://github.com/scikit-learn/scikit-learn/commit/cc84db3775f8eb0e72f65dff810628dee656bc80,refactoring to simplify,1,Rename Variable,,
c41e640dccadbbba833efdd1d7eb0044822dfbae,2015-05-15T21:39:59Z,https://github.com/scikit-learn/scikit-learn/commit/c41e640dccadbbba833efdd1d7eb0044822dfbae,rename variable and minor pep8 fix,1,Rename Variable,,
8ea474c00ef5a1563456e7e083ed2d1910290a6d,2015-03-24T16:06:01Z,https://github.com/scikit-learn/scikit-learn/commit/8ea474c00ef5a1563456e7e083ed2d1910290a6d,"cleaned up input validation, added tests for copy keyword.",1,Rename Variable,,
35c2535bfc838db31a14b4da9d0f4bd195b9e252,2015-01-13T05:27:13Z,https://github.com/scikit-learn/scikit-learn/commit/35c2535bfc838db31a14b4da9d0f4bd195b9e252,rename cw option to subsample & refactor its implementation,1,Rename Variable,,
cad87b578cf8a91d4d59834452ff632819d60279,2015-01-10T19:49:42Z,https://github.com/scikit-learn/scikit-learn/commit/cad87b578cf8a91d4d59834452ff632819d60279,rename vars & copy sample_weight,1,Rename Variable,,
ac9ab961bb55d9e39834a521ac022aeb0157bc9d,2015-01-08T10:31:24Z,https://github.com/scikit-learn/scikit-learn/commit/ac9ab961bb55d9e39834a521ac022aeb0157bc9d,Y-org rename & whats_new update,1,Rename Variable,,
aede3d64f18b6fe4651e24acfb0e51f14dc89613,2014-12-16T10:50:01Z,https://github.com/scikit-learn/scikit-learn/commit/aede3d64f18b6fe4651e24acfb0e51f14dc89613,Rename parameter value 'ledoit_wolf' to 'auto'.,1,Rename Variable,,
a5ae150846e0d04cb40265785578532840c8a3d0,2014-12-16T10:35:58Z,https://github.com/scikit-learn/scikit-learn/commit/a5ae150846e0d04cb40265785578532840c8a3d0,rename alpha to shrinkage + docstring cosmits,1,Rename Variable,,
6296194eddac7c4620208dae6adec6e1d5501d20,2014-12-16T10:35:56Z,https://github.com/scikit-learn/scikit-learn/commit/6296194eddac7c4620208dae6adec6e1d5501d20,Parameters are now consistently named; also refactored the _means_cov() function,1,Rename Variable,Rename Method,
83efd8a91106449b8ced8e9eabebe236c57f63e3,2014-12-16T08:18:03Z,https://github.com/scikit-learn/scikit-learn/commit/83efd8a91106449b8ced8e9eabebe236c57f63e3,"TST, test ward_tree_distance on known dataset  - Solve PEP8 problems in test_ward_tree_distance and ward_tree - Refactor return_height into return_distance for ward_tree. - Test that structured and unstructured versions of ward_tree return the   same distances on a known dataset. - structured and unstructured versions return children with the same   order",1,Rename Variable,,
ecc19dc345ccdf821349ecf998ad49d8366f78c7,2014-12-15T17:34:16Z,https://github.com/scikit-learn/scikit-learn/commit/ecc19dc345ccdf821349ecf998ad49d8366f78c7,Minor changes: float conversion and rename rnd into rng,1,Rename Variable,,
54e7f886ce2d4e04415be0d71b753ac4a4d37e83,2014-12-05T13:07:17Z,https://github.com/scikit-learn/scikit-learn/commit/54e7f886ce2d4e04415be0d71b753ac4a4d37e83,Rename global_clusters to n_clusters again,1,Rename Variable,Rename Method,
767bf266d5b7f8174f6e8e26ddf9594750320a6d,2014-12-05T13:07:16Z,https://github.com/scikit-learn/scikit-learn/commit/767bf266d5b7f8174f6e8e26ddf9594750320a6d,API: Rename n_clusters to global_clusters,1,Rename Variable,,
504d2228f2a5f5dd697dd1f60ca7a29ff74364de,2014-11-30T18:12:40Z,https://github.com/scikit-learn/scikit-learn/commit/504d2228f2a5f5dd697dd1f60ca7a29ff74364de,Replace 'coefs' by 'coef_' in PLSRegression,1,Rename Variable,,
b7ee11b38d6ec1188a981c263a578734a9b45b15,2014-10-24T22:48:03Z,https://github.com/scikit-learn/scikit-learn/commit/b7ee11b38d6ec1188a981c263a578734a9b45b15,Merge pull request #3797 from Titan-C/clean  A short cleanup,1,Rename Variable,,
51d6fa2bc27b772d15971fc2f6cc2b56e6188a5c,2014-10-23T17:21:05Z,https://github.com/scikit-learn/scikit-learn/commit/51d6fa2bc27b772d15971fc2f6cc2b56e6188a5c,A short cleanup,1,Rename Variable,,
8955fd09b1d4a1f8550464e54c909bae915b56f7,2014-10-09T15:25:49Z,https://github.com/scikit-learn/scikit-learn/commit/8955fd09b1d4a1f8550464e54c909bae915b56f7,COSMIT: Renamed n_all to all_combinations in theil_sen.py,1,Rename Variable,,
d3de5795be1ed82c1a2c2d9d13de828ff32ff755,2014-10-09T14:13:34Z,https://github.com/scikit-learn/scikit-learn/commit/d3de5795be1ed82c1a2c2d9d13de828ff32ff755,COSMIT: Renamed spmed[_old] to spatial_median[_old],1,Rename Variable,,
51cef86e472188dee73c8088593edb0404607f79,2014-10-09T14:12:11Z,https://github.com/scikit-learn/scikit-learn/commit/51cef86e472188dee73c8088593edb0404607f79,COSMIT: Renamed y -> x_old in _modified_weiszfeld_step,1,Rename Variable,,
ef17f8067bcc1a13abb34858e73ed9a175e1578c,2014-09-24T20:58:29Z,https://github.com/scikit-learn/scikit-learn/commit/ef17f8067bcc1a13abb34858e73ed9a175e1578c,ENH: Improvements in the Theil-Sen regressor  - Renamed TheilSen to TheilSenRegressor - Renamed n_iter parameter to max_iter - Better warning message when maximum iteration number reached - Added docstring for fit - Removed backend and max_nbytes parameters in Parallel - Removed n_dim return value from _check_subparams - Some PEP8 corrections - Added an attribute n_iter_ to show number of iterations - Removed unnecessary array to list conversion ix = list(ix) - Remove random_state_ as attribute,1,Rename Variable,,
cdfa0ce73c7d7365fefdadc5918986c8d4c0bd85,2014-09-09T02:32:38Z,https://github.com/scikit-learn/scikit-learn/commit/cdfa0ce73c7d7365fefdadc5918986c8d4c0bd85,Removed some unnecessary lines and reformatted for consistency in _multinomial_loss and _multinomial_loss_grad_hess.,1,Rename Variable,,
4cb2d9348f73a8bfa55823ffaa60327196686692,2014-07-22T14:57:39Z,https://github.com/scikit-learn/scikit-learn/commit/4cb2d9348f73a8bfa55823ffaa60327196686692,Refactor and some bug fixing,1,Rename Variable,,
f4ac2b648c38b0632c1d78dbca09529969db5295,2014-07-17T09:21:27Z,https://github.com/scikit-learn/scikit-learn/commit/f4ac2b648c38b0632c1d78dbca09529969db5295,ENH simplify label ranking average precision (thanks @jnothman),1,Rename Variable,,
e242ebc5c7893208245977aab53987c4f6aaad73,2014-07-16T14:20:10Z,https://github.com/scikit-learn/scikit-learn/commit/e242ebc5c7893208245977aab53987c4f6aaad73,ENH rename parameters in MockListClassifiers.,1,Rename Variable,,
a22225e274e61bcc1d687d4bb587baa08f4f133a,2014-06-14T04:50:48Z,https://github.com/scikit-learn/scikit-learn/commit/a22225e274e61bcc1d687d4bb587baa08f4f133a,"Minor refactoring of the repeated-roc-thresholds test, for clarity.",1,Rename Variable,,
bd7d423c36954f52e1690d20626959aafbf31bb2,2014-06-08T01:46:05Z,https://github.com/scikit-learn/scikit-learn/commit/bd7d423c36954f52e1690d20626959aafbf31bb2,Reverting array X to vector x rename,1,Rename Variable,,
d7c27d3e8eeca0dd07d9c9dac395253249479f9b,2014-06-05T12:36:40Z,https://github.com/scikit-learn/scikit-learn/commit/d7c27d3e8eeca0dd07d9c9dac395253249479f9b,"Refactoring, small improvements, and cleaning notation of IsotonicRegression",1,Rename Variable,,
cda03fa67ae60c0e2ca0ee2837b479fef5c7f4f5,2014-05-28T17:56:10Z,https://github.com/scikit-learn/scikit-learn/commit/cda03fa67ae60c0e2ca0ee2837b479fef5c7f4f5,Rename arguments  Rename affinity to metric and affinities to distances,1,Rename Variable,,
d7e915a26908fbef10947b8ec8b88f1176f3333a,2014-05-28T17:56:09Z,https://github.com/scikit-learn/scikit-learn/commit/d7e915a26908fbef10947b8ec8b88f1176f3333a,Rename attributes,1,Rename Variable,,
a2d209c84bffa17860c0b5f86a9fdb9b9be73498,2014-05-28T17:54:15Z,https://github.com/scikit-learn/scikit-learn/commit/a2d209c84bffa17860c0b5f86a9fdb9b9be73498,Refactoring  * distances -> affinities * use MACHINE_EPSILON from numpy * use double precision in binary search,1,Rename Variable,,
31d438eb3df7e75f53d4cf895c7a0d91269be399,2014-04-26T18:08:58Z,https://github.com/scikit-learn/scikit-learn/commit/31d438eb3df7e75f53d4cf895c7a0d91269be399,COSMIT: Replaced ptr1/2 with start/stop,1,Rename Variable,,
4ec4b2f625917dca03f2e055c2cbab573e73fb0a,2014-01-20T11:12:46Z,https://github.com/scikit-learn/scikit-learn/commit/4ec4b2f625917dca03f2e055c2cbab573e73fb0a,ENH remove unnecessary CSR->CSC transform in text feature extractors,1,Rename Variable,,
64dbd450a4ffaaeb3f9779f6d59dd516e47f6fa3,2014-01-16T03:43:16Z,https://github.com/scikit-learn/scikit-learn/commit/64dbd450a4ffaaeb3f9779f6d59dd516e47f6fa3,Remove wrong variable names,1,Rename Variable,,
33b84302032d467f0cba44f461bb87f65b9c52d8,2013-12-31T14:44:52Z,https://github.com/scikit-learn/scikit-learn/commit/33b84302032d467f0cba44f461bb87f65b9c52d8,Use internal sample_with_replacement rather than Python's random.sample,1,Rename Variable,,
20e45bf2c820b307eef80f5984e7e6f698439201,2013-10-20T13:58:05Z,https://github.com/scikit-learn/scikit-learn/commit/20e45bf2c820b307eef80f5984e7e6f698439201,Rename estimator to base_estimator,1,Rename Variable,,
6ee0197a5b887dd8f2375d879e91cb071c5af432,2013-10-20T13:58:03Z,https://github.com/scikit-learn/scikit-learn/commit/6ee0197a5b887dd8f2375d879e91cb071c5af432,Remove _n_ from min_samples,1,Rename Variable,,
bbaa9d9634d8c3bfda69269eb959aa00fa22f207,2013-09-20T10:41:39Z,https://github.com/scikit-learn/scikit-learn/commit/bbaa9d9634d8c3bfda69269eb959aa00fa22f207,"Avoid list, preallocate a numpy array for indices instead.  It appears that the sorted() call is unnecessary here.",1,Rename Variable,,
14124bae0a06ae75645761597a24bf46e7c99263,2013-08-27T08:29:40Z,https://github.com/scikit-learn/scikit-learn/commit/14124bae0a06ae75645761597a24bf46e7c99263,Code cleanup in pairwise_distances_argmin,1,Rename Variable,,
34bc6b20bd33eb645ff874afce110b9b6fc29fd4,2013-08-27T08:28:27Z,https://github.com/scikit-learn/scikit-learn/commit/34bc6b20bd33eb645ff874afce110b9b6fc29fd4,Change signature of euclidean_distances_argmin()  THe function is passed the number of chunks instead of the number of rows in a chunk.  Replaced custom code by gen_even_slices(),1,Rename Variable,,
fd3a816afb1b05eeb299560b29e06ebcb35f069e,2013-08-24T16:04:11Z,https://github.com/scikit-learn/scikit-learn/commit/fd3a816afb1b05eeb299560b29e06ebcb35f069e,renamed supported_loss to _SUPPORTED_LOSS (constants) add test for deprecated warning,1,Rename Variable,,
2df651b4175a8e2070fe707dce28c0bbeec937ac,2013-07-28T15:41:27Z,https://github.com/scikit-learn/scikit-learn/commit/2df651b4175a8e2070fe707dce28c0bbeec937ac,Merge pull request #2299 from ogrisel/grid-scores  Rename cv_scores(_) back to grid_scores(_) to keep the name free,1,Rename Variable,,
b0035bf9e87294a0bc50e282425ebf9eccc91442,2013-07-28T15:10:14Z,https://github.com/scikit-learn/scikit-learn/commit/b0035bf9e87294a0bc50e282425ebf9eccc91442,Rename cv_scores(_) back to grid_scores(_) to keep the name free for a future refactoring,1,Rename Variable,,
f9670d860a786834564656aeab0ca6c0f22b2849,2013-07-25T17:19:25Z,https://github.com/scikit-learn/scikit-learn/commit/f9670d860a786834564656aeab0ca6c0f22b2849,consistency changes: - renamed maxiter to max_iter - named arguments to apply_along_axis(),1,Rename Variable,,
419c2beceb1a3c1dff93f0fa0f7ad704ce67f8dd,2013-07-25T08:21:23Z,https://github.com/scikit-learn/scikit-learn/commit/419c2beceb1a3c1dff93f0fa0f7ad704ce67f8dd,Rename LabelBinarizer.multilabel to .multilabel_ + DOC,1,Rename Variable,,
712f3cc86c770d1f8d9153dab6585a3ff10f3f1d,2013-07-24T15:27:20Z,https://github.com/scikit-learn/scikit-learn/commit/712f3cc86c770d1f8d9153dab6585a3ff10f3f1d,ENH rename n_particles to batch_size in RBM,1,Rename Variable,,
96a2834af2b6ef7f1f8eaa842384398b7e7161aa,2013-07-24T15:27:17Z,https://github.com/scikit-learn/scikit-learn/commit/96a2834af2b6ef7f1f8eaa842384398b7e7161aa,rename h_samples to h_samples_,1,Rename Variable,,
8f78ab8898a64d9a3f559d025814bf5aea743bfa,2013-06-24T02:45:59Z,https://github.com/scikit-learn/scikit-learn/commit/8f78ab8898a64d9a3f559d025814bf5aea743bfa,Merge pull request #2090 from kanielc/fix_weight  MAINT renamed weight to sample_weight in sklearn/isotonic.py,1,Rename Variable,,
54931e350e85e9befa1241a64dfbf3cedd60aeab,2013-06-24T02:32:42Z,https://github.com/scikit-learn/scikit-learn/commit/54931e350e85e9befa1241a64dfbf3cedd60aeab,renamed weight to sample_weight in sklearn/isotonic.py,1,Rename Variable,,
d63535e4ac536451777809d1d00a73cf243c7f4b,2013-06-14T07:09:29Z,https://github.com/scikit-learn/scikit-learn/commit/d63535e4ac536451777809d1d00a73cf243c7f4b,factorized instance extraction + plots,1,Rename Variable,,
f1df9ab19da4ea7e159ba1d24f92edd419eb2244,2013-04-27T13:24:44Z,https://github.com/scikit-learn/scikit-learn/commit/f1df9ab19da4ea7e159ba1d24f92edd419eb2244,Replaced 'for i' with 'for _' at place where i is not used. fix pep8 for weighted_boosting.py,1,Rename Variable,,
7975ccbf3fdcec64877bfbf3a4cea042808623b7,2013-03-09T16:59:57Z,https://github.com/scikit-learn/scikit-learn/commit/7975ccbf3fdcec64877bfbf3a4cea042808623b7,COSMIT get rid of undocumented attributes on SVMs  sparse was superseded by _sparse; renamed impl to _impl.,1,Rename Variable,,
e375677b56502efd3f1e4f4552131a27fda0c518,2013-02-03T15:24:46Z,https://github.com/scikit-learn/scikit-learn/commit/e375677b56502efd3f1e4f4552131a27fda0c518,"MISC pep8: rename scorers to SCORERS, remove score_objects getter",1,Rename Variable,,
8511f487f9d8b5980f39eb2125fbed59fbea17d1,2013-02-03T14:49:38Z,https://github.com/scikit-learn/scikit-learn/commit/8511f487f9d8b5980f39eb2125fbed59fbea17d1,"ENH rename scorer objects to lowercase as they are instances, not classes",1,Rename Variable,,
053b6e7d64afd30f9ac3c45fdffa76cf4566c739,2013-02-03T14:49:37Z,https://github.com/scikit-learn/scikit-learn/commit/053b6e7d64afd30f9ac3c45fdffa76cf4566c739,"ENH renamed ap and auc, added RecallScorrer",1,Rename Variable,,
e8fa4c38581eafa03d3c9bf07ac3c283bc2a3c38,2013-02-03T14:49:35Z,https://github.com/scikit-learn/scikit-learn/commit/e8fa4c38581eafa03d3c9bf07ac3c283bc2a3c38,"ENH refactor, taking @GaelVaroquaux's and @ogrisel's suggestions into account",1,Rename Variable,Rename Method,
fa5a69801b1e70703ce910f982644d154ec56d6d,2013-01-19T15:44:09Z,https://github.com/scikit-learn/scikit-learn/commit/fa5a69801b1e70703ce910f982644d154ec56d6d,"COMP in SVC rename self.label_ to self._label (it is redunant now but I don't want to refactor the rest of the day) and add a deprecated property label_, that points to classes_.",1,Rename Variable,,
685c6529b6eb623710cb92b2ae8b79f3bd9f7570,2013-01-07T08:41:48Z,https://github.com/scikit-learn/scikit-learn/commit/685c6529b6eb623710cb92b2ae8b79f3bd9f7570,ENH rename proximity to dissimilarity,1,Rename Variable,,
dc25f231e2242137c475439be1fd33612a7b8615,2013-01-03T12:15:41Z,https://github.com/scikit-learn/scikit-learn/commit/dc25f231e2242137c475439be1fd33612a7b8615,renamed the new parameter to class_wieght,1,Rename Variable,,
db4422fcf9d949e5bb4a6b76bf4e6296c508bf27,2012-12-21T13:48:01Z,https://github.com/scikit-learn/scikit-learn/commit/db4422fcf9d949e5bb4a6b76bf4e6296c508bf27,ENH Simplify assert_raise_message + TST add them,1,Rename Variable,,
616e2b5d6454106c7005ecd0295597098b853bf3,2012-12-21T13:48:01Z,https://github.com/scikit-learn/scikit-learn/commit/616e2b5d6454106c7005ecd0295597098b853bf3,ENH Rename Bernoulli random projection to sparse random projection,1,Rename Variable,,
12c8d3be79dc1cf30964a8711b74d96ffe80175f,2012-12-21T13:48:01Z,https://github.com/scikit-learn/scikit-learn/commit/12c8d3be79dc1cf30964a8711b74d96ffe80175f,ENH Rename Bernoulli random projection to sparse random projection,1,Rename Variable,,
0799ee977860f62b24bfda5846e22a19e5d1df99,2012-12-04T15:24:07Z,https://github.com/scikit-learn/scikit-learn/commit/0799ee977860f62b24bfda5846e22a19e5d1df99,ENH: Simplify the shape of (n_)classes in forest,1,Rename Variable,,
db98995e3812e1992fca99a95c40d809a9a19e36,2012-12-04T13:25:14Z,https://github.com/scikit-learn/scikit-learn/commit/db98995e3812e1992fca99a95c40d809a9a19e36,ENH: Simplify the shape of (n_)classes_ for single output trees,1,Rename Variable,,
46f15875db2de9f50c990db4c761d2c39d174090,2012-11-27T14:35:45Z,https://github.com/scikit-learn/scikit-learn/commit/46f15875db2de9f50c990db4c761d2c39d174090,"RENAME rename eigen_tol and eigen_solver, and warning about using old variable name eig_tol and mode",1,Rename Variable,,
0ef3aadc69755cfd7a97250a34033c9e6d8bc9d5,2012-11-27T14:35:16Z,https://github.com/scikit-learn/scikit-learn/commit/0ef3aadc69755cfd7a97250a34033c9e6d8bc9d5,RENAME parameter rename in examples,1,Rename Variable,,
fd82afae95138636d617bd2885af80a39b63b0c2,2012-11-27T07:36:46Z,https://github.com/scikit-learn/scikit-learn/commit/fd82afae95138636d617bd2885af80a39b63b0c2,renamed: ncols -> n_cols;          partial_dependence_plots -> plot_partial_dependence,1,Rename Variable,Rename Method,
bf5c124192378358ba92e9707beae50ba39778ce,2012-11-10T11:56:13Z,https://github.com/scikit-learn/scikit-learn/commit/bf5c124192378358ba92e9707beae50ba39778ce,rename learn_rate -> learning_rate,1,Rename Variable,,
87d3246e9ead499fced9771cbf3fa28bb14ced41,2012-10-30T07:24:59Z,https://github.com/scikit-learn/scikit-learn/commit/87d3246e9ead499fced9771cbf3fa28bb14ced41,renamed dependency -> dependence; docstring and cosmit,1,Rename Variable,,
e3d369d38cf06ecdcab73d52c0936f19f0c4beba,2012-10-27T21:39:54Z,https://github.com/scikit-learn/scikit-learn/commit/e3d369d38cf06ecdcab73d52c0936f19f0c4beba,MISC: minor clean ups in hmm code,1,Rename Variable,,
36efa068b695e4449bbaf437e368032ede5b5154,2012-10-27T18:39:35Z,https://github.com/scikit-learn/scikit-learn/commit/36efa068b695e4449bbaf437e368032ede5b5154,"Documentation changes, removed more camel case variables",1,Rename Variable,,
c326b1fabee05f975a5ebc281a6237050093f660,2012-10-27T17:19:57Z,https://github.com/scikit-learn/scikit-learn/commit/c326b1fabee05f975a5ebc281a6237050093f660,ENH removed ``remove_zeros`` parameter.,1,Rename Variable,,
fd595a7388f068fb4c176a5d25f7850e0b5ce8a3,2012-10-26T14:03:05Z,https://github.com/scikit-learn/scikit-learn/commit/fd595a7388f068fb4c176a5d25f7850e0b5ce8a3,Renamed learning_rate loss in PassiveAggressive,1,Rename Variable,,
dd58d6ee547495b441fd332c7c5617cb7d45238f,2012-10-13T17:29:00Z,https://github.com/scikit-learn/scikit-learn/commit/dd58d6ee547495b441fd332c7c5617cb7d45238f,API : rename psi to noise_variance + some cleanup in FA,1,Rename Variable,,
b39609af4eaae69591008c2cd7f8a5c3de48fb45,2012-10-11T19:56:03Z,https://github.com/scikit-learn/scikit-learn/commit/b39609af4eaae69591008c2cd7f8a5c3de48fb45,ENH rename rho in SGD,1,Rename Variable,,
16aabc7c3f690e512c7edd78dfd86b6cac1a4262,2012-10-11T19:56:03Z,https://github.com/scikit-learn/scikit-learn/commit/16aabc7c3f690e512c7edd78dfd86b6cac1a4262,ENH rename rho to l1_ratio in ElasticNet and friends,1,Rename Variable,,
9bd0aadaa30295452ba1ba1811b4086cbb2ef5f3,2012-10-10T18:10:29Z,https://github.com/scikit-learn/scikit-learn/commit/9bd0aadaa30295452ba1ba1811b4086cbb2ef5f3,MISC renamed n_iterations to n_iter in all other places.,1,Rename Variable,,
0a818270f393ded19c2a83a58ee12e33986299c7,2012-10-10T18:10:29Z,https://github.com/scikit-learn/scikit-learn/commit/0a818270f393ded19c2a83a58ee12e33986299c7,COSMIT rename n_iterations to n_iter in cross_validation,1,Rename Variable,,
ceb80b0f29a2b1620a9d6668569f71b4ea036b49,2012-10-10T18:10:29Z,https://github.com/scikit-learn/scikit-learn/commit/ceb80b0f29a2b1620a9d6668569f71b4ea036b49,ENH rename k to n_folds and n_bootstraps to n_iterations,1,Rename Variable,,
ffc865628e0a8dbd335617af0a8718899c704f03,2012-10-03T13:09:09Z,https://github.com/scikit-learn/scikit-learn/commit/ffc865628e0a8dbd335617af0a8718899c704f03,"ENH rename ``_classes`` to ``classes_``, fix outlier labeling, remove unnecessary mapping to indices.",1,Rename Variable,,
425d1f9a2e737f997e11549013639231dd5e1f77,2012-09-04T05:56:52Z,https://github.com/scikit-learn/scikit-learn/commit/425d1f9a2e737f997e11549013639231dd5e1f77,refactored prediction and decision_function (rm duplicate code),1,Rename Variable,Rename Method,
d70ee4e3a70b991bd89a0896d3d7ea12b8aab24c,2012-09-02T21:10:13Z,https://github.com/scikit-learn/scikit-learn/commit/d70ee4e3a70b991bd89a0896d3d7ea12b8aab24c,Renamed parameter convit to convergence_iteration and deprecated the old API,1,Rename Variable,,
58ed13617314a2474f4cfe52d5b886558db48e92,2012-09-02T20:14:09Z,https://github.com/scikit-learn/scikit-learn/commit/58ed13617314a2474f4cfe52d5b886558db48e92,"Revert ""Rename Y to y in PLS""  This reverts commit a10928c55353eee1d3a3bd9ef77bf34895c994e6.",1,Rename Variable,,
a10928c55353eee1d3a3bd9ef77bf34895c994e6,2012-09-02T13:14:07Z,https://github.com/scikit-learn/scikit-learn/commit/a10928c55353eee1d3a3bd9ef77bf34895c994e6,Rename Y to y in PLS,1,Rename Variable,,
949ddd10b138816db1e454826d81da93ad50f4f6,2012-08-26T17:04:41Z,https://github.com/scikit-learn/scikit-learn/commit/949ddd10b138816db1e454826d81da93ad50f4f6,ENH renamed ``neq_sqr_euclidean`` to ``euclidean`` so we it is easier to parse,1,Rename Variable,,
2b328caee809045ebdecc1167e540625136861b2,2012-08-26T15:29:46Z,https://github.com/scikit-learn/scikit-learn/commit/2b328caee809045ebdecc1167e540625136861b2,"COSMIT renamed n_points to n_samples everywhere, fixed shape docstring that @mblondel pointed out.",1,Rename Variable,,
da809975795d8dd49233432fd693029ee957c0a0,2012-08-25T19:16:56Z,https://github.com/scikit-learn/scikit-learn/commit/da809975795d8dd49233432fd693029ee957c0a0,"ENH rename paramter ``p`` of AffinitPropagation to ``preference``, slightly change the meaning of scalar parameter. Scaling the medium seems more intuitive that giving absolute values.",1,Rename Variable,,
bf787ac11f806aeab509734c4df1a69c126b5586,2012-08-19T13:26:09Z,https://github.com/scikit-learn/scikit-learn/commit/bf787ac11f806aeab509734c4df1a69c126b5586,"ENH renamed parameter bounds_n to ngram_range, fixed doctests and tests.",1,Rename Variable,,
47c156295da56e1f29809d7dd36aeb9cbd88f02c,2012-08-19T13:26:09Z,https://github.com/scikit-learn/scikit-learn/commit/47c156295da56e1f29809d7dd36aeb9cbd88f02c,ENH renamed ``min_n`` and ``max_n`` parameters in CountVectorizer to enable gridsearch over them together.,1,Rename Variable,,
0b7c93ce318286c91a030bcd52c2a45f2645d6dd,2012-08-14T12:33:43Z,https://github.com/scikit-learn/scikit-learn/commit/0b7c93ce318286c91a030bcd52c2a45f2645d6dd,"ENH slight cleanup in LDA, QDA, support for arbitrary class labels.",1,Rename Variable,,
6df5d76a1309daa8dfa2a905d131a07b342f1af8,2012-08-08T09:02:30Z,https://github.com/scikit-learn/scikit-learn/commit/6df5d76a1309daa8dfa2a905d131a07b342f1af8,"ENH slight cleanup in LDA, QDA, support for arbitrary class labels.",1,Rename Variable,,
c24702e09a644443139735805048121298d71416,2012-07-23T14:07:14Z,https://github.com/scikit-learn/scikit-learn/commit/c24702e09a644443139735805048121298d71416,rename mahalanobis_values to raw_values in covariance decision method.  This is to ensure further compatibility with other classifiers' decision function. An optional argument was also added to mahalanobis_distance method in order to consider already centered data.,1,Rename Variable,,
cfb65107295de1b476bc25e66eb886c750b2cfd0,2012-07-18T05:42:04Z,https://github.com/scikit-learn/scikit-learn/commit/cfb65107295de1b476bc25e66eb886c750b2cfd0,COSMIT: rename M matrix to loo_values,1,Rename Variable,,
c4d2fe04c61115ce2fdcadd6d7b4f596b1bb3984,2012-06-01T16:24:21Z,https://github.com/scikit-learn/scikit-learn/commit/c4d2fe04c61115ce2fdcadd6d7b4f596b1bb3984,MDS: renamed positions_ to embedding_,1,Rename Variable,,
d9a6243c98915bbb677e70dd71f247cb6be880ca,2012-05-30T05:41:34Z,https://github.com/scikit-learn/scikit-learn/commit/d9a6243c98915bbb677e70dd71f247cb6be880ca,ENH rename k in clustering examples and doctests to n_clusters,1,Rename Variable,,
805c0f354012e07724535af37cae8985ebd45d10,2012-05-30T05:41:34Z,https://github.com/scikit-learn/scikit-learn/commit/805c0f354012e07724535af37cae8985ebd45d10,ENH renamed 'k' to n_clusters in SpectralClustering,1,Rename Variable,,
388c1af757683da64400112aea8b0fc588bb2c12,2012-05-30T05:41:34Z,https://github.com/scikit-learn/scikit-learn/commit/388c1af757683da64400112aea8b0fc588bb2c12,ENH rename 'k' in KMeans and MiniBatchKMeans,1,Rename Variable,,
02d1d85566bd8b6a35bc744d25b7b3a797f6a364,2012-05-15T21:11:01Z,https://github.com/scikit-learn/scikit-learn/commit/02d1d85566bd8b6a35bc744d25b7b3a797f6a364,ENH rename unmixing_matrix_ to components_ in FastICA,1,Rename Variable,,
5ad3bc672c97c87d20c2fe40eccdd0734d7c137a,2012-05-06T14:08:25Z,https://github.com/scikit-learn/scikit-learn/commit/5ad3bc672c97c87d20c2fe40eccdd0734d7c137a,ENH rename out_dim to  n_components in manifold module,1,Rename Variable,,
7b75227afb263cb1b7cf404e8c263547efa87821,2012-05-02T08:23:21Z,https://github.com/scikit-learn/scikit-learn/commit/7b75227afb263cb1b7cf404e8c263547efa87821,"Rename ""p"" to ""espilon"".",1,Rename Variable,,
692e07df5eba5a3c20d304c5bd213ad16be2503f,2012-04-28T12:19:32Z,https://github.com/scikit-learn/scikit-learn/commit/692e07df5eba5a3c20d304c5bd213ad16be2503f,revert PLS param rename + move input validation out of loop,1,Rename Variable,,
b3ca4eef192ec4867712d21cee57809f147b9645,2012-04-22T14:42:54Z,https://github.com/scikit-learn/scikit-learn/commit/b3ca4eef192ec4867712d21cee57809f147b9645,ENH: train_size and test_size in ShuffleSplit (#721)  * renamed test_fraction and train_fraction to test_size and train_size * deprecated test_fraction and train_fraction * added tests for checking deprecation warnings * modified documentation,1,Rename Variable,,
a52a526d3919a32b7ae2a719ac76dfb7e8dd3830,2012-03-20T14:57:17Z,https://github.com/scikit-learn/scikit-learn/commit/a52a526d3919a32b7ae2a719ac76dfb7e8dd3830,use random_sample_mask (issue pointed out by @glouppe); rename train_deviance and oob_deviance to train_score_ and oob_score_; doc attributes,1,Rename Variable,,
a8359d6684fde32544014480b310fb90c0f7bde3,2012-03-04T17:15:03Z,https://github.com/scikit-learn/scikit-learn/commit/a8359d6684fde32544014480b310fb90c0f7bde3,"ENH issue #661, plus some renaming and minor cleanup",1,Rename Variable,,
139283ef62a279a32a9204194d0998fb1410791b,2012-03-03T21:07:30Z,https://github.com/scikit-learn/scikit-learn/commit/139283ef62a279a32a9204194d0998fb1410791b,"ENH rename parameter ""multi_class"" of LinearSVC to ""crammer_singer"", add docs, add tests",1,Rename Variable,,
61b0e28f9f217f403950507291054563d4775915,2012-03-03T17:30:02Z,https://github.com/scikit-learn/scikit-learn/commit/61b0e28f9f217f403950507291054563d4775915,MISC removed deprecated api from examples,1,Rename Variable,,
51b6faa44af0040e3fb32b5bb81e23de1abdc7b1,2012-03-03T10:44:08Z,https://github.com/scikit-learn/scikit-learn/commit/51b6faa44af0040e3fb32b5bb81e23de1abdc7b1,renamed and updated covertype benchmark.,1,Rename Variable,,
8195db25afd8087fdff4a085cf7a8fe0646769ff,2012-02-28T11:46:18Z,https://github.com/scikit-learn/scikit-learn/commit/8195db25afd8087fdff4a085cf7a8fe0646769ff,"refactoring (thanks @GaelVaroquaux, @mblondel)",1,Rename Variable,,
49462943cb5e74a0720612a08046cf015885e278,2012-02-15T22:38:11Z,https://github.com/scikit-learn/scikit-learn/commit/49462943cb5e74a0720612a08046cf015885e278,"MISC renamed min_split and min_leaf to min_samples_split, min_samples_leaf, added them to the ensemble classifiers and documented them....",1,Rename Variable,,
8648cfefecc093dd5329823dba2af72bae0c0e17,2012-01-24T21:59:47Z,https://github.com/scikit-learn/scikit-learn/commit/8648cfefecc093dd5329823dba2af72bae0c0e17,renamed estimators to estimators_,1,Rename Variable,,
59db66eb4e0483eea4b87892142ce1ca2ca54c66,2012-01-23T10:00:08Z,https://github.com/scikit-learn/scikit-learn/commit/59db66eb4e0483eea4b87892142ce1ca2ca54c66,"Refactor in KFold.  Fixed the misleading line ```ceil(n / k)``` . Since n and k are integers, n / k is an integer (at least for python2) and thus what it is computing is floor(float(n) / k), where / is now the floating-point division.  Renamed j --> fold_size for clarity and added check for integer values.  Conflicts:  	sklearn/cross_validation.py",1,Rename Variable,,
8db0338bfda93ef582ae99fcf11c6573597ea952,2012-01-09T23:27:23Z,https://github.com/scikit-learn/scikit-learn/commit/8db0338bfda93ef582ae99fcf11c6573597ea952,"replace log_weights_ by weights_, which makes the API more consistent",1,Rename Variable,,
dac2e4fe1bb2bc2832a251a67c2d5de997518e3f,2012-01-07T11:00:46Z,https://github.com/scikit-learn/scikit-learn/commit/dac2e4fe1bb2bc2832a251a67c2d5de997518e3f,"- renamed (n_samples, n_states) -> (n_observations, n_components) in hmm.py  - renamed mathematical symbols to thier actual meanings in _hmmc.pyx e.g. lnA -> log_transmat  - added a sample code that uses Gaussian HMM",1,Rename Variable,,
a7030481fd8353cc99da634b2c73641c397e21c2,2012-01-06T16:33:10Z,https://github.com/scikit-learn/scikit-learn/commit/a7030481fd8353cc99da634b2c73641c397e21c2,"replaced (T, N) -> (n_samples, n_states)",1,Rename Variable,,
68a8b8b46d0982e9c47330827395f38e824d72bd,2012-01-05T22:35:33Z,https://github.com/scikit-learn/scikit-learn/commit/68a8b8b46d0982e9c47330827395f38e824d72bd,ENH renamed best_estimator and best_score in examples and tests.,1,Rename Variable,,
c6ee39b8a44a4ca9e2fda6a17c5fe416f7336035,2011-12-20T13:17:48Z,https://github.com/scikit-learn/scikit-learn/commit/c6ee39b8a44a4ca9e2fda6a17c5fe416f7336035,ENH: renamed D to n_components for consitency,1,Rename Variable,,
6db1ff8d0b5433572f566b2bfd5281e0d1eaa2f0,2011-12-19T15:28:41Z,https://github.com/scikit-learn/scikit-learn/commit/6db1ff8d0b5433572f566b2bfd5281e0d1eaa2f0,WIP: n_init refactoring,1,Rename Variable,,
5bf49f97cb5de2b63f79e5eccc9e3076b2475dcf,2011-11-02T20:04:25Z,https://github.com/scikit-learn/scikit-learn/commit/5bf49f97cb5de2b63f79e5eccc9e3076b2475dcf,Renamed k_features to max_features,1,Rename Variable,,
a03b1048d57a014939883d27c2fcc2053d0ca512,2011-10-25T21:22:44Z,https://github.com/scikit-learn/scikit-learn/commit/a03b1048d57a014939883d27c2fcc2053d0ca512,"ENH sample_weight argument in discrete NB estimators  Also, renamed Naive Bayes' unique_y attribute to _classes; it was undocumented.",1,Rename Variable,,
d63f39c669177747b665711ced742ef40efe602b,2011-10-25T07:37:43Z,https://github.com/scikit-learn/scikit-learn/commit/d63f39c669177747b665711ced742ef40efe602b,rename node.sample_mask to node.terminal_region renamed BernoulliLoss to BinomialLoss and rm old BinomialLoss,1,Rename Variable,,
51d4310c6feeb1ace394cc577dac06f22b6e1a75,2011-10-21T11:58:08Z,https://github.com/scikit-learn/scikit-learn/commit/51d4310c6feeb1ace394cc577dac06f22b6e1a75,COSMIT rename safe_asanyarray to safe_asarray to prevent confusion,1,Rename Variable,,
9fb3257df932e16603d1f397cb0e7161bd16adb8,2011-09-26T13:43:04Z,https://github.com/scikit-learn/scikit-learn/commit/9fb3257df932e16603d1f397cb0e7161bd16adb8,refactor and simplify naive_bayes  Fewer transpositions and closer to linear model conventions.,1,Rename Variable,,
6f84f45814b2a1d9f9ddfd9fdd91687c5aa03b45,2011-09-26T13:08:25Z,https://github.com/scikit-learn/scikit-learn/commit/6f84f45814b2a1d9f9ddfd9fdd91687c5aa03b45,Merge pull request #357 from larsmans/overwrite-to-copy  rename overwrite_Foo params to copy_Foo (and inversed their meaning),1,Rename Variable,,
56d26f9fdd77322bb78d5d8d26b94259a5bb2b6a,2011-09-25T14:52:29Z,https://github.com/scikit-learn/scikit-learn/commit/56d26f9fdd77322bb78d5d8d26b94259a5bb2b6a,rename overwrite_Foo params to copy_Foo (and inversed their meaning),1,Rename Variable,,
9da4e66899a198a581906f3a96ff0a8efe795442,2011-09-04T09:18:57Z,https://github.com/scikit-learn/scikit-learn/commit/9da4e66899a198a581906f3a96ff0a8efe795442,style: constant in capital letter on top + extract graphviz tree template,1,Rename Variable,,
d771289fdeadfb55146afa9b2ba978a0e67a0ce5,2011-09-03T10:43:29Z,https://github.com/scikit-learn/scikit-learn/commit/d771289fdeadfb55146afa9b2ba978a0e67a0ce5,renamed var to variance,1,Rename Variable,,
b5d63bafe243100135da94d89fd8824bd1096da7,2011-09-03T09:35:07Z,https://github.com/scikit-learn/scikit-learn/commit/b5d63bafe243100135da94d89fd8824bd1096da7,renamed K to n_classes,1,Rename Variable,,
30fb575e6946543adcba607b66702045352bbf1d,2011-09-03T09:33:05Z,https://github.com/scikit-learn/scikit-learn/commit/30fb575e6946543adcba607b66702045352bbf1d,renamed C to predictions,1,Rename Variable,,
03b41d7e8e1b7d2dd31ba9cdb4c17d0f7f6d5f81,2011-09-03T09:28:52Z,https://github.com/scikit-learn/scikit-learn/commit/03b41d7e8e1b7d2dd31ba9cdb4c17d0f7f6d5f81,renamed n_dims to n_features,1,Rename Variable,,
2b27be5a8553dd1b4b4016bd150a2caffc3406df,2011-09-03T09:28:00Z,https://github.com/scikit-learn/scikit-learn/commit/2b27be5a8553dd1b4b4016bd150a2caffc3406df,renamed labels to y,1,Rename Variable,,
38cff847def07787541c48b45cde90bb604f7cd0,2011-09-03T09:25:46Z,https://github.com/scikit-learn/scikit-learn/commit/38cff847def07787541c48b45cde90bb604f7cd0,renamed features to X,1,Rename Variable,,
bf6a075e0326a83ca524f4ead830228e28c80460,2011-09-03T09:22:09Z,https://github.com/scikit-learn/scikit-learn/commit/bf6a075e0326a83ca524f4ead830228e28c80460,renamed F to max_features,1,Rename Variable,,
2fa536390791006f2460ad82aa6710f4a4d50ecf,2011-09-03T09:14:08Z,https://github.com/scikit-learn/scikit-learn/commit/2fa536390791006f2460ad82aa6710f4a4d50ecf,Renamed K to n_classes,1,Rename Variable,,
a5538b9da5ddc934184eeacb4989f9b6d9b2b27f,2011-09-02T20:50:57Z,https://github.com/scikit-learn/scikit-learn/commit/a5538b9da5ddc934184eeacb4989f9b6d9b2b27f,refactor neighbors module,1,Rename Variable,,
f1110e0afe911a6d080cff1ef495d3d6b9004496,2011-08-24T13:31:07Z,https://github.com/scikit-learn/scikit-learn/commit/f1110e0afe911a6d080cff1ef495d3d6b9004496,rename eps to tol in omp code,1,Rename Variable,,
f90293095460ba30f6b352bcd6222789e02132a5,2011-08-18T17:03:50Z,https://github.com/scikit-learn/scikit-learn/commit/f90293095460ba30f6b352bcd6222789e02132a5,Mean shift: settled on term 'bin' and removed unnecessary references to 'bucketing' or 'discretization' from variable names and documentation,1,Rename Variable,,
7e5f107ab2dbafa12f7d14791ff6f403d8d6f8b6,2011-08-08T11:00:09Z,https://github.com/scikit-learn/scikit-learn/commit/7e5f107ab2dbafa12f7d14791ff6f403d8d6f8b6,s/seed/random_state in patch extractor,1,Rename Variable,,
d8abe5a46112584731de73ab76a43a22b870da4c,2011-08-04T18:30:15Z,https://github.com/scikit-learn/scikit-learn/commit/d8abe5a46112584731de73ab76a43a22b870da4c,`seed` renamed to `random_state` and default value set to None.,1,Rename Variable,,
4f76bb88c6922273cfa29925a355668bb0d85a3e,2011-08-03T12:25:43Z,https://github.com/scikit-learn/scikit-learn/commit/4f76bb88c6922273cfa29925a355668bb0d85a3e,Description for components_ attribute. Renamed core_samples_ attribute to core_samples_indices_ to remove confusion,1,Rename Variable,,
3670ea39dd5d5a798e738a1bdbf55178c0592d02,2011-08-03T12:10:30Z,https://github.com/scikit-learn/scikit-learn/commit/3670ea39dd5d5a798e738a1bdbf55178c0592d02,Replace points with samples everywhere,1,Rename Variable,,
fa7b914e5f964358f61735c3caaa6313e281b20f,2011-07-28T10:50:42Z,https://github.com/scikit-learn/scikit-learn/commit/fa7b914e5f964358f61735c3caaa6313e281b20f,"Remove max_features keyword from lars_path.  Use max_iter or alpha instead. In the LAR case, max_iter is equivalent to max_features and n_nonzero_coefs.",1,Rename Variable,,
2df0620e4263926aa8dde8fdb387333dc93d351c,2011-07-27T00:56:11Z,https://github.com/scikit-learn/scikit-learn/commit/2df0620e4263926aa8dde8fdb387333dc93d351c,Merge pull request #278 from agramfort/rename_lars  API : renaming LARS to Lars,1,Rename Variable,,
c77bf7b14cedf3100589dfa866fbbd4ed42851fd,2011-07-20T13:41:35Z,https://github.com/scikit-learn/scikit-learn/commit/c77bf7b14cedf3100589dfa866fbbd4ed42851fd,Rename n_states --> n_components in mixture & hmm + cosmetic changes.,1,Rename Variable,,
f38c5abaac6b1057c2430f4c9dbe2f1225253c8c,2011-07-15T12:14:46Z,https://github.com/scikit-learn/scikit-learn/commit/f38c5abaac6b1057c2430f4c9dbe2f1225253c8c,"Refactor naive_bayes and don't treat BernoulliNB as linear model  It may have a linear formulation, but I can't figure it out without sacrificing efficiency on sparse input.",1,Rename Variable,,
61cb91238fe2bf565529abd25dc2c1169b3ecd63,2011-07-10T12:50:39Z,https://github.com/scikit-learn/scikit-learn/commit/61cb91238fe2bf565529abd25dc2c1169b3ecd63,s/seed/random_state in patch extractor,1,Rename Variable,,
3f4d0cc2359c6ebc7a4adf547cfaf5c35ad25555,2011-07-05T11:49:29Z,https://github.com/scikit-learn/scikit-learn/commit/3f4d0cc2359c6ebc7a4adf547cfaf5c35ad25555,"Optimize CountVectorizer.fit_transform (+ minor refactoring)  * Replace sort-then filter, O(n lg n), by filter only, O(n)   ~20% speedup in fit_transform on grid search example, see   https://gist.github.com/1064655 * Use defaultdict where applicable for more compact code * Changed a test which relied on unspecified tie-breaking behavior",1,Rename Variable,,
dd64030c1f9297260dfd5acd0953fc1f71da63bd,2011-05-30T12:00:43Z,https://github.com/scikit-learn/scikit-learn/commit/dd64030c1f9297260dfd5acd0953fc1f71da63bd,Simplify intercept fitting in MultinomialNB,1,Rename Variable,,
2dd421d4948e1c30a9cbc669090fafd8adbdc2c6,2011-05-26T07:46:18Z,https://github.com/scikit-learn/scikit-learn/commit/2dd421d4948e1c30a9cbc669090fafd8adbdc2c6,NB: rename use_prior to fit_prior,1,Rename Variable,,
e83a8ccb51061582374841fa716da77cec4af6ed,2011-05-20T11:32:51Z,https://github.com/scikit-learn/scikit-learn/commit/e83a8ccb51061582374841fa716da77cec4af6ed,naive bayes: copyedit + rename alpha_i to alpha,1,Rename Variable,,
81f2fbe8bbf0aa98841f270d593ae353a7b31816,2011-05-11T13:02:50Z,https://github.com/scikit-learn/scikit-learn/commit/81f2fbe8bbf0aa98841f270d593ae353a7b31816,Rename embdding_vectors_ --> embedding_,1,Rename Variable,,
6ee9d6825035a66cfd792e02be2f39f8c818c0b2,2011-05-04T07:45:16Z,https://github.com/scikit-learn/scikit-learn/commit/6ee9d6825035a66cfd792e02be2f39f8c818c0b2,rename rng to random_state,1,Rename Variable,,
69c05ea2f0badbede3dc5953e1f5868ae36adcdc,2011-04-20T14:23:33Z,https://github.com/scikit-learn/scikit-learn/commit/69c05ea2f0badbede3dc5953e1f5868ae36adcdc,rename grid_points_scores_ to grid_scores_ in GridSearchCV,1,Rename Variable,,
0a898c39620c78995970a40cdfa49aa804aa5413,2011-04-20T08:47:47Z,https://github.com/scikit-learn/scikit-learn/commit/0a898c39620c78995970a40cdfa49aa804aa5413,More low-level refactoring.,1,Rename Variable,,
ad7ae97873f3b020cb3a217ee33b39663850db42,2011-04-18T13:49:40Z,https://github.com/scikit-learn/scikit-learn/commit/ad7ae97873f3b020cb3a217ee33b39663850db42,libsvm low-level API refactoring.  Mostly for ease of use and to support the upcoming cross validation objects.,1,Rename Variable,,
c429a0b1960652d2932092389b5ceb04950a7d9f,2011-04-06T13:25:55Z,https://github.com/scikit-learn/scikit-learn/commit/c429a0b1960652d2932092389b5ceb04950a7d9f,"ENH: low-level API of libsvm.  Also renamed parameter p in SVR to epsilon, as it apears on the libsvm article. Also restored this parameter from NuSVR (it wasn't exposed).",1,Rename Variable,,
ab506f1141de4e50a78e6a0afc75162d55c23da6,2011-04-03T00:38:38Z,https://github.com/scikit-learn/scikit-learn/commit/ab506f1141de4e50a78e6a0afc75162d55c23da6,Attributes renamed and documented.,1,Rename Variable,,
5f32ef339d6a0f6110815c163fb77c90a30b226b,2011-04-01T16:08:20Z,https://github.com/scikit-learn/scikit-learn/commit/5f32ef339d6a0f6110815c163fb77c90a30b226b,Renaming; removed numpy 2-norm,1,Rename Variable,,
f86395a3e0f5a465368225825f09800646850d3b,2011-04-01T03:58:15Z,https://github.com/scikit-learn/scikit-learn/commit/f86395a3e0f5a465368225825f09800646850d3b,Renamed tolerance to tol for consistency.,1,Rename Variable,,
618a1b52e7ef7f4d7a94c4e71b6f18e3536d279f,2011-03-15T15:29:49Z,https://github.com/scikit-learn/scikit-learn/commit/618a1b52e7ef7f4d7a94c4e71b6f18e3536d279f,"refactored SGD module (removed code duplication, better variable naming). added interface for sample weight. added seed to interface of sparse SGD classifier and regressor.",1,Rename Variable,,
8d893587d87769367c219b850b50f59a9a806575,2011-03-06T14:13:14Z,https://github.com/scikit-learn/scikit-learn/commit/8d893587d87769367c219b850b50f59a9a806575,"Extended docstring, renamed variables from javaStyle to python_style, replaced tab-indents with space-indents, pep8",1,Rename Variable,,
898ab690efa5e13f7dc76743cfd8edd28e94ee8c,2011-02-27T12:04:13Z,https://github.com/scikit-learn/scikit-learn/commit/898ab690efa5e13f7dc76743cfd8edd28e94ee8c,Rename nobs --> n_obs,1,Rename Variable,,
5ea578a19c177e7b6ccb4d4193bf33342fe261b6,2011-02-27T12:04:13Z,https://github.com/scikit-learn/scikit-learn/commit/5ea578a19c177e7b6ccb4d4193bf33342fe261b6,Rename ndim --> n_dim,1,Rename Variable,,
123c0f8c11fe273295b5f304c094e96a986c6f0e,2011-02-27T11:15:50Z,https://github.com/scikit-learn/scikit-learn/commit/123c0f8c11fe273295b5f304c094e96a986c6f0e,better name: rename class_names to target_names for consistency,1,Rename Variable,,
80673ed07d9aba3bf9cea8253cd3bb1c20b14b66,2011-02-24T19:03:16Z,https://github.com/scikit-learn/scikit-learn/commit/80673ed07d9aba3bf9cea8253cd3bb1c20b14b66,Rename strategy --> algorithm in Neighbors*.,1,Rename Variable,,
4a6e16fee57e6b9910e6b2d77be7b9fc892e1ab2,2011-02-23T09:53:24Z,https://github.com/scikit-learn/scikit-learn/commit/4a6e16fee57e6b9910e6b2d77be7b9fc892e1ab2,Rename inplace --> brute_inplace,1,Rename Variable,,
94f65ccb717ce97dbf9fb650b7a07cc9a6f95064,2011-02-17T09:23:33Z,https://github.com/scikit-learn/scikit-learn/commit/94f65ccb717ce97dbf9fb650b7a07cc9a6f95064,Rename barycenter --> barycenter_weights (as it was before).,1,Rename Variable,,
50e8a9a0e28f91a46e9936dc2866daca5e57f623,2011-01-26T11:12:11Z,https://github.com/scikit-learn/scikit-learn/commit/50e8a9a0e28f91a46e9936dc2866daca5e57f623,Rename lb -> label_binarizer.,1,Rename Variable,,
544e5317a0d858e68946e4777fd0112f06884823,2011-01-22T19:13:35Z,https://github.com/scikit-learn/scikit-learn/commit/544e5317a0d858e68946e4777fd0112f06884823,ENH: KMeans tolerance parameter renamed tol (as in coordinate descent) and made public,1,Rename Variable,,
89377b979acf54e4edb1b6ef56bc27e9d13b2842,2010-12-12T04:14:55Z,https://github.com/scikit-learn/scikit-learn/commit/89377b979acf54e4edb1b6ef56bc27e9d13b2842,"API : maxit replaced by max_iter everywhere API : removing default computation of r2 coef in coordinate_descent (speed up +     can be accessed simply eg. lasso.score(X, y))",1,Rename Variable,,
d7609b38a7d08bfc317a08bdf5912aeac08e184b,2010-12-10T19:04:51Z,https://github.com/scikit-learn/scikit-learn/commit/d7609b38a7d08bfc317a08bdf5912aeac08e184b,consistently rename n_comp to n_components,1,Rename Variable,,
560c6c7c174f4f2b563453aa853ae9e3cb8d06ee,2010-12-01T10:38:28Z,https://github.com/scikit-learn/scikit-learn/commit/560c6c7c174f4f2b563453aa853ae9e3cb8d06ee,More rename in the sgd module.  Merge stochastic_descent into linear_model.,1,Rename Variable,,
7efcff49a721872236badb42fc3f822629f9a6a8,2010-11-16T21:57:54Z,https://github.com/scikit-learn/scikit-learn/commit/7efcff49a721872236badb42fc3f822629f9a6a8,"Replaced np.matrix(A) * np.matrix(B) by np.dot(A,B), so that the code is a lot clearer to read... Implemented the solve_triangular function accounting for backward compatibility (following Fabian's trick).",1,Rename Variable,,
431d8f4c4dfde2c1ea47c5e89cbf2c4b494799fe,2010-11-07T21:21:09Z,https://github.com/scikit-learn/scikit-learn/commit/431d8f4c4dfde2c1ea47c5e89cbf2c4b494799fe,rename HMM.n_dim to HMM.n_features to be consistent with the rest of the scikit,1,Rename Variable,,
cd74e3265fdc05091da1afda4a40237bf055d1bc,2010-11-07T21:08:28Z,https://github.com/scikit-learn/scikit-learn/commit/cd74e3265fdc05091da1afda4a40237bf055d1bc,rename GMM.n_dim to GMM.n_features to be consistent with the rest of the scikit,1,Rename Variable,,
11465983d158e3e42e114b137ccd45f88d665caf,2010-10-19T09:47:28Z,https://github.com/scikit-learn/scikit-learn/commit/11465983d158e3e42e114b137ccd45f88d665caf,"Bindings for libsvm-dense  Split cython modules libsvm-dense and libsvm-sparse  This allows us to have both efficient bindings witht the same code source, by using different #defines each time, also add support for returning the indices of support vectors.",1,Rename Variable,,
5c99998c73ad3bb5c33274a5634f10e08878a926,2010-10-18T08:50:18Z,https://github.com/scikit-learn/scikit-learn/commit/5c99998c73ad3bb5c33274a5634f10e08878a926,remove n_dim property (use plain field).,1,Rename Variable,,
246102642635d9c18bf144e2a9545bd1fbe65ff3,2010-09-29T12:12:09Z,https://github.com/scikit-learn/scikit-learn/commit/246102642635d9c18bf144e2a9545bd1fbe65ff3,Refactoring in sparse SVM and bug solving (default value of gamma).,1,Rename Variable,,
6053027f7b509541e686fef839797b7fe021cb19,2010-09-14T16:15:37Z,https://github.com/scikit-learn/scikit-learn/commit/6053027f7b509541e686fef839797b7fe021cb19,LARS refactoring speedup Work In Progress!!!,1,Rename Variable,,
4287862761461d9ebaa229ad558c32f304acb4fa,2010-09-14T09:18:01Z,https://github.com/scikit-learn/scikit-learn/commit/4287862761461d9ebaa229ad558c32f304acb4fa,"Rename PyBallTree* --> BallTree* in BallTree.cpp.  According to ticket #24 description, ""user code should never define  names that begin with Py ..."".",1,Rename Variable,,
e7c8ba6b69c240f30329c49b0b4d68504a724b6c,2010-09-09T11:57:10Z,https://github.com/scikit-learn/scikit-learn/commit/e7c8ba6b69c240f30329c49b0b4d68504a724b6c,ENH: Port the nipy k-means with some cleanups and enhancements.,1,Rename Variable,,
cade67f029141ef06a8188decf33b6d802cb9aa7,2010-09-08T12:29:55Z,https://github.com/scikit-learn/scikit-learn/commit/cade67f029141ef06a8188decf33b6d802cb9aa7,Update docstrings in svm and logistic.  Also renamed has_intercept -> fit_intercept for consistency with glm.* objects.,1,Rename Variable,,
56910261abb67eee2c81940b72c54600e4d242eb,2010-09-06T10:07:51Z,https://github.com/scikit-learn/scikit-learn/commit/56910261abb67eee2c81940b72c54600e4d242eb,Rename nSV_ --> n_support_ in svm module.,1,Rename Variable,,
c62aa8875df9e5e4f6b23ad71eb118696ca7dcfc,2010-08-30T12:29:14Z,https://github.com/scikit-learn/scikit-learn/commit/c62aa8875df9e5e4f6b23ad71eb118696ca7dcfc,Some patches for k_means.    * rename minit --> init in docstring to match actual type.   * rename iter --> n_iter in the doc to match actual type.   * add k-means++ initialization to docstring.   * rename kinit --> k_init (consistency with k_means)   * call asanyarray in fit.,1,Rename Variable,,
4e79a78ad1cc22a0d8fe51f4f4f09665081f2b6a,2010-08-19T09:47:46Z,https://github.com/scikit-learn/scikit-learn/commit/4e79a78ad1cc22a0d8fe51f4f4f09665081f2b6a,"Refactoring & bug solving in liblinear.  Solved a bug that prevented to correctly use the intercept in predict.  Muticlass prediction is still broken, thou.",1,Rename Variable,,
efc32a51ed261bf945949d679211eafd497034e8,2010-08-18T19:27:12Z,https://github.com/scikit-learn/scikit-learn/commit/efc32a51ed261bf945949d679211eafd497034e8,More refactoring in libsvm + liblinear.  Added a (skipped) failing test.,1,Rename Variable,,
28ca33eb8028c56d37e96252f57fc57aa68e142d,2010-08-18T10:03:16Z,https://github.com/scikit-learn/scikit-learn/commit/28ca33eb8028c56d37e96252f57fc57aa68e142d,More refactoring in libsvm + liblinear.  Added a (skipped) failing test.,1,Rename Variable,,
ea20d1c30b3305367915e02853471bfe7352c937,2010-07-04T15:10:11Z,https://github.com/scikit-learn/scikit-learn/commit/ea20d1c30b3305367915e02853471bfe7352c937,remove labels handling from vectorizer code,1,Rename Variable,,
9c0408ac95e7d9fcaac4ae468a6e75c9e0e3a9fc,2010-06-18T09:56:02Z,https://github.com/scikit-learn/scikit-learn/commit/9c0408ac95e7d9fcaac4ae468a6e75c9e0e3a9fc,LeastAngleRegression fixes & refactoring.  Work in progress.,1,Rename Variable,,
3b211b5ffc145f533e8e57eded58c6443d9889cf,2010-06-02T13:04:28Z,https://github.com/scikit-learn/scikit-learn/commit/3b211b5ffc145f533e8e57eded58c6443d9889cf,Remove property _ndim (replaced with field ndim) in gmm,1,Rename Variable,,
414aa79bb724839115b15168fdc3e42cbc985744,2010-05-07T14:52:21Z,https://github.com/scikit-learn/scikit-learn/commit/414aa79bb724839115b15168fdc3e42cbc985744,"ENH to LassoPath: cleaner, shorter code and storing path is now optional",1,Rename Variable,,
08403989fe8728d68fc557090da2d3bafa643456,2010-05-05T10:22:28Z,https://github.com/scikit-learn/scikit-learn/commit/08403989fe8728d68fc557090da2d3bafa643456,MISC: Rename *_indexes to *_indices in cross_val.,1,Rename Variable,,
8ab0e8ff9d8e48bc7731978d4a299d82f5ffb154,2010-01-27T14:46:57Z,https://github.com/scikit-learn/scikit-learn/commit/8ab0e8ff9d8e48bc7731978d4a299d82f5ffb154,Refactor test_neighbors.  Just some name updates.  From: Fabian Pedregosa <fabian.pedregosa@inria.fr>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@382 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8,1,Rename Variable,,
bd1e6b281a436e856eafbd999aa4d19c6cdfd07c,2010-01-05T16:26:14Z,https://github.com/scikit-learn/scikit-learn/commit/bd1e6b281a436e856eafbd999aa4d19c6cdfd07c,More clean up  From: cdavid <cdavid@cb17146a-f446-4be1-a4f7-bd7c5bb65646>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@142 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8,1,Rename Variable,,
7c48b548a399df7e09c6f302090a8dab293d0723,2010-01-05T13:50:44Z,https://github.com/scikit-learn/scikit-learn/commit/7c48b548a399df7e09c6f302090a8dab293d0723,Heavy refactoring. These are more or less complete now. Small additions remain to make the interface more obvious for users.  From: fred.mailhot <fred.mailhot@cb17146a-f446-4be1-a4f7-bd7c5bb65646>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@31 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8,1,Rename Variable,,
633fbccdc6b26836d64792083f3127dd51975d7a,2010-01-05T13:48:39Z,https://github.com/scikit-learn/scikit-learn/commit/633fbccdc6b26836d64792083f3127dd51975d7a,Refactoring SRN based on MLP. Simple 1-step backprop only.  From: fred.mailhot <fred.mailhot@cb17146a-f446-4be1-a4f7-bd7c5bb65646>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@28 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8,1,Rename Variable,,
b8f69d0d10e74c3718e5c79891fdc2a5ac8887d0,2023-08-17T16:34:47Z,https://github.com/huggingface/transformers/commit/b8f69d0d10e74c3718e5c79891fdc2a5ac8887d0,Add Text-To-Speech pipeline (#24952)  * add AutoModelForTextToSpeech class  * add TTS pipeline and tessting  * add docstrings to text_to_speech pipeline  * fix torch dependency  * corrector 'processor is None' case in Pipeline  * correct repo id  * modify text-to-speech -> text-to-audio  * remove processor  * rename text_to_speech pipelines files to text_audio  * add textToWaveform and textToSpectrogram instead of textToAudio classes  * update TTS pipeline to the bare minimum  * update tests TTS pipeline  * make style and erase useless import torch in TTS pipeline tests  * modify how to check if generate or forward in TTS pipeline  * remove unnecessary extra new lines  * Apply suggestions from code review  Co-authored-by: Sanchit Gandhi <93869735+sanchit-gandhi@users.noreply.github.com>  * refactor input_texts -> text_inputs  * correct docstrings of TTS.__call__  * correct the shape of generated waveform  * take care of Bark tokenizer special case  * correct run_pipeline_test TTS  * make style  * update TTS docstrings  * address Sylvain nit refactors  * make style  * refactor into one liners  * correct squeeze  * correct way to test if forward or generate  * Update output audio waveform shape  * make style  * correct import  * modify how the TTS pipeline test if a model can generate  * align shape output of TTS pipeline with consistent shape  ---------  Co-authored-by: Sanchit Gandhi <93869735+sanchit-gandhi@users.noreply.github.com>,1,Rename Variable,,
ee4250a35f3bd5e9a4379b4907b3d8f9d5d9523f,2023-07-19T12:26:27Z,https://github.com/huggingface/transformers/commit/ee4250a35f3bd5e9a4379b4907b3d8f9d5d9523f,[`Llama2`] replace `self.pretraining_tp` with `self.config.pretraining_tp` (#24906)  * add possibility to disable TP  * fixup  * adapt from offline discussions,1,Rename Variable,,
9dc965bb404c2bb8e3c02eaa5eea6502af1aee1a,2023-07-17T18:52:28Z,https://github.com/huggingface/transformers/commit/9dc965bb404c2bb8e3c02eaa5eea6502af1aee1a,deprecate no_cuda (#24863)  * deprecate no_cuda  * style  * remove doc  * remove doc 2  * fix style,1,Rename Variable,,
f42a35e611ae3916cfb5b1e8a0540606abb31466,2023-07-17T16:53:24Z,https://github.com/huggingface/transformers/commit/f42a35e611ae3916cfb5b1e8a0540606abb31466,"Add bark (#24086)  * first raw version of the bark integration  * working code on small models with single run  * add converting script from suno weights 2 hf  * many changes  * correct past_kv output  * working implementation for inference  * update the converting script according to the architecture changes  * add a working end-to-end inference code  * remove some comments and make small changes  * remove unecessary comment  * add docstrings and ensure no unecessary intermediary output during audio generation  * remove done TODOs  * make style + add config docstrings  * modification for batch inference support on the whole model  * add details to .generation_audio method  * add copyright  * convert EncodecModel from original library to transformers implementation  * add two class in order to facilitate model and sub-models loading from the hub  * add support of loading the whole model  * add BarkProcessor  * correct modeling according to processor output  * Add proper __init__ and auto support  * Add up-to-date copyright/license message  * add relative import instead of absolute  * cleaner head_dim computation  * small comment removal or changes  * more verbose LayerNorm init method  * specify eps for clearer comprehension  * more verbose variable naming in the MLP module  * remove unecessary BarkBlock parameter  * clearer code in the forward pass of the BarkBlock  * remove _initialize_modules method for cleaner code  * Remove unnecessary methods from sub-models  * move code to remove unnecessary function  * rename a variable for clarity and change an assert  * move code and change variable name for clarity  * remove unnecessary asserts  * correct small bug  * correct a comment  * change variable names for clarity  * remove asserts  * change import from absolute to relative  * correct small error due to comma missing + correct import  * Add attribute Bark config  * add first version of tests  * update attention_map  * add tie_weights and resize_token_embeddings for fineModel  * correct getting attention_mask in generate_text_semantic  * remove Bark inference trick  * leave more choices in barkProcessor  * remove _no_split_modules  * fixe error in forward of block and introduce clearer notations  * correct converting script with last changes  * make style + add draft bark.mdx  * correct BarkModelTest::test_generate_text_semantic  * add Bark in main README  * add dummy_pt_objects for Bark  * add missing models in the main init  * correct test_decoder_model_past_with_large_inputs  * disable torchscript test  * change docstring of BarkProcessor  * Add test_processor_bark  * make style  * correct copyrights  * add bark.mdx + make style, quality and consistency  * Apply suggestions from code review  Co-authored-by: Sanchit Gandhi <93869735+sanchit-gandhi@users.noreply.github.com>  * Remove unnecessary test method  * simply logic of a test  * Only check first ids for slow audio generation  * split full end-to-end generation tests  * remove unneccessary comment  * change submodel names for clearer naming  * remove ModuleDict from modeling_bark  * combine two if statements  * ensure that an edge misued won't happen  * modify variable name  * move code snippet to the right place (coarse instead of semantic)  * change BarkSemanticModule -> BarkSemanticModel  * align BarkProcessor with transformers paradigm  * correct BarkProcessor tests with last commit changes  * change _validate_voice_preset to an instance method instead of a class method  * tie_weights already called with post_init  * add codec_model config to configuration  * update bark modeling tests with recent BarkProcessor changes  * remove SubModelPretrainedModel + change speakers embeddings prompt type in BarkModel  * change absolute imports to relative  * remove TODO  * change docstrings  * add examples to docs and docstrings  * make style  * uses BatchFeature in BarkProcessor insteads of dict  * continue improving docstrings and docs + make style  * correct docstrings examples  * more comprehensible speaker_embeddings load/Save  * rename speaker_embeddings_dict -> speaker_embeddings  * correct bark.mdx + add bark to documentation_tests  * correct docstrings configuration_bark  * integrate last nit suggestions  * integrate BarkGeneration configs  * make style  * remove bark tests from documentation_tests.txt because timeout - tested manually  * add proper generation config initialization  * small bark.mdx documentation changes  * rename bark.mdx -> bark.md  * add torch.no_grad behind BarkModel.generate_audio()  * replace assert by ValueError in convert_suno_to_hf.py  * integrate a series of short comments from reviewer  * move SemanticLogitsProcessors and remove .detach() from Bark docs and docstrings  * actually remove SemanticLogitsProcessor from modeling_bark.oy  * BarkProcessor returns a single output instead of tuple + correct docstrings  * make style + correct bug  * add initializer_range to BarkConfig + correct slow modeling tests  * add .clone() to history_prompt.coarse_prompt to avoid modifying input array  * Making sure no extra ""`"" are present  * remove extra characters in modeling_bark.py  * Correct output if history_prompt is None  * remove TODOs  * remove ravel comment  * completing generation_configuration_bark.py docstrings  * change docstrings - number of audio codebooks instead of Encodec codebooks  * change 'bias' docstrings in configuration_bark.py  * format code  * rename BarkModel.generate_audio -> BarkModel.generate_speech  * modify AutoConfig instead of EncodecConfig in BarkConfig  * correct AutoConfig wrong init  * refactor BarkModel and sub-models generate_coarse, generate_fine, generate_text_semantic  * remove SemanticLogitsProcessor and replace it with SuppressTokensLogitsProcessor  * move nb_codebook related config arguments to BarkFineConfig  * rename bark.mdx -> bark.md  * correcting BarkModelConfig from_pretrained + remove keys_to_ignore  * correct bark.md with correct hub path  * correct code bug in bark.md  * correct list tokens_to_suppress  * modify Processor to load nested speaker embeddings in a safer way  * correct batch sampling in BarkFineModel.generate_fine  * Apply suggestions from code review  Small docstrings correction and code improvements  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>  * give more details about num_layers in docstrings  * correct indentation mistake  * correct submodelconfig order of docstring variables  * put audio models in alphabetical order in utils/check_repo.my  * remove useless line from test_modeling_bark.py  * makes BarkCoarseModelTest inherits from (ModelTesterMixin, GenerationTesterMixin, unittest.TestCase) instead of BarkSemanticModelTest  * make a Tester class for each sub-model instead of inheriting  * add test_resize_embeddings=True for Bark sub-models  * add Copied from transformers.models.gpt_neo.modeling_gpt_neo.GPTNeoSelfAttention._split_heads  * remove 'Copied fom Bark' comment  * remove unneccessary comment  * change np.min -> min in modeling_bark.py  * refactored all custom layers to have Bark prefix  * add attention_mask as an argument of generate_text_semantic  * refactor sub-models start docstrings to have more precise config class definition  * move _tied_weights_keys overriding  * add docstrings to generate_xxx in modeling_bark.py  * add loading whole BarkModel to convert_suno_to_hf  * refactor attribute and variable names  * make style convert_suno  * update bark checkpoints  * remove never entered if statement  * move bark_modeling docstrings after BarkPretrainedModel class definition  * refactor modeling_bark.py: kv -> key_values  * small nits - code refactoring and removing unecessary lines from _init_weights  * nits - replace inplace method by variable assigning  * remove *optional* when necessary  * remove some lines in generate_speech  * add default value for optional parameter  * Refactor preprocess_histories_before_coarse -> preprocess_histories  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * correct usage after refactoring  * refactor Bark's generate_xxx -> generate and modify docstrings and tests accordingly  * update docstrings python in configuration_bark.py  * add bark files in utils/documentation_test.txt  * correct docstrings python snippet  * add the ability to use parameters in the form of e.g coarse_temperature  * add semantic_max_new_tokens in python snippet in docstrings for quicker generation  * Reformate sub-models kwargs in BakModel.generate  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>  * correct kwargs in BarkModel.generate  * correct attention_mask kwarg in BarkModel.generate  * add tests for sub-models args in BarkModel.generate and correct BarkFineModel.test_generate_fp16  * enrich BarkModel.generate docstrings with a description of how to use the kwargs  ---------  Co-authored-by: Sanchit Gandhi <93869735+sanchit-gandhi@users.noreply.github.com> Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com> Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>",1,Rename Variable,,
857d4e1c8764169277fa9a318d4082d39cc08f12,2023-06-01T14:54:01Z,https://github.com/huggingface/transformers/commit/857d4e1c8764169277fa9a318d4082d39cc08f12,rename DocumentQuestionAnsweringTool parameter input to match docstring (#23939)  rename encode input to match docstring,1,Rename Variable,,
527ab894e59b6582578008e3b47648a65063f73d,2023-05-23T09:43:12Z,https://github.com/huggingface/transformers/commit/527ab894e59b6582578008e3b47648a65063f73d,Add PerSAM [bis] (#23659)  * Add PerSAM args  * Make attn_sim optional  * Rename to attention_similarity  * Add docstrigns  * Improve docstrings,1,Rename Variable,,
f143037789288ba532dada934a118e648e715738,2023-04-20T17:27:24Z,https://github.com/huggingface/transformers/commit/f143037789288ba532dada934a118e648e715738,"Add `automatic-mask-generation` pipeline for Segment Anything Model (SAM) (#22840)  * cleanup  * updates  * more refactoring  * make style  * update inits  * support other inputs in base  * update based on review  Co-authored-by: Nicolas Patry <patry.nicolas@gmail.com>  * Update tests/pipelines/test_pipelines_automatic_mask_generation.py  Co-authored-by: Nicolas Patry <patry.nicolas@protonmail.com>  * update  * fixup  * TODO x and y to refactor, _h _w refactored here  * update docstring  * more nits  * style on these  * more doc fix  * rename variables  * update  * updates  * style  * update  * fix `_mask_to_rle_pytorch`  * styling  * fix ask to rle, wrong outputs  * add device arg  * update  * more updates, fix tets  * udpate  * update docstrings  * styling  * fixup  * add notebook on the docs  * update orginal sizes  * fix docstring  * updat condition on point_per-batch  * updates tests  * fix CI  test  * extend is required, append does not work!  * fixup  * fix CI tests  * whit pixels left  * address doc comments  * fix doc  * slow pipeline tests  * update auto init  * add revision  * make fixup  * update p!ipoeline tag when calling tests  * alphabeitcal order in inits  * fix copies  * last style nits  * Apply suggestions from code review  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>  * reformat docstring  * more reformat  * address most of the comments  * Update src/transformers/pipelines/mask_generation.py  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>  * final refactor  * Update src/transformers/models/sam/image_processing_sam.py  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>  * fixup and fix slow tests  * revert  ---------  Co-authored-by: Nicolas Patry <patry.nicolas@gmail.com> Co-authored-by: Nicolas Patry <patry.nicolas@protonmail.com> Co-authored-by: younesbelkada <younesbelkada@gmail.com> Co-authored-by: Younes Belkada <49240599+younesbelkada@users.noreply.github.com> Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>",1,Rename Variable,,
4116d1ec75517dae99fc5881c3e3b567a3e3b40a,2023-04-20T12:51:01Z,https://github.com/huggingface/transformers/commit/4116d1ec75517dae99fc5881c3e3b567a3e3b40a,[Examples/TensorFlow] minor refactoring to allow compatible datasets to work (#22879)  minor refactoring to allow compatible datasets to work.,1,Rename Variable,,
d62e7d8842514b3d857a0df0957a8ddb3b5929fd,2023-03-22T18:13:20Z,https://github.com/huggingface/transformers/commit/d62e7d8842514b3d857a0df0957a8ddb3b5929fd,"Chunkable token classification pipeline (#21771)  * Chunkable classification pipeline   The TokenClassificationPipeline is now able to process sequences longer than 512. No matter the framework, the model, the tokenizer. We just have to pass process_all=True and a stride number (optional). The behavior remains the same if you don't pass these optional parameters. For overlapping parts when using stride above 0, we consider only the max scores for each overlapped token in all chunks where the token is.  * Update token_classification.py  * Update token_classification.py  * Update token_classification.py  * Update token_classification.py  * Update token_classification.py  * Update token_classification.py  * Update token_classification.py  * Update token_classification.py  * Update token_classification.py  * Update token_classification.py  * Update token_classification.py  * Update token_classification.py  * update with latest black format  * update black format  * Update token_classification.py  * Update token_classification.py  * format correction  * Update token_classification.py  * Update token_classification.py  * Update token_classification.py  * Update token_classification.py  * Update comments  * Update src/transformers/pipelines/token_classification.py  Co-authored-by: Nicolas Patry <patry.nicolas@protonmail.com>  * Update token_classification.py  Correct spaces, remove process_all and keep only stride. If stride is provided, the pipeline is applied to the whole text.  * Update token_classification.py  * Update token_classification.py  * Update token_classification.py  * Update token_classification.py  * Update token_classification.py  * Update token_classification.py  * Update token_classification.py  * Update token_classification.py  * Update chunk aggregation  Update the chunk aggregation strategy based on entities aggregation.  * Update token_classification.py  * Update token_classification.py  * Update token_classification.py  * Update token_classification.py  * Update token_classification.py  * Update token_classification.py  * Update token_classification.py  * Update token_classification.py  * Update token_classification.py  * Update token_classification.py  * Update token_classification.py  * Update token_classification.py  Remove unnecessary pop from outputs dict  * Update token_classification.py  * Update token_classification.py  * Update token_classification.py  * Update token_classification.py  * Update token_classification.py  * Update token_classification.py  * Update token_classification.py  * Update src/transformers/pipelines/token_classification.py  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * add chunking tests  * correct formating  * correct formatting  * correct model id for test chunking  * update scores with nested simplify  * Update test_pipelines_token_classification.py  * Update test_pipelines_token_classification.py  * update model to a tiny one  * Update test_pipelines_token_classification.py  * Adding smaller test for chunking.  * Fixup  * Update token_classification.py  * Update src/transformers/pipelines/token_classification.py  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * Update src/transformers/pipelines/token_classification.py  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  ---------  Co-authored-by: Nicolas Patry <patry.nicolas@protonmail.com> Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>",1,Rename Variable,,
087fd5f368a8c22a67e98790f6d83bf31305213f,2023-02-17T17:57:05Z,https://github.com/huggingface/transformers/commit/087fd5f368a8c22a67e98790f6d83bf31305213f,[`ImageProcessor`] Refactor default `mean` & `std` to `OPENAI_CLIP_MEAN` & `OPENAI_CLIP_STD` (#21425)  * fix default value  * add the fix on other models,1,Rename Variable,,
12eb528b5a88d66b81957139ae452acec99a083a,2023-02-07T08:51:35Z,https://github.com/huggingface/transformers/commit/12eb528b5a88d66b81957139ae452acec99a083a,[CI ] Remove `past` in favor of `pat_key_values` (#21443)  * fix past renamed to past_key_value  * update more `past`that were ski^êd  * fixup  * remove changes made to rag  * refactor `_reorder_cache` to use `past_key_values`  * fix git `prepare_inputs_for_generation` to pass tests when false is needed in use_cache,1,Rename Variable,,
4e41b87e3d13af0d1d7d3d27d101e60c33c92100,2023-01-26T10:31:31Z,https://github.com/huggingface/transformers/commit/4e41b87e3d13af0d1d7d3d27d101e60c33c92100,Use `model_class.__name__` and compare against `XXX_MAPPING_NAMES` (#21304)  * update  * update all  * clean up  * make quality  * clean up  Co-authored-by: ydshieh <ydshieh@users.noreply.github.com>,1,Rename Variable,,
39799fbf85280cdfc93549ffb638b66d8b71db29,2023-01-25T17:25:59Z,https://github.com/huggingface/transformers/commit/39799fbf85280cdfc93549ffb638b66d8b71db29,[CI-Daily] replace `past` in prepare inputs for generation (#21296)  replace `past` in prepare inputs for generation,1,Rename Variable,,
99e79054225c4547bb2870526a287320aef0bd32,2023-01-25T09:16:31Z,https://github.com/huggingface/transformers/commit/99e79054225c4547bb2870526a287320aef0bd32,"Supporting `ImageProcessor` in place of `FeatureExtractor` for pipelines (#20851)  * Fixing the pipeline with image processor.  * Update the slow test.  * Using only the first image processor.  * Include exclusion mecanism for Image processor.  * Do not handle Gitconfig, deemed as a bug.  * Apply suggestions from code review  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>  * Remove `conversational` changes. They are not supposed to be here.  * Address first row of comments.  * Remove OneFormer modifications.  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>",1,Rename Variable,,
c18b4fbe9f8d05c96deff23ee92037912f68a50c,2023-01-23T18:45:27Z,https://github.com/huggingface/transformers/commit/c18b4fbe9f8d05c96deff23ee92037912f68a50c,Add class properties with warnings (#21195)  * Replace reduce_labels with do_reduce_labels  * Replace only for __init__ and preprocess  * Add class properties with warnings  * Update tests,1,Rename Variable,,
354ea4434052f36ec5ce506c13e5efc7cbdad8c1,2023-01-23T17:21:33Z,https://github.com/huggingface/transformers/commit/354ea4434052f36ec5ce506c13e5efc7cbdad8c1,Replace reduce_labels with do_reduce_labels (#21218)  * Replace reduce_labels with do_reduce_labels  * Replace only for __init__ and preprocess  * Update tests,1,Rename Variable,,
023f51fe16e34e0ca2b5598791ae508874d5b443,2023-01-18T10:24:37Z,https://github.com/huggingface/transformers/commit/023f51fe16e34e0ca2b5598791ae508874d5b443,`blip` support for training (#21021)  * `blip` support for training  * remove labels creation  * remove unneeded `decoder_input_ids` creation  * final changes  - add colab link to documentation - reduction = mean for loss  * fix nits  * update link  * clearer error message,1,Rename Variable,,
e3ecbaa4abfeb98807d75fcb3fb7f68d88d41c4d,2023-01-09T17:12:13Z,https://github.com/huggingface/transformers/commit/e3ecbaa4abfeb98807d75fcb3fb7f68d88d41c4d,"Patch-past-refactor (#21050)  * small patches, forgot a line  * refactor PT  * the actual fix",1,Rename Variable,,
f0577df6de36e7e7f28e90fa76da0657de038a39,2023-01-08T09:21:40Z,https://github.com/huggingface/transformers/commit/f0577df6de36e7e7f28e90fa76da0657de038a39,Replace `past` with `past_key_values` (#20944)  * start cleanup  * more updates  * more models are affected  * more updates  * update generation utils  * style  * revert change that removed reorder cachce  * update generation utils  * style  * style  * remove reorder cache,1,Rename Variable,,
12313838d33373d06d35b48c3c501fa832f16443,2023-01-05T12:30:25Z,https://github.com/huggingface/transformers/commit/12313838d33373d06d35b48c3c501fa832f16443,Make sure dynamic objects can be saved and reloaded (#21008)  * Make sure dynamic objects can be saved and reloaded  * Remove processor test,1,Rename Variable,,
367fdf3330121a075c06d796bb95dfb1c69c65e4,2023-01-03T11:29:02Z,https://github.com/huggingface/transformers/commit/367fdf3330121a075c06d796bb95dfb1c69c65e4,`MinNewTokensLengthLogitsProcessor` for `.generate` method #20814 (#20892)  * feat: add min new length logit processor  * test: add min new length logit processor  * docs: add MinNewTokensLengthLogitsProcessor  * feat: import MinNewTokensLengthLogitsProcessor  * fix: update pytorch dummy objects  * refactor & fix: rename attributes and var and get rid of dynamic attribute  * tests: align test with new interface  * docs: fix typo  * docs: minor clarification  * Empty-Commit  * empty commit  * run automated quality edits  Co-authored-by: Joao Gante <joao@huggingface.co>,1,Rename Variable,,
f41a11a16ff1a5dbb8c6f79ca17055b3f98bd413,2022-12-12T19:02:16Z,https://github.com/huggingface/transformers/commit/f41a11a16ff1a5dbb8c6f79ca17055b3f98bd413,rename `layoutlm_job` to `exotic_models_job` (#20736)  Co-authored-by: ydshieh <ydshieh@users.noreply.github.com>,1,Rename Variable,,
e8d448edcfe6348177f0e99774b51eeef8e50b62,2022-11-29T14:58:54Z,https://github.com/huggingface/transformers/commit/e8d448edcfe6348177f0e99774b51eeef8e50b62,extract warnings in GH workflows (#20487)  Co-authored-by: ydshieh <ydshieh@users.noreply.github.com>,1,Rename Variable,,
92cfe8b0741cc98e2aed6aef28c85c6615fd2933,2022-11-15T14:12:41Z,https://github.com/huggingface/transformers/commit/92cfe8b0741cc98e2aed6aef28c85c6615fd2933,Remove `authorized_missing_keys`in favor of _keys_to_ignore_on_load_missing (#20228),1,Rename Variable,,
8827e1b217ca7149a06eebd457bbf9eb26c8a139,2022-11-02T11:03:43Z,https://github.com/huggingface/transformers/commit/8827e1b217ca7149a06eebd457bbf9eb26c8a139,clean up vision/text config dict arguments (#19954)  * clean up  * For backward compatibility  * clean up  * Same changes for more models  Co-authored-by: ydshieh <ydshieh@users.noreply.github.com>,1,Rename Variable,,
7487829a230de3823be61020d05949a12d1a1756,2022-10-21T12:32:10Z,https://github.com/huggingface/transformers/commit/7487829a230de3823be61020d05949a12d1a1756,Added support for multivariate independent emission heads (#19453)  * Added support for multivariate independent emission heads  * fix typo  * rename distr_cls  * scale is a vector for multivariate  * set affine transform event_dim  * fix typo  * added variable  * added beta in the config  * set beta  * remove beta-nll option in nll,1,Rename Variable,,
b651efe59ea506d38173e3a60a4228e7e74719f9,2022-10-11T13:21:29Z,https://github.com/huggingface/transformers/commit/b651efe59ea506d38173e3a60a4228e7e74719f9,[Swin] Replace hard-coded batch size to enable dynamic ONNX export (#19475)  * [Swin] Replace hard-coded batch size to enable dynamic ONNX export,1,Rename Variable,,
36f52e9593cce6530b04cee7a16ed84b8f424a2e,2022-10-03T09:02:51Z,https://github.com/huggingface/transformers/commit/36f52e9593cce6530b04cee7a16ed84b8f424a2e,"Restructure DETR post-processing, return prediction scores (#19262)  * Restructure DetrFeatureExtractor post-processing methods * Update post_process_instance_segmentation and post_process_panoptic_segmentation methods to return prediction scores * Update DETR models docs",1,Rename Variable,,
226b0e46d50dc763dceeeab9682dc83ee70e8c6a,2022-09-27T11:54:05Z,https://github.com/huggingface/transformers/commit/226b0e46d50dc763dceeeab9682dc83ee70e8c6a,"Add a use_parallel_residual argument to control the residual computing way (#18695)  * Add a gpt_j_residual argument to control the residual computing way  * Put duplicate code outside of the if block  * Rename parameter ""gpt_j_residual"" to ""use_parallel_residual"" and set the default value to True",1,Rename Variable,,
7743caccb95acb26a8bcc8806bd697d8a882e786,2022-09-15T11:01:19Z,https://github.com/huggingface/transformers/commit/7743caccb95acb26a8bcc8806bd697d8a882e786,[bnb] Small improvements on utils (#18646)  * Small replacement  - replace `modules_to_not_convert` by `module_to_not_convert`  * refactor a bit  - changed variables name - now output a list - change error message  * make style  * add list  * make style  * change args name  Co-authored-by: stas00 <stas00@users.noreply.github.com>  * fix comment  * fix typo  Co-authored-by: stas00 <stas00@users.noreply.github.com>  * Update src/transformers/modeling_utils.py  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  Co-authored-by: stas00 <stas00@users.noreply.github.com> Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>,1,Rename Variable,,
76454b08c8ec09b0debeb1c94a3855cde8167d84,2022-08-18T13:13:54Z,https://github.com/huggingface/transformers/commit/76454b08c8ec09b0debeb1c94a3855cde8167d84,"Rename second input dimension from ""sequence"" to ""num_channels"" for CV models (#17976)",1,Rename Variable,,
151a2aaa4e58e808dea062a73ae79c4822826df5,2022-08-01T16:10:20Z,https://github.com/huggingface/transformers/commit/151a2aaa4e58e808dea062a73ae79c4822826df5,Split model list on modality (#18328)  * 📝 split up model list  * Adapt script to reorg  * apply niels feedback  Co-authored-by: Sylvain Gugger <Sylvain.gugger@gmail.com>,1,Rename Variable,,
90ed9ae2d1ddc3ba020e8dae5a60facca2b9e4b5,2022-06-09T16:38:48Z,https://github.com/huggingface/transformers/commit/90ed9ae2d1ddc3ba020e8dae5a60facca2b9e4b5,fix use_amp rename after pr 17138 (#17636),1,Rename Variable,,
cb555af2c7737a750366a2829cc0145a731c55ee,2022-04-21T13:09:00Z,https://github.com/huggingface/transformers/commit/cb555af2c7737a750366a2829cc0145a731c55ee,Return input_ids in ImageGPT feature extractor (#16872),1,Rename Variable,,
50dd314d939a86f3a81e19af01459f449fbaeeca,2022-03-09T16:36:59Z,https://github.com/huggingface/transformers/commit/50dd314d939a86f3a81e19af01459f449fbaeeca,Add ONNX export for ViT (#15658)  * Add ONNX support for ViT  * Refactor to use generic preprocessor  * Add vision dep to tests  * Extend ONNX slow tests to ViT  * Add dummy image generator  * Use model_type to determine modality  * Add deprecation warnings for tokenizer argument  * Add warning when overwriting the preprocessor  * Add optional args to docstrings  * Add minimum PyTorch version to OnnxConfig  * Refactor OnnxConfig class variables from CONSTANT_NAME to snake_case  * Add reasonable value for default atol  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>,1,Rename Variable,,
f4e4ad34ccee6f011be1b21c28e78d4816601059,2022-03-09T09:19:05Z,https://github.com/huggingface/transformers/commit/f4e4ad34ccee6f011be1b21c28e78d4816601059,Add `ForInstanceSegmentation` models to `image-segmentation` pipelines (#15937)  * Adding ForInstanceSegmentation to pipelines.  * Last fix `category_id` renamed to `label_id`.  * Can't be none no more.  * No `is_thing_map` anymore.,1,Rename Variable,,
e9fa7cd5d74363eaa737c369902532f864221977,2022-03-07T18:10:32Z,https://github.com/huggingface/transformers/commit/e9fa7cd5d74363eaa737c369902532f864221977,Make is_thing_map in Feature Extractor post_process_panoptic_segmentation defaults to all instances (#15954)  * is_thing_map defaults to all instances  * better naming  * control flow  * resolving conversations,1,Rename Variable,,
6e57a56987ff201747f5f01bbce3ed2c0fda1910,2022-03-02T09:49:05Z,https://github.com/huggingface/transformers/commit/6e57a56987ff201747f5f01bbce3ed2c0fda1910,Adding timestamps for CTC with LM in ASR pipeline. (#15863)  * Adding timestamps for CTC with LM in ASR pipeline.  * iRemove print.  * Nit change.,1,Rename Variable,,
0b5bf6abef93220fe1cf35ece99d0b54d6f00f3d,2022-02-25T17:00:00Z,https://github.com/huggingface/transformers/commit/0b5bf6abef93220fe1cf35ece99d0b54d6f00f3d,Framework split model report (#15825),1,Rename Variable,,
f9582c205afaa4bb117bb67a4bf5184b053417b3,2022-02-23T08:41:42Z,https://github.com/huggingface/transformers/commit/f9582c205afaa4bb117bb67a4bf5184b053417b3,"Adding ZeroShotImageClassificationPipeline (#12119)  * [Proposal] Adding ZeroShotImageClassificationPipeline  - Based on CLIP  * WIP, Resurection in progress.  * Resurrection... achieved.  * Reword handling different `padding_value` for `feature_extractor` and `tokenizer`.  * Thanks doc-builder !  * Adding docs + global namespace `ZeroShotImageClassificationPipeline`.  * Fixing templates.  * Make the test pass and be robust to floating error.  * Adressing suraj's comments on docs mostly.  * Tf support start.  * TF support.  * Update src/transformers/pipelines/zero_shot_image_classification.py  Co-authored-by: Suraj Patil <surajp815@gmail.com>  Co-authored-by: Suraj Patil <surajp815@gmail.com>",1,Rename Variable,,
ac6aa10f23967373142d7a23d84a45ffd494d64b,2022-02-04T19:52:07Z,https://github.com/huggingface/transformers/commit/ac6aa10f23967373142d7a23d84a45ffd494d64b,Standardize semantic segmentation models outputs (#15469)  * Standardize instance segmentation models outputs  * Rename output  * Update src/transformers/modeling_outputs.py  Co-authored-by: NielsRogge <48327001+NielsRogge@users.noreply.github.com>  * Add legacy argument to the config and model forward  * Update src/transformers/models/beit/modeling_beit.py  Co-authored-by: Lysandre Debut <lysandre@huggingface.co>  * Copy fix in Segformer  Co-authored-by: NielsRogge <48327001+NielsRogge@users.noreply.github.com> Co-authored-by: Lysandre Debut <lysandre@huggingface.co>,1,Rename Variable,,
e695470794f236392f249aeb815b62490126f595,2022-01-25T14:41:21Z,https://github.com/huggingface/transformers/commit/e695470794f236392f249aeb815b62490126f595,"Avoid using get_list_of_files (#15287)  * Avoid using get_list_of_files in config  * Wip, change tokenizer file getter  * Remove call in tokenizer files  * Remove last call to get_list_model_files  * Better tests  * Unit tests for new function  * Document bad API",1,Rename Variable,,
b18d8534ea62f144a4002b9e2afcb4588518e945,2021-12-16T17:03:55Z,https://github.com/huggingface/transformers/commit/b18d8534ea62f144a4002b9e2afcb4588518e945,[Generate] Make generate multi-modal (#14784)  * finish refactor  * refactor  * add tests  * add more tests  * up  * finish tests  * finish  * up  * Apply suggestions from code review  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * improve docstring  * fix docs  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>,1,Rename Variable,,
a33168aa7894d5665eacf891ffdcb433cde0f38c,2021-11-16T21:50:04Z,https://github.com/huggingface/transformers/commit/a33168aa7894d5665eacf891ffdcb433cde0f38c,Avoid looping when data exhausted (#14413)  * stop training when a finite IterableDataset is exhausted  when using an iterable dataset num_epochs is set to sys.maxsize to make sure all data is consumed likewise we want to set max_steps high enough but still stop when all data is consumed  (cherry picked from commit 6f0e1d6363153da9051e93acffe1cbab3a3f3b12)  * fix typo flase -> false  * add test for stopping training on exhausted finite iterable dataset  * remove redundant gradient_accumulation_steps  * run make style  reformat training_args docstring,1,Rename Variable,,
62ccbe0960019aceb4e36b1ee929ed2349e9653e,2021-10-22T17:05:45Z,https://github.com/huggingface/transformers/commit/62ccbe0960019aceb4e36b1ee929ed2349e9653e,Rename variables with unclear naming (#14122)  * Rename var  * Add comments,1,Rename Variable,,
4a320f6c9a00fbbeca4aff0abc0acfefc94bcd6a,2021-09-24T05:01:11Z,https://github.com/huggingface/transformers/commit/4a320f6c9a00fbbeca4aff0abc0acfefc94bcd6a,[ASR] Add official ASR CTC example to `examples/pytorch/speech-recognition` (#13620)  * up  * rename  * add asr example  * add auto feature extractor  * some more fixes  * correct layerdrop  * correct for multi-gpu dist  * clean up  * refactor  * refactor  * more fixes  * more fixes  * clean-up  * finish  * up  * Apply suggestions from code review  * fix isort  * update  * up  * add note  * apply surajs suggestions  * Apply suggestions from code review  Co-authored-by: Suraj Patil <surajp815@gmail.com>  * isort  * small change  * Apply suggestions from code review  Co-authored-by: Anton Lozhkov <aglozhkov@gmail.com>  * Apply suggestions from code review  Co-authored-by: Anton Lozhkov <aglozhkov@gmail.com>  * add hubert  * Update examples/pytorch/speech-recognition/run_speech_recognition_ctc.py  Co-authored-by: Suraj Patil <surajp815@gmail.com> Co-authored-by: Anton Lozhkov <aglozhkov@gmail.com>,1,Rename Variable,,
e59d4d0147f91831b4ef7eb44abee8db0a835243,2021-09-09T17:04:37Z,https://github.com/huggingface/transformers/commit/e59d4d0147f91831b4ef7eb44abee8db0a835243,Refactor internals for Trainer push_to_hub (#13486),1,Rename Variable,,
1fc6817a30ea583a02bffb77215f213429d5b5bc,2021-06-29T07:07:46Z,https://github.com/huggingface/transformers/commit/1fc6817a30ea583a02bffb77215f213429d5b5bc,Rename detr targets to labels (#12280)  * Rename target to labels in DetrFeatureExtractor  * Update DetrFeatureExtractor tests accordingly  * Improve docs of DetrFeatureExtractor  * Improve docs  * Make style,1,Rename Variable,,
dad414d5f9c20627ee6c16f62e8a2056916bf35b,2021-06-22T02:30:50Z,https://github.com/huggingface/transformers/commit/dad414d5f9c20627ee6c16f62e8a2056916bf35b,[trainer + examples] set log level from CLI (#12276)  * set log level from CLI  * add log_level_replica + test + extended docs  * cleanup  * Apply suggestions from code review  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * rename datasets objects to allow datasets module  * improve the doc  * style  * doc improve  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>,1,Rename Variable,,
d472bd7b180d41b4fdaf716286d8cc29ea32a18c,2021-06-09T17:40:56Z,https://github.com/huggingface/transformers/commit/d472bd7b180d41b4fdaf716286d8cc29ea32a18c,"Wav2Vec2 Pretraining (#11306)  * Working quantizer forward  * Working quantizer forward  * Clean up unused model parts, test reproducibility  * Working quantizer forward  * Clean up unused model parts, test reproducibility  * Remove custom outputs from the shared ones  * correct conversion  * correct bug  * add first pretrain script  * save intermediate  * static shapes  * save intermediate  * finish first pretrain script version  * more refactor  * remove wanddb  * refactor more  * improve test  * correct perplexity compute bug  * finish model implementation  * add to docs  * finish docs  * finish pretraining script  * finish pretraining script  * remove wandb  * finish PR for merge  * finish config  * finish  * make deepspeed work  * Apply suggestions from code review  Co-authored-by: Lysandre Debut <lysandre@huggingface.co> Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * apply suggestions  * fix flaky test  Co-authored-by: patrickvonplaten <patrick.v.platen@gmail.com> Co-authored-by: Lysandre Debut <lysandre@huggingface.co> Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>",1,Rename Variable,,
11d86d3de420210073538c8d7e1e44f9492d02bc,2021-06-08T19:32:03Z,https://github.com/huggingface/transformers/commit/11d86d3de420210073538c8d7e1e44f9492d02bc,[Deepspeed Wav2vec2] integration (#11638)  * wip  * wip - but working with https://github.com/microsoft/DeepSpeed/pull/1044  * cleanup  * workaround  * working 5/8 modes  * solve fp32 distributed zero3  * style  * sync  * sync  * rework  * deprecation  * cleanup  * https://github.com/microsoft/DeepSpeed/pull/1044 pr was merged  * clean up  * add a guide  * more prose  * more prose  * fix  * more prose  * sub_group_size was too big  * Apply suggestions from code review  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * refactor  * bug fix  * make the true check explicit  * new deepspeed release  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>,1,Rename Variable,,
f4a0d6ff867e8a82a33d7a653e7d45372a463271,2021-05-20T16:02:29Z,https://github.com/huggingface/transformers/commit/f4a0d6ff867e8a82a33d7a653e7d45372a463271,"A cleaner and more scalable implementation of symbolic tracing (#11763)  Cleaner and more scalable implementation of symbolic tracing with torch.fx, and provides support for new architectures: - ALBERT - DistilBERT - MobileBERT - MegatronBERT - GPT2 - GPT Neo  Co-authored-by: Michael Benayoun <michael@huggingface.co>",1,Rename Variable,,
00440e350f58e33435f823ec8a940bd3861fe7ba,2021-05-19T11:00:58Z,https://github.com/huggingface/transformers/commit/00440e350f58e33435f823ec8a940bd3861fe7ba,[Flax MLM] Refactor run mlm with optax (#11745)  * refactor  * update  * update  * update  * refactor run mlm  * finalize  * refactor more  * fix typo  * update  * finish refactor  * modify run mlm  * Apply suggestions from code review  * Apply suggestions from code review  * Apply suggestions from code review  * small fixes  * upload  * upload  * finish run mlm script  Co-authored-by: Patrick von Platen <patrick@huggingface.co>,1,Rename Variable,,
20d6931e322436f9fdc3dc914af15b3af509e9b9,2021-04-30T12:45:33Z,https://github.com/huggingface/transformers/commit/20d6931e322436f9fdc3dc914af15b3af509e9b9,"Update TF text classification example (#11496)  Big refactor, fixes and multi-GPU/TPU support",1,Rename Variable,,
f2b744f690e71756e0752255f3580b75f845ff95,2021-03-19T15:26:32Z,https://github.com/huggingface/transformers/commit/f2b744f690e71756e0752255f3580b75f845ff95,Add transformers id to hub requests (#10811)  * add uuid.hext to user_agent  * add log  * changed order of it  * renamed as session id  * renamed variable  * reverted naming of the const,1,Rename Variable,,
90ecc29656ce37fdbe7279cf586511ed678c0cb7,2021-03-05T23:06:55Z,https://github.com/huggingface/transformers/commit/90ecc29656ce37fdbe7279cf586511ed678c0cb7,"Refactoring checkpoint names for multiple models (#10527)  * Refactor checkpoint name in ALBERT and ALBERT_tf  * Refactor checkpoint name in BART and BART_tf  * Refactor checkpoint name in BERT generation  * Refactor checkpoint name in Blenderbot_tf  * Refactor checkpoint name in Blenderbot_small_tf  * Refactor checkpoint name in ConvBERT AND CONVBERT_TF  * Refactor checkpoint name in CTRL AND CTRL_TF  * Refactor checkpoint name in DistilBERT AND DistilBERT_TF  * Refactor checkpoint name in DistilBERT redo  * Refactor checkpoint name in Electra and Electra_tf  * Refactor checkpoint name in FlauBERT and FlauBERT_tf  * Refactor checkpoint name in FSMT  * Refactor checkpoint name in GPT2 and GPT2_tf  * Refactor checkpoint name in IBERT  * Refactor checkpoint name in LED and LED_tf  * Refactor checkpoint name in Longformer and Longformer_tf  * Refactor checkpoint name in Lxmert and Lxmert_tf  * Refactor checkpoint name in Marian_tf  * Refactor checkpoint name in MBART and MBART_tf  * Refactor checkpoint name in MobileBERT and MobileBERT_tf  * Refactor checkpoint name in mpnet and mpnet_tf  * Refactor checkpoint name in openai and openai_tf  * Refactor checkpoint name in pegasus_tf  * Refactor checkpoint name in reformer  * Refactor checkpoint name in Roberta and Roberta_tf  * Refactor checkpoint name in SqueezeBert  * Refactor checkpoint name in Transformer_xl and Transformer_xl_tf  * Refactor checkpoint name in XLM and XLM_tf  * Refactor checkpoint name in XLNET and XLNET_tf  * Refactor checkpoint name in BERT_tf  * run make tests, style, quality, fixup",1,Rename Variable,,
801ff969ce179b86b8052b8311b87abbd49c4065,2021-03-03T16:21:17Z,https://github.com/huggingface/transformers/commit/801ff969ce179b86b8052b8311b87abbd49c4065,Refactor checkpoint name in BERT and MobileBERT (#10424)  * Refactor checkpoint name in BERT and MobileBERT  * Add option to check copies  * Add QuestionAnswering  * Add last models  * Make black happy,1,Rename Variable,,
e84786aaa69f9013ed596cf1d368d12999903005,2020-11-23T20:33:13Z,https://github.com/huggingface/transformers/commit/e84786aaa69f9013ed596cf1d368d12999903005,consistent ignore keys + make private (#8737)  * consistent ignore keys + make private  * style  * - authorized_missing_keys    => _keys_to_ignore_on_load_missing   - authorized_unexpected_keys => _keys_to_ignore_on_load_unexpected  * move public doc of private attributes to private comment,1,Rename Variable,,
3bc1540070a97ed3adaf55856e1e047c53e54da5,2020-11-18T15:48:31Z,https://github.com/huggingface/transformers/commit/3bc1540070a97ed3adaf55856e1e047c53e54da5,New TF loading weights (#8490)  * New TF loading weights  * apply style  * Better naming  * Largely comment the loading method  * Apply style  * Address Patrick's comments  * Remove useless line of code  * Update Docstring  * Address Sylvain's and Lysandre's comments  * Simplify the names computation  * Typos,1,Rename Variable,Rename Method,
a1bbcf3f6c20e15fe799a8659d6b7bd36fdf11ed,2020-11-03T15:04:22Z,https://github.com/huggingface/transformers/commit/a1bbcf3f6c20e15fe799a8659d6b7bd36fdf11ed,Refactoring the generate() function (#6949)  * first draft  * show design proposition for new generate method  * up  * make better readable  * make first version  * gpt2 tests pass  * make beam search for gpt2 work  * add first encoder-decoder code  * delete typo  * make t5 work  * save indermediate  * make bart work with beam search  * finish beam search bart / t5  * add default kwargs  * make more tests pass  * fix no bad words sampler  * some fixes and tests for all distribution processors  * fix test  * fix rag slow tests  * merge to master  * add nograd to generate  * make all slow tests pass  * speed up generate  * fix edge case bug  * small fix  * correct typo  * add type hints and docstrings  * fix typos in tests  * add beam search tests  * add tests for beam scorer  * fix test rag  * finish beam search tests  * move generation tests in seperate file  * fix generation tests  * more tests  * add aggressive generation tests  * fix tests  * add gpt2 sample test  * add more docstring  * add more docs  * finish doc strings  * apply some more of sylvains and sams comments  * fix some typos  * make fix copies  * apply lysandres and sylvains comments  * final corrections on examples  * small fix for reformer,1,Rename Variable,,
9eb3a410cd826e47b7c97db8af4056a2465e65eb,2020-10-30T19:27:20Z,https://github.com/huggingface/transformers/commit/9eb3a410cd826e47b7c97db8af4056a2465e65eb,Remove deprecated arguments from new run_clm (#8197),1,Rename Variable,,
8ff88d25e9a7655c062f31e81f807f3015c53de7,2020-09-21T13:13:35Z,https://github.com/huggingface/transformers/commit/8ff88d25e9a7655c062f31e81f807f3015c53de7,"[fsmt] rewrite SinusoidalPositionalEmbedding + USE_CUDA test fixes + new TranslationPipeline test (#7224)  * fix USE_CUDA, add pipeline  * USE_CUDA fix  * recode SinusoidalPositionalEmbedding into nn.Embedding subclass  was needed for torchscript to work - this is now part of the state_dict, so will have to remove these keys during save_pretrained  * back out (ci debug)  * restore  * slow last?  * facilitate not saving certain keys and test  * remove no longer used keys  * style  * fix logging import  * cleanup  * Update src/transformers/modeling_utils.py  Co-authored-by: Sam Shleifer <sshleifer@gmail.com>  * fix bug in max_positional_embeddings  * rename keys to keys_to_never_save per suggestion, improve the setup  * Update src/transformers/modeling_utils.py  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  Co-authored-by: Sam Shleifer <sshleifer@gmail.com> Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>",1,Rename Variable,,
995a958dd18d4326e608efc3bfc4005acfef8e56,2020-09-07T07:03:45Z,https://github.com/huggingface/transformers/commit/995a958dd18d4326e608efc3bfc4005acfef8e56,feat: allow prefix for any generative model (#5885)  * feat: allow padding_text for any generative model  * docs(pipelines.py): correct typo  * Update src/transformers/pipelines.py  Co-authored-by: Sam Shleifer <sshleifer@gmail.com>  * feat: rename padding_text to prefix  * fix: cannot tokenize empty text  * fix: pass prefix arg to pipeline  * test: add prefix to text-generetation pipeline  * style: fix style  * style: clean code and variable name more explicit  * set arg docstring to optional  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  Co-authored-by: Sam Shleifer <sshleifer@gmail.com> Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>,1,Rename Variable,,
ed6b8f3128e3c126f97a00bcddf0f746b30b48fa,2020-08-05T11:23:55Z,https://github.com/huggingface/transformers/commit/ed6b8f3128e3c126f97a00bcddf0f746b30b48fa,Update to match renamed attributes in fairseq master (#5972)  * Update to match renamed attributes in fairseq master  RobertaModel no longer have model.encoder and args.num_classes attributes as of 5/28/20.  * Quality  Co-authored-by: Lysandre <lysandre.debut@reseau.eseo.fr>,1,Rename Variable,,
0b2da0e592fcb3a361494509031f91e1b700e4ad,2020-07-17T18:24:16Z,https://github.com/huggingface/transformers/commit/0b2da0e592fcb3a361494509031f91e1b700e4ad,"XLNet `use_cache` refactor (#5770)  Slightly breaking change, changes functionality for `use_cache` in XLNet: if use_cache is True and mem_len is 0 or None (which is the case in the base model config), the model behaves like GPT-2 and returns mems to be used as past in generation. At training time `use_cache` is overriden and always True.",1,Rename Variable,,
98109464c12619c4164ba7714f3e5526a290239a,2020-06-28T12:32:25Z,https://github.com/huggingface/transformers/commit/98109464c12619c4164ba7714f3e5526a290239a,clean reformer reverse sort (#5343),1,Rename Variable,,
4ab742459735671189d774cfa336d52561655816,2020-06-05T22:45:19Z,https://github.com/huggingface/transformers/commit/4ab742459735671189d774cfa336d52561655816,[cleanup/marian] pipelines test and new kwarg (#4812),1,Rename Variable,,
f1fe18465d8c4ee3f5710cdfd7de387a1d136f6b,2020-06-05T20:41:46Z,https://github.com/huggingface/transformers/commit/f1fe18465d8c4ee3f5710cdfd7de387a1d136f6b,Use labels to remove deprecation warnings (#4807),1,Rename Variable,,
715aa5b1356b878cbab7a7415a1c1b03a7777ae2,2020-04-07T23:08:26Z,https://github.com/huggingface/transformers/commit/715aa5b1356b878cbab7a7415a1c1b03a7777ae2,[Bart] Replace config.output_past with use_cache kwarg (#3632),1,Rename Variable,,
10989715d001f2f735614f5db019452c71cc18d5,2020-03-11T10:06:56Z,https://github.com/huggingface/transformers/commit/10989715d001f2f735614f5db019452c71cc18d5,rename variable,1,Rename Variable,,
ca2047bc352e32f8d6dc26f4e55c2556149230d9,2020-03-11T10:06:56Z,https://github.com/huggingface/transformers/commit/ca2047bc352e32f8d6dc26f4e55c2556149230d9,refactor variable naming and improve tf generate in line with torch generate,1,Rename Variable,,
5b3000d9334e8f92cc9812bbc1ee7285eb26ed5e,2020-03-11T10:06:56Z,https://github.com/huggingface/transformers/commit/5b3000d9334e8f92cc9812bbc1ee7285eb26ed5e,renamed min_len to min_length,1,Rename Variable,,
006097f8ad63636b1eb0ebc67a5b921d22d4c57f,2020-03-04T17:01:17Z,https://github.com/huggingface/transformers/commit/006097f8ad63636b1eb0ebc67a5b921d22d4c57f,rename variables named 'word' to 'token' in generate fn (#3119)  * fix conflits  * fixed naming bug  * make style,1,Rename Variable,,
88def24c4583d19c7338aa0c8215826093aabf75,2019-12-25T23:27:16Z,https://github.com/huggingface/transformers/commit/88def24c4583d19c7338aa0c8215826093aabf75,merge conflicts - renamed to previous_token singular,1,Rename Variable,,
3d2096f516e99da79f1c6c60a48f828b4e7733ef,2019-12-18T10:50:54Z,https://github.com/huggingface/transformers/commit/3d2096f516e99da79f1c6c60a48f828b4e7733ef,further cleanup,1,Rename Variable,,
79526f82f5d6757812f3691949cf03b864697f46,2019-12-09T21:24:35Z,https://github.com/huggingface/transformers/commit/79526f82f5d6757812f3691949cf03b864697f46,Remove unnecessary epoch variable,1,Rename Variable,,
f10b925015b03612877fc2213e118d9507dd3ff2,2019-12-03T15:14:02Z,https://github.com/huggingface/transformers/commit/f10b925015b03612877fc2213e118d9507dd3ff2,"Imrpovements: model_path renamed pretrained_model, tokenizer loaded from pretrained_model, pretrained_model set to discriminator's when discrim is specified, sample = False by default but cli parameter introduced. To obtain identical samples call the cli with --sample",1,Rename Variable,,
61a12f790de9795af1c3dff5fad7e2c4f6808d05,2019-12-03T15:14:02Z,https://github.com/huggingface/transformers/commit/61a12f790de9795af1c3dff5fad7e2c4f6808d05,Renamed SmallConst to SMALL_CONST and introduced BIG_CONST. Identical output as before.,1,Rename Variable,,
e0e55bc550a16289763b4f656790e30ed86e428f,2019-11-22T21:27:45Z,https://github.com/huggingface/transformers/commit/e0e55bc550a16289763b4f656790e30ed86e428f,Manage training example & refactor the refactor,1,Rename Variable,,
df99f8c5a1c54d64fb013b43107011390c3be0d5,2019-11-14T21:10:31Z,https://github.com/huggingface/transformers/commit/df99f8c5a1c54d64fb013b43107011390c3be0d5,Merge pull request #1832 from huggingface/memory-leak-schedulers  replace LambdaLR scheduler wrappers by function,1,Rename Variable,Rename Method,
d7092d592ca55391b3c07505539b9e4c71bf79de,2019-10-10T10:51:14Z,https://github.com/huggingface/transformers/commit/d7092d592ca55391b3c07505539b9e4c71bf79de,rename the attributes in the Bert Layer  Since the preloading of weights relies on the name of the class's attributes changing the namespace breaks loading pretrained weights on Bert and all related models. I reverted `self_attention` to `attention` and us `crossattention` for the decoder instead.,1,Rename Variable,,
e179c55490269432fd9c67fd867f555e81259a34,2019-07-23T14:43:01Z,https://github.com/huggingface/transformers/commit/e179c55490269432fd9c67fd867f555e81259a34,"Add docs for from_pretrained functions, rename return_unused_args",1,Rename Variable,,
52c53f39d076249f379c397d34fe27f67d382dc9,2018-12-13T12:02:17Z,https://github.com/huggingface/transformers/commit/52c53f39d076249f379c397d34fe27f67d382dc9,clean up apex integration,1,Rename Variable,,
34bdc8b54fc6cd9d3877df43e23356cfd79cdfe9,2018-11-09T08:19:45Z,https://github.com/huggingface/transformers/commit/34bdc8b54fc6cd9d3877df43e23356cfd79cdfe9,remove duplicate accumulate gradient step arguments,1,Rename Variable,,
d3bcfc947d692256c27a3b0486504c8c306ca739,2020-10-31T16:58:10Z,https://github.com/tensorflow/tensorflow/commit/d3bcfc947d692256c27a3b0486504c8c306ca739,Remove keras dependency from TFLite tests and BUILD filesPiperOrigin-RevId: 340033160Change-Id: Ia7007ddb1bcd128c684712eafa284af79fedac05,1,Rename Module,,
a6cef1917bfd199c357eddbee0352bb18f39cc5d,2020-09-28T17:53:56Z,https://github.com/tensorflow/tensorflow/commit/a6cef1917bfd199c357eddbee0352bb18f39cc5d,Move v1-specific training_utils to training_utils_v1.pyPiperOrigin-RevId: 334192852Change-Id: Id61d2f6eba25d63dc9486b24f1905e4ad423de04,1,Rename Module,,
949f8ea44a94a38b76580bc4ca0e4c8251aad6c8,2020-09-24T22:34:58Z,https://github.com/tensorflow/tensorflow/commit/949f8ea44a94a38b76580bc4ca0e4c8251aad6c8,Move v1-specific training_utils to training_utils_v1.pyPiperOrigin-RevId: 333612671Change-Id: I63e2058f4c2053fd5d4ec1bcca0ad4810ddcb136,1,Rename Module,,
54b7f366ac72e70b4e8e59680d7c8a72c7e1beba,2020-09-24T20:26:38Z,https://github.com/tensorflow/tensorflow/commit/54b7f366ac72e70b4e8e59680d7c8a72c7e1beba,Move v1-specific training_utils to training_utils_v1.pyPiperOrigin-RevId: 333585512Change-Id: I9341ebc25d33bab26d0ae500216cccbc1d894de7,1,Rename Module,,
246d6c3818ead7bf019c2dd69e8ad785b6da5fc2,2020-09-03T23:48:15Z,https://github.com/tensorflow/tensorflow/commit/246d6c3818ead7bf019c2dd69e8ad785b6da5fc2,PSv2: Rename parameter_server_client_mpr_test.py to client_mpr_test.py.PiperOrigin-RevId: 330019101Change-Id: I0a2dd739481bae8d5d8a77b94e6893874e94cea6,1,Rename Module,,
3f532b99c6dd89ac18b62a8d20732a517ee1e767,2020-04-10T04:18:52Z,https://github.com/tensorflow/tensorflow/commit/3f532b99c6dd89ac18b62a8d20732a517ee1e767,Move image_grad_test.py to image_grad_test_base.py,1,Rename Module,,
4807acc07e7a51c61a0da6a2f6dd4d4558fa08a5,2020-07-21T21:02:42Z,https://github.com/tensorflow/tensorflow/commit/4807acc07e7a51c61a0da6a2f6dd4d4558fa08a5,Keras TF API usage cleanup: Copy test_util.use_gpu into Keras and replace the usage within Keras.PiperOrigin-RevId: 322436993Change-Id: Ic5ed83a643999afec71054aba9484a4a5e4caf88,1,Rename Module,,
dc30240f53bcf1fa2098461b4c2c60d0805b4744,2020-06-24T19:12:55Z,https://github.com/tensorflow/tensorflow/commit/dc30240f53bcf1fa2098461b4c2c60d0805b4744,Rename import to avoid conflict with parameters.PiperOrigin-RevId: 318113928Change-Id: I06da2eff0eacc8e5bedfd20cf7334c17bcab008f,1,Rename Module,,
15f6b288fd9d20d2ad5f417cc88bd86856c202d0,2020-03-18T01:55:24Z,https://github.com/tensorflow/tensorflow/commit/15f6b288fd9d20d2ad5f417cc88bd86856c202d0,Simplify lite_v2_test.py code (NFC)PiperOrigin-RevId: 301499818Change-Id: Ief73ffdf0421c8a55c99a4e4d307a3eeaeae0255,1,Rename Module,,
f330d291471e4974b433f01c6185f89aabc6149c,2020-03-12T16:19:57Z,https://github.com/tensorflow/tensorflow/commit/f330d291471e4974b433f01c6185f89aabc6149c,Rename test file to more accurately reflect the tests it contains.  (ragged_string_ops_test -> strings_reduce_join_op_test)PiperOrigin-RevId: 300562188Change-Id: Ie52646b2a8f4002e1fa137170b4f6fa5ea34cbd7,1,Rename Module,,
891dcbe7c050aeb648cd1512879634075fc058d0,2020-03-02T21:33:10Z,https://github.com/tensorflow/tensorflow/commit/891dcbe7c050aeb648cd1512879634075fc058d0,"Refactor the testing_utils to not relying on keras at a whole.Breaking out test_utils as a separate build target, which will be usedin my follow up cls. Adding TODO to not export test_util in keras targetsince it probably should not export test related code.PiperOrigin-RevId: 298431578Change-Id: Ib3c773ef160270295328978c048f05e2d641e9a0",1,Rename Module,,
662f9cb266ea61958e45234d0cbcc6d3ab43ddf1,2020-02-04T15:17:59Z,https://github.com/tensorflow/tensorflow/commit/662f9cb266ea61958e45234d0cbcc6d3ab43ddf1,Rename explicit_batch_test.py to trt_mode_test.py,1,Rename Module,,
25f3d2b02dfa7e77b17787996b469e9c4162c75a,2019-11-20T19:47:45Z,https://github.com/tensorflow/tensorflow/commit/25f3d2b02dfa7e77b17787996b469e9c4162c75a,"Restructure the internal mechanism for reporting errors related to unsupported Python language elements, for better simplicity and robustness. This adds generic error types in pyct, the TF-independent part of autograph, which is consistently used by the low-level components. This fixes a bug in which expected errors, like refusal to convert mangled names asks the user to file a bug.PiperOrigin-RevId: 281567971Change-Id: If39ed5deb1ac54bfd12337b2b028eb26ed80e674",1,Rename Module,,
eedbcd1ebd32a427d511a84930cba4a23b21e39b,2019-11-13T01:56:39Z,https://github.com/tensorflow/tensorflow/commit/eedbcd1ebd32a427d511a84930cba4a23b21e39b,Move CSRSparseMatrix tests to linalg/sparse. Make file names consistent.PiperOrigin-RevId: 280097036Change-Id: I4578cacb876f3d27bb860c3794b685f2bc26da03,1,Rename Module,,
df92a489ea129c64114b9f5141ebc217317e8aad,2019-11-08T22:46:55Z,https://github.com/tensorflow/tensorflow/commit/df92a489ea129c64114b9f5141ebc217317e8aad,OSS multi_worker_callback_tf2_test. Rename existing multi_worker_callback_test to multi_worker_callback_tf1_test to distinguish it with the new test. Goal is to migrate existing tf1 tests to tf2 tests which are powered by multi-processes.PiperOrigin-RevId: 279395186Change-Id: Ide7afeba5924634bc84c6b7941efb9922d41b7f7,1,Rename Module,,
a8076df44f842aeced040fab49112b2768ab5a32,2019-11-08T17:22:27Z,https://github.com/tensorflow/tensorflow/commit/a8076df44f842aeced040fab49112b2768ab5a32,OSS multi_worker_callback_tf2_test. Rename existing multi_worker_callback_test to multi_worker_callback_tf1_test to distinguish it with the new test. Goal is to migrate existing tf1 tests to tf2 tests which are powered by multi-processes.PiperOrigin-RevId: 279328412Change-Id: I35158df58b4e3829fae7614903c94b9d4f10792f,1,Rename Module,,
cab28a0bb1488a9a395d6b217d1014721b1700e8,2019-10-07T17:49:50Z,https://github.com/tensorflow/tensorflow/commit/cab28a0bb1488a9a395d6b217d1014721b1700e8,"Remove the __init__.py content for keras/utils.1. Change all imports that uses keras.utils to be explicit import of individual module.2. Removed deprecated util imports in keras_preprocessing.3. Moved all the public symbol from __init__.py to all_utils.py, which is used by keras/application for injection.PiperOrigin-RevId: 273327600",1,Rename Module,,
49151a0661405a6ef1c957743228c6ed69edbbb0,2019-09-26T20:06:55Z,https://github.com/tensorflow/tensorflow/commit/49151a0661405a6ef1c957743228c6ed69edbbb0,Remove __init__ entry for keras/wrappers.This is the first of many cls that remove __init__ file content from keras toprevent hourglass imports.PiperOrigin-RevId: 271414127,1,Rename Module,,
caba13e2c617a398aa5acdcdf19c5e027000135a,2019-08-05T18:06:00Z,https://github.com/tensorflow/tensorflow/commit/caba13e2c617a398aa5acdcdf19c5e027000135a,[tf.data] Refactoring iterator checkpointing tests.PiperOrigin-RevId: 261723781,1,Rename Module,,
cf9bdb260f298f4f0f8b4dd8423884cc3406294f,2019-06-19T22:48:04Z,https://github.com/tensorflow/tensorflow/commit/cf9bdb260f298f4f0f8b4dd8423884cc3406294f,Move Keras SavedModel code into separate files and directory.No changes have been made to the implementation.PiperOrigin-RevId: 254087120,1,Rename Module,,
0d4485677356a761f21ad7223759cd89bcc9034c,2019-06-13T22:37:52Z,https://github.com/tensorflow/tensorflow/commit/0d4485677356a761f21ad7223759cd89bcc9034c,"Refactor combinations.py to extract TF-specific parts out.The logic is separated by introducing the TestCase class.  It may return instances of the Parameter class.The code is also split into two files: one generic and one tensorflow-specific.  The eventual names I'd like to have are ""combinations"" and ""tf_combinations"" correspondingly, but I minimized the disruption of renaming to make this changelist easier to review.  I plan to do the rename separately.It also now supports multiple arguments of type NamedDistribution.PiperOrigin-RevId: 253119531",1,Rename Module,,
e211a81070cc5b0b6c6c9e6c0fce2304d28f2d74,2019-05-23T21:25:48Z,https://github.com/tensorflow/tensorflow/commit/e211a81070cc5b0b6c6c9e6c0fce2304d28f2d74,Refactor the training logic based on the input data type.PiperOrigin-RevId: 249715219,1,Rename Module,,
555eda8a0eaad1db9d5f20e5e4b4cf94a863aa1d,2019-05-14T01:31:39Z,https://github.com/tensorflow/tensorflow/commit/555eda8a0eaad1db9d5f20e5e4b4cf94a863aa1d,Move unique naming mechanism from base_layer_utils to backendPiperOrigin-RevId: 248052659,1,Rename Module,,
06449352cca4d12722143cf5b49b0467551bc97f,2019-03-26T07:17:15Z,https://github.com/tensorflow/tensorflow/commit/06449352cca4d12722143cf5b49b0467551bc97f,refactored fftshift and ifftshift code,1,Rename Module,,
0cf8555526ca8125f0c3e3b4352b1738d75bdb90,2019-03-19T22:40:55Z,https://github.com/tensorflow/tensorflow/commit/0cf8555526ca8125f0c3e3b4352b1738d75bdb90,Rename wrap_conversion to wrap_py_utils and move it to the tensorflow/compilerdirectory.PiperOrigin-RevId: 239284996,1,Rename Module,,
bd36b48c555b2d46c41a179ed9f27a04806e9e66,2019-02-16T01:23:48Z,https://github.com/tensorflow/tensorflow/commit/bd36b48c555b2d46c41a179ed9f27a04806e9e66,Rename Checkpointable -> Trackable and AutoCheckpointable -> AutoTrackableNo API changes in this CL. Just more refactoring for a future API change.PiperOrigin-RevId: 234242335,1,Rename Module,,
db22ae4d912dd5d25a0394d4c596e02a2107a24e,2018-12-03T20:16:22Z,https://github.com/tensorflow/tensorflow/commit/db22ae4d912dd5d25a0394d4c596e02a2107a24e,Import rename for Estimator modules.PiperOrigin-RevId: 223840000,1,Rename Module,,
70738af3f685531a7d9fa169f35640c0810dfd2e,2018-04-16T18:47:11Z,https://github.com/tensorflow/tensorflow/commit/70738af3f685531a7d9fa169f35640c0810dfd2e,Refactoring: Rename the __ops module to ag__ (double underscore prefix has special meaning in Python). Consolidate all internal API calls through the ag__ module.PiperOrigin-RevId: 193074379,1,Rename Module,,
db076ca01f12368c9476fa4db9d87756f22f9670,2018-03-26T22:52:12Z,https://github.com/tensorflow/tensorflow/commit/db076ca01f12368c9476fa4db9d87756f22f9670,Rename convert_savedmodel to convert_saved_modelto be consistent with export_saved_modelPiperOrigin-RevId: 190539064,1,Rename Module,,
54cc8b35f1062f385f0e97c397e1ae96c91c9f62,2018-03-26T20:30:17Z,https://github.com/tensorflow/tensorflow/commit/54cc8b35f1062f385f0e97c397e1ae96c91c9f62,Global rename of py2tf to autographPiperOrigin-RevId: 190515509,1,Rename Module,,
1034bb2e69cae7ddd7f26f818e0d8527c5d4c3e9,2018-02-27T21:49:03Z,https://github.com/tensorflow/tensorflow/commit/1034bb2e69cae7ddd7f26f818e0d8527c5d4c3e9,Renames sequential_feature_column to sequence_feature_column and adds pydoc.PiperOrigin-RevId: 187226365,1,Rename Module,,
eeba54b939a8c3a0da1805a52163f39afb2bd940,2018-02-14T19:28:29Z,https://github.com/tensorflow/tensorflow/commit/eeba54b939a8c3a0da1805a52163f39afb2bd940,"Minor refactoring: rename the _canonicalization.py files, consistent with the list comprehension transformer.PiperOrigin-RevId: 185717464",1,Rename Module,,
1542d977f410eddf2896553fbbd5f697605d57c9,2017-11-16T01:44:18Z,https://github.com/tensorflow/tensorflow/commit/1542d977f410eddf2896553fbbd5f697605d57c9,"Rename layers.base.Network -> layers.network.GraphNetworkSplits GraphNetwork out into a new file, moves some shared utility functions tolayers.utils. Should have no functional changes.PiperOrigin-RevId: 175909000",1,Rename Module,,
f30460b9f69bcaf0b5b6721acd3e18d4dcf987d5,2016-07-14T01:45:13Z,https://github.com/tensorflow/tensorflow/commit/f30460b9f69bcaf0b5b6721acd3e18d4dcf987d5,Rename io directory to learn_io because non-absolute import can confuse this with the standard io module.Change: 127385608,1,Rename Module,,
7c10d9a66fbe923e475eff6fc818feffd41db574,2016-05-31T03:19:53Z,https://github.com/tensorflow/tensorflow/commit/7c10d9a66fbe923e475eff6fc818feffd41db574,Inflow: rename Column to SeriesChange: 123605859,1,Rename Module,,
455a27f0a64753fc83d7d91b6b33881dfcf63679,2016-04-22T13:25:14Z,https://github.com/tensorflow/tensorflow/commit/455a27f0a64753fc83d7d91b6b33881dfcf63679,Rename python/platform/logging.py to python/platform/tf_logging to simplify future platform refactoringsChange: 120541613,1,Rename Module,,
8e677731f07bc457c3e4278f4b865d6edcd6a678,2016-03-31T00:45:01Z,https://github.com/tensorflow/tensorflow/commit/8e677731f07bc457c3e4278f4b865d6edcd6a678,"Renamed float_wrapper.py to json_util.py, and moved it to the new directory tensorboard/lib/python directory for shared Python utilities.Change: 118634201",1,Rename Module,Move Module,
4fffb513b2a6fb64c0d6b1e3406cd0de63f6b78c,2023-02-02T17:35:39Z,https://github.com/keras-team/keras/commit/4fffb513b2a6fb64c0d6b1e3406cd0de63f6b78c,Cleanup: rename initializers_v2.py to initializers.py.  PiperOrigin-RevId: 506645119,1,Rename Module,,
06d7947a93050d8cfc908c0c304cc62f8c778eab,2023-02-01T00:07:07Z,https://github.com/keras-team/keras/commit/06d7947a93050d8cfc908c0c304cc62f8c778eab,Refactor keras/metrics to be modular.  PiperOrigin-RevId: 506144312,1,Rename Module,,
1c21178247e21000d5c720bf139c4a6e925eb8b1,2022-12-07T00:27:34Z,https://github.com/keras-team/keras/commit/1c21178247e21000d5c720bf139c4a6e925eb8b1,Rename `optimizers/optimizer_v2/` dir to `optimizers/legacy` for clarity.  PiperOrigin-RevId: 493443143,1,Rename Module,,
98ffe08a03ebcd5140112c4fdf844b1f4b7e711d,2018-03-01T01:25:27Z,https://github.com/keras-team/keras/commit/98ffe08a03ebcd5140112c4fdf844b1f4b7e711d,Rename training_utils to multi_gpu_utils,1,Rename Module,,
0e9ac3dae0359db9fba655e76da5a443bf1d935d,2017-02-28T22:41:07Z,https://github.com/keras-team/keras/commit/0e9ac3dae0359db9fba655e76da5a443bf1d935d,visualize_util -> vis_utils,1,Rename Module,,
54d3b9e67355be8eb41aab22ba6f481b7d07c65c,2015-12-15T21:30:01Z,https://github.com/keras-team/keras/commit/54d3b9e67355be8eb41aab22ba6f481b7d07c65c,rename test_sequences to test_sequence.py,1,Rename Module,,
3dd4b2e8ab2db2c04cf349b580886521295f386e,2015-06-23T04:03:31Z,https://github.com/keras-team/keras/commit/3dd4b2e8ab2db2c04cf349b580886521295f386e,Rename test folder,1,Rename Module,,
a1912b0774672753cff0f44e4b6457a9689441cc,2015-06-23T04:03:31Z,https://github.com/keras-team/keras/commit/a1912b0774672753cff0f44e4b6457a9689441cc,Rename lossweights test,1,Rename Module,,
dd82a3944eb449fd765d6186917e4d0be3a6bcf0,2015-06-21T19:00:57Z,https://github.com/keras-team/keras/commit/dd82a3944eb449fd765d6186917e4d0be3a6bcf0,Rename test folder,1,Rename Module,,
9763f811859791db876d69c35cd7adf065e10681,2015-06-21T18:54:25Z,https://github.com/keras-team/keras/commit/9763f811859791db876d69c35cd7adf065e10681,Rename lossweights test,1,Rename Module,,
0a21abc8102771da76fca01800e497d7d014d10c,2015-06-21T10:08:54Z,https://github.com/keras-team/keras/commit/0a21abc8102771da76fca01800e497d7d014d10c,Rename a manual test to a check,1,Rename Module,,
1fc3c4b22ec11ae098e0d3127346b08b1bc00a04,2015-06-21T10:06:36Z,https://github.com/keras-team/keras/commit/1fc3c4b22ec11ae098e0d3127346b08b1bc00a04,"Renamed non-automatable tests as ""checks"" Moved tests into either manual or auto subdirectories.",1,Rename Module,,
106459acac181ea1c019f2c298f7d52517626965,2020-09-09T06:08:55Z,https://github.com/pytorch/pytorch/commit/106459acac181ea1c019f2c298f7d52517626965,"Rename test_distributed to test_distributed_fork (#42932)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/42932Follow up from https://github.com/pytorch/pytorch/pull/41769, rename `test_distributed` to `test_distributed_fork` to make it explicit that it forks.New command to run test:`python test/run_test.py -i distributed/test_distributed_fork -v`ghstack-source-id: 111632568Test Plan: `python test/run_test.py -i distributed/test_distributed_fork -v`Reviewed By: izdebyDifferential Revision: D23072201fbshipit-source-id: 48581688b6c5193a309e803c3de38e70be980872",1,Rename Module,,
1921b244f6a7ddc01d2604be11843f387c001e0f,2021-02-10T00:59:23Z,https://github.com/pytorch/pytorch/commit/1921b244f6a7ddc01d2604be11843f387c001e0f,[DataLoader] Rename files of functional datapipes (#51880)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/51880Using the reference of [iter-tools](https://more-itertools.readthedocs.io/en/stable/api.html) to rename files based on the functionality.Test Plan: Imported from OSSReviewed By: VitalyFedyuninDifferential Revision: D26314776Pulled By: ejguanfbshipit-source-id: e97bac047a0fa808676cd6f3a9202109d17f81ca,1,Rename Module,,
1d0ec50a02616d2b1e11628670314b3c6e1ad12d,2020-05-29T19:24:34Z,https://github.com/pytorch/pytorch/commit/1d0ec50a02616d2b1e11628670314b3c6e1ad12d,[quant][graphmode] Rename _quantize_script.py to quantize_script.py (#39122)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/39122Test Plan: Imported from OSSDifferential Revision: D21757619fbshipit-source-id: 603c020aaaf6f467e63f15b4f271fe946d9fb949,1,Rename Module,,
1e4292a1e8c1a2adf5fe0d27ab0f83eb1eae79cd,2023-05-26T23:36:38Z,https://github.com/pytorch/pytorch/commit/1e4292a1e8c1a2adf5fe0d27ab0f83eb1eae79cd,"[export] Rename graph_module.py to exported_program.py (#102260)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/102260 Approved by: https://github.com/ydwu4, https://github.com/tugsbayasgalan",1,Rename Module,,
27dc5952159031348ccca8b89aa2b465fc311e72,2019-10-03T01:49:47Z,https://github.com/pytorch/pytorch/commit/27dc5952159031348ccca8b89aa2b465fc311e72,Rename _intrinsic to intrinsicSummary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/27194Test Plan: Imported from OSSDifferential Revision: D17704957Pulled By: zafartahirovfbshipit-source-id: 46f02d129aa77c3047b2a6c606bfadd831a6b0fc,1,Rename Module,,
2f342af22fadf338eb8dcd6b776d4dbb213c6bbe,2016-08-01T16:01:46Z,https://github.com/pytorch/pytorch/commit/2f342af22fadf338eb8dcd6b776d4dbb213c6bbe,Move optim to legacy,1,Rename Module,,
4a192bcc3d297d5934dce2dc46cc11ff6b4baf2c,2018-07-27T06:26:07Z,https://github.com/pytorch/pytorch/commit/4a192bcc3d297d5934dce2dc46cc11ff6b4baf2c,Rename onnx integration tests file to avoid confusionSummary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/9913Differential Revision: D9026787Pulled By: bddppqfbshipit-source-id: a3e7e79973abc4f5fe163f3e86b24382a1efd082,1,Rename Module,,
4e02ad753834f0109bd35f8a4c48e19016a8b130,2023-03-03T04:58:39Z,https://github.com/pytorch/pytorch/commit/4e02ad753834f0109bd35f8a4c48e19016a8b130,Rename inductor collectives test (#95889)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/95889 Approved by: https://github.com/kumpera,1,Rename Module,,
5b15f32697f8bb6b04ad65fedb283464b9013c3e,2019-11-19T05:27:05Z,https://github.com/pytorch/pytorch/commit/5b15f32697f8bb6b04ad65fedb283464b9013c3e,"rename benchmark_all_other_test (#30048)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/30048as title(Note: this ignores all push blocking failures!)Test Plan:```buck run mode/opt caffe2/benchmarks/operator_benchmark:benchmark_all_other_test# ----------------------------------------# PyTorch/Caffe2 Operator Micro-benchmarks# ----------------------------------------# Tag : short# Benchmarking PyTorch: add# Mode: Eager# Name: add_M64_N64_K64_cpu# Input: M: 64, N: 64, K: 64, device: cpuForward Execution Time (us) : 142.032...Reviewed By: hl475Differential Revision: D18580754fbshipit-source-id: 125482d2987cbdb1d019ccedf56a9da5a7cebaba",1,Rename Module,,
5d709af59a67b84f5b035f70604e19197de22e48,2023-02-03T21:01:27Z,https://github.com/pytorch/pytorch/commit/5d709af59a67b84f5b035f70604e19197de22e48,Rename aot_cudagraphs to cudagraphs (#93821)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/93821 Approved by: https://github.com/ezyang,1,Rename Module,,
5f57b363184cbb330551cc7fdee820b7067ac6fd,2023-03-23T17:41:19Z,https://github.com/pytorch/pytorch/commit/5f57b363184cbb330551cc7fdee820b7067ac6fd,Rename torch._inductor.triton_ops.autotune to torch._inductor.triton_heuristics (#95558)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/95558 Approved by: https://github.com/Chillee,1,Rename Module,,
76e832437087f756460d756a5d0c12763058db8b,2021-02-19T18:01:33Z,https://github.com/pytorch/pytorch/commit/76e832437087f756460d756a5d0c12763058db8b,[package] rename ex/importer.py to package_ex/importer.py (#52320)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/52320as titleTest Plan: Imported from OSSReviewed By: zdevitoDifferential Revision: D26468416Pulled By: suofbshipit-source-id: 890eecea76426918daff900402fbcbc149e48535,1,Rename Module,,
8a949f9e51adeeae9ce86eb670d8745a4e35e79b,2021-04-29T18:02:54Z,https://github.com/pytorch/pytorch/commit/8a949f9e51adeeae9ce86eb670d8745a4e35e79b,[23/n][torch/elastic][upstream] Rename torch.distributed.elastic_launch to torch.distributed.run (#56831)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/56831Rename torch.distributed.elastic_launch to torch.distributed.runTest Plan:buck test mode/dev-nosan //pytorch/elastic/torchelastic/...  buck test mode/dev-nosan //caffe2/test/distributed/elastic/agent/server/test/...  flow-cli canary  pytorch.elastic.examples.classy_vision.main --entitlement gpu_prod --run-as-secure-group oncall_dai_pet --buck-target //fblearner/flow/projects/pytorch/elastic/examples:workflowReviewed By: kiukchungDifferential Revision: D27921159fbshipit-source-id: cc7f2f035223b2d4abd7373af298998887e14c12,1,Rename Module,,
b6c5c5d90ef8c5560ba7e9b4d471d8949babd1bd,2021-05-27T06:02:09Z,https://github.com/pytorch/pytorch/commit/b6c5c5d90ef8c5560ba7e9b4d471d8949babd1bd,[quant][refactor tests] Rename test_numeric_suite and equalization tests (#58999)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/58999  Rename the test files to be more explicit that they are for eager mode  Test Plan: python test/test_quantization.py  Imported from OSS  Reviewed By: HDCharles  Differential Revision: D28713909  fbshipit-source-id: b4ccd06c841fe96edf8c065a0bceae15fed260f9,1,Rename Module,,
c249f49dddb26db081efeb6ae17ae59653439128,2018-02-23T04:22:39Z,https://github.com/pytorch/pytorch/commit/c249f49dddb26db081efeb6ae17ae59653439128,Rename caffe2_ref_test.py to c2_ref_test.py (#2016)* Rename caffe2_ref_test.py to c2_ref_test.py* Rename the module name doc too,1,Rename Module,,
d80056312aa8bb56a17a9b3fc7d353a0240c8152,2022-12-01T17:37:07Z,https://github.com/pytorch/pytorch/commit/d80056312aa8bb56a17a9b3fc7d353a0240c8152,"[Quant][fx][bc-breaking] Rename fx/*patterns.py (#89872)  Summary: This commit renames fx/quantization_patterns.py to fx/quantize_handler.py, and fx/fusion_patterns.py to fx/fuse_handler.py. This is because these files contain only QuantizeHandler and FuseHandler respectively, so the new names are more descriptive. A future commit will further break BC by removing all the empty *QuantizeHandler classes.  BC-breaking notes:  The following classes under the `torch.ao.quantization.fx.quantization_patterns` namespace are migrated to the `torch.ao.quantization.fx.quantize_handler` namespace: ``` QuantizeHandler BinaryOpQuantizeHandler CatQuantizeHandler ConvReluQuantizeHandler LinearReLUQuantizeHandler BatchNormQuantizeHandler EmbeddingQuantizeHandler RNNDynamicQuantizeHandler DefaultNodeQuantizeHandler FixedQParamsOpQuantizeHandler CopyNodeQuantizeHandler GeneralTensorShapeOpQuantizeHandler CustomModuleQuantizeHandler StandaloneModuleQuantizeHandler ```  The following classes under the `torch.ao.quantization.fx.fusion_patterns` namespace are migrated to the `torch.ao.quantization.fx.fuse_handler` namespace: ``` DefaultFuseHandler FuseHandler ```  Test Plan: python test/test_quantization.py TestQuantizeFx python test/test_quantization.py TestQuantizeFxOps  Reviewers: jerryzh168, vkuzo  Subscribers: jerryzh168, vkuzo  Pull Request resolved: https://github.com/pytorch/pytorch/pull/89872 Approved by: https://github.com/jerryzh168",1,Rename Module,,
dda7ce4bb381a3a339fbd59b031be8c15fdbb658,2023-04-13T16:30:47Z,https://github.com/pytorch/pytorch/commit/dda7ce4bb381a3a339fbd59b031be8c15fdbb658,"Revert ""[core][pruning][be] Rename sparsifier folder to pruner (#98758)""  This reverts commit 778fd1922ae127250126e845ecd4a1cb9e335fb5.  Reverted https://github.com/pytorch/pytorch/pull/98758 on behalf of https://github.com/jcaip due to https://www.internalfb.com/diff/D44905951 need to fix broken import in fbcode",1,Rename Module,,
f4944f0f8acda3bb3c0cf7ab690df6b4400598bd,2018-10-18T06:00:11Z,https://github.com/pytorch/pytorch/commit/f4944f0f8acda3bb3c0cf7ab690df6b4400598bd,Rename test/common.py to test/common_utils.py (#12794)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/12794common.py is used in base_module for almost all tests in test/. Thename of this file is so common that can easily conflict with other dependenciesif they happen to have another common.py in the base module. Rename the file toavoid conflict.Reviewed By: orionrDifferential Revision: D10438204fbshipit-source-id: 6a996c14980722330be0a9fd3a54c20af4b3d380,1,Rename Module,,
b2f489dc573facc9f8e64d7271b552215e43e73d,2020-06-20T01:08:37Z,https://github.com/pytorch/pytorch/commit/b2f489dc573facc9f8e64d7271b552215e43e73d,[quant][graphmode] Rename graph mode quantization API to `quantize_jit` (#40212)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/40212Test Plan: Imported from OSSReviewed By: z-a-fDifferential Revision: D22144745fbshipit-source-id: 38a19b5afdddbbce262eea8ddf5b68458e6017b3,1,Rename Module,Rename Class,
a70082a863e8287cad9d8369129a4b3dda29410d,2022-11-30T01:50:44Z,https://github.com/pytorch/pytorch/commit/a70082a863e8287cad9d8369129a4b3dda29410d,[functorch] Move `cond.py` to `_cond.py` and expose `cond()` under functorch.experimental.control_flow. (#89819)  Summary: Similar to https://github.com/pytorch/pytorch/pull/88767 we want to reduce the chance that users accidentally import private functions from `functorch.experimental.cond` as if they were public interfaces. We also move `cond()` under `control_flow.py` to stay consistent with `map()` op.  Test Plan: CI  Reviewers:  Subscribers:  Tasks:  Tags:  Pull Request resolved: https://github.com/pytorch/pytorch/pull/89819 Approved by: https://github.com/zou3519,1,Rename Module,,
ab3065de25df005364ae91713efcfdea80b2bbbb,2018-03-20T04:21:17Z,https://github.com/pytorch/pytorch/commit/ab3065de25df005364ae91713efcfdea80b2bbbb,"Playground refactoring and DataPreproc reader for DAIPlayground at facebookadd one more input module preproc everstore for IN1k.  It uses the same datasets of sherlock everstroe input reader, then it us DAtaPreproc operator to distribute the image preprocessing on other machine other than the trainer.  Suppose to release some compute burdent from trainers.@override-unit-failures(Note: this ignores all push blocking failures!)",1,Rename Module,Move Variable,
8b8beb854a9ca4a6d2335abdcc17efadbf47f16f,2022-05-12T21:13:29Z,https://github.com/scikit-learn/scikit-learn/commit/8b8beb854a9ca4a6d2335abdcc17efadbf47f16f,MNT Use cimport numpy as cnp for sklearn/feature_extraction (#23331),1,Rename Module,,
cf2e4e334077b1f563bb17930896b90112e8e10e,2021-09-01T09:50:16Z,https://github.com/scikit-learn/scikit-learn/commit/cf2e4e334077b1f563bb17930896b90112e8e10e,MNT replace if_delegate_has_method by available_if in _search.py (#20685)  * MNT replace if_delegate_has_method by available_if in _search.py  * iter  * iter  * apply changes from thomas  * iter  * fix  * iter,1,Rename Module,,
57996433e65c8df88d30b45bb3913317286eb7c1,2019-10-30T02:36:46Z,https://github.com/scikit-learn/scikit-learn/commit/57996433e65c8df88d30b45bb3913317286eb7c1,MNT Removes trailing underscore from files (#15397),1,Rename Module,,
6ac9dc4878d29b99f581a407120b82b9d25855d4,2019-10-16T17:16:26Z,https://github.com/scikit-learn/scikit-learn/commit/6ac9dc4878d29b99f581a407120b82b9d25855d4,MNT make the modules in sklearn.mixture private (#15166)  * renaming  * renamed some imports  * added test and gitignore,1,Rename Module,,
c1aea3f868652e23eb01a1ebaf22ab0e77c4e9ee,2016-01-21T19:27:15Z,https://github.com/scikit-learn/scikit-learn/commit/c1aea3f868652e23eb01a1ebaf22ab0e77c4e9ee,MAINT: Renamed module mutual_info to mutual_info_,1,Rename Module,,
86974f8d725fc3b1956bdc141ae0381e1c710205,2015-11-02T18:24:51Z,https://github.com/scikit-learn/scikit-learn/commit/86974f8d725fc3b1956bdc141ae0381e1c710205,Rename example to plot_gmm_covariances.py,1,Rename Module,,
25a8c5f05ab3ec8076fd10866e7ce1a522ccb802,2014-05-28T17:56:09Z,https://github.com/scikit-learn/scikit-learn/commit/25a8c5f05ab3ec8076fd10866e7ce1a522ccb802,Adress Gael's comments  * rename _binary_search to _utils * indent list elements * use default parameters in examples,1,Rename Module,,
bbb8f1d1bf4145e9495016c22a892d59e5088c8a,2014-03-27T07:50:45Z,https://github.com/scikit-learn/scikit-learn/commit/bbb8f1d1bf4145e9495016c22a892d59e5088c8a,Moved sparsefuncs to sparsefuncs_fast,1,Rename Module,,
4e1e1ab7726e62ad3f41963624e38c855d29c58b,2013-07-22T08:27:26Z,https://github.com/scikit-learn/scikit-learn/commit/4e1e1ab7726e62ad3f41963624e38c855d29c58b,"Now that the folder has more than just mst in it, rename to sparsetools, which should help with referencing it.",1,Rename Module,,
ad64a0da2ec0eed0a650f9da770f39e6a6e7e80e,2013-01-14T13:15:41Z,https://github.com/scikit-learn/scikit-learn/commit/ad64a0da2ec0eed0a650f9da770f39e6a6e7e80e,rename plot_adaboost_classification.py -> plot_adaboost_twoclass.py and add predict_twoclass method to AdaBoostClassifier,1,Rename Module,,
d9bb6ac8e9b89b8d8bb0a4e3e0c9f7e9ca49f641,2012-11-05T07:29:12Z,https://github.com/scikit-learn/scikit-learn/commit/d9bb6ac8e9b89b8d8bb0a4e3e0c9f7e9ca49f641,Rename pa.py to passive_aggressive.py.,1,Rename Module,,
7da9bf0759ae773414c3b0c4178f32e050291882,2012-10-23T13:50:25Z,https://github.com/scikit-learn/scikit-learn/commit/7da9bf0759ae773414c3b0c4178f32e050291882,Rename euclidean_fast to _euclidean_fast,1,Rename Module,,
3ea19f0d82ae7470ce1d89c8b213dd42ad3ece6f,2012-03-06T07:10:51Z,https://github.com/scikit-learn/scikit-learn/commit/3ea19f0d82ae7470ce1d89c8b213dd42ad3ece6f,renamed largescale -> large_scale,1,Rename Module,,
43b962a21006b09a98b9b4219a328268fb6c1203,2012-03-01T16:16:41Z,https://github.com/scikit-learn/scikit-learn/commit/43b962a21006b09a98b9b4219a328268fb6c1203,"Section 4 done - images/links/htmls for images -_plot_pca_3d renamed to plot_pca_3d -plot_pca_3d still needs quiver, but plot works now -plot_lena_ward added to plot ward clustering of lena",1,Rename Module,,
e1938f9be301791e090dedfd287d7c0fb619e03b,2012-02-02T14:43:25Z,https://github.com/scikit-learn/scikit-learn/commit/e1938f9be301791e090dedfd287d7c0fb619e03b,ENH: renamed plot_gmm_model_selection.py to plot_gmm_selection.py,1,Rename Module,,
8ea63e9cd92740c49e0a95c6b82783037fb84200,2011-10-31T09:57:25Z,https://github.com/scikit-learn/scikit-learn/commit/8ea63e9cd92740c49e0a95c6b82783037fb84200,COSMIT: no import as  There is really no point to do an 'import as' to rename a function. It is bad for readability.,1,Rename Module,,
54af74d18c15265d463c22657b9d0d2245bf43fa,2011-09-13T21:41:23Z,https://github.com/scikit-learn/scikit-learn/commit/54af74d18c15265d463c22657b9d0d2245bf43fa,Merge remote-tracking branch 'jakevdp/neighbors-refactor',1,Rename Module,,
1be34bcdccc861216b0de028efea5e22bdce0a78,2011-09-12T17:38:52Z,https://github.com/scikit-learn/scikit-learn/commit/1be34bcdccc861216b0de028efea5e22bdce0a78,Merge remote-tracking branch 'jakevdp/neighbors-refactor' into jakevdp-neighbors-refactor,1,Rename Module,,
b8d4d4ba9eb3f2f2165ee18fde067ba0f79bb11e,2011-09-05T20:07:33Z,https://github.com/scikit-learn/scikit-learn/commit/b8d4d4ba9eb3f2f2165ee18fde067ba0f79bb11e,renamed scikits.learn to sklearn,1,Rename Module,,
f7ee93fc2022486eba7a311436d3420ed88e5a80,2011-07-29T12:46:52Z,https://github.com/scikit-learn/scikit-learn/commit/f7ee93fc2022486eba7a311436d3420ed88e5a80,kmeans example renamed,1,Rename Module,,
cd01f48f1dc7a6156e3dc515f72857e4f866202e,2011-04-07T13:44:02Z,https://github.com/scikit-learn/scikit-learn/commit/cd01f48f1dc7a6156e3dc515f72857e4f866202e,Renamed fastica.py to fastica_.py,1,Rename Module,,
8d4e32ab5a10faaeddc0fe0312ab3ebd4c1b1757,2011-04-04T08:52:38Z,https://github.com/scikit-learn/scikit-learn/commit/8d4e32ab5a10faaeddc0fe0312ab3ebd4c1b1757,Rename plot_kpca.py to plot_kernel_pca.py.,1,Rename Module,,
ccb58f14cc9634b36290682bac45a32bfb208a7c,2010-12-03T15:22:03Z,https://github.com/scikit-learn/scikit-learn/commit/ccb58f14cc9634b36290682bac45a32bfb208a7c,rename lars --> least_angle,1,Rename Module,,
0dcfcd7db97efa311bb326ca8e1d4170df86c44f,2010-11-30T10:17:51Z,https://github.com/scikit-learn/scikit-learn/commit/0dcfcd7db97efa311bb326ca8e1d4170df86c44f,move sgd into linear_model and rename sgd to stochastic_gradient.,1,Rename Module,,
68bc58d029ef9540fffa98ea8c5a23834a123989,2010-11-25T15:27:30Z,https://github.com/scikit-learn/scikit-learn/commit/68bc58d029ef9540fffa98ea8c5a23834a123989,"glm --> linear_model rename holocaust.  I also moved cd_fast.pyx from its src subdirectory to linear_models, to match the sgd module structure.",1,Rename Module,,
f00bdfa5b06daca830a04c4628c00d7b2840e18e,2010-11-23T14:15:38Z,https://github.com/scikit-learn/scikit-learn/commit/f00bdfa5b06daca830a04c4628c00d7b2840e18e,"Rename scikits.learn.gmm to scikits.learn.mixture.  In the future mixture will become a directory, but for now there are just GMMs.",1,Rename Module,,
dbfd17ba792a1374e9201b1dbea2f890aea22744,2010-11-14T10:55:52Z,https://github.com/scikit-learn/scikit-learn/commit/dbfd17ba792a1374e9201b1dbea2f890aea22744,Renames as suggested by Alexandre. Simplification of the examples. Remove the interactive contour label picking in the probabilistic classification example.,1,Rename Module,,
26bdc720b71c530560bad0b0826130bede6c7d40,2010-10-05T10:25:22Z,https://github.com/scikit-learn/scikit-learn/commit/26bdc720b71c530560bad0b0826130bede6c7d40,Rename features --> feature_extraction to match module feature_selection.,1,Rename Module,,
bb34e5fcc9c51e47dc9a15885fa6acfa24691f7f,2010-09-06T10:07:51Z,https://github.com/scikit-learn/scikit-learn/commit/bb34e5fcc9c51e47dc9a15885fa6acfa24691f7f,Refactoring in glm.benchmarks.  Rename as other benchmark directories.,1,Rename Module,,
c6b9b284756a0554d0062cd2be82b3bdd6d4b6f2,2010-07-27T07:42:50Z,https://github.com/scikit-learn/scikit-learn/commit/c6b9b284756a0554d0062cd2be82b3bdd6d4b6f2,MISC: rename base_estimator.py to base.py,1,Rename Module,,
52fededf6ed9e04169230aab908c6d5a999eace0,2010-07-26T19:02:24Z,https://github.com/scikit-learn/scikit-learn/commit/52fededf6ed9e04169230aab908c6d5a999eace0,MISC: rename base_estimator.py to base.py,1,Rename Module,,
a3f4f6b3aaff8122b3a93559de37d582201f6126,2010-07-16T12:03:08Z,https://github.com/scikit-learn/scikit-learn/commit/a3f4f6b3aaff8122b3a93559de37d582201f6126,MISC: Rename to let the underscore RULE!,1,Rename Module,,
860f0099645bf90e300b59e1377fbf9637ca14f2,2010-06-26T13:18:33Z,https://github.com/scikit-learn/scikit-learn/commit/860f0099645bf90e300b59e1377fbf9637ca14f2,Rename examples that do not plot results.  This was making the other plots plotting bad.,1,Rename Module,,
2740b6d85ed38bbed64a2ed0ba7318b81d29e9fe,2010-06-23T12:58:43Z,https://github.com/scikit-learn/scikit-learn/commit/2740b6d85ed38bbed64a2ed0ba7318b81d29e9fe,Rename minilearn -> _minilearn,1,Rename Module,,
03ea91ad8e762d9d5247fd3522c48b1b1524ccd3,2010-06-23T12:58:43Z,https://github.com/scikit-learn/scikit-learn/commit/03ea91ad8e762d9d5247fd3522c48b1b1524ccd3,Rename C extension liblinear -> _liblinear,1,Rename Module,,
3382ec2ac45445673f42356d034e4a173c68f2d1,2010-06-22T06:59:33Z,https://github.com/scikit-learn/scikit-learn/commit/3382ec2ac45445673f42356d034e4a173c68f2d1,Rename module BallTree -> ball_tree  PEP8 is beautiful.,1,Rename Module,,
47ef1690c9d5c2b9eb5616933f6feac01c5a41b8,2010-06-21T14:00:39Z,https://github.com/scikit-learn/scikit-learn/commit/47ef1690c9d5c2b9eb5616933f6feac01c5a41b8,Rename libsvm --> _libsvm,1,Rename Module,,
1a521951141460698096a9d542f6036af9203484,2010-05-27T13:25:02Z,https://github.com/scikit-learn/scikit-learn/commit/1a521951141460698096a9d542f6036af9203484,Rename plotted examples.,1,Rename Module,,
6e4bc670993e498e0709dfdce7fa54e5ec94fdba,2023-05-25T13:38:21Z,https://github.com/huggingface/transformers/commit/6e4bc670993e498e0709dfdce7fa54e5ec94fdba,Revamp test selection for the example tests (#23737)  * Revamp test selection for the example tests  * Rename old XLA test and fake modif in run_glue  * Fixes  * Fake Trainer modif  * Remove fake modifs,1,Rename Module,,
fc8a93507c365580b27612089bca59d18b66e053,2023-01-19T14:46:07Z,https://github.com/huggingface/transformers/commit/fc8a93507c365580b27612089bca59d18b66e053,Rename GLPN image processor tests (#21194),1,Rename Module,,
0dde58978a81dbbaf29b725c3faf929990d4c957,2023-01-17T14:04:07Z,https://github.com/huggingface/transformers/commit/0dde58978a81dbbaf29b725c3faf929990d4c957,Rename test_feature_extraction files (#21140)  * Rename files  * Update file names in tests,1,Rename Module,,
659b27fd26dee80f7ecd313089c3fa2e457ea90f,2022-06-02T08:24:16Z,https://github.com/huggingface/transformers/commit/659b27fd26dee80f7ecd313089c3fa2e457ea90f,Print more library versions in CI (#17384)  * print more lib. versions and just befor test runs  * update print_env_pt.py  * rename to print_env  * Disable warning + better job name  * print python version  Co-authored-by: ydshieh <ydshieh@users.noreply.github.com>,1,Rename Module,,
986ac03e374a00a52cee98c8ac14fb1ba6b66610,2021-06-23T16:16:24Z,https://github.com/huggingface/transformers/commit/986ac03e374a00a52cee98c8ac14fb1ba6b66610,changed modeling_fx_utils.py to utils/fx.py for clarity (#12326)  Co-authored-by: Michael Benayoun <michael@huggingface.co>,1,Rename Module,,
f0c96fafd16d206b22a74fe76b251414f7314703,2020-04-16T19:15:19Z,https://github.com/huggingface/transformers/commit/f0c96fafd16d206b22a74fe76b251414f7314703,[examples] summarization/bart/finetune.py supports t5 (#3824)  renames `run_bart_sum.py` to `finetune.py`,1,Rename Module,,
df27648bd942d59481a13842904f8cb500136e31,2020-01-30T15:07:22Z,https://github.com/huggingface/transformers/commit/df27648bd942d59481a13842904f8cb500136e31,Rename test_examples to test_doc_samples,1,Rename Module,,
a3c5883f2c9a12360cee0734dfb262f92b912b24,2019-12-22T14:35:25Z,https://github.com/huggingface/transformers/commit/a3c5883f2c9a12360cee0734dfb262f92b912b24,Rename file for consistency.,1,Rename Module,,
6f152572cd0fe5c84127a1bc25668e5fce918744,2019-09-08T12:02:06Z,https://github.com/huggingface/transformers/commit/6f152572cd0fe5c84127a1bc25668e5fce918744,"add conversion script, rename conversion scripts",1,Rename Module,,
5951d86024e2366a83019f5d676f25757540ed0a,2019-09-05T01:10:11Z,https://github.com/huggingface/transformers/commit/5951d86024e2366a83019f5d676f25757540ed0a,"add conversion script, rename conversion scripts",1,Rename Module,,
c41f2bad69923da6f23d76e47639ad350206d757,2019-07-03T20:54:39Z,https://github.com/huggingface/transformers/commit/c41f2bad69923da6f23d76e47639ad350206d757,WIP XLM + refactoring,1,Rename Module,,
e77721e4fe8f2665132bf11ab26c3ab352e2f2a2,2019-02-07T22:15:15Z,https://github.com/huggingface/transformers/commit/e77721e4fe8f2665132bf11ab26c3ab352e2f2a2,renamed examples,1,Rename Module,,
bde1eeebe0d5ab10de6100f9ad46376f87f917be,2019-02-05T15:11:22Z,https://github.com/huggingface/transformers/commit/bde1eeebe0d5ab10de6100f9ad46376f87f917be,rename,1,Rename Module,,
8962db0c26b3a9d0eae6b3ab393cf6106571a574,2021-01-29T19:56:06Z,https://github.com/tensorflow/tensorflow/commit/8962db0c26b3a9d0eae6b3ab393cf6106571a574,remove underscore,1,Rename Method,,
74c2870b60f7a944b182e94dff713a4d94eff26b,2021-01-14T23:07:35Z,https://github.com/tensorflow/tensorflow/commit/74c2870b60f7a944b182e94dff713a4d94eff26b,"PSV2: Close worker thread when ClusterCoordinator is destroyed.Close worker thread when __del__() of ClusterCoordinator object is destoryed.Also rename WorkerPreemptionHanlder._mark_finished() to destory(), to avoid naming confusion to _CoordinatedClosureQueue.mark_finished().PiperOrigin-RevId: 351884974Change-Id: I18a81eb1d3562c874cbc37ea40bd4e9f38d34e16",1,Rename Method,,
733c07a88f46fe99fd90c035d75b45e600ebea57,2021-01-11T20:06:58Z,https://github.com/tensorflow/tensorflow/commit/733c07a88f46fe99fd90c035d75b45e600ebea57,simplify the test name,1,Rename Method,,
6244efd0b425a01bb4035906adb7520b5db9dcd8,2021-01-11T19:59:01Z,https://github.com/tensorflow/tensorflow/commit/6244efd0b425a01bb4035906adb7520b5db9dcd8,renamed test for clarity,1,Rename Method,,
c1714094928cac396438837ec452e11d0fc42f15,2021-01-04T14:24:11Z,https://github.com/tensorflow/tensorflow/commit/c1714094928cac396438837ec452e11d0fc42f15,rename test for clarity,1,Rename Method,,
fbe14f3bf379e33d14f35f914db56143e817edda,2020-11-17T18:43:15Z,https://github.com/tensorflow/tensorflow/commit/fbe14f3bf379e33d14f35f914db56143e817edda,"Refactor: changing the internal name of `summary_ops_v2.graph`  to `graph_v1`.In addition, we changed `summary_ops_v2.graph_v2` to `graph`.PiperOrigin-RevId: 342896045Change-Id: I40ab3e87aab6501f8381c9690b465ffb3991681c",1,Rename Method,,
5c0138550113e772a803d2902466e66b237fd5e3,2020-10-27T23:48:22Z,https://github.com/tensorflow/tensorflow/commit/5c0138550113e772a803d2902466e66b237fd5e3,Eager execution coverage for extract_volume_patches_grad_test.py. Removed  run_deprecated_v1 decorators. (Part 1)PiperOrigin-RevId: 339358673Change-Id: I2973285dbbeacddff9e3f1e2e97cf9a436f35bd1,1,Rename Method,,
d555a0cd098043acd322e33ad54ddfe5208b2517,2020-10-01T09:01:28Z,https://github.com/tensorflow/tensorflow/commit/d555a0cd098043acd322e33ad54ddfe5208b2517,Rename `choose_the_best` function to something more user friendly.PiperOrigin-RevId: 334769362Change-Id: If5267ba52ee0171504ea0ea98762aadfafa521fa,1,Rename Method,,
36905b9dfff0499d7bddc662ec0265cffa10a81f,2020-09-28T15:24:42Z,https://github.com/tensorflow/tensorflow/commit/36905b9dfff0499d7bddc662ec0265cffa10a81f,MultiProcessRunner: String replacement of `proc_func` -> `fn`.PiperOrigin-RevId: 334161881Change-Id: I6af13347926cff311329a3a4d305c113c22fcad7,1,Rename Method,,
d234e832a7c85bdd2d1a7baf649d0f74855d7579,2020-09-26T04:23:10Z,https://github.com/tensorflow/tensorflow/commit/d234e832a7c85bdd2d1a7baf649d0f74855d7579,Removed MKL binary blob and replaced openmp with opensource lib.,1,Rename Method,,
406ca6ad78421100e252762844e6fc0bf37a1906,2020-09-24T01:10:40Z,https://github.com/tensorflow/tensorflow/commit/406ca6ad78421100e252762844e6fc0bf37a1906,"Rename ""experimental_distribute_datasets_from_function"" to ""distribute_datasets_from_function"".PiperOrigin-RevId: 333413940Change-Id: I06f79b8b9bb1445e2b890e4c49138e7463e37a5e",1,Rename Method,,
6f0dd6eac487a70b908e2e509a43e17fb1a3cba2,2020-09-15T17:50:06Z,https://github.com/tensorflow/tensorflow/commit/6f0dd6eac487a70b908e2e509a43e17fb1a3cba2,Replace keras usages of private `function.defun` with `tf.function`PiperOrigin-RevId: 331804876Change-Id: If44165155c160ffe35a263f9d5c98f6a73ccb41b,1,Rename Method,,
576863f05063d2e68285da81853cd70549305fa9,2020-08-12T20:34:54Z,https://github.com/tensorflow/tensorflow/commit/576863f05063d2e68285da81853cd70549305fa9,don't return erased element and clean tests,1,Rename Method,,
a67138f13e87481b45cc6184cfdc1e543da82645,2020-06-29T23:58:06Z,https://github.com/tensorflow/tensorflow/commit/a67138f13e87481b45cc6184cfdc1e543da82645,Code clean-ups for custom gradients- Remove unnecessary set operation since all args are converted to  tensors.- Make _get_dependent_variables private- Avoid redundant calls to nest.flatten by requiring inputs to  _get_dependent_variables be flattened.- Clean up session usage in tests- Clean up asserts in testsPiperOrigin-RevId: 318922308Change-Id: Ie30dac5f5c610c6610bfe4c6084c6543d059844e,1,Rename Method,,
ce054f48e61fbff37ed7512b74732bd875d9d63e,2020-06-29T18:23:20Z,https://github.com/tensorflow/tensorflow/commit/ce054f48e61fbff37ed7512b74732bd875d9d63e,Clean up the test to remove duplication and run with within the real framework.PiperOrigin-RevId: 318854218Change-Id: I45125a5a028a6d5fd7ae8cd9bed698d31d04196b,1,Rename Method,,
b7ca93ad917ae84c47d4aee26a03d284f99032b5,2020-05-27T23:59:20Z,https://github.com/tensorflow/tensorflow/commit/b7ca93ad917ae84c47d4aee26a03d284f99032b5,Rename experimental version of snapshot to legacy_snapshot in preparation for opensourcing of new snapshot implementationPiperOrigin-RevId: 313491515Change-Id: I85cbc67ddb44a48f7a31e2858ea7c33b06ff0f1e,1,Rename Method,,
6dcb7268bb28221134cd1151a730e89023d59623,2020-05-18T21:33:45Z,https://github.com/tensorflow/tensorflow/commit/6dcb7268bb28221134cd1151a730e89023d59623,Rename `_get_closest` to more accurately reflect what it does.PiperOrigin-RevId: 312155516Change-Id: I27d8dd110ace0150ea735f718ed94948a9a75a74,1,Rename Method,,
151a62f3d891d071cbbad7faeb477c2233ec1f31,2020-03-17T23:36:04Z,https://github.com/tensorflow/tensorflow/commit/151a62f3d891d071cbbad7faeb477c2233ec1f31,Remove underscore in front of _list_to_tuple.py in nest namespace. There is noneed to have both nest.list_to_tuple and nest._list_to_tuple anymore.PiperOrigin-RevId: 301479033Change-Id: I894c0d07dab768f6bf7d2a13bc96907d1c1c6ec5,1,Rename Method,,
3511dbe928a8c71944b4bd52b15d1f73b0b0ee17,2020-03-12T19:58:34Z,https://github.com/tensorflow/tensorflow/commit/3511dbe928a8c71944b4bd52b15d1f73b0b0ee17,"Improve depthwise_conv_op_test.py.Before, most the forward pass tests didn't actually test anything. It would compare the outputs of depthwise_conv2d and depthwise_conv2d_native to make sure they were the same. However, depthwise_conv2d simply forwards to depthwise_conv2d_native, adding dilations to the filter. However, no test used dilations, making depthwise_conv2d and depthwise_conv2d_native equivalent.I changed the test to add a Numpy implementation of depthwise convolutions, and compare depthwise_conv2d to the Numpy version. I additionally added dilations tests.I also made some refactors to make the code clearer.PiperOrigin-RevId: 300607077Change-Id: Ib4fcdee02f633a62b884d81dd5772ecd42e2258f",1,Rename Method,,
a70a66d2193a0f7cd0a7014a5f2c55d508559c56,2020-03-08T20:50:33Z,https://github.com/tensorflow/tensorflow/commit/a70a66d2193a0f7cd0a7014a5f2c55d508559c56,Refactoring of TensorFlow runtime support for executing multi-device functions.The main change is that rendezvous factory is moved from FunctionLibraryRuntime::Options to ProcessFunctionLibraryRuntime constructor. This avoids the complexity of piping the factory method through the executor to the runtime (which is not always done correctly in the current implementation) where it is actually needed.This CL also makes tf.data's GeneratorDataset functions to use multi-device function backend.Both of the above changes are important steps towards making it possible to support Python generator + Keras on TPU.PiperOrigin-RevId: 299715147Change-Id: I53ab7bf9e3a9d3a1a202ce96d54b78ba43500409,1,Rename Method,,
2a2c812ab2330c9aac33335f10679a346436acfb,2019-12-02T19:20:05Z,https://github.com/tensorflow/tensorflow/commit/2a2c812ab2330c9aac33335f10679a346436acfb,[tf.data] Migrating remaining core API tests to use TF combinations and performing various minor test cleanup.PiperOrigin-RevId: 283378763Change-Id: Ice08340d289406eb691fb261c20329ada7c23c8a,1,Rename Method,,
0f2f9d54eefc6490609988e7b0eed4b4f747fc39,2019-11-21T22:48:46Z,https://github.com/tensorflow/tensorflow/commit/0f2f9d54eefc6490609988e7b0eed4b4f747fc39,"dropout optimization1. remove .numpy() call, which is expensive2. instead of using 1, using tensor(1), which avoid convert_to_tensor cost3. In the case rate is scale, directly calculate instead of generating ops4. Instead of calling math_op binary ops, directly call gen_math_op since the inputs are known to be tensor.PiperOrigin-RevId: 281837216Change-Id: I9f96ae248f7528d715e353826c79df24a055c39a",1,Rename Method,,
a3f9b9ba89f28dcc512c645f513e2ef6a3ef9238,2019-10-23T00:24:07Z,https://github.com/tensorflow/tensorflow/commit/a3f9b9ba89f28dcc512c645f513e2ef6a3ef9238,"Rename get_next_as_list_deprecated() to get_next_as_list_static_shapes().The method is not slated for deletion, and is in fact faster as long as we have static shapes.Document this tradeoff in the docstring.PiperOrigin-RevId: 276177997Change-Id: I04189cc5b1b52e7cc8a62a0584aea30a37351eb6",1,Rename Method,,
c3973c78f03c50d8514c14c2866ab30e708aea24,2019-10-12T08:24:25Z,https://github.com/tensorflow/tensorflow/commit/c3973c78f03c50d8514c14c2866ab30e708aea24,Rename internal_convert_to_tensor for performanceCalling ops.internal_convert_to_tensor is more efficient than callingops.convert_to_tensor due to skipping the deprecated_argument_lookup andalso less python function calling overhead. We thus swap these functionsnames so we can optimize most code paths.PiperOrigin-RevId: 274321742,1,Rename Method,,
0cae72d907e0d51c678b3ee1c121459e5fedc753,2019-08-01T19:47:19Z,https://github.com/tensorflow/tensorflow/commit/0cae72d907e0d51c678b3ee1c121459e5fedc753,"Remove unnecessary container name and rename the TRT engine resource ops,for better maintenance and extensibility.PiperOrigin-RevId: 261177377",1,Rename Method,,
a2ade2ecb4796e1e944d9c5e3382d71d9d11d522,2019-07-31T23:52:35Z,https://github.com/tensorflow/tensorflow/commit/a2ade2ecb4796e1e944d9c5e3382d71d9d11d522,"[XLA] Rename Executable::SizeInBytes to Executable::SizeOfGeneratedCodeInBytesOn the GPU backend a lot of library code is used: cuDNN, cuBLAS, etc.We do not know the size of the used kernels, so we can not report the totalamount of loaded kernels.Renaming to SizeOfGeneratedCodeInBytes makes it clear that the returned numberdoes not include library code.PiperOrigin-RevId: 261026023",1,Rename Method,,
5abd6055e17d274f90351493c7ff3c2d176cd2a0,2019-07-24T19:06:11Z,https://github.com/tensorflow/tensorflow/commit/5abd6055e17d274f90351493c7ff3c2d176cd2a0,"[INTEL MKL] changed the function name matmul_prefix() to matmul_op_name() and also changed the function to return op name directly instead of name prefix, with this change, we can remove many string concatation in the test to improve the performance",1,Rename Method,,
e79459acdbcd97c4adc888ee7452c19f38178ee0,2019-05-25T01:06:15Z,https://github.com/tensorflow/tensorflow/commit/e79459acdbcd97c4adc888ee7452c19f38178ee0,"Unexpose enable_mixed_precision_graph_rewrite in TF 2.It will be usable in TF 2 only through tf.compat.v1.train.experimental.enable_mixed_precision_graph_rewrite.Also, remove any statements like ""We currently recommend using enable_mixed_precision_graph_rewrite over the tf.keras API"". Since we're removing the graph rewrite, it doesn't make sense it recommend it. Once the tf.keras API is more complete, we will recommend that instead.I had to remove a paragraph from the Policy docstring, since it referenced enable_mixed_precision_graph_rewrite, which is not exposed in TF 2.PiperOrigin-RevId: 249929657",1,Rename Method,,
472450176c013f7320fd7c67494f38ac9b503073,2019-05-23T11:56:51Z,https://github.com/tensorflow/tensorflow/commit/472450176c013f7320fd7c67494f38ac9b503073,TST: clean test case,1,Rename Method,,
0ccca332e66d13f7494e19a009c7b78dafbafdc1,2019-05-16T18:10:09Z,https://github.com/tensorflow/tensorflow/commit/0ccca332e66d13f7494e19a009c7b78dafbafdc1,Benchmark name cleanup.PiperOrigin-RevId: 248562139,1,Rename Method,,
f7e3da0d6a284399ef2d6e79f4dbe61b32ae70f5,2019-04-29T23:06:41Z,https://github.com/tensorflow/tensorflow/commit/f7e3da0d6a284399ef2d6e79f4dbe61b32ae70f5,Replace per_device with per_replica to complete the renaming of the PerReplica class.Related github PR for tensorflow_models/ : https://github.com/tensorflow/models/pull/6693.PiperOrigin-RevId: 245843263,1,Rename Method,,
daf8f006143906e864707b1ad85254944beb8c47,2019-04-29T19:33:14Z,https://github.com/tensorflow/tensorflow/commit/daf8f006143906e864707b1ad85254944beb8c47,"Cleanup: remove some redundancies, speed tests up and remove some of the deprecated annotations.PiperOrigin-RevId: 245801166",1,Rename Method,,
52d006a310b8ef6b8bbe48911a183215c4494943,2019-04-17T19:19:00Z,https://github.com/tensorflow/tensorflow/commit/52d006a310b8ef6b8bbe48911a183215c4494943,"Rename a few tf.image functions to not duplicate the ""image"" part.PiperOrigin-RevId: 244043733",1,Rename Method,,
4e4943edc3d2409bffb5776f99b941987d6eda82,2019-04-10T08:43:29Z,https://github.com/tensorflow/tensorflow/commit/4e4943edc3d2409bffb5776f99b941987d6eda82,"Refactor wrapping of partial functions.#26602 -> this will not be fixed, because as I learned during this refactoring, it is a limitation of functools.partial.PiperOrigin-RevId: 242826003",1,Rename Method,,
add240c14d5bc08d2d79c8bf4dfad98cc0da3bd3,2019-04-10T05:09:09Z,https://github.com/tensorflow/tensorflow/commit/add240c14d5bc08d2d79c8bf4dfad98cc0da3bd3,Properly rename _apply_gradients functions,1,Rename Method,,
c76cef535562d9b2c6d790ddfc20eb0df06a031b,2019-04-10T00:45:12Z,https://github.com/tensorflow/tensorflow/commit/c76cef535562d9b2c6d790ddfc20eb0df06a031b,Change path to loss scaling codeAnd revert _maybe_apply_gradients_cross_replica function rename,1,Rename Method,,
47115477d4ad5dff7c6dec5fc3c5b2f72447bfc2,2019-04-02T23:18:23Z,https://github.com/tensorflow/tensorflow/commit/47115477d4ad5dff7c6dec5fc3c5b2f72447bfc2,"Make CustomKernelCreator into a abstract classInstead of a function, we make CustomKernelCreator into an abstractclass in order to add a CanCreateKernel method. This allows us todistinguish between unsupported operations and an actual failure whencreating a kernel. As a result, we also rename CreateXlaLaunchOp toXlaKernelCreator.We also remove the CustomCreatorSingleton since only eager requires thecustom kernel creator to be set. As a result, we are able to furthersimply the flr construction signature.Note that noinline tests needed to be disabled since this changeshowed the tests were not operating as intended.PiperOrigin-RevId: 241625510",1,Rename Method,,
56c8527fa73f694b76963dbb28a9d011d233086f,2019-03-28T03:35:57Z,https://github.com/tensorflow/tensorflow/commit/56c8527fa73f694b76963dbb28a9d011d233086f,"Remove the type and value analyses, along with auxiliary constructs. The only transformer that still performs some static look-ups is the directives transformer. This speeds up the conversion process by about 20%.PiperOrigin-RevId: 240702979",1,Rename Method,,
2fa3d9448753b20aef4f28ca26f20abb3a657904,2019-03-15T00:01:55Z,https://github.com/tensorflow/tensorflow/commit/2fa3d9448753b20aef4f28ca26f20abb3a657904,Rename `tf.distribute.Strategy.unwrap` -> ...`.experimental_local_results` to clarify the semantics whenusing MultiWorkerMirroredStrategy.PiperOrigin-RevId: 238549191,1,Rename Method,,
91d3b3add93dc530abb91b2e6a8913f55aefe867,2019-02-27T01:21:28Z,https://github.com/tensorflow/tensorflow/commit/91d3b3add93dc530abb91b2e6a8913f55aefe867,"Rename tf.summary trace API symbols to all start with `trace`This ensures they appear grouped together lexicographically and it's easy to see them as a sort of ""sub-API"".  I also swapped out ""enable/disable"" for ""on/off"" which are a bit more concise; if that change is undesirable I can back out just that part.PiperOrigin-RevId: 235825040",1,Rename Method,,
268f66fb2f1c973192801f1da60a6cca37f18132,2019-02-26T00:11:00Z,https://github.com/tensorflow/tensorflow/commit/268f66fb2f1c973192801f1da60a6cca37f18132,"[tf.data] Remove the `Dataset.output_{types,shapes,classes}` properties in V2.These reflection properties are lightly used in non-test code, and donot properly reflect some of the recent developments in custom andnested structures (e.g. nested datasets returned by`Dataset.window()`, datasets containing `tf.data.experimental.Optional`, etc.).For internal users,`dataset_ops.get_legacy_output_{types,shapes,classes}(dataset)`provide a short-term replacement, and `dataset_ops.get_structure(dataset)`exposes the same information as a `tf.data.experimental.Structure` object.The replacement public property/API is still TBD, and will be addedpost 2.0-alpha.PiperOrigin-RevId: 235621094",1,Rename Method,,
32187f06dcd54c13ed489796c6ef4e10ed9f310d,2019-02-22T17:40:15Z,https://github.com/tensorflow/tensorflow/commit/32187f06dcd54c13ed489796c6ef4e10ed9f310d,Renames to prepare for the TF2.0 API. HashTable -> StaticHashTable and MutableDenseHashTable -> DenseHashTable. Also insert -> insert_or_assign and remove -> erase for DenseHashTable.PiperOrigin-RevId: 235206233,1,Rename Method,,
ec0d3ca37888dbaff3697b12749b48636a5553e2,2019-02-21T01:11:38Z,https://github.com/tensorflow/tensorflow/commit/ec0d3ca37888dbaff3697b12749b48636a5553e2,"Rename Keras export function to export_saved_model and fix documentation. In addition, the function now saves the SavedModel in the directory specified, instead of creating a new SavedModel.PiperOrigin-RevId: 234900123",1,Rename Method,,
7195464dc8a65071beb1a163fcb39bcf4a80f954,2019-02-20T01:01:03Z,https://github.com/tensorflow/tensorflow/commit/7195464dc8a65071beb1a163fcb39bcf4a80f954,[XLA:Python] Minor refactoring to add a helper method for wrapping program shapes.[TF:TPU] Make TPU core coordinate method public. This is for XRT interoperability.PiperOrigin-RevId: 234702954,1,Rename Method,,
9d1679d8f3fbc76f2b2a74cce7e8014f8d4543bc,2019-01-11T05:13:49Z,https://github.com/tensorflow/tensorflow/commit/9d1679d8f3fbc76f2b2a74cce7e8014f8d4543bc,Rename `SavedPolymorphicFunction` to `SavedFunction and `MonomorphicFunction` to `ConcreteFunction` and `concrete_function` attribute (in `ConcreteFunction` proto) to `name`,1,Rename Method,,
a76b3af1c33425fd01e7b3826de321c22e509760,2018-12-21T18:59:25Z,https://github.com/tensorflow/tensorflow/commit/a76b3af1c33425fd01e7b3826de321c22e509760,Rename run_deprecated_v1 to deprecated_graph_mode_only and maintain it as an aliasPiperOrigin-RevId: 226513083,1,Rename Method,,
49348b894d754b42ec145f66298810a689cef984,2018-12-19T18:59:33Z,https://github.com/tensorflow/tensorflow/commit/49348b894d754b42ec145f66298810a689cef984,"Internal clean up: ""distribution_strategy"" -> ""strategy"".PiperOrigin-RevId: 226199738",1,Rename Method,Rename Variable,
b69dce1d9fd31ed88abff8bf8bbbf87023655533,2018-12-01T04:31:37Z,https://github.com/tensorflow/tensorflow/commit/b69dce1d9fd31ed88abff8bf8bbbf87023655533,"Rename the unified_rnn_test to unified_lstm_test, since it only test the LSTM layer.We will probably have new test for unified_gru later.PiperOrigin-RevId: 223613402",1,Rename Method,,
aaff777c6d90f1717c970f3651fc254d20a95146,2018-11-16T22:15:09Z,https://github.com/tensorflow/tensorflow/commit/aaff777c6d90f1717c970f3651fc254d20a95146,"Remove rewriter_config parameter from create_inference_graph, that existedbefore because Grappler's OptimizeGraph() needs one. Now OptimizeGraph() ischanged to accept a ConfigProto so we can provide the RewriterConfig inside the'session_config' parameter.PiperOrigin-RevId: 221850911",1,Rename Method,,
2330933ddd0b29ad206e351c9120e621cdaf6312,2018-09-27T23:19:09Z,https://github.com/tensorflow/tensorflow/commit/2330933ddd0b29ad206e351c9120e621cdaf6312,Rename TFLite Extended -> TFLite FlexPiperOrigin-RevId: 214854303,1,Rename Method,,
1084594657a5d139102ac794f84d1427a710e39a,2018-09-27T19:51:52Z,https://github.com/tensorflow/tensorflow/commit/1084594657a5d139102ac794f84d1427a710e39a,TFLite: Rename ResetVariableTensorsToZero -> ResetVariableTensorsPiperOrigin-RevId: 214820383,1,Rename Method,,
c1e050cc75c6ced7b68a2349a012b2e5a3d04538,2018-09-24T14:58:00Z,https://github.com/tensorflow/tensorflow/commit/c1e050cc75c6ced7b68a2349a012b2e5a3d04538,Rename source_map to create_source_map. Reorganize the tests to be clearer about the expected functionality.PiperOrigin-RevId: 214266947,1,Rename Method,,
4d39844c1dafb6b74ad49b231bc949a2e026f5ea,2018-09-20T22:37:17Z,https://github.com/tensorflow/tensorflow/commit/4d39844c1dafb6b74ad49b231bc949a2e026f5ea,"Split XlaLaunch into XlaCompile and XlaRun; NFCThis CL splits the functionality in XlaLaunch into two separate operations: - XlaCompile, responsible for compiling a TF function into a LocalExecutable - XlaRun, responsible for executing a LocalExecutable created by XlaCompileThis CL is a stepping stone towards implementing lazy compilation for TF/XLA.The XlaCompile op is spec'ed to return a boolean indicating whether thecompilation was successful.  Right now that boolean is always set to true byXlaCompile and its value is otherwise ignored, but in the future it will be usedto indicate whether the TF function was compiled or not, and thus whether weshould execute XlaRun or just directly call the TF function.XlaLaunch still exists, and will be created by create_xla_launch_op.cc.  In thefuture we may consider removing it altogether.  build_xla_launch_ops.cc, nowrenamed to build_xla_ops.cc, creates a XlaCompile/XlaRun pair instead ofXlaLaunch.This CL is organized as follows: - jit/ops/xla_ops.cc gets two new XLA-specific operations, XlaCompile and   XlaRun, described above.  XlaRun redundantly takes the must-be-constant   inputs to the TensorFlow cluster to keep the implementation simple (simple in   the sense of similar to XlaLaunch), but I will remove this in a subsequent   cleanup CL. - jit/kernels/xla_ops.cc implements XlaCompile and XlaRun in a fairly   straightforward manner.  XlaCompile compiles the TF function, puts it in a   process-global storage, XlaExecutableClosureStore, and produces a int64 key.   XlaRun uses the key to read out the LocalExecutable and execute it.  I'm not   sure if XlaExecutableClosureStore should be a resource like   XlaCompilationCache; I did not immediately see any reason to make it so. - There are changes to the various _device files to register XlaCompile and   XlaRun for the XLA_* devices. - Finally, I had to fix some tests that were expecting XlaLaunch in the   execution timeline.PiperOrigin-RevId: 213895405",1,Rename Method,,
a5559a9d28bab6abfd65a9fad116ef9c6e13f8c2,2018-08-21T03:51:19Z,https://github.com/tensorflow/tensorflow/commit/a5559a9d28bab6abfd65a9fad116ef9c6e13f8c2,CLN: rename _shape_tensor_equal to _shape_tensor_compatible,1,Rename Method,,
09e272a6a5c3359b671a068f4dac2bca8b312358,2018-08-16T18:07:17Z,https://github.com/tensorflow/tensorflow/commit/09e272a6a5c3359b671a068f4dac2bca8b312358,Renamed function in freeze_graph.py.PiperOrigin-RevId: 209013414,1,Rename Method,,
dcf4254078453bce00e87f03769c2c74eabde2a1,2018-08-14T06:10:43Z,https://github.com/tensorflow/tensorflow/commit/dcf4254078453bce00e87f03769c2c74eabde2a1,CLN: rename unsafe_div => div_no_nan,1,Rename Method,,
919e59cc49ada3d529e080ee8eebaaec7f621844,2018-07-28T02:27:01Z,https://github.com/tensorflow/tensorflow/commit/919e59cc49ada3d529e080ee8eebaaec7f621844,De-dup and clean get metric name and function code between graph and eager modeAlso allow usage of string 'crossentropy'/'ce' for cross entropy metrics in eager modePiperOrigin-RevId: 206407222,1,Rename Method,,
e25386e18a2bea60886daa3157dfb3a32781d863,2018-07-24T20:33:37Z,https://github.com/tensorflow/tensorflow/commit/e25386e18a2bea60886daa3157dfb3a32781d863,Remove functions from TFLite public Python API.PiperOrigin-RevId: 205882419,1,Rename Method,,
274cce5990ff279e2ce293ae9ce1c1d0445d3242,2018-07-14T02:59:51Z,https://github.com/tensorflow/tensorflow/commit/274cce5990ff279e2ce293ae9ce1c1d0445d3242,"Broad refactor (part 7): Swap in the new CFG implementation, along with the new directives support. Simplify the process by which transformers are applied and their testing.Changes to converters: * all tests have been refactored to use the new helpers; functionally they remain the same * several converters have been renamed to be more consistent with the overall naming patterns: single_return.py -> return_statements.py; list_comprehension.py -> list_comprehensions.py; if_exp.py -> conditional_expressions.py * conditional expression converter has been rewritten to use local functions instead of lambdas, which are not yet supported by the static analyzers * the handling of if statements in control_flow.py now uses both the liveness and reaching definitions analyses to more robustly detect output variables * a new directives.py converter is introduced, that transforms user directives (see lang/directives.py) into AST annotations and removes the function calls from the code * list_comprehensions.py is slightly refactored for better readability; it is still not yet enabled * slices.py and lists.py now use the new directives mechanism to obtain list type information * side_effects_guards_test.py has been refactored to avoid flakinessChanges to AG core: * conversion.py now uses the helpers from converter.py and removes the redundant function * converter_testing.py now offers a more unified helper that can be used to test most use cases with less boilerplate * the new directives module now completely replaces the obsolete type_hints.pyChanges to static analysis: * activity.py no longer considers index mutation to modify the parent (e.g. a[0] = 1 is not considered to modify a) * activity.py no longer detects the local symbol changes (the IS_MODIFIED_SINCE_ENTRY annotation), which is now handled by reaching_definitions.py * activity.py marks the created field as obsolete, to be removed once the loops in control_flow are migrated to use the dataflow analyses * the obsolete annos.py extension has been removes in favor of the consolidated tags in anno.py * the new CFG implementation now completely replaces the old version * live_values.py and type_info.py also use the symbol definitions from reaching_definitions.pyPiperOrigin-RevId: 204563046",1,Rename Method,,
ea218582ff1798eb504249d5d02a05bb6141d2ed,2018-06-25T15:42:43Z,https://github.com/tensorflow/tensorflow/commit/ea218582ff1798eb504249d5d02a05bb6141d2ed,"[tf.data] Rename private `filter_irregular_batches()` function with leading underscore.Its functionality has been subsumed by the `drop_remainder` arguments to `Dataset.batch()`, `Dataset.padded_batch()` and `tf.contrib.data.map_and_batch()`.PiperOrigin-RevId: 201959371",1,Rename Method,,
09a5f58fdc108e084b3d4a3c569a694fa5a96812,2018-05-17T16:57:16Z,https://github.com/tensorflow/tensorflow/commit/09a5f58fdc108e084b3d4a3c569a694fa5a96812,Rename private push/pop API and use from `stop_recording` method.PiperOrigin-RevId: 197007561,1,Rename Method,,
c08bf79144b3acc731018147e92fd389bcb60b2d,2018-05-02T17:57:49Z,https://github.com/tensorflow/tensorflow/commit/c08bf79144b3acc731018147e92fd389bcb60b2d,Renames _regression_head_with_mean_squared_error_loss to _regression_head.PiperOrigin-RevId: 195117425,1,Rename Method,,
533cb5caa4c88d3f76e1994e8f039ea04d342482,2018-04-28T15:30:56Z,https://github.com/tensorflow/tensorflow/commit/533cb5caa4c88d3f76e1994e8f039ea04d342482,Remove assertions,1,Rename Method,,
96dc82647d0eb5d1903242c2dde1cf9dd5bb36f0,2018-04-28T15:28:33Z,https://github.com/tensorflow/tensorflow/commit/96dc82647d0eb5d1903242c2dde1cf9dd5bb36f0,Rename API method,1,Rename Method,,
ddf54d1c24a2b4dcfd8eb52d21dc1f393785f1e9,2018-04-07T00:13:13Z,https://github.com/tensorflow/tensorflow/commit/ddf54d1c24a2b4dcfd8eb52d21dc1f393785f1e9,"Remove zipped argument, and use an implicit dispatch mechanismPiperOrigin-RevId: 191962157",1,Rename Method,,
c4acdccbb7284c6a63e6824a7ee45ce7a86606b9,2018-03-30T18:12:24Z,https://github.com/tensorflow/tensorflow/commit/c4acdccbb7284c6a63e6824a7ee45ce7a86606b9,Rename distributed_apply to _distributed_apply in OptimizerV2 to matchthe Optimizer base class.PiperOrigin-RevId: 191089407,1,Rename Method,,
6a16e22421626ceffecb025b1cd80722c36aea0d,2018-03-20T16:27:24Z,https://github.com/tensorflow/tensorflow/commit/6a16e22421626ceffecb025b1cd80722c36aea0d,"Revise the main API for more consistent notation and add a supplemental shortcut to mark functions as ""run in py_func"". This is an intermediate step to simplifying the execution of plotting code.PiperOrigin-RevId: 189753509",1,Rename Method,,
ac8ce1fe760efff6585d790b784ec67255198879,2018-03-14T21:34:15Z,https://github.com/tensorflow/tensorflow/commit/ac8ce1fe760efff6585d790b784ec67255198879,Rename KMeans _parse_tensor_or_dict to _parse_features_if_necessary and add a unit test.PiperOrigin-RevId: 189087384,1,Rename Method,,
37cef895bfe06913477b87917cbee7284aefa7cd,2018-03-07T20:03:56Z,https://github.com/tensorflow/tensorflow/commit/37cef895bfe06913477b87917cbee7284aefa7cd,"eager: Rename in_eager_mode to executing_eagerly and get rid of in_graph_mode.This is in preparation to introduce one public, stable symbol: tf.executing_eagerly()(i.e., part of moving APIs related to eager execution from ""contrib"" to a namespacewhere we provide API stability guarantees)PiperOrigin-RevId: 188212646",1,Rename Method,,
c97c223935c2a0b1d50926342252707c02afed8c,2018-01-18T00:01:29Z,https://github.com/tensorflow/tensorflow/commit/c97c223935c2a0b1d50926342252707c02afed8c,Merge commit for internal changes,1,Rename Method,,
969f5a06271f506ce53c0078d2cf706393a7ee56,2018-01-05T02:53:50Z,https://github.com/tensorflow/tensorflow/commit/969f5a06271f506ce53c0078d2cf706393a7ee56,Refactoring and bug-fixes for _build_initializer_expr.- Rename _build_initializer_expr to _try_guard_against_uninitialized_dependencies so as to clarify what it does.- Avoid invoking the logic in _try_guard_against_uninitialized_dependencies for cyclic graphs. This currently results in infinite recursion which blows the stack.- Use memoization to reduce the number of redundant operations created by _try_guard_against_uninitialized_dependencies when it encounters initial values with diamond-shaped dependencies.- Refactoring: Remove unnecessary logic in _try_guard_against_uninitialized_dependencies for dealing with types other than Tensor or Operation. The dependency graph of a Variable's _initial_value should only ever comprise these two types.- Refactoring: Added some filtering logic to _try_guard_against_uninitialized_dependencies to avoid initial_values with cyclic dependencies- Refactoring: Moved the recursive traversal of initial_value`s dependencies into _safe_initial_value_from_tensor and _safe_initial_value_from_op.- Refactoring: Made it so _find_initialized_value_for_variable will return None when it can't find the initialized_value. Currently it returns a Tensor when it finds the initialized_value and an Operation when it can't. This makes the logic in the caller a bit more consistent and explicit.Future changes will address more of the shortcomings of _build_initializer_expr.PiperOrigin-RevId: 180876754,1,Rename Method,,
8ad62af489df718992561710123bc8c037e7d17b,2017-12-07T02:40:17Z,https://github.com/tensorflow/tensorflow/commit/8ad62af489df718992561710123bc8c037e7d17b,Split the tests so that it doesn't time out.PiperOrigin-RevId: 178185460,1,Rename Method,,
de1ee126c094c840668d5e794e347159be66b23c,2017-12-01T23:48:30Z,https://github.com/tensorflow/tensorflow/commit/de1ee126c094c840668d5e794e347159be66b23c,Rename create_summary_file_writer to create_file_writerPiperOrigin-RevId: 177651937,1,Rename Method,,
4d8277747afc62fd3959fc249545f237e5f0ca80,2017-12-01T16:27:27Z,https://github.com/tensorflow/tensorflow/commit/4d8277747afc62fd3959fc249545f237e5f0ca80,"1) Make `tensor_pool` support a list of input_values, so we can store (generated_input, generated_data) tuples in the pool.2) Rename `tensor_pool` function to `random_tensor_pool` so the function name does not collide with the pkg name.PiperOrigin-RevId: 177594443",1,Rename Method,,
780c64e3e872269e76efa27b5bb7fe2465c26dfe,2017-11-17T02:23:32Z,https://github.com/tensorflow/tensorflow/commit/780c64e3e872269e76efa27b5bb7fe2465c26dfe,Turn off graph optimization in max pooling test because of the inconsistentbehavior on handling NaN and -Inf in different MaxPooling implementations. Split the tests as ConfigProto could interfere with each other.PiperOrigin-RevId: 176054079,1,Rename Method,,
aa4162ac9f1812a0966d3cd9b5e441e47f035828,2017-11-16T18:23:48Z,https://github.com/tensorflow/tensorflow/commit/aa4162ac9f1812a0966d3cd9b5e441e47f035828,"contrib/summary: refactor summary_test_utilA logdir may contain files other than summary event files, e.g., checkpoints.So add a method ""events_from_file"" to load events from a single file.The existing ""events_from_logdir"" method now calls the new method.PiperOrigin-RevId: 175981886",1,Rename Method,,
2ceaad624dd749bd21ce1cad58143acb9366f297,2017-10-23T20:08:26Z,https://github.com/tensorflow/tensorflow/commit/2ceaad624dd749bd21ce1cad58143acb9366f297,Rename add_layer -> track_layer in Network.PiperOrigin-RevId: 173159032,1,Rename Method,,
ad37fa81fde6ab767cc6f2ec0b687f16d905705b,2017-10-03T23:51:29Z,https://github.com/tensorflow/tensorflow/commit/ad37fa81fde6ab767cc6f2ec0b687f16d905705b,Refactor ExportStrategies into Exporters.This design eliminates some indirection.  Instead of combining an `export_fn` with `make_export_strategy` call to arrive at an ExportStrategy that is going to call the supplied `export_fn` inside its `export` call with Exporters one just defines the `export` call in an Exporter.PiperOrigin-RevId: 170936640,1,Rename Method,,
b0b4b608dcc68a9efeaa325e069275bae0de045d,2017-09-28T21:09:59Z,https://github.com/tensorflow/tensorflow/commit/b0b4b608dcc68a9efeaa325e069275bae0de045d,"[tf.data] Rename `Dataset.make_dataset_resource()` to `Dataset._as_variant_tensor()`.This method is not intended to be part of the public API for users, so thischange will remove it from the documentation.PiperOrigin-RevId: 170395458",1,Rename Method,,
7aa94908e00d609760c9d0aa5e76441008592a27,2017-09-17T20:38:59Z,https://github.com/tensorflow/tensorflow/commit/7aa94908e00d609760c9d0aa5e76441008592a27,Rename all BackProp to Backprop for consistency. (#12623),1,Rename Method,,
6e39440e5908a2149512916ff6bc707c290de547,2017-08-28T07:49:53Z,https://github.com/tensorflow/tensorflow/commit/6e39440e5908a2149512916ff6bc707c290de547,TST: rename test function,1,Rename Method,,
0c58aad7e01319a650b0bd7fe475807c9b2feef5,2017-08-25T04:30:09Z,https://github.com/tensorflow/tensorflow/commit/0c58aad7e01319a650b0bd7fe475807c9b2feef5,TST: rename function,1,Rename Method,,
11dff5b05b3488520d3a415173d73ae91fded092,2017-07-18T23:30:45Z,https://github.com/tensorflow/tensorflow/commit/11dff5b05b3488520d3a415173d73ae91fded092,"Remove all references to OperatorPD and replace with LinearOperator.  - Only dependent is Wishart, which is updated to use LinearOperator.PiperOrigin-RevId: 162421033",1,Rename Method,,
b5cceb367525c85bf8b05fe6aa0d7e1b327c4ce9,2017-07-14T03:14:22Z,https://github.com/tensorflow/tensorflow/commit/b5cceb367525c85bf8b05fe6aa0d7e1b327c4ce9,Refactoring the TPUEstimator.PiperOrigin-RevId: 161905196,1,Rename Method,,
ea3d9ab10f6391ce131f0fd39a214c66fdf06ae6,2017-07-11T05:01:27Z,https://github.com/tensorflow/tensorflow/commit/ea3d9ab10f6391ce131f0fd39a214c66fdf06ae6,Removed the _tensor_summary_v2 op.Made the tensor_summary op directly use the TensorSummaryV2 kernel.PiperOrigin-RevId: 161486007,1,Rename Method,,
90b32e54da641f023e72fc80222bf2acbfb57a4c,2017-05-11T23:02:56Z,https://github.com/tensorflow/tensorflow/commit/90b32e54da641f023e72fc80222bf2acbfb57a4c,"Rename some fields, from discussion in go/tf-feature-column and other cls.PiperOrigin-RevId: 155809199",1,Rename Method,,
3c2dc3baaae762b00d90761f47265411f54033b3,2017-05-11T20:27:35Z,https://github.com/tensorflow/tensorflow/commit/3c2dc3baaae762b00d90761f47265411f54033b3,"Renames _parse_example_config to _parse_example_spec, adds tests and other cleanup.PiperOrigin-RevId: 155788799",1,Rename Method,,
1e3e5d424eaa6332314f8ad1d54089eb0f9e02e7,2017-04-27T00:12:34Z,https://github.com/tensorflow/tensorflow/commit/1e3e5d424eaa6332314f8ad1d54089eb0f9e02e7,"Refactor Keras layers to rely on core TF layers.API change: for users of custom Keras layers built using `tf.contrib.keras`, the method `add_weight` of the Keras base layer has now a new API (synced with the main Keras GitHub repo).Change: 154366685",1,Rename Method,,
b791ee38270b6cc75a3ea641f1343264b0351b88,2017-03-15T18:50:52Z,https://github.com/tensorflow/tensorflow/commit/b791ee38270b6cc75a3ea641f1343264b0351b88,Split up module contents.Change: 150221535,1,Rename Method,,
92f285f281328aa003e4e0449371beab5add316d,2017-03-13T20:53:40Z,https://github.com/tensorflow/tensorflow/commit/92f285f281328aa003e4e0449371beab5add316d,"Refactor the PluginAsset class so that PluginAssets are not directly responsible for serialization.In the current PluginAsset api, the PluginAsset provides a serialize_to_directory method in which it directly writes contents to disk. This means that we as framework maintainers don't have the flexibility to change the serialization strategy in different contexts, e.g. providing good ways to serialize in contexts where we are writing to a db rather than to disk. Also, it presents a trivial landmine where users may use standard python file APIs rather than gfile and thus provide implementations that work externally but break within g3.After the change, the PluginAsset instead provides an 'assets' method, which provides asset names and asset contents. How this gets written out is now an implementation detail handled by the tf.summary.FileWriter.We haven't yet exposed the PluginAsset class as part of the TensorFlow API (it's hidden) so this isn't an API break.Change: 149985564",1,Rename Method,,
994fb05113f147f7ece04d8d68db91ce70834e35,2017-03-10T18:01:19Z,https://github.com/tensorflow/tensorflow/commit/994fb05113f147f7ece04d8d68db91ce70834e35,Rename Estimator.fit() -> Estimator.train() and ModeKeys.FIT -> ModeKeys.TRAIN.Change: 149768595,1,Rename Method,,
bb5ba002c9b41e2f01e53ffc49d69422d2973145,2017-02-01T03:16:06Z,https://github.com/tensorflow/tensorflow/commit/bb5ba002c9b41e2f01e53ffc49d69422d2973145,"BREAKING CHANGE: Rename bijector shape getters, e.g., ""get_forward_event_shape()"" to ""forward_event_shape()"", ""forward_event_shape()"" to ""forward_event_shape_tensor(), and same for ""inverse"" counterparts.Change: 146196054",1,Rename Method,,
2ddb9a0960af173cbc596be8436ec79bc7efb000,2017-02-01T00:38:34Z,https://github.com/tensorflow/tensorflow/commit/2ddb9a0960af173cbc596be8436ec79bc7efb000,"BREAKING CHANGE: Rename shape getters, e.g., ""get_event_shape()"" to ""event_shape()"", ""event_shape()"" to ""event_shape_tensor(), and same for ""batch_shape"".BUGFIX: *onehot_categorical.py returns vector not scalar.Change: 146182622",1,Rename Method,,
7e935c1d91d84979e671cc62a78d54e624a349b9,2017-01-19T20:28:19Z,https://github.com/tensorflow/tensorflow/commit/7e935c1d91d84979e671cc62a78d54e624a349b9,Rename head_ops to create_model_fn_ops.Change: 144994566,1,Rename Method,,
78b11cef0ce2092c52f834648427e2a5773424a1,2017-01-13T00:13:55Z,https://github.com/tensorflow/tensorflow/commit/78b11cef0ce2092c52f834648427e2a5773424a1,"Remove tf.mul, tf.neg and tf.sub from the public APIChange: 144384783",1,Rename Method,,
cb4acf5e47574deccf0c578d6d1d18d74f6117af,2016-12-20T22:12:07Z,https://github.com/tensorflow/tensorflow/commit/cb4acf5e47574deccf0c578d6d1d18d74f6117af,"Rename usages of tf.mul, tf.neg, tf.sub that are used internallyChange: 142595367",1,Rename Method,,
6e479d372fa0d805aea0ee04aafbdb927143df9a,2016-12-12T19:54:36Z,https://github.com/tensorflow/tensorflow/commit/6e479d372fa0d805aea0ee04aafbdb927143df9a,Refactor unit tests to make them easier to follow.Change: 141792372,1,Rename Method,,
4cbdead95f22de74bcbc72a68c9a38d465202db9,2016-11-03T16:24:37Z,https://github.com/tensorflow/tensorflow/commit/4cbdead95f22de74bcbc72a68c9a38d465202db9,Renamed: * tf.all_variables to tf.global_variables * tf.VARIABLES -> tf.GLOBAL_VARIABLES * tf.initialize_all_variables -> tf.global_variable_initializersChange: 138078998,1,Rename Method,,
3adb3fd05f816bb6c68d13753bbdfa83516b26b6,2016-10-24T19:31:54Z,https://github.com/tensorflow/tensorflow/commit/3adb3fd05f816bb6c68d13753bbdfa83516b26b6,"Rename tf.image.per_image_whitening() to tf.image.per_image_standardization(). This adds a temporary per_image_whitening() wrapper to keep callers working. Subsequent changes will change call sites, and finally remove the wrapper.Change: 137065813",1,Rename Method,,
75071ed23c9f1533f1951beca012150cc71ab95c,2016-10-06T17:50:56Z,https://github.com/tensorflow/tensorflow/commit/75071ed23c9f1533f1951beca012150cc71ab95c,Removes deprecated to_weighted_sum and hides to_dnn_input.Change: 135377502,1,Rename Method,,
236a1c7f7d577d9758d06a6c382035065075578d,2016-09-16T20:22:55Z,https://github.com/tensorflow/tensorflow/commit/236a1c7f7d577d9758d06a6c382035065075578d,"De-flake learn tests.- Removed score assertions from nonlinear_test. These will never be stable until we can make TF deterministic, and even if we could they wouldn't be particularly useful tests for an inherently stochastic system.- Removed saver_test. It wasn't testing anything useful.- Removed early_stopping_test in favor of a better unit test for ValidationMonitor.Change: 133420080",1,Rename Method,,
8d54103171827b17cd062a71bc1b50fb80b3bb82,2016-09-15T16:56:40Z,https://github.com/tensorflow/tensorflow/commit/8d54103171827b17cd062a71bc1b50fb80b3bb82,Some cleanup.Change: 133273363,1,Rename Method,,
612bae7e9fbe6ebf09a5e90279897baf950e5f28,2016-09-09T19:03:09Z,https://github.com/tensorflow/tensorflow/commit/612bae7e9fbe6ebf09a5e90279897baf950e5f28,"Rename NoGradient -> NotDifferentiable, to make it clearabout when it should be used.Keep the old name around for temporary backwards compatibility.Change: 132700646",1,Rename Method,,
b0ce8deae4f8b0b24c8d8e18c4f62c3b1927f9d8,2016-09-09T17:30:10Z,https://github.com/tensorflow/tensorflow/commit/b0ce8deae4f8b0b24c8d8e18c4f62c3b1927f9d8,Some cleanup of dynamic_rnn_estimator:- Changed `logits` to `activations` to include regression as well as classification.- Added name_scope to several functions.Change: 132689120,1,Rename Method,Rename Variable,
d210c607e0d8d8fd15a13cd742bfe9d0ae981912,2016-08-29T16:47:17Z,https://github.com/tensorflow/tensorflow/commit/d210c607e0d8d8fd15a13cd742bfe9d0ae981912,"Re-arranged coordinator.join call in MonitoredSession. Now there is only one place which calls ""join""Deleted public access to internal TF session and coordinator.Change: 131602130",1,Rename Method,,
eece52911b3b4c23a82f1385dd29a5dca520e743,2016-08-03T23:05:36Z,https://github.com/tensorflow/tensorflow/commit/eece52911b3b4c23a82f1385dd29a5dca520e743,Renames sparse_merge 'in_row_major_order' arg to 'already_sorted'To make the API more consistentChange: 129270382,1,Rename Method,,
81338de1ffebb717f175dc5193fcf6c8965d1d6f,2016-07-18T06:41:17Z,https://github.com/tensorflow/tensorflow/commit/81338de1ffebb717f175dc5193fcf6c8965d1d6f,Remove read_analogies() from word2vec class initialization.,1,Rename Method,,
70f1a7ab0e18a3dbfd67a04f685099e25338ac96,2016-06-02T02:48:22Z,https://github.com/tensorflow/tensorflow/commit/70f1a7ab0e18a3dbfd67a04f685099e25338ac96,Rename tf.contrib.losses.log to tf.contrib.losses.log_lossChange: 123823505,1,Rename Method,,
bca38c48901c9a8e1266859fb056ef9aff10ba24,2016-05-31T16:38:36Z,https://github.com/tensorflow/tensorflow/commit/bca38c48901c9a8e1266859fb056ef9aff10ba24,Renamed 'create_dict_for_parse_example' to create_feature_spec_for_parsing.Change: 123650024,1,Rename Method,,
ec89b0c218c340b9b8bc43ac9a1b9120ea81c175,2016-04-18T16:37:55Z,https://github.com/tensorflow/tensorflow/commit/ec89b0c218c340b9b8bc43ac9a1b9120ea81c175,"Adding several loss functions including cosine_distance_loss, log_loss, softmax_cross_entropy_loss, and sum_of_pairwise_squares_loss. Refactoring old losses for consistency.Change: 120130871",1,Rename Method,,
6778e5d7d02bc48587be61f1b3e0b4cd92b62888,2016-03-14T16:48:10Z,https://github.com/tensorflow/tensorflow/commit/6778e5d7d02bc48587be61f1b3e0b4cd92b62888,Split tests for each loss type into separate test classes.Change: 117142191,1,Rename Method,Move Method,
57df84c47eac324418b2bf11d33cb4b50ba274b2,2016-02-24T19:12:13Z,https://github.com/tensorflow/tensorflow/commit/57df84c47eac324418b2bf11d33cb4b50ba274b2,"Rename map in control_flow_ops to map_fn, to avoid name conflict with Python's native 'map' function. This also fixes the bug with control_flow_ops.caseChange: 115472163",1,Rename Method,,
715fc5aa1a2e465ddcf0ae45dcb25d8e9fa09fef,2016-02-20T00:01:05Z,https://github.com/tensorflow/tensorflow/commit/715fc5aa1a2e465ddcf0ae45dcb25d8e9fa09fef,Rename `testDoubleRandomTranposeBoth` to `testDoubleRandomTransposeBoth`.This PR renames a test case in `matmul_op_test.py` to fix a typo.,1,Rename Method,,
1c1825253900acd5aeb76f2ed18fa55d0dee3600,2016-01-25T19:00:51Z,https://github.com/tensorflow/tensorflow/commit/1c1825253900acd5aeb76f2ed18fa55d0dee3600,Remove camel case ConstantValue alias from tensor_utilConstantValue is now constant_value.Change: 112966774,1,Rename Method,,
877fcd1a113797a1c5847dd5fdbef7868addded0,2016-01-20T23:36:06Z,https://github.com/tensorflow/tensorflow/commit/877fcd1a113797a1c5847dd5fdbef7868addded0,"Prepare to hide tf.tensor_util1. There is a new tf.unsupported module to hold things which some people use   but which we don't yet support.2. tf.tensor_util.ConstantValue is now tf.unsupported.constant_value.  Most   users use this, but tf.tensor_util.ConstantValue is still available; it   will be removed in a following commit.3. tensor_util.MakeTensorShapeProto is now make_tensor_shape_proto.  It looks   like all users of this access the tensor_util module directly (not through   tf), so for now it is not in unsupported.This commit does not remove tensor_util from tf.__all__; a few more downstreamusers must be changed before that can happen.Change: 112626961",1,Rename Method,,
c645d7a7482f064b77c63aeed2b3b4784a5d6ab6,2023-01-25T18:15:44Z,https://github.com/keras-team/keras/commit/c645d7a7482f064b77c63aeed2b3b4784a5d6ab6,Change back_up > backup to keep consistent with other callsites.  PiperOrigin-RevId: 504595178,1,Rename Method,,
c2fc680dac8a4eb108077ed396bbdc98ebacbfbe,2022-12-13T23:36:11Z,https://github.com/keras-team/keras/commit/c2fc680dac8a4eb108077ed396bbdc98ebacbfbe,Change is_split_variable to test class names instead of attribute names. This avoids expensive retrieval of distributed variable values at each call.  PiperOrigin-RevId: 495143791,1,Rename Method,,
eaf9cd283fb3f076beebb2cb0652df9aa8ee87be,2022-04-29T21:11:44Z,https://github.com/keras-team/keras/commit/eaf9cd283fb3f076beebb2cb0652df9aa8ee87be,Modify augment_bounding_box() API - rename it to augment_bounding_boxes() - add image arg - renamed arg bounding_box to bounding_boxes  PiperOrigin-RevId: 445502826,1,Rename Method,,
f5dcdb669b1a767b05d9694f699395ae3b7d1c09,2022-04-15T16:25:22Z,https://github.com/keras-team/keras/commit/f5dcdb669b1a767b05d9694f699395ae3b7d1c09,renames tests with common convention,1,Rename Method,Extract Method,
027f0776814de831341f9bcff3e9212e57713346,2022-01-24T15:40:38Z,https://github.com/keras-team/keras/commit/027f0776814de831341f9bcff3e9212e57713346,Migrate AutoTrackable._list_functions_for_serialization to _trackable_children  PiperOrigin-RevId: 423811834,1,Rename Method,,
01321c530ea84be2fd796aed4b8da8e5e095be80,2021-10-14T09:15:20Z,https://github.com/keras-team/keras/commit/01321c530ea84be2fd796aed4b8da8e5e095be80,Renamed Block functions.,1,Rename Method,,
b2f6e348a82cafe4a9566191ff5eb09d1d26ad93,2021-08-31T00:53:20Z,https://github.com/keras-team/keras/commit/b2f6e348a82cafe4a9566191ff5eb09d1d26ad93,"Rename internal set_policy function to set_global_policy.  Also change some references to the experimental ""set_policy"" function to the nonexperimental ""set_global_policy"" function.  PiperOrigin-RevId: 393891991",1,Rename Method,,
b1030b2e6db8d7d5bf91e43f57f63e2576e06ed2,2021-06-20T19:51:44Z,https://github.com/keras-team/keras/commit/b1030b2e6db8d7d5bf91e43f57f63e2576e06ed2,Rename methods,1,Rename Method,,
ba7ab2ffe62143949b9730a55291c474352f31e5,2018-09-13T18:55:47Z,https://github.com/keras-team/keras/commit/ba7ab2ffe62143949b9730a55291c474352f31e5,[Refactoring] Removed code duplication in the theano backend. (#11131)  * Removed code duplication in the theano backend.  * Changed the name of the function to _set_keras_shape_for_reduction.,1,Rename Method,Remove Dead Code,
cac308e88d07e06415bff8a41100c235d28b7c02,2015-12-05T21:36:12Z,https://github.com/keras-team/keras/commit/cac308e88d07e06415bff8a41100c235d28b7c02,few refactoring ideas,1,Rename Method,,
08c873669f39b37743014db99fcd2d308f8ea5ea,2018-05-22T21:03:51Z,https://github.com/keras-team/keras/commit/08c873669f39b37743014db99fcd2d308f8ea5ea,Refactor ImageDataGenerator (#10130)  * Create get_random_transform and refactor  * Fix style and add tests  * Add more tests  * Fix documentation error  * Fix documentation style issue  * add apply_affine_transform  * document transformation dictionary  * Doc style fix,1,Rename Method,Rename Variable,
49f5b931410bc2e56378f20a15e8ac919e0efb88,2018-04-24T19:34:58Z,https://github.com/keras-team/keras/commit/49f5b931410bc2e56378f20a15e8ac919e0efb88,Refactor topological part of `engine` module (#10023)  * Refactor topological part of Keras engine.  * Fix imports  * Fix merge mixup.,1,Rename Method,,
be1ec8aeccccbe6c5f3c2ef1047256016b607395,2015-05-09T22:36:47Z,https://github.com/keras-team/keras/commit/be1ec8aeccccbe6c5f3c2ef1047256016b607395,Layer API refactor,1,Rename Method,,
06757acb300dc9be44f8eda6945b0548f5ce2eb2,2019-08-28T20:11:17Z,https://github.com/pytorch/pytorch/commit/06757acb300dc9be44f8eda6945b0548f5ce2eb2,Refactor MinMax observer (#23902)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/23902Copied from Daya's diff in pytorch/pytorch #23191Refactor MinMax observer and create the base observer class to prepare for future observers such as histogram observer.ghstack-source-id: 89146014Test Plan:Added a test test_minmax_observerbuck test mode/dev caffe2/test:quantization -- 'test_minmax_observer'```Running 1 testsStarted new test run: https://our.intern.facebook.com/intern/testinfra/testrun/2533274797931635      ?caffe2/test:quantization - test_minmax_observer (test_quantization.ObserverTest) 0.055 1/1 (passed)Finished test run: https://our.intern.facebook.com/intern/testinfra/testrun/2533274797931635Summary (total time 4.26s):  PASS: 1  FAIL: 0  SKIP: 0  FATAL: 0  TIMEOUT: 0  OMIT: 0```buck test mode/dev caffe2/test:quantization -- 'test_observer_scriptable'```Running 1 testsStarted new test run: https://our.intern.facebook.com/intern/testinfra/testrun/5348024563344195      ?caffe2/test:quantization - test_observer_scriptable (test_quantization.ObserverTest) 1.762 1/1 (passed)Finished test run: https://our.intern.facebook.com/intern/testinfra/testrun/5348024563344195Summary (total time 6.02s):  PASS: 1  FAIL: 0  SKIP: 0  FATAL: 0  TIMEOUT: 0  OMIT: 0```Differential Revision: D16663221fbshipit-source-id: 3d0e1aa9e4d27808e61b10604782606de067a34a,1,Rename Method,Rename Class,
0705f759a326491a91af1f77874a5c11a60c716e,2019-09-19T21:27:35Z,https://github.com/pytorch/pytorch/commit/0705f759a326491a91af1f77874a5c11a60c716e,"Implement multiple dispatch (#26468)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/26468Instead of considering only the TensorTypeSet of the first argument, we collect all Tensor and TensorList arguments and union them together before computing the dispatch type id.XLA companion patch at https://github.com/pytorch/xla/pull/1031Billing of changes:* ATenDispatch fallback code (i.e., what gets run if there is no entry for a function in the table) now lives out-of-line in a function `getFallbackOp`. This gave me an opportunity to write a more detailed error message, providing information about what registrations were available. There is a TODO in the fallback code, suggesting that we could automatically redispatch in the event that there is no handler for the key. But this is a bit of a design question, because it's not clear if automatic redispatch would cover up errors in the dispatch table (i.e., there *should* have been something registered at some key, but there wasn't.)* Collection of Tensor/TensorList arguments is done using the trusty old IterArgs helper class. A minor bit of refactoring I had to do to get here was move the IterArgs functionality in torch/csrc/utils/variadic.h into ATen/core.  There's some refactoring due on that file too (it has copies of some C++ helper pieces which already live in c10--you can't actually move the whole thing because it is literally incompatible with other code in the codebase). So instead of calling `type_set()` to get the type set of the dispatch argument, now we just call `at::detail::multi_dispatch_tensor_type_set` on all of the tensor/tensor list arguments.* The code generator is adjusted to codegen collection of arguments as needed. There is a little bit of a hack in the code generator to turn 'self' arguments into '*this'.  I think this may be duplicated with some logic somewhere else but I have to double check.The new generated code looks like this:```inline Tensor & Tensor::copy_(const Tensor & src, bool non_blocking) const {    static auto table = globalATenDispatch().getOpTable(""aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"");    return table->getOp<Tensor & (Tensor &, const Tensor &, bool)>(at::detail::multi_dispatch_tensor_type_set(*this, src))(const_cast<Tensor&>(*this), src, non_blocking);}```The key difference is that previously we wrote `type_set()` as argument to getOp; now it is a call to `multi_dispatch_tensor_type_set` which collects the type ids together.After turning on multi-dispatch, I had to refactor existing code which previously dispatched one place, but now dispatches somewhere else. The primary component affected by this is sparse.* Binary operations (add/sub/mul/div/addmm) now dispatch to sparse kernels even if you did add(dense, sparse). So I delete all the sparse handling code from dense kernels, and bulk up the sparse error handling to handle when the first argument is dense. In the case of addmm, I can eliminate the bridge code entirely (well, not quite: more on this below). I also updated the dispatch on sparse to actually point at sparse kernels. Pay special attention to the handling of `div_` by scalar: previously this logic lived in the ""dense"" `div_` implementation, but there is actually not any sparse kernel we dispatch to. I solved this particular problem by making a redispatch, but another valid approach would have been to add specific dispatches for sparse div on scalar. This codepath is poorly tested because it is only exercised from C++.* One minor annoyance is that because I now want separate dispatch for dense and sparse, I also need to replicate the `add`, `add_`, `add_out` trifecta on the sparse side. I opted for a compromise here: I wrote new a new `add_sparse` trifecta, but reused the implementation between CPU and CUDA. This means that I hav to do another dispatch once I get to `add_out`. The alternative would have been to do twice as many copies for CPU and CUDA (thereby eliminating the extra dispatch) but that seemed distinctly not worth it.* A lot of kernels in sparse assumed that the dispatch argument must be sparse. This is no longer true with dispatch, so I converted the asserts into plain error checking. This also means that we've perturbed the error message in the case of TestSparseOneOff.test_cuda_sparse_cpu_dense_add (I just updated the saved error message)* `addmm` is a little bit even more special: the bridge code also handled broadcasting. I replicated the broadcasting logic between CPU and CUDA implementations to avoid an extra dispatch.* `_sparse_addmm` gave me a bit of trouble, because I had forgotten why we had `torch.sparse.addmm` in the first place. But in the end, its changes followed along with the structural changes I made in addmm. I opted for an extra dispatch here for simplicity.* c10d has some Variable-Tensor confusion in its sparse code. I've worked around it by judiciously inserting ""no variable type"" guards, but a more correct fix would be to just solve the confusion entirely.Benchmark:Apply the following patch to the base commit and this commit:``` diff --git a/aten/src/ATen/native/Const.cpp b/aten/src/ATen/native/Const.cppnew file mode 100644index 0000000000..b66f4d3ece --- /dev/null+++ b/aten/src/ATen/native/Const.cpp@@ -0,0 +1,10 @@+#include <ATen/ATen.h>++namespace at {+namespace native {++Tensor _const5(const Tensor& self, const Tensor& second, const Tensor& third, const Tensor& fourth, const Tensor& fifth) {+  return self;+}++}} // namespace at::native diff --git a/aten/src/ATen/native/native_functions.yaml b/aten/src/ATen/native/native_functions.yamlindex b494ed7950..fddae638bb 100644 --- a/aten/src/ATen/native/native_functions.yaml+++ b/aten/src/ATen/native/native_functions.yaml@@ -5878,3 +5878,9 @@   dispatch:     CPU: im2col_backward_cpu     CUDA: im2col_backward_cuda++# For benchmarking+- func: _const5(Tensor self, Tensor second, Tensor third, Tensor fourth, Tensor fifth) -> Tensor+  variants: function+  dispatch:+    CPU: _const5```Comparisons with timeit:One-argument, representative case:Before:```In [6]: %timeit x.reshape(1, 1)1.46 µs ± 1.38 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)In [7]: %timeit x.reshape(1, 1)1.48 µs ± 29.8 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)In [8]: %timeit x.reshape(1, 1)1.52 µs ± 61.9 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)```After:```In [3]: %timeit x.reshape(1, 1)1.42 µs ± 1.34 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)In [4]: %timeit x.reshape(1, 1)1.43 µs ± 1.01 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)In [5]: %timeit x.reshape(1, 1)1.42 µs ± 0.982 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)```Five-argument, synthetic case (we expect, with enough Tensor arguments, for there to be a slowdown, as we scale `O(n)` with number of arguments, compared to old dispatcher which is `O(1)` with number of arguments):Before:```In [1]: import torchIn [2]: x = torch.zeros(1)In [3]: %timeit torch._const5(x, x, x, x, x)949 ns ± 1.3 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)In [4]: %timeit torch._const5(x, x, x, x, x)954 ns ± 1.96 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)In [5]: %timeit torch._const5(x, x, x, x, x)947 ns ± 0.601 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)```After:```In [3]: %timeit torch._const5(x, x, x, x, x)985 ns ± 9.11 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)In [4]: %timeit torch._const5(x, x, x, x, x)984 ns ± 1.17 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)In [5]: %timeit torch._const5(x, x, x, x, x)988 ns ± 0.555 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)```Signed-off-by: Edward Z. Yang <ezyang@fb.com>Test Plan: Imported from OSSReviewed By: bddppqDifferential Revision: D17481256Pulled By: ezyangfbshipit-source-id: b3206936b4ca8938d45ea90fd71422e0d80b5f96",1,Rename Method,,
0a804be47d0a784e11b04d521d5ba220e304c02d,2020-08-08T01:47:13Z,https://github.com/pytorch/pytorch/commit/0a804be47d0a784e11b04d521d5ba220e304c02d,"[NCCL] DDP communication hook: getFuture() without cudaStreamAddCallback (#42335)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/42335**Main goal:** For DDP communication hook, provide an API called ""get_future"" to retrieve a future associated with the completion of c10d.ProcessGroupNCCL.work. Enable NCCL support for this API in this diff.We add an API `c10::intrusive_ptr<c10::ivalue::Future> getFuture()` to `c10d::ProcessGroup::Work`. This API will only be supported by NCCL in the first version, the default implementation will throw UnsupportedOperation.We no longer consider a design that involves cudaStreamAddCallback which potentially was causing performance regression in [#41596](https://github.com/pytorch/pytorch/pull/41596).ghstack-source-id: 109461507Test Plan:```(pytorch) [sinannasir@devgpu017.ash6 ~/local/pytorch] python test/distributed/test_c10d.pyCouldn't download test skip set, leaving all tests enabled.................................s.....................................................s................................----------------------------------------------------------------------Ran 117 tests in 298.042sOK (skipped=2)```### Facebook Internal:2\. HPC PT trainer run to validate no regression. Check the QPS number:**Master:** QPS after 1000 iters: around ~34100```hpc_dist_trainer --fb-data=none --mtml-fusion-level=1 --target-model=ifr_video --max-ind-range=1000000 --embedding-partition=row-wise mast --domain $USER""testvideo_master"" --trainers 16 --trainer-version 1c53912``````[0] I0806 142048.682 metrics_publishers.py:50] Finished iter 999, Local  window NE: [0.963963 0.950479 0.953704], lifetime NE: [0.963963 0.950479 0.953704], loss: [0.243456 0.235225 0.248375], QPS: 34199```[detailed logs](https://www.internalfb.com/intern/tupperware/details/task/?handle=priv3_global%2Fmast_hpc%2Fhpc.sinannasirtestvideo_mastwarm.trainer.trainer%2F0&ta_tab=logs)**getFuture/new design:** QPS after 1000 iters: around ~34030```hpc_dist_trainer --fb-data=none --mtml-fusion-level=1 --target-model=ifr_video --max-ind-range=1000000 --embedding-partition=row-wise mast --domain $USER""testvideo_getFutureCyclicFix"" --trainers 16 --trainer-version 8553aee``````[0] I0806 160149.197 metrics_publishers.py:50] Finished iter 999, Local  window NE: [0.963959 0.950477 0.953704], lifetime NE: [0.963959 0.950477 0.953704], loss: [0.243456 0.235225 0.248375], QPS: 34018```[detailed logs](https://www.internalfb.com/intern/tupperware/details/task/?handle=priv3_global%2Fmast_hpc%2Fhpc.sinannasirtestvideo_getFutureCyclicFix.trainer.trainer%2F0&ta_tab=logs)**getFuture/new design Run 2:** QPS after 1000 iters: around ~34200```hpc_dist_trainer --fb-data=none --mtml-fusion-level=1 --target-model=ifr_video --max-ind-range=1000000 --embedding-partition=row-wise mast --domain $USER""test2video_getFutureCyclicFix"" --trainers 16 --trainer-version 8553aee``````[0] I0806 160444.650 metrics_publishers.py:50] Finished iter 999, Local  window NE: [0.963963 0.950482 0.953706], lifetime NE: [0.963963 0.950482 0.953706], loss: [0.243456 0.235225 0.248375], QPS: 34201```[detailed logs](https://www.internalfb.com/intern/tupperware/details/task/?handle=priv3_global%2Fmast_hpc%2Fhpc.sinannasirtest2video_getFutureCyclicFix.trainer.trainer%2F0&ta_tab=logs)**getFuture/old design (Regression):** QPS after 1000 iters: around ~31150```hpc_dist_trainer --fb-data=none --mtml-fusion-level=1 --target-model=ifr_video --max-ind-range=1000000 --embedding-partition=row-wise mast --domain $USER”testvideo_OLDgetFutureD22583690 (https://github.com/pytorch/pytorch/commit/d904ea597277673eefbb3661430d3f905e8760d5)"" --trainers 16 --trainer-version 1cb5cbb``````priv3_global/mast_hpc/hpc.sinannasirtestvideo_OLDgetFutureD22583690 (https://github.com/pytorch/pytorch/commit/d904ea597277673eefbb3661430d3f905e8760d5).trainer.trainer/0 [0] I0805 101320.407 metrics_publishers.py:50] Finished iter 999, Local  window NE: [0.963964 0.950482 0.953703], lifetime NE: [0.963964 0.950482 0.953703], loss: [0.243456 0.235225 0.248375], QPS: 31159```3\. `flow-cli` tests; roberta_base; world_size=4:**Master:** f210039922```total:  32 GPUs -- 32 GPUs: p25:  0.908    35/s  p50:  1.002    31/s  p75:  1.035    30/s  p90:  1.051    30/s  p95:  1.063    30/sforward:  32 GPUs -- 32 GPUs: p25:  0.071   452/s  p50:  0.071   449/s  p75:  0.072   446/s  p90:  0.072   445/s  p95:  0.072   444/sbackward:  32 GPUs -- 32 GPUs: p25:  0.821    38/s  p50:  0.915    34/s  p75:  0.948    33/s  p90:  0.964    33/s  p95:  0.976    32/soptimizer:  32 GPUs -- 32 GPUs: p25:  0.016  2037/s  p50:  0.016  2035/s  p75:  0.016  2027/s  p90:  0.016  2019/s  p95:  0.016  2017/s```**getFuture new design:** f210285797```total:  32 GPUs -- 32 GPUs: p25:  0.952    33/s  p50:  1.031    31/s  p75:  1.046    30/s  p90:  1.055    30/s  p95:  1.070    29/sforward:  32 GPUs -- 32 GPUs: p25:  0.071   449/s  p50:  0.072   446/s  p75:  0.072   445/s  p90:  0.072   444/s  p95:  0.072   443/sbackward:  32 GPUs -- 32 GPUs: p25:  0.865    37/s  p50:  0.943    33/s  p75:  0.958    33/s  p90:  0.968    33/s  p95:  0.982    32/soptimizer:  32 GPUs -- 32 GPUs: p25:  0.016  2037/s  p50:  0.016  2033/s  p75:  0.016  2022/s  p90:  0.016  2018/s  p95:  0.016  2017/s```Reviewed By: ezyangDifferential Revision: D22833298fbshipit-source-id: 1bb268d3b00335b42ee235c112f93ebe2f25b208",1,Rename Method,API Refactoring,
0aecbbb7625f8c5809b0a6ce7ca28c622404d8a2,2020-06-10T16:01:02Z,https://github.com/pytorch/pytorch/commit/0aecbbb7625f8c5809b0a6ce7ca28c622404d8a2,"Changes TensorIterator computation to not consider out kwarg, lets UnaryOps safe cast to out (#39655)Summary:**BC breaking note:**In PyTorch 1.5 passing the out= kwarg to some functions, like torch.add, could affect the computation. That is,```out = torch.add(a, b)```could produce a different tensor than```torch.add(a, b, out=out)```This is because previously the out argument participated in the type promotion rules. For greater consistency with NumPy, Python, and C++, in PyTorch 1.6 the out argument no longer participates in type promotion, and has no effect on the computation performed.**ORIGINAL PR NOTE**This PR effectively rewrites Tensor Iterator's ""compute_types"" function to both clarify its behavior and change how our type promotion works to never consider the out argument when determining the iterator's ""common dtype,"" AKA its ""computation type."" That is,```a = op(b, c)```should always produce the same result as```op(b, c, out=a)```This is consistent with NumPy and programming languages like Python and C++.The conceptual model for this change is that a TensorIterator may have a ""common computation type"" that all inputs are cast to and its computation performed in. This common computation type, if it exists, is determined by applying our type promotion rules to the inputs.A common computation type is natural for some classes of functions, like many binary elementwise functions (e.g. add, sub, mul, div...). (NumPy describes these as ""universal functions."") Many functions, however, like indexing operations, don't have a natural common computation type. In the future we'll likely want to support setting the TensorIterator's common computation type explicitly to enable ""floating ufuncs"" like the sin function that promote integer types to the default scalar type. Logic like that is beyond the type promotion system, which can only review inputs.Implementing this change in a readable and maintainable manner was challenging because compute_types() has had many small modifications from many authors over ~2 year period, and the existing logic was in some places outdated and in other places unnecessarily complicated. The existing ""strategies"" approach also painted with a broad brush, and two of them no longer made conceptual sense after this change. As a result, the new version of this function has a small set of flags to control its behavior. This has the positive effect of disentangling checks like all operands having the same device and their having the same dtype.Additional changes in this PR:- Unary operations now support out arguments with different dtypes. Like binary ops they check canCast(computation type, out dtype).- The dtype checking for lerp was outdated and its error message included the wrong variable. It has been fixed.- The check for whether all tensors are on the same device has been separated from other checks. TensorIterators used by copy disable this check.- As a result of this change, the output dtype can be computed if only the input types are available.- The ""fast path"" for checking if a common dtype computation is necessary has been updated and simplified to also handle zero-dim tensors.- A couple helper functions for compute_types() have been inlined to improve readability.- The confusingly named and no longer used promote_gpu_output_dtypes_ has been removed. This variable was intended to support casting fp16 reductions on GPU, but it has become a nullop. That logic is now implemented here: https://github.com/pytorch/pytorch/blob/856215509d89c935cd1768ce4b496d4fc0e919a6/aten/src/ATen/native/ReduceOpsUtils.h#L207.Pull Request resolved: https://github.com/pytorch/pytorch/pull/39655Differential Revision: D21970878Pulled By: mruberryfbshipit-source-id: 5e6354c78240877ab5d6b1f7cfb351bd89049012",1,Rename Method,,
0c40305ddd9e2c1834e923bd76029eb196dc43d2,2017-09-22T14:42:04Z,https://github.com/pytorch/pytorch/commit/0c40305ddd9e2c1834e923bd76029eb196dc43d2,"Rewrite torch.jit interface.torch.jit now contains two user-facing functions: compile and trace(corresponding to what was previously trace/traced and record_trace).The non-curried versions of these functions have been eliminated, sothat there is only one function in the API (we *must* have thecurried versions, since these enable their use as decorators).  There isdetailed usage documentation in the docblocks for these methods.This comes with a complete rewrite of the internals of torch.jit, in the processfixing a number of bugs.  Key points of the new implementation:- compile and trace both always return a Module representing the wrapped  with compilation/tracing underlying function/module.  This makes handling  of the function/module cases more uniform, as we can think of the function  case as creating an on-the-fly module with the parameters explicitly  specified by the user.  For technical reasons, we now *require* any parameters  in the function case to be honest-to-goodness Parameters (gory details:  you can't register a Variable as a Parameter to a Module, but you can't  create a Parameter from a Variable while sharing the same underlying  identity.)- Flattening and unflattening is done a lot more uniformly.  We now have  a _flatten and _unflatten function which are inverses of each other:  _flatten always returns both the flat, tuple of Variables, *as well as*  the ""proto"" (now referred in the code as the ""struct"") from which we  can unflatten the variables.  Low level functions like 'raw_trace'  always work with the flattened inputs/outputs, which keeps their logic  simple.- JIT trace keying now also includes the ""struct"" of the input arguments.  This is a step towards accepting non-Variable arguments in functions,  although flatten/unflatten don't currently support it.- TraceForKey (previously TraceInfo) has had its API reworked to have  less degrees of freedom when you are interacting with it.TODO: Verify, timing, and trace dumping have been temporarily excised.  Iplan on adding them back.Signed-off-by: Edward Z. Yang <ezyang@fb.com>",1,Rename Method,,
0e3a05ec002c997794bd97c34a045b5800112894,2020-05-06T18:27:59Z,https://github.com/pytorch/pytorch/commit/0e3a05ec002c997794bd97c34a045b5800112894,"[JIT] rename enable_profiling_mode to enable_profiling_mode_for_profiling_tests (#37825)Summary:The existing contextmanager only conditionally enabled_profiling_mode, which was counter intuitive. When we changed the default executor it broke internal benchmarking as a result.Pull Request resolved: https://github.com/pytorch/pytorch/pull/37825Differential Revision: D21404611Pulled By: eellisonfbshipit-source-id: 306b3c333ef4eb44ab6a6e5ab4e0682e5ce312ce",1,Rename Method,,
10990734cead19fb8fa6811f3f046b4a3fdf707d,2023-02-02T15:10:14Z,https://github.com/pytorch/pytorch/commit/10990734cead19fb8fa6811f3f046b4a3fdf707d,"[FSDP][2/N] `_summon_full_params` -> `_unshard_params` (#92297)  **Overview** This PR stack will add support for unsharding FSDP's sharded parameters for `fully_shard`. This PR takes the first step by doing some internal refactoring. - The existing API for wrapper FSDP is the static method `summon_full_params()`, which calls into the helper `_summon_full_params()`. - This PR refactors:     - `summon_full_params()` core logic to `_unshard_params()`     - `_summon_full_params()` to `_unshard_params_recurse()`, which has a `recurse: bool` argument     - Previous `_unshard_params()` to `_unshard_fsdp_state_params()`, which applies to a single FSDP state  **Details** - This PR introduces `_get_fsdp_states_with_modules()` and `_get_root_fsdp_states_with_modules()`, which additionally return the modules along with the FSDP states. The modules are needed for handling `FlatParameter` registration.     - We may be able to remove this if we clean up the `use_orig_params=True` vs. `False` code paths because for `True`, the `FlatParameter` is not registered, meaning that it does not need to be de-registered.     - Since `fully_shard` requires `use_orig_params=True`, we may not need `_get_fsdp_states_with_modules()` and `_get_root_fsdp_root_modules()`; however, I prefer to make the separation of FSDP state and module explicit for now for clarity.  **Follow-Ups** - `writeback=True` and `rank0_only=True` raises an error. The previous explanation was: > is not supported, as model parameter shapes will be different across ranks, and writing to them can lead to inconsistencies across ranks when the context is exited.  I am not exactly sure what the different model parameter shapes refers to. However, I believe that we can support `writeback=True` and `rank0_only=True` by broadcasting the `FlatParameter` from rank 0 in the `finally`, writing back, and freeing. This should not increase the peak memory since rank 0 already holds the unsharded `FlatParameter` in GPU memory before writing back and nonzero ranks do not have any other unsharded `FlatParameter`s in GPU memory. Pull Request resolved: https://github.com/pytorch/pytorch/pull/92297 Approved by: https://github.com/rohan-varma",1,Rename Method,,
126d00c8ddcca996a5045f6a6c59cf86c120936c,2020-04-09T15:54:04Z,https://github.com/pytorch/pytorch/commit/126d00c8ddcca996a5045f6a6c59cf86c120936c,"[pytorch] move force schema registration output into a separate file (#36284)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/36284ATen/gen.py's `force_schema_registration` flag was added in #34622 to unblock c10 boxing for custom build,as full-JIT frontend expects certain op schemas are always registered (the actual op implementation can beskipped if it's not used).The flag didn't work together with `per_op_registration` flag, which was added for FB BUCK selective build.This PR made it work with `per_op_registration` flag, by moving schema registrations to a separate file.This way, internal full-JIT can include the new source file while lite-JIT can ignore it. OSS custom buildshould still work as before.Updated table of codegen flags and 5 build configurations that are related to mobile:```+--------------------------------------+-----------------------------------------------------------------------------+--------------------------------------------+|                                      |                              Open Source                                    |                  FB BUCK                   |+--------------------------------------+---------------------+---------------------------+---------------------------+---------------+----------------------------+|                                      |    Default Build    | Custom Build w/ Stat-Disp | Custom Build w/ Dyna-Disp |   Full-JIT    |         Lite-JIT           |+--------------------------------------+---------------------+---------------------------+---------------------------+---------------+----------------------------+| Dispatch Type                        | Static              | Static                    | Dynamic                   | Dynamic       | Dynamic                    |+--------------------------------------+---------------------+---------------------------+---------------------------+---------------+----------------------------+| ATen/gen.py                          |                     |                           |                           |               |                            |+--------------------------------------+---------------------+---------------------------+---------------------------+---------------+----------------------------+| --op_registration_whitelist          | unset               | used root ops             | closure(used root ops)    | unset         | closure(possibly used ops) || --backend_whitelist                  | CPU Q-CPU           | CPU Q-CPU                 | CPU Q-CPU                 | CPU Q-CPU     | CPU Q-CPU                  || --per_op_registration                | false               | false                     | false                     | true          | true                       || --force_schema_registration          | false               | true                      | true                      | true          | true (output unused)       |+--------------------------------------+---------------------+---------------------------+---------------------------+---------------+----------------------------+| tools/setup_helpers/generate_code.py |                     |                           |                           |               |                            |+--------------------------------------+---------------------+---------------------------+---------------------------+---------------+----------------------------+| --disable-autograd                   | true                | true                      | true                      | false         | WIP                        || --selected-op-list-path              | file(used root ops) | file(used root ops)       | file(used root ops)       | unset         | unset                      || --selected-op-list (WIP)             | unset               | unset                     | unset                     | unset         | used root ops              || --force_schema_registration (WIP)    | false               | true                      | true                      | true          | false                      |+--------------------------------------+---------------------+---------------------------+---------------------------+---------------+----------------------------+```ghstack-source-id: 101840182Test Plan:- check OSS CI;- patch D20577433 on top of this change to make sure test passes on it;- check mobile build size bot;Differential Revision: D20932484fbshipit-source-id: 5028a6f90f2c7ee66fc70c562643b536a32b4d33",1,Rename Method,API Refactoring,
1ad61a18b27d33315cde64cf2d072329b519a99e,2018-09-06T18:40:09Z,https://github.com/pytorch/pytorch/commit/1ad61a18b27d33315cde64cf2d072329b519a99e,Rename cuda tests to have 'cuda' in their names (#11332)Summary:Not a lot changedPull Request resolved: https://github.com/pytorch/pytorch/pull/11332Differential Revision: D9683680Pulled By: zou3519fbshipit-source-id: 95f444e54049dd268fc10effe425ef2df79c6467,1,Rename Method,,
1eaaf8b68bd0c3490f1be37c6f8c89ab315e83e2,2019-09-24T00:22:20Z,https://github.com/pytorch/pytorch/commit/1eaaf8b68bd0c3490f1be37c6f8c89ab315e83e2,"A few hub improvements (#25980)Summary:This PR does a few small improvements to hub:- add support `verbose` option in `torch.load`. Note that this mutes hitting cache message but keeps the message of first download as suggested. fixes https://github.com/pytorch/pytorch/issues/24791- add support loading state dict from tar file or zip file in `torch.hub.load_state_dict_from_url`.- add `torch.hub.download_url_to_file` as public API, and add BC bit for `_download_url_to_file`.- makes hash check in filename optional through `check_hash`, many users don't have control over the naming, relaxing this constraint could potentially avoid duplicating download code on user end.- move pytorch CI off `pytorch/vision` and use `ailzhang/torchhub_example` as a dedicated test repo. fixes https://github.com/pytorch/pytorch/issues/25865Pull Request resolved: https://github.com/pytorch/pytorch/pull/25980Differential Revision: D17495679Pulled By: ailzhangfbshipit-source-id: 695df3e803ad5f9ca33cfbcf62f1a4f8cde0dbbe",1,Rename Method,Extract Method,
209c6f9ab57f7c6b3d79ac69a23b2b38bfcfcf63,2020-05-05T01:42:28Z,https://github.com/pytorch/pytorch/commit/209c6f9ab57f7c6b3d79ac69a23b2b38bfcfcf63,"Move device type init from BackendSelect to backend kernels (#37402)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/37402Previously, BackendSelect kernels did just-in-time device typeinitialization by calling `LegacyTypeDispatch.initForDispatchKey()`with a computed dispatch key. Here we move the initialization tothe backend kernels themselves, where we can call the device-specific initializer directly.Putting this up to run tests on it, but a couple questions remain:* why were only BackendSelect kernels doing this initialization?  Not all factory ops appear there, nor are all the ops that do  appear there factory ops. Currently we generate init code for  exactly the BackendSelect ops, but the choice should be better  motivated.* the previous scheme maps HIP to its own legacy type dispatch  entry, but the logic assumes it's exclusive with CUDA, and no  ops appear to mention HIP explicitly, so the new logic doesn't  expose a static entry point for it. Needs to be verified.Test Plan: Imported from OSSDifferential Revision: D21282974Pulled By: bhosmerfbshipit-source-id: cd46eb788596948e0572a15fac0f8b43feca5d75",1,Rename Method,,
24af02154c1a599e2d785ed667c8c2968e230e87,2016-12-29T01:34:23Z,https://github.com/pytorch/pytorch/commit/24af02154c1a599e2d785ed667c8c2968e230e87,"Use ForkingPickler for sharing tensor/storages across processes (#344)This hooks into the (internal) ForkingPickler class in multiprocessingto reduce tensors, storages, and CUDA events instead of our queue fromjoblib. This makes it easier to use the standard multiprocessing classesin later versions of Python.This also exposes: - Tensor/Storage.share_memory_() - Module.share_memory()These methods move the CPU tensors and storages to shared memory. Ifyou're using the ""fork"" method of multiprocessing, these objects can bedirectly inherited instead of serialized through a queue.",1,Rename Method,API Refactoring,
277d442d18887aa541eb24addf5fe5747d91e613,2019-09-18T12:44:43Z,https://github.com/pytorch/pytorch/commit/277d442d18887aa541eb24addf5fe5747d91e613,"Rename torch.namedtensor -> torch._namedtensor_internals (#26349)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/26349The directory holds a lot of private helper functions that helpimplement named tensor functionality. Instead of naming each helperfunction with a leading underscore, I change the name of the import to`_namedtensor_internals` to signal it should not be used directly.Test Plan: - [namedtensor ci]Differential Revision: D17424178Pulled By: zou3519fbshipit-source-id: 8f7b74346765759303480e581038a661021acf53",1,Rename Method,,
281737ea6fc3f5d8a5980420d832855a6826935b,2021-08-04T21:37:23Z,https://github.com/pytorch/pytorch/commit/281737ea6fc3f5d8a5980420d832855a6826935b,"[DDP Communication Hook] Rename 4 Methods of GradBucket Class  Summary: 1. getPerParameterTensors -> getGradients 2. getModelParamsForBucket -> getParameters 3. isTheLastBucketToAllreduce -> IsLast  Test Plan: Test results for ""buck test mode/dev-nosan caffe2/test/distributed:c10d"": https://pxl.cl/1Mrq8  Test results for ""buck test mode/dev-nosan caffe2/test/distributed:distributed_nccl_fork"": https://pxl.cl/1MrtP  Reviewed By: SciPioneer  Differential Revision: D30076436  fbshipit-source-id: 0bd1e410186a318ea6328f4c1e830ea5632f8a47",1,Rename Method,,
29c8b1db572856e87f12bd7b6beb2ad13438d19f,2021-08-02T16:33:32Z,https://github.com/pytorch/pytorch/commit/29c8b1db572856e87f12bd7b6beb2ad13438d19f,"[DDP Communication Hook] Rename 4 Methods of GradBucket Class (#62510)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/62510  `GradBucket` is an important class defined in both C++ and Python, used for PyTorch Distributed Training. We need to rename the following methods for simplicity: 1) get_index -> index 2) is_the_last_bucket_to_allreduce -> is_last, 3) get_per_parameter_tensors -> gradients, 4) get_model_params_for_bucket -> parameters.  Test Plan: Local run comprehensive test with following results: https://pxl.cl/1Ml8b For two timeout failure test cases, most likely environment related and fail in my devserver.  Reviewed By: SciPioneer  Differential Revision: D30024161  fbshipit-source-id: 07e6072a2f7b81f731425d9b71f8c8b60d383b0f",1,Rename Method,,
2ca787fcf40d65065a2cf036d238f748ec18d227,2017-03-15T20:26:02Z,https://github.com/pytorch/pytorch/commit/2ca787fcf40d65065a2cf036d238f748ec18d227,Refactor attribute names in autograd,1,Rename Method,,
2fcdb3a1f33787c0f2433677139a33784d393be6,2019-08-14T16:31:54Z,https://github.com/pytorch/pytorch/commit/2fcdb3a1f33787c0f2433677139a33784d393be6,"Rename set_names -> view_names, set_names_ -> names_ (#23962)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/23962This change should make the semantics clearer.`tensor.names_(names)` sets tensor.names to be `names`.`tensor.view_names(names)` returns a view of the tensor with names`names`.Test Plan- [namedtensor ci]Test Plan: Imported from OSSDifferential Revision: D16710915Pulled By: zou3519fbshipit-source-id: c82fa9812624d03c86f7be84b0a460e3c047aaa0",1,Rename Method,,
308a58ebcaa703fa2fc4d543ac531283df2e51a8,2023-03-16T00:31:29Z,https://github.com/pytorch/pytorch/commit/308a58ebcaa703fa2fc4d543ac531283df2e51a8,[FSDP]  Rename to _get_orig_buffer_dtypes (#96790)  Reland this PR  Differential Revision: [D44078430](https://our.internmc.facebook.com/intern/diff/D44078430/) Pull Request resolved: https://github.com/pytorch/pytorch/pull/96790 Approved by: https://github.com/awgu,1,Rename Method,,
3b7e1cd2cc3c8345228bdaca3c09ad7d58cc8bdf,2020-03-18T21:57:20Z,https://github.com/pytorch/pytorch/commit/3b7e1cd2cc3c8345228bdaca3c09ad7d58cc8bdf,"Makes floor_divide a method, adds sparse floor division (#34552)Summary:(Updated per review feedback)`torch.floor_divide` is currently a function that can operate on two tensors or a tensor and a scalar (scalar x scalar floor division is handled natively by Python and the JIT has a builtin function for it). This PR updates it to:- have an out variant: `floor_divide(x, y, out=z)`- be a method on a tensor: `x.floor_divide(y)`- have an in-place variant: `x.floor_divide_(y)`- work with sparse tensorsTests are added to test_sparse.py and test_torch.py for these new behaviors.In addition, this PR:- cleans up the existing sparse division and true_division code and improves their error message- adds testing of sparse true_division to test_sparse.py- extends existing floor_divide testing in test_torch to run on CUDA, too, not just the CPUUnfortunately, making floor_divide a method requires breaking backwards compatibility, and floor_divide has been added to the BC whitelist since this is international. The BC issue is that the first parameter name to torch.floor_divide is changing from input to self. If you previously called torch.floor_divide with keyword arguments, e.g. torch.floor_divide(input=x, other=y), you will need to update to torch.floor_divide(self=x, other=y), or the more common torch.floor_divide(x, y).The intent of this PR is to allow floor_divide to be substituted for division (torch.div, /) wherever division was previously used. In 1.6 we expect torch.div to perform true_division, and floor_divide is how users can continue to perform integer division with tensors.There are two potential follow-up issues suggested by this PR:- the test framework might benefit from additional tensor construction classes, like one to create dividends and divisors for multiple dtypes- the test framework might benefit from a universal function test class. while methods have reasonable coverage as part of test_torch.py's TestTensorOp tests, function coverage is spotty. Universal functions are similar enough it should be possible to generate tests for them.Pull Request resolved: https://github.com/pytorch/pytorch/pull/34552Differential Revision: D20509850Pulled By: mruberryfbshipit-source-id: 2cd3c828aad67191c77f2ed8470411e246f604f8",1,Rename Method,,
3f72bcfcaacadfbbfb40e1cc32fc15fdec26bca5,2019-09-24T17:53:02Z,https://github.com/pytorch/pytorch/commit/3f72bcfcaacadfbbfb40e1cc32fc15fdec26bca5,Remove _dequantize_per_tensor (#26681)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/26681attTest Plan:ciImported from OSSDifferential Revision: D17542833fbshipit-source-id: 653e906b0e146763609c69ef0de7f9cf38621586,1,Rename Method,,
4011685a8bd0c8a5467300bc446631db5b8188b5,2020-08-14T23:43:55Z,https://github.com/pytorch/pytorch/commit/4011685a8bd0c8a5467300bc446631db5b8188b5,"[fx] split Node into Node/Proxy (#42991)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/42991Have Node both be a record of the operator in the graph, and theway we _build_ the graph made it difficult to keep the IR datastructureseparate from the proxying logic in the build.Among other issues this means that typos when using nodes would addthings to the graph:```    for node in graph.nodes:        node.grph # does not error, returns an node.Attribute object!```This separates the builder into a Proxy object. Graph/Node no longerneed to understand `delegate` objects since they are now just pure IR.This separates the `symbolic_trace` (proxy.py/symbolic_trace.py) fromthe IR (node.py, graph.py).This also allows us to add `create_arg` to the delegate object,allowing the customization of how aggregate arguments are handledwhen converting to a graph.Test Plan: Imported from OSSReviewed By: jamesr66aDifferential Revision: D23099786Pulled By: zdevitofbshipit-source-id: 6f207a8c237e5eb2f326b63b0d702c3ebcb254e4",1,Rename Method,,
411cf434afe9c594dfb2a383d5c3475ee0726a28,2019-02-26T00:11:47Z,https://github.com/pytorch/pytorch/commit/411cf434afe9c594dfb2a383d5c3475ee0726a28,Batch of expect file removals Remove dce expect files (#17471)Summary:Batch of removing expect test filesPull Request resolved: https://github.com/pytorch/pytorch/pull/17471Differential Revision: D14217265Pulled By: eellisonfbshipit-source-id: 425da022115b7e83aca86ef61d4d41fd046d439e,1,Rename Method,,
41e7e1bc40ba8bb50b84afc3addf514549d23336,2018-12-19T20:11:49Z,https://github.com/pytorch/pytorch/commit/41e7e1bc40ba8bb50b84afc3addf514549d23336,"Rename potrs to cholesky_solve (#15334)Summary:Changelog:- Renames `potrs` to `cholesky_solve` to remain consistent with Tensorflow and Scipy (not really, they call their function chol_solve)- Default argument for upper in cholesky_solve is False. This will allow a seamless interface between `cholesky` and `cholesky_solve`, since the `upper` argument in both function are the same.- Rename all tests- Create a tentative alias for `cholesky_solve` under the name `potrs`, and add deprecated warning to not promote usage.Pull Request resolved: https://github.com/pytorch/pytorch/pull/15334Differential Revision: D13507724Pulled By: soumithfbshipit-source-id: b826996541e49d2e2bcd061b72a38c39450c76d0",1,Rename Method,,
421b508d55caa39a983be29e2e6ce79b91f9405e,2019-03-18T23:01:02Z,https://github.com/pytorch/pytorch/commit/421b508d55caa39a983be29e2e6ce79b91f9405e,"Rename gesv to solve (#18060)Summary:Changelog:- Renames `gesv` to `solve` to remain consistent with `cholesky_solve`.- Rename all tests, fix callsites- Create a tentative alias for `solve` under the name `gesv`, and add a deprecated warning to not promote usage.Pull Request resolved: https://github.com/pytorch/pytorch/pull/18060Differential Revision: D14503117Pulled By: zou3519fbshipit-source-id: 99c16d94e5970a19d7584b5915f051c030d49ff5",1,Rename Method,,
4584851da5cad7f2e5f9fd5ed2245f3a06f8359e,2023-04-10T21:25:19Z,https://github.com/pytorch/pytorch/commit/4584851da5cad7f2e5f9fd5ed2245f3a06f8359e,[core][pruning][be] rename BaseSparsifier to BasePruner (#98747)  Summary:  att  Test Plan: `python test/test_ao_sparsity.py -- TestBasePruner` Pull Request resolved: https://github.com/pytorch/pytorch/pull/98747 Approved by: https://github.com/jerryzh168,1,Rename Method,,
45d5b6be48caae761970d6d4c99e4ed8bc82263e,2019-04-19T00:03:56Z,https://github.com/pytorch/pytorch/commit/45d5b6be48caae761970d6d4c99e4ed8bc82263e,"Enhance front-end to add op (#19433)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/19433For operator benchmark project, we need to cover a lot of operators, so the interface for adding operators needs to be very clean and simple. This diff is implementing a new interface to add op.Here is the logic to add new operator to the benchmark:```long_config = {}short_config = {}map_funcadd_test(  [long_config, short_config],  map_func,  [caffe2 op]  [pt op])```Reviewed By: zheng-xqDifferential Revision: D14791191fbshipit-source-id: ac6738507cf1b9d6013dc8e546a2022a9b177f05",1,Rename Method,Inline Method,
48a571b29c3e74fc443e50c2ece7e24b177faa98,2019-10-08T18:22:18Z,https://github.com/pytorch/pytorch/commit/48a571b29c3e74fc443e50c2ece7e24b177faa98,"Rename variables and add comments (#27286)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/27286The name `runUDFFunction` stutters because the F in UDF also standsfor function. Renamed these variables to be identical to their Pythonequivalents. Renamed those to share a prefix and drop `internal`,because internal functions can use an underscore prefix.Test Plan: Imported from OSSDifferential Revision: D17808208Pulled By: pieternfbshipit-source-id: 7619f07fc8215203dfb1da1eb281845edcd2bb99",1,Rename Method,Rename Variable,
4a85e7955c41704c4e2925429b96d93a0024a46b,2019-05-22T02:49:29Z,https://github.com/pytorch/pytorch/commit/4a85e7955c41704c4e2925429b96d93a0024a46b,Rename FC to Linear in the test routine (#20716)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/20716As Title says.Reviewed By: zafartahirovDifferential Revision: D15410823fbshipit-source-id: e82fc241ee288b41304675cb087c0cdcd60d7148,1,Rename Method,,
4fada962184038ef626c4709cb9e42279c7e8be0,2019-09-22T22:36:47Z,https://github.com/pytorch/pytorch/commit/4fada962184038ef626c4709cb9e42279c7e8be0,"Renames `tensor.renamed -> rename`, `tensor.names_ -> rename_` (#26548)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/26548This makes the naming more consistent with PyTorch's API. The originalconcern was that `tensor.rename` might make the operation seem like itis in-place. However, we have many ""verb"" APIs: `tensor.add(other)`, forexample, doesn't add other to tensor in-place, but `tensor.add_(other)`does.`tensor.rename_` does exactly the same place as `tensor.rename`, butin-place.Test Plan: - [namedtensor ci]Differential Revision: D17502021Pulled By: zou3519fbshipit-source-id: 6a5b93136a820075013cd1e30fb8fc6b9d77d7d9",1,Rename Method,,
50149fb66b78ef83a0a83d9b106ebcccce54a78f,2019-05-10T19:49:10Z,https://github.com/pytorch/pytorch/commit/50149fb66b78ef83a0a83d9b106ebcccce54a78f,Adds quantized addition and renames sum to add (#20233)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/20233Adding a quantized addition (without relu)Reviewed By: jianyuhDifferential Revision: D15245791fbshipit-source-id: 34ede5d805d9ab0d31e8ae87cefb110504bd3c87,1,Rename Method,,
52de407b4b675d71174d24dd653f55b29d9c756f,2021-02-03T14:51:44Z,https://github.com/pytorch/pytorch/commit/52de407b4b675d71174d24dd653f55b29d9c756f,[DataLoader] Rename Functional DataSet to DataPipe (#51488)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/51488Test Plan: Imported from OSSReviewed By: H-HuangDifferential Revision: D26209888Pulled By: ejguanfbshipit-source-id: cb8bc852b1e4d72be81e0297308a43954cd95332,1,Rename Method,,
57cec0a72087d57240f306b592cb89210d33c577,2019-07-18T16:56:26Z,https://github.com/pytorch/pytorch/commit/57cec0a72087d57240f306b592cb89210d33c577,Named inference rules for split/chunkSummary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/22971Test Plan: Imported from OSSDifferential Revision: D16342783Pulled By: zou3519fbshipit-source-id: 379edc8eb2f45a82ee8a6320f8285f8f81ea0b1b,1,Rename Method,,
63297e1a1f632f920a980bcaeb04e455fe54d404,2017-10-26T04:49:35Z,https://github.com/pytorch/pytorch/commit/63297e1a1f632f920a980bcaeb04e455fe54d404,"RunNetOnce->RunNet (removes rnn_executor overhead)Summary:seq2seq/translate.py was running much slower on RNNExecutor. This was because RNNExecutor has significant init overhead (I have another diff to reduce, but not completely eliminate it), and translate was calling the decoder with RunNetOnce -- thus always recreating the net and the ops. Changhing this to RunNet() makes translate run faster than without executor. RunNet uses the net name and uses the already created net, while RunNetOnce passes the whole protobuffer.Noticed similar bug in seq2seq ensemble bean model, which also calls CreateNet() but uses RunNetOnce() instead of RunNet().Reviewed By: jhcrossDifferential Revision: D6156566fbshipit-source-id: a933453e36a0d8fd163d0584186fda427a680687",1,Rename Method,,
639133d6d17722284562dc3d371bebc4c34da329,2019-11-18T14:05:14Z,https://github.com/pytorch/pytorch/commit/639133d6d17722284562dc3d371bebc4c34da329,"rename init_model_parallel to init_rpc (#29762)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/29762Rename this API as discussed, since it's use cases extend beyond onlymodel parallelism.ghstack-source-id: 94020627Test Plan: Unit tests passDifferential Revision: D18491743fbshipit-source-id: d07676bb14f072c64da0ce99ee818bcc582efc57",1,Rename Method,,
63bb7c6dbab5644c6f95ccfb66de00db40fa6340,2021-09-28T01:56:04Z,https://github.com/pytorch/pytorch/commit/63bb7c6dbab5644c6f95ccfb66de00db40fa6340,"Refactor AotCompile to return a pair (#65707)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/65707  Refactoring aotCompile to return a pair of compiled function and the LLVM assembly instead of updating an incoming string with assembly code  Testing: Gives expected results when compiled and run ``` (pytorch)  ~/local/pytorch refactor_aot └─ $ build/bin/aot_model_compiler --model mobilenetv3.pt --model_name=pytorch_dev_mobilenetv3 --model_version=v1 --input_dims=""2,2,2"" The compiled model was saved to mobilenetv3.compiled.pt ```  Test Plan: Imported from OSS  Reviewed By: qihqi  Differential Revision: D31220452  Pulled By: priyaramani  fbshipit-source-id: f957c53ba83f876a2e7dbdd4b4571a760b3b6a9a",1,Rename Method,,
63e66fd26714c767be87bcd5f3cebda2bc567bdf,2019-11-20T09:11:11Z,https://github.com/pytorch/pytorch/commit/63e66fd26714c767be87bcd5f3cebda2bc567bdf,"Split ConcreteModuleType into two types (#29824)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/29824We have two distinct phases/uses for ConcreteModuleType:1. We are building it up and using it to check whether we canreuse JIT types. (RawConcreteModuleType)2. We are using it to satisfy ModuleValue::attr queries.(ConcreteModuleType)These types share an underlying `ConcreteModuleTypeData` whichactually stores the relevant info.Previously they were the same type because I was lazy, but it's been thesource of a bug. So split them to formalize the differing invariants forthe two phases.Test Plan: Imported from OSSDifferential Revision: D18575010Pulled By: suofbshipit-source-id: 3e4ebcd36e78b947150d8f0dbb74ecccad23e7c4",1,Rename Method,,
67a9948d87d858a06ea22c88aba14407d5c73e7e,2018-05-04T21:00:09Z,https://github.com/pytorch/pytorch/commit/67a9948d87d858a06ea22c88aba14407d5c73e7e,Refactor rnn export (#7263)* rnn refactor: extract rnn weights and biases* rnn refactor: make rnn with converted outputs* rnn refactor: finish it off,1,Rename Method,Extract Method,
6a266f5832dca59871ee719dbb21445a748eee97,2018-01-03T16:14:27Z,https://github.com/pytorch/pytorch/commit/6a266f5832dca59871ee719dbb21445a748eee97,s/uses_grad/uses_single_grad/ for more clarity.Signed-off-by: Edward Z. Yang <ezyang@fb.com>,1,Rename Method,,
6a3170dba1b621308f80ef2bfcee181ebc20029d,2021-07-09T08:28:24Z,https://github.com/pytorch/pytorch/commit/6a3170dba1b621308f80ef2bfcee181ebc20029d,"[package] minor cleanups to internal APIs (#61428)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/61428  I was reading this code again after a while and didn't understand as quickly as I would have liked. Some of the function names are no longer accurate, etc.  This PR renames these functions to be in the same language of ""dependencies"" that the rest of the API uses. I think the resulting usage of the APIs is more clear than before  Test Plan: Imported from OSS  Reviewed By: Chillee  Differential Revision: D29620946  Pulled By: suo  fbshipit-source-id: 7df640a7ffbd43998063b9ee3955c9dfcbc42cfb",1,Rename Method,,
71741ba1159cbaabc79d9853d5dae0ce4a5b15a2,2019-06-21T04:52:38Z,https://github.com/pytorch/pytorch/commit/71741ba1159cbaabc79d9853d5dae0ce4a5b15a2,rename test to be more consistentSummary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/22057Differential Revision: D15936870Pulled By: soumithfbshipit-source-id: ab6194219da2582efdf324b89b2bc87dfe4e5d69,1,Rename Method,,
7aaad0b8325b83cf1bb551db271a1cb370b9b88c,2023-01-17T13:36:41Z,https://github.com/pytorch/pytorch/commit/7aaad0b8325b83cf1bb551db271a1cb370b9b88c,"Rename flag that enables/disables _SingleLevelFunction for functorch (#92025)  functorch used to have a switch that enables/disables autograd.Function. That switch now enables/disables torch.autograd.function._SingleLevelFunction, so I've renamed it accordingly.  We could just delete the switch because users should not be directly working with torch.autograd.function._SingleLevelFunction. However, it was useful for debugging when something went wrong when I was implementing the autograd.Function <> functorch interaction, so I want to keep it around as a debugging tool for a while since the code is already there.  Test Plan: - updated tests Pull Request resolved: https://github.com/pytorch/pytorch/pull/92025 Approved by: https://github.com/soulitzer",1,Rename Method,,
7f997aa39313c1e0e170d034ac2240f45355f42d,2023-05-04T02:44:22Z,https://github.com/pytorch/pytorch/commit/7f997aa39313c1e0e170d034ac2240f45355f42d,"[codemod] Replace hasattr with getattr in caffe2/test/distributed/fsdp/test_fsdp_optim_state.py (#100360)  Summary: The pattern ``` X.Y if hasattr(X, ""Y"") else Z ``` can be replaced with ``` getattr(X, ""Y"", Z) ```  The [getattr](https://www.w3schools.com/python/ref_func_getattr.asp) function gives more succinct code than the [hasattr](https://www.w3schools.com/python/ref_func_hasattr.asp) function. Please use it when appropriate.  **This diff is very low risk. Green tests indicate that you can safely Accept & Ship.**  Test Plan: Sandcastle  Differential Revision: D44886500  Pull Request resolved: https://github.com/pytorch/pytorch/pull/100360 Approved by: https://github.com/rohan-varma, https://github.com/Skylion007, https://github.com/awgu",1,Rename Method,,
80f59cc61acafbffacb536e1f2bbf743f8f686da,2023-06-02T14:29:04Z,https://github.com/pytorch/pytorch/commit/80f59cc61acafbffacb536e1f2bbf743f8f686da,"Change some py_context_manager_DEPRECATED to py_context_manager (#102643)  I confirmed that there are no usages of these APIs on github code search or internally. There may still be usages (hence the BC-breaking label), but I expect none to very few.  There are some leftover py_context_manager_DEPRECATED that will likely stay that way for a while because: - they are used outside of the pytorch repo (`_AutoDispatchBelowAutograd`, `_DisableTorchDispatch`, `_InferenceMode`) - they are high risk (all of the torch_function / torch_dispatch related stuff) - PyTorch requires that the object behaves like a ""Python RAII guard"" (`_DisableFuncTorch`, `_MultithreadingEnabled`)  This is probably the last PR in the context manager cleanup series.  Test Plan: - existing tests  Pull Request resolved: https://github.com/pytorch/pytorch/pull/102643 Approved by: https://github.com/bdhirsh",1,Rename Method,,
828c08b4c7b20bb3250a5c3c27548250e5f36a62,2019-07-26T19:12:41Z,https://github.com/pytorch/pytorch/commit/828c08b4c7b20bb3250a5c3c27548250e5f36a62,allow passing a list of operators to benchmark (#23442)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/23442Replace the argument name from `operator` to `operators` which can take a list of operators to test.Reviewed By: hl475Differential Revision: D16520779fbshipit-source-id: 94284a87c64471793e319f5bd3143f89b9a192bb,1,Rename Method,,
83513506c3531093746302145c74dd14d10d2541,2019-11-19T14:39:52Z,https://github.com/pytorch/pytorch/commit/83513506c3531093746302145c74dd14d10d2541,"poll for timed out futures in process group agent (#29601)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/29601Follow up from https://github.com/pytorch/pytorch/pull/28392. Adds a background thread to `ProcessGroupAgent` that polls for timed out RPCs at a pre-set interval, and marks them as completed with a timeout exception if they have timed out. Also deletes the futures from the corresponding maps `futures_` and `futureTimeouts`. Unit tests are added to ensure that timed out RPCs are appropriately cleaned up.Also adds a `shutdown` variable to process group agent to control the shutting down of this background thread, which can eventually be extended to use for controlling a clean shutdown of process group agent.ghstack-source-id: 94175131Test Plan: Added unit testsDifferential Revision: D18434215fbshipit-source-id: c48abdb8759fe1447200ec66bb9d4b1c50ec4535",1,Rename Method,,
85a90d9181bb16d29360abd246985eaec8ee8123,2023-04-08T04:44:55Z,https://github.com/pytorch/pytorch/commit/85a90d9181bb16d29360abd246985eaec8ee8123,"Rename assert options, turn off by default (#98616)  Rename the runtime assert checking options to be more clear. Also turn off the slow path checking, since it is slow enough to significantly affect our compilation time speed in dashboard.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/98616 Approved by: https://github.com/davidberard98, https://github.com/Neilblaze",1,Rename Method,,
89956374c3a377723a0288a7973f22aeafdfaba7,2019-08-02T17:04:17Z,https://github.com/pytorch/pytorch/commit/89956374c3a377723a0288a7973f22aeafdfaba7,Remove qconfig_dict from API (#23465)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/23465We decided not to allow user to use qconfig_dict to do quantizationsince that API is not robust.Differential Revision: D16611504fbshipit-source-id: b0d1d311b32c990a165c480f50e9ce3d68b785b5,1,Rename Method,Rename Class,
8bec7cfa910086f9d659a1f6ecfe52c75b8d487f,2020-09-11T21:48:45Z,https://github.com/pytorch/pytorch/commit/8bec7cfa910086f9d659a1f6ecfe52c75b8d487f,[rpc] rename some functions (#43042)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/43042Test Plan: Imported from OSSReviewed By: mrshenliDifferential Revision: D23228894Pulled By: wanchaolfbshipit-source-id: 3702b7826ecb455073fabb9dc5dca804c0e092b2,1,Rename Method,,
8c2d35c75442859421d0c130979aaf05d3a2d2d4,2018-01-17T10:58:08Z,https://github.com/pytorch/pytorch/commit/8c2d35c75442859421d0c130979aaf05d3a2d2d4,Refactor distributions (#4688),1,Rename Method,API Refactoring,
8d5c899b195c15faefd3a17e6da376ed59da96b4,2020-10-13T15:24:07Z,https://github.com/pytorch/pytorch/commit/8d5c899b195c15faefd3a17e6da376ed59da96b4,"Rename legacy_dispatcher to native. (#45974)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/45974The term ""legacy dispatcher"" caused a bunch of confusion betweenme and Sebastian when discussing what the intended semantics oflegacy dispatcher argument is.  Legacy dispatcher argument impliesthat you ought NOT to use it when you have use_c10_dispatcher: full;but that's not really what's going on; legacy dispatcher API describesthe API that you write native:: functions (NativeFunctions.h) to.Renaming it here makes this more clear.I applied these seds:```git grep -l 'legacy_dispatcher' | xargs sed -i 's/legacy_dispatcher/native/g'git grep -l 'legacydispatcher' | xargs sed -i 's/legacydispatcher/native/g'git grep -l 'LegacyDispatcher' | xargs sed -i 's/LegacyDispatcher/Native/g'```and also grepped for ""legacy"" in tools/codegen and fixed documentation.Signed-off-by: Edward Z. Yang <ezyang@fb.com>Test Plan: Imported from OSSReviewed By: smessmerDifferential Revision: D24223101Pulled By: ezyangfbshipit-source-id: d1913b8b823b3b95e4546881bc0e876acfa881eb",1,Rename Method,Rename Class,
8d60e39fdca925525e105e2e48e1907d584b1d87,2016-12-30T18:03:34Z,https://github.com/pytorch/pytorch/commit/8d60e39fdca925525e105e2e48e1907d584b1d87,Rename torch.nn.functions to torch.nn._functions,1,Rename Method,,
90586d925f119e59eecfaef8f139dd68e7924296,2018-04-23T17:39:37Z,https://github.com/pytorch/pytorch/commit/90586d925f119e59eecfaef8f139dd68e7924296,[DT] [38/n] Rename add_stop_signal to add_stop_condition (#6825)att,1,Rename Method,,
91ea2cd5a76172bf25b51b19fbd2191544ef3e45,2019-06-10T18:10:11Z,https://github.com/pytorch/pytorch/commit/91ea2cd5a76172bf25b51b19fbd2191544ef3e45,"clip sigmoid to prevent transforms return inf/nan values (#20288)Summary:This PR addresses some numerical issues of Sigmoid/StickBreakingTransform, where these transforms give +-inf when the unconstrained values move to +-20 areas.For example, with```t = torch.distributions.SigmoidTransform()x = torch.tensor(20.)t.inv(t(x)), t.log_abs_det_jacobian(x, t(x))```current behaviour the inverse will return `inf` and logdet return `-inf` while this PR makes it to `15.9424` and `-15.9424`.And for```t = torch.distributions.StickBreakingTransform()x = torch.tensor([20., 20.])t.inv(t(x)), t.log_abs_det_jacobian(x, t(x))```current value is `(inf, nan)` and `-inf` for logdet, while this PR makes it `[16.6355, 71.3942]` and `-47.8272` for logdet.Although these finite values are wrong and seems unavoidable, it is better than returning `inf` or `nan` in my opinion. This is useful in HMC where despite that the grad will be zero when the unconstrained parameter moves to unstable area (due to clipping), velocity variable will force the parameter move to another area which by chance can move the parameter out of unstable area. But inf/nan can be useful to stop doing inference early. So the changes in this PR might be inappropriate.I also fix some small issues of `_Simplex` and `_RealVector` constraints where batch shape of the input is not respected when checking validation.Pull Request resolved: https://github.com/pytorch/pytorch/pull/20288Differential Revision: D15742047Pulled By: ezyangfbshipit-source-id: b427ed1752c41327abb3957f98d4b289307a7d17",1,Rename Method,,
9f2111af73fd51dd0f21c4045cf4e862cf5c53c9,2017-01-02T00:24:02Z,https://github.com/pytorch/pytorch/commit/9f2111af73fd51dd0f21c4045cf4e862cf5c53c9,Rename Variable.no_grad to Variable.detach,1,Rename Method,Rename Variable,
a5872a16a0e4577caa296d9ecc97323cee59ccee,2019-08-14T19:01:12Z,https://github.com/pytorch/pytorch/commit/a5872a16a0e4577caa296d9ecc97323cee59ccee,Rename torchtest.test_all_device_types to torchtest.for_all_device_types (#24337)Summary:Rename decorator to `for_all_device_types` as `test_` prefixed name recognized as test in some environments.Pull Request resolved: https://github.com/pytorch/pytorch/pull/24337Differential Revision: D16806807Pulled By: VitalyFedyuninfbshipit-source-id: 3132366046e183329ba5838a4bc29441fdb5bd4e,1,Rename Method,,
b123bace1bbdfd4d4f92e9022affd67cb0417a5a,2016-12-30T18:18:52Z,https://github.com/pytorch/pytorch/commit/b123bace1bbdfd4d4f92e9022affd67cb0417a5a,Rename torch.autograd.functions to torch.autograd._functions,1,Rename Method,,
b4f4cca875d00172545bc652501923297d44efbb,2016-10-27T15:23:18Z,https://github.com/pytorch/pytorch/commit/b4f4cca875d00172545bc652501923297d44efbb,Rename training and evaluation methods,1,Rename Method,,
c4752b1a9118b1ce18dfa10e255fe249507fd48f,2023-05-11T09:27:29Z,https://github.com/pytorch/pytorch/commit/c4752b1a9118b1ce18dfa10e255fe249507fd48f,[MPS] Rename metalIndexingFunction to metalIndexingPSO (#101156)  Rename to reflect its return type.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/101156 Approved by: https://github.com/DenisVieriu97,1,Rename Method,,
c6b7eeb654f92c9b42b8d98e51b815471f446453,2020-09-28T21:51:49Z,https://github.com/pytorch/pytorch/commit/c6b7eeb654f92c9b42b8d98e51b815471f446453,"Gh/taylorrobie/timer cleanup (#45361)Summary:This PR cleans up some of the rough edges around `Timer` and `Compare`* Moves `Measurement` to be dataclass based* Adds a bunch of type annotations. MyPy is now happy.* Allows missing entries in `Compare`. This is one of the biggest usability issues with `Compare` right now, both from an API perspective and because the current failure mode is really unpleasant.* Greatly expands the testing of `Compare`Pull Request resolved: https://github.com/pytorch/pytorch/pull/45361Test Plan: Changes to Timer are covered under existing tests, changes to `Compare` are covered by the expanded `test_compare` method.Reviewed By: bwastiDifferential Revision: D23966816Pulled By: robietafbshipit-source-id: 826969f73b42f72fa35f4de3c64d0988b61474cd",1,Rename Method,API Refactoring,
d8588d8007c5e4e07d585c854f7cab8f7f2a3359,2017-03-07T18:07:23Z,https://github.com/pytorch/pytorch/commit/d8588d8007c5e4e07d585c854f7cab8f7f2a3359,CUDA version of elementwise power + rename to Pow + gradientSummary: Renamed ElementwisePower to Pow for better discoverability. Added CUDA version and Gradient + tests.Reviewed By: kennyhorrorDifferential Revision: D4665550fbshipit-source-id: dd33d8ad3917d71504e363ab397af50d38a63b1f,1,Rename Method,,
db071ef0058190720abe637365a4fde9c71b52c7,2021-08-02T23:38:09Z,https://github.com/pytorch/pytorch/commit/db071ef0058190720abe637365a4fde9c71b52c7,"[Reland][DDP Communication Hook] Rename 4 Methods of GradBucket Class (#62592)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/62592  Reland #62510  `GradBucket` is an important class defined in both C++ and Python, used for PyTorch Distributed Training. We need to rename the following methods for simplicity: 1) get_index -> index 2) is_the_last_bucket_to_allreduce -> is_last, 3) get_per_parameter_tensors -> gradients, 4) get_model_params_for_bucket -> parameters. ghstack-source-id: 134848352  Test Plan: unit test  Reviewed By: andwgu  Differential Revision: D30049431  fbshipit-source-id: 1bcac331aa30e529b7230e3891bc811c531b0ea9",1,Rename Method,,
dd05f028e246e09ccabb153364fd81359db19fe3,2023-01-25T23:52:45Z,https://github.com/pytorch/pytorch/commit/dd05f028e246e09ccabb153364fd81359db19fe3,[PT-D][Checkpoint] Rename DCP storage layer init() (#92869)  Rename DCP storage layer init() and update tests accordingly. Pull Request resolved: https://github.com/pytorch/pytorch/pull/92869 Approved by: https://github.com/kumpera,1,Rename Method,,
e4f1681c82fe6a8c11400bec80b520aba9ceb495,2019-03-27T21:29:45Z,https://github.com/pytorch/pytorch/commit/e4f1681c82fe6a8c11400bec80b520aba9ceb495,"Rename isTensor api -> isCompleteTensor (#18437)Summary:Is Tensor has been brought up as misleading a couple times, rename it isCompleteTensor for clarity.Pull Request resolved: https://github.com/pytorch/pytorch/pull/18437Differential Revision: D14605223Pulled By: eellisonfbshipit-source-id: 189f67f12cbecd76516a04e67d8145c260c79036",1,Rename Method,,
e73be58ff7f9df478cdb57fad6102a2dcf5dc181,2019-03-29T19:58:23Z,https://github.com/pytorch/pytorch/commit/e73be58ff7f9df478cdb57fad6102a2dcf5dc181,"Rename `btriunpack` to `lu_unpack` (#18529)Summary:Changelog:- Renames `btriunpack` to `lu_unpack` to remain consistent with the `lu` function interface.- Rename all relevant tests, fix callsites- Create a tentative alias for `lu_unpack` under the name `btriunpack` and add a deprecation warning to not promote usage.Pull Request resolved: https://github.com/pytorch/pytorch/pull/18529Differential Revision: D14683161Pulled By: soumithfbshipit-source-id: 994287eaa15c50fd74c2f1c7646edfc61e8099b1",1,Rename Method,,
fe23881e76bd5bda9f54e688137e7a7b0cd4f83c,2021-05-03T03:10:58Z,https://github.com/pytorch/pytorch/commit/fe23881e76bd5bda9f54e688137e7a7b0cd4f83c,"fx quant: readability improvements on observer functions (#57368)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/573681. renames functions which only sometimes insert observers to start with `maybe_`,to clarify the difference from functions which always insert observers2. saves a level of indent in `maybe_insert_observer_for_output_of_the_node`Test Plan:```python test/test_quantization.py TestQuantizeFx```Imported from OSSReviewed By: jerryzh168Differential Revision: D28126897fbshipit-source-id: 4cbc184dbf5e85954314cfbbcdd1551474175bf0",1,Rename Method,,
feb5d26510919b23ba35a90e45cd5a0f4cc26474,2019-04-11T18:15:47Z,https://github.com/pytorch/pytorch/commit/feb5d26510919b23ba35a90e45cd5a0f4cc26474,Rename ONNX util test names (#19153)Summary:Rename test cases.Pull Request resolved: https://github.com/pytorch/pytorch/pull/19153Reviewed By: zrpherculeDifferential Revision: D14890095Pulled By: houseroadfbshipit-source-id: 37a787398c88d9cc92b411c2355b43200cf1c4b0,1,Rename Method,,
ad07f5f05d3d6ec294fc529f86ece5db8bc24cde,2017-08-24T17:10:58Z,https://github.com/pytorch/pytorch/commit/ad07f5f05d3d6ec294fc529f86ece5db8bc24cde,Added norm-based gradient clipping to optimizer librarySummary: Moved code for global norm-based gradient clipping from fb specific workflows (seq2seq) to the open-source caffe2 optimizer libraryReviewed By: jhcrossDifferential Revision: D5637453fbshipit-source-id: 7e73c9a1c97c28a152c188467b27a6449f79242e,1,Rename Method,API Refactoring,
bab87e4b609658683982a2a8f6120d403435c9cf,2020-01-16T15:07:11Z,https://github.com/pytorch/pytorch/commit/bab87e4b609658683982a2a8f6120d403435c9cf,"reimplement __torch_function__ overrides for torch.functional using inline logic (#32194)Summary:Fixes https://github.com/pytorch/pytorch/issues/30831.This improves the performance of operators in the `torch.functional` namespace that are overridable by `__torch_function__` implementations when supplied with `Tensor` operands.Running the split benchmark in various configurations produces the following timings:<details><summary>Expand for timings on <code>master</code> </summary>```# ----------------------------------------# PyTorch/Caffe2 Operator Micro-benchmarks# ----------------------------------------# Tag : short# Benchmarking PyTorch: split# Mode: Eager# Name: split_M8_N8_parts2_cpu# Input: M: 8, N: 8, parts: 2, device: cpuForward Execution Time (us) : 3.340# Benchmarking PyTorch: split# Mode: Eager# Name: split_M8_N8_parts2_cuda# Input: M: 8, N: 8, parts: 2, device: cudaForward Execution Time (us) : 3.333# Benchmarking PyTorch: split# Mode: Eager# Name: split_M256_N512_parts2_cpu# Input: M: 256, N: 512, parts: 2, device: cpuForward Execution Time (us) : 3.366# Benchmarking PyTorch: split# Mode: Eager# Name: split_M256_N512_parts2_cuda# Input: M: 256, N: 512, parts: 2, device: cudaForward Execution Time (us) : 3.385# Benchmarking PyTorch: split# Mode: Eager# Name: split_M512_N512_parts2_cpu# Input: M: 512, N: 512, parts: 2, device: cpuForward Execution Time (us) : 3.468# Benchmarking PyTorch: split# Mode: Eager# Name: split_M512_N512_parts2_cuda# Input: M: 512, N: 512, parts: 2, device: cudaForward Execution Time (us) : 3.416```</details><details><summary>Expand for timings with this pull request applied</summary>```# ----------------------------------------# PyTorch/Caffe2 Operator Micro-benchmarks# ----------------------------------------# Tag : short# Benchmarking PyTorch: split# Mode: Eager# Name: split_M8_N8_parts2_cpu# Input: M: 8, N: 8, parts: 2, device: cpuForward Execution Time (us) : 2.261# Benchmarking PyTorch: split# Mode: Eager# Name: split_M8_N8_parts2_cuda# Input: M: 8, N: 8, parts: 2, device: cudaForward Execution Time (us) : 2.223# Benchmarking PyTorch: split# Mode: Eager# Name: split_M256_N512_parts2_cpu# Input: M: 256, N: 512, parts: 2, device: cpuForward Execution Time (us) : 2.237# Benchmarking PyTorch: split# Mode: Eager# Name: split_M256_N512_parts2_cuda# Input: M: 256, N: 512, parts: 2, device: cudaForward Execution Time (us) : 2.218# Benchmarking PyTorch: split# Mode: Eager# Name: split_M512_N512_parts2_cpu# Input: M: 512, N: 512, parts: 2, device: cpuForward Execution Time (us) : 2.259# Benchmarking PyTorch: split# Mode: Eager# Name: split_M512_N512_parts2_cuda# Input: M: 512, N: 512, parts: 2, device: cudaForward Execution Time (us) : 2.234```</details><details><summary>Expand for timings on <code>master</code> with <code>__torch_function__</code> dispatch disabled </summary>```# ----------------------------------------# PyTorch/Caffe2 Operator Micro-benchmarks# ----------------------------------------# Tag : short# Benchmarking PyTorch: split# Mode: Eager# Name: split_M8_N8_parts2_cpu# Input: M: 8, N: 8, parts: 2, device: cpuForward Execution Time (us) : 2.180# Benchmarking PyTorch: split# Mode: Eager# Name: split_M8_N8_parts2_cuda# Input: M: 8, N: 8, parts: 2, device: cudaForward Execution Time (us) : 2.172# Benchmarking PyTorch: split# Mode: Eager# Name: split_M256_N512_parts2_cpu# Input: M: 256, N: 512, parts: 2, device: cpuForward Execution Time (us) : 2.171# Benchmarking PyTorch: split# Mode: Eager# Name: split_M256_N512_parts2_cuda# Input: M: 256, N: 512, parts: 2, device: cudaForward Execution Time (us) : 2.146# Benchmarking PyTorch: split# Mode: Eager# Name: split_M512_N512_parts2_cpu# Input: M: 512, N: 512, parts: 2, device: cpuForward Execution Time (us) : 2.175# Benchmarking PyTorch: split# Mode: Eager# Name: split_M512_N512_parts2_cuda# Input: M: 512, N: 512, parts: 2, device: cudaForward Execution Time (us) : 2.152```</details>So at least on the machine I'm testing on, this brings the overhead down to less than 100 ns. For comparison, the overhead for `__array_function__` in NumPy is about 850 ns on the same machine.<details><summary>Expand for timings for NumPy <code>__array_function__</code> dispatch </summary>```In [1]: import numpy as npIn [2]: %timeit np.mean([1])8.89 µs ± 17.6 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)In [3]: %timeit np.mean._implementation([1])8.04 µs ± 28.2 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)```See [the implementation in NumPy](https://github.com/numpy/numpy/blob/master/numpy/core/overrides.py#L195) for why this measures `__array_function__` overhead.</details>Pull Request resolved: https://github.com/pytorch/pytorch/pull/32194Differential Revision: D19410396Pulled By: ezyangfbshipit-source-id: ada788a4399c81cd7eb2d548aa04a2459e96634a",1,Rename Method,,
e43ffb014806757ad91fc70c9ec5c5f44a4eaa2e,2018-10-01T18:10:15Z,https://github.com/pytorch/pytorch/commit/e43ffb014806757ad91fc70c9ec5c5f44a4eaa2e,nomnigraph - easy - some code cleanup for transformations_test (#12101)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/12101clean up some duplicate test codeReviewed By: ZolotukhinMDifferential Revision: D10051914fbshipit-source-id: 698ff144a85e8c70572116c5ddb415cd2396b4e3,1,Rename Method,Extract Method,
f304bd5062e0b5103cd441755d7edcbad46660f3,2019-11-20T20:35:28Z,https://github.com/pytorch/pytorch/commit/f304bd5062e0b5103cd441755d7edcbad46660f3,rename join_rpc to wait_all_workers in public api (#30050)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/30050Renames this API to wait_all_workers as discussed.ghstack-source-id: 94273005Test Plan: Unit tests passDifferential Revision: D18581466fbshipit-source-id: 4ff5d5fb2d528f17252d5b5f30c3047d2efb92bf,1,Rename Method,,
15f7cfbc0528442115937c670b6cc80fbac768ef,2023-06-14T16:50:04Z,https://github.com/scikit-learn/scikit-learn/commit/15f7cfbc0528442115937c670b6cc80fbac768ef,CLN Renames missing_values_in_feature_mask (#26580),1,Rename Method,,
42c2731af1ff97216b947225545cb8c086243f8b,2023-04-19T14:05:08Z,https://github.com/scikit-learn/scikit-learn/commit/42c2731af1ff97216b947225545cb8c086243f8b,MAINT Refactor GraphicalLasso and graphical_lasso (#26033)  Co-authored-by: Guillaume Lemaitre <g.lemaitre58@gmail.com> Co-authored-by: Jérémie du Boisberranger <34657725+jeremiedbb@users.noreply.github.com>,1,Rename Method,,
effdd6e215c67f2ae8ed1e378ea1661e936059a4,2022-05-30T19:35:40Z,https://github.com/scikit-learn/scikit-learn/commit/effdd6e215c67f2ae8ed1e378ea1661e936059a4,API Rename base_estimator in CalibratedClassifierCV (#22054)  Co-authored-by: Kevin Roice <kevinroice@Kevins-Air.broadband> Co-authored-by: Guillaume Lemaitre <g.lemaitre58@gmail.com> Co-authored-by: Thomas J. Fan <thomasjpfan@gmail.com>,1,Rename Method,,
fc2c0dae0ae43e5ca2e794106a333cf9ace06cd5,2022-05-30T17:23:24Z,https://github.com/scikit-learn/scikit-learn/commit/fc2c0dae0ae43e5ca2e794106a333cf9ace06cd5,MNT Minor refactor of `n_support` (#23353),1,Rename Method,,
1c094728a33f05bb6c83d7b856b87254964e0e8c,2022-03-11T18:48:27Z,https://github.com/scikit-learn/scikit-learn/commit/1c094728a33f05bb6c83d7b856b87254964e0e8c,CLN clean _preprocess_data in linear_model (#22762),1,Rename Method,,
fac31e727947ad53f2ed107f58a10b56b165cee7,2021-09-02T14:15:31Z,https://github.com/scikit-learn/scikit-learn/commit/fac31e727947ad53f2ed107f58a10b56b165cee7,MNT replace if_delegate_has_method by available_if in example (#20684)  Co-authored-by: Thomas J. Fan <thomasjpfan@gmail.com> Co-authored-by: Adrin Jalali <adrin.jalali@gmail.com>,1,Rename Method,,
4637682965c9880371f86f82ada08f229f08c20b,2021-08-16T12:59:21Z,https://github.com/scikit-learn/scikit-learn/commit/4637682965c9880371f86f82ada08f229f08c20b,MNT Replace @property with @available_if (#20749)  Signed-off-by: harupy <hkawamura0130@gmail.com>,1,Rename Method,,
5562cc5d58cbac6a5d2f97f55801764cac4e3ae5,2021-07-27T11:46:50Z,https://github.com/scikit-learn/scikit-learn/commit/5562cc5d58cbac6a5d2f97f55801764cac4e3ae5,MNT: replace __file__ with importlib.resources  (#20297)  (compat with pyOxidizer and zipapp),1,Rename Method,,
3250ffb785fed45712868fd618929a3015639b1c,2020-07-17T00:45:57Z,https://github.com/scikit-learn/scikit-learn/commit/3250ffb785fed45712868fd618929a3015639b1c,TST More cleaning/refactoring in KMeans tests (#17885),1,Rename Method,,
51df2624226a2922dcd6b7ac9a275723df2db661,2020-06-08T14:21:07Z,https://github.com/scikit-learn/scikit-learn/commit/51df2624226a2922dcd6b7ac9a275723df2db661,MNT remove boston from the common test / estimator checks (#17356),1,Rename Method,,
68a639e3fdcbd41a556a43768c1270cece18702c,2020-02-29T19:20:40Z,https://github.com/scikit-learn/scikit-learn/commit/68a639e3fdcbd41a556a43768c1270cece18702c,MNT rename _parallel_fit_estimator to _fit_single_estimator to reflect lack of parallelism in the method (#16599),1,Rename Method,,
bb3b3f9261bd092ed010d80de35fe031123c1687,2019-10-25T20:41:13Z,https://github.com/scikit-learn/scikit-learn/commit/bb3b3f9261bd092ed010d80de35fe031123c1687,MNT Make modules private in feature_extraction (#15321),1,Rename Method,,
c3415b8bd101d6e8e99edae8a86a99ba0b153d05,2019-02-27T10:39:16Z,https://github.com/scikit-learn/scikit-learn/commit/c3415b8bd101d6e8e99edae8a86a99ba0b153d05,TST change name of test such that they are included by pytest in test_split (#13299),1,Rename Method,,
401d2a178c8b4eb6ebdcea493f85ded41d41d4dd,2016-08-28T23:30:49Z,https://github.com/scikit-learn/scikit-learn/commit/401d2a178c8b4eb6ebdcea493f85ded41d41d4dd,Test method test_grid_search_incorrect_param_grid has been renamed to test_grid_search_param_grid_includes_sequence_of_a_zero_length.,1,Rename Method,,
4d33cd62e4c3be012e083811cf8dc9a06dc7080b,2016-07-01T19:50:40Z,https://github.com/scikit-learn/scikit-learn/commit/4d33cd62e4c3be012e083811cf8dc9a06dc7080b,rename function to func (#6700),1,Rename Method,,
835102ab6a4bae273e0641d3634e4849aa36a256,2016-01-21T19:27:15Z,https://github.com/scikit-learn/scikit-learn/commit/835102ab6a4bae273e0641d3634e4849aa36a256,API: Split mutual_info into _regression and _classif,1,Rename Method,,
bc02bd524373232718bb2690b844dd0cd6439c4b,2015-10-21T15:05:56Z,https://github.com/scikit-learn/scikit-learn/commit/bc02bd524373232718bb2690b844dd0cd6439c4b,ENH rename decision_paths to decision_path,1,Rename Method,,
141eb0b27c8a3ff7f30dc7fdfe4c46ac2f74a7f2,2015-10-19T16:04:56Z,https://github.com/scikit-learn/scikit-learn/commit/141eb0b27c8a3ff7f30dc7fdfe4c46ac2f74a7f2,REFACTOR Rename GPR method sample to sample_y,1,Rename Method,,
641bd932e2fdc310690176d3c0805883f682d04e,2015-04-15T02:46:26Z,https://github.com/scikit-learn/scikit-learn/commit/641bd932e2fdc310690176d3c0805883f682d04e,Change xrange to range and remove patching import,1,Rename Method,,
ce5fada305ab253657808250daf73d1a10215fb5,2015-04-10T09:45:40Z,https://github.com/scikit-learn/scikit-learn/commit/ce5fada305ab253657808250daf73d1a10215fb5,Deprecated load_lfw_pairs and load_lfw_people  Added deprecated decorator  Added import statement  Added tests  Added newline  Ignored deprecation warnings  Renamed tests for fetch_lfw_  Added imports for load_lfw_,1,Rename Method,,
709b41a87782648dac3bbf2ca36eb678d909b2af,2015-01-28T16:55:19Z,https://github.com/scikit-learn/scikit-learn/commit/709b41a87782648dac3bbf2ca36eb678d909b2af,TST: Refactor tests for k and radius neighbors,1,Rename Method,,
6dce07733d7a7c887bb33f4b6c17bdf691953a06,2014-12-30T01:40:34Z,https://github.com/scikit-learn/scikit-learn/commit/6dce07733d7a7c887bb33f4b6c17bdf691953a06,"remove bad estimator test as it was enforcing too many restrictions, instead test that we don't enforce these restrictions.",1,Rename Method,,
41e2c10a9ee928c626b50ac44abd13a4933db618,2014-12-19T22:27:27Z,https://github.com/scikit-learn/scikit-learn/commit/41e2c10a9ee928c626b50ac44abd13a4933db618,rename decorator,1,Rename Method,,
2daa0289efcf622366cbd27450123346ccf015f6,2014-10-21T07:21:30Z,https://github.com/scikit-learn/scikit-learn/commit/2daa0289efcf622366cbd27450123346ccf015f6,Renamed csc_row_median to csc_median_axis_0,1,Rename Method,,
89d5aa02fe9a5428cafb92ad992c21bc19a6a509,2014-10-09T14:03:35Z,https://github.com/scikit-learn/scikit-learn/commit/89d5aa02fe9a5428cafb92ad992c21bc19a6a509,COSMIT: Replaced xrange by range  range still is xrange: from sklearn.externals.six import xrange as range,1,Rename Method,,
7354359bca58c080b36bf4459448d0ea0d2e5338,2014-09-22T14:44:47Z,https://github.com/scikit-learn/scikit-learn/commit/7354359bca58c080b36bf4459448d0ea0d2e5338,"MAINT refactor DictVectorizer's transform+fit_transform (1)  Also:  * postpone attribute setting to the end of the fit_transform algorithm,   so that exceptions leave the transformer in a consistent state; * call sort_indices on CSR result.  Didn't refactor fit as I couldn't get the code shorter without making _transform cumbersome to read.",1,Rename Method,,
e44f9c7d8eea0c7e003d42e03e69b2431e4eb3f3,2014-09-05T22:15:03Z,https://github.com/scikit-learn/scikit-learn/commit/e44f9c7d8eea0c7e003d42e03e69b2431e4eb3f3,COSMIT: Renamed _lse to _lstsq in theil_sen.py,1,Rename Method,,
9c1217ce5b679614d27e20b3160d1e680ad5ef09,2014-07-15T10:09:45Z,https://github.com/scikit-learn/scikit-learn/commit/9c1217ce5b679614d27e20b3160d1e680ad5ef09,TYPO remove mutli (did you mean Muttley?),1,Rename Method,,
f13007934163d6e8817b71acac6881d08c06eb5d,2014-07-14T18:47:17Z,https://github.com/scikit-learn/scikit-learn/commit/f13007934163d6e8817b71acac6881d08c06eb5d,TST split test for partial_fit and fit,1,Rename Method,,
acd5df39df3d9b967b11538d6d3d12723b7dd5f5,2014-06-10T15:35:08Z,https://github.com/scikit-learn/scikit-learn/commit/acd5df39df3d9b967b11538d6d3d12723b7dd5f5,COSMIT: Replaced xrange with range,1,Rename Method,,
b9dc77dcf6727f34404ba402e7bd65f22361e3ea,2014-05-22T14:42:02Z,https://github.com/scikit-learn/scikit-learn/commit/b9dc77dcf6727f34404ba402e7bd65f22361e3ea,TST refactor oob score testing,1,Rename Method,,
5cb9b7690dfa7cb69e1582c2afe9a8cf74fca168,2014-05-22T11:59:30Z,https://github.com/scikit-learn/scikit-learn/commit/5cb9b7690dfa7cb69e1582c2afe9a8cf74fca168,TST Refactor test of sklearn/ensemble/tests/test_forest.py,1,Rename Method,,
fc634f95f249e7cba7e5a219831ea66ce106a071,2014-04-30T17:57:26Z,https://github.com/scikit-learn/scikit-learn/commit/fc634f95f249e7cba7e5a219831ea66ce106a071,Made the following changes 1. Minor changes to docs 2. Replaced swap with inplace_swap,1,Rename Method,,
261da69b3d28ce4d9c7370d85ee064190fdc5132,2014-03-24T09:35:37Z,https://github.com/scikit-learn/scikit-learn/commit/261da69b3d28ce4d9c7370d85ee064190fdc5132,TST remove n_jobs=-1 usages in tests,1,Rename Method,,
de2be61e460023c0d0a15d419fe9fb9bddce2502,2014-01-16T03:43:17Z,https://github.com/scikit-learn/scikit-learn/commit/de2be61e460023c0d0a15d419fe9fb9bddce2502,Rename fit_and_score to _fit_and_score.,1,Rename Method,,
d818519c138105056dbe22022f6bfeeb18f2b724,2014-01-16T03:43:16Z,https://github.com/scikit-learn/scikit-learn/commit/d818519c138105056dbe22022f6bfeeb18f2b724,Rename _split_with_kernel to _safe_split.  Kernels are not always used so I find this name better.,1,Rename Method,,
aaa4f81b67710bec9ff6e6d6ba0a9b868ef84bf2,2014-01-16T03:43:16Z,https://github.com/scikit-learn/scikit-learn/commit/aaa4f81b67710bec9ff6e6d6ba0a9b868ef84bf2,Rename '_split' to '_split_with_kernel',1,Rename Method,,
f512bd82c9f282aff50dd94976fb225d6d824ab3,2014-01-04T13:07:42Z,https://github.com/scikit-learn/scikit-learn/commit/f512bd82c9f282aff50dd94976fb225d6d824ab3,renamed partial_fit -> fit_more for GBRT,1,Rename Method,,
224a4d593b1feb27da8ca787afdbdbcaec63d791,2014-01-01T12:00:50Z,https://github.com/scikit-learn/scikit-learn/commit/224a4d593b1feb27da8ca787afdbdbcaec63d791,TST/COSMIT cleaner make_classification and fix tests  * refactored make_classification * new test for make_classification * skip problematic common test for class_weights,1,Rename Method,,
5d26ad7c6c1c09b7f57721da4d45eb02f457da51,2013-10-20T13:58:04Z,https://github.com/scikit-learn/scikit-learn/commit/5d26ad7c6c1c09b7f57721da4d45eb02f457da51,Rename min_samples,1,Rename Method,,
711bfd2285682f318cbefe45a3a69b3e3446b6d5,2013-08-27T08:29:40Z,https://github.com/scikit-learn/scikit-learn/commit/711bfd2285682f318cbefe45a3a69b3e3446b6d5,"[API] Renamed pairwise_distances_argmin  The function is now called pairwise_distances_argmin_min.  One of the ""batch_size"" arguments has been dropped.",1,Rename Method,,
89011e369a2954e0ac1585368d1dc197786bf2d3,2013-07-29T01:06:58Z,https://github.com/scikit-learn/scikit-learn/commit/89011e369a2954e0ac1585368d1dc197786bf2d3,MISC: deprecate balance_weights (it's internal),1,Rename Method,,
32eb8b57f8af07daffaa5c70cabb77380f03e747,2013-07-26T21:32:23Z,https://github.com/scikit-learn/scikit-learn/commit/32eb8b57f8af07daffaa5c70cabb77380f03e747,ENH rename eval / pseudolikelihood to score_samples,1,Rename Method,,
808799c1469c6becfefe61495d6212e145a6d2a6,2013-07-26T17:40:56Z,https://github.com/scikit-learn/scikit-learn/commit/808799c1469c6becfefe61495d6212e145a6d2a6,"ENH rewrite multiclass_log_loss, rename log_loss, document it",1,Rename Method,,
5694d34022693e4df469c568bb60a9ef47656bec,2013-07-25T17:19:19Z,https://github.com/scikit-learn/scikit-learn/commit/5694d34022693e4df469c568bb60a9ef47656bec,renamed 'preprocess' to 'normalize',1,Rename Method,,
125ee1aa6639c85b9acabf536724d172f15bb717,2013-07-25T17:19:14Z,https://github.com/scikit-learn/scikit-learn/commit/125ee1aa6639c85b9acabf536724d172f15bb717,made internal functions private,1,Rename Method,,
08de819b2c4fdf2a4cf1d6664adbfb0975facc4d,2013-07-25T09:16:29Z,https://github.com/scikit-learn/scikit-learn/commit/08de819b2c4fdf2a4cf1d6664adbfb0975facc4d,Rename helper partial_fit function,1,Rename Method,,
59631d6cb9c54d73a5e3acec267964af49558f6d,2013-07-24T15:27:22Z,https://github.com/scikit-learn/scikit-learn/commit/59631d6cb9c54d73a5e3acec267964af49558f6d,replaced test_gibbs by a smoke test for NaNs,1,Rename Method,,
97c9760ce12acb225a55a1ca98d1b0fce2573046,2013-07-24T15:27:17Z,https://github.com/scikit-learn/scikit-learn/commit/97c9760ce12acb225a55a1ca98d1b0fce2573046,renamed _sigmoid to _logistic_sigmoid,1,Rename Method,,
9dc2b467d9c53807de64b4cf86294a0c141058b1,2013-06-17T08:37:24Z,https://github.com/scikit-learn/scikit-learn/commit/9dc2b467d9c53807de64b4cf86294a0c141058b1,more structured iteration using islice + wrappers; renamed chunk for minibatch as the latter seems more common in hte literature,1,Rename Method,,
721be7f8a06a22eb2a38062d80f7381c90329074,2013-06-12T00:51:01Z,https://github.com/scikit-learn/scikit-learn/commit/721be7f8a06a22eb2a38062d80f7381c90329074,A further refactor,1,Rename Method,,
9f17401eab69aef64119b3f0b4457a4b5e760cee,2013-06-12T00:46:39Z,https://github.com/scikit-learn/scikit-learn/commit/9f17401eab69aef64119b3f0b4457a4b5e760cee,Include LeavePLabelOut in refactoring,1,Rename Method,,
5afc1c980a124f7c31777ea7ce3fcae6201af945,2013-06-12T00:36:00Z,https://github.com/scikit-learn/scikit-learn/commit/5afc1c980a124f7c31777ea7ce3fcae6201af945,COSMIT refactor cross-validation strategies,1,Rename Method,,
017afab7afdff92a5906ffc53a5b4bc734324bab,2013-06-05T10:56:33Z,https://github.com/scikit-learn/scikit-learn/commit/017afab7afdff92a5906ffc53a5b4bc734324bab,Rename _apply_transform to _transform_selected and make it a function rather than a method.,1,Rename Method,,
1faff8b15d1979deb5abd2af390c356a322b8d91,2013-03-23T05:14:02Z,https://github.com/scikit-learn/scikit-learn/commit/1faff8b15d1979deb5abd2af390c356a322b8d91,rename dist conversion funcs,1,Rename Method,,
bec12269339dc30bda1c2bc74bde7530e299b1fc,2013-02-15T17:14:09Z,https://github.com/scikit-learn/scikit-learn/commit/bec12269339dc30bda1c2bc74bde7530e299b1fc,"Made more changes renamed pairwise_kernel_functions, kernel_params to allcaps",1,Rename Method,,
829d3fcf9e12fca7bb754939d65df93b16124e74,2013-02-15T17:14:09Z,https://github.com/scikit-learn/scikit-learn/commit/829d3fcf9e12fca7bb754939d65df93b16124e74,pairwise_distance_functions renamed to PAIRWISE_DISTANCE_FUNCTIONS,1,Rename Method,,
3d89ae17e31aa1ee29de9420ec405ec661f56934,2013-01-23T07:53:49Z,https://github.com/scikit-learn/scikit-learn/commit/3d89ae17e31aa1ee29de9420ec405ec661f56934,ENH: remove boost_method parameter and use a string as switch,1,Rename Method,,
18352da31f349f2667856423f200276a58677265,2013-01-17T16:46:59Z,https://github.com/scikit-learn/scikit-learn/commit/18352da31f349f2667856423f200276a58677265,ENH rename cosine_kernel to cosine_similarity. Also make the test actually do something.,1,Rename Method,,
6cf5ee0fbf672bd56ae7ee32c417a698ed4970a5,2013-01-09T14:31:57Z,https://github.com/scikit-learn/scikit-learn/commit/6cf5ee0fbf672bd56ae7ee32c417a698ed4970a5,ENH rename zero_loss_score to accuracy_score,1,Rename Method,,
e7b8f6e329490ca70131f89a858f99ca957aaba0,2013-01-09T14:28:23Z,https://github.com/scikit-learn/scikit-learn/commit/e7b8f6e329490ca70131f89a858f99ca957aaba0,ENH renamed metrics.zero_one to metrics.zero_one_loss,1,Rename Method,,
b5d3e93e7723a84685e13ceef976f87bc4b3a031,2013-01-09T06:20:55Z,https://github.com/scikit-learn/scikit-learn/commit/b5d3e93e7723a84685e13ceef976f87bc4b3a031,ENH: rename boost method to _boost,1,Rename Method,,
4734f6ae36d5ea6de64c58b9fcde572c8cb9a168,2012-12-21T13:47:59Z,https://github.com/scikit-learn/scikit-learn/commit/4734f6ae36d5ea6de64c58b9fcde572c8cb9a168,"COSMIT (typo, doc, simplify code)",1,Rename Method,,
3676a3ecc3cef30676aedaaf89e34e92de96f0d9,2012-12-21T13:47:57Z,https://github.com/scikit-learn/scikit-learn/commit/3676a3ecc3cef30676aedaaf89e34e92de96f0d9,ENH Rename sample_int to sample_without_replacement,1,Rename Method,,
54b122838232a232767516fc583021fb4d8817a1,2012-11-26T21:15:46Z,https://github.com/scikit-learn/scikit-learn/commit/54b122838232a232767516fc583021fb4d8817a1,"ENH renamed chi2 to additive_chi2 and exponential_chi2 to chi2, as usually the exponential version is meant with ""chi2""",1,Rename Method,,
ca60c93ee7279aaff167a3236cd5ad0f8356eb72,2012-11-14T06:23:49Z,https://github.com/scikit-learn/scikit-learn/commit/ca60c93ee7279aaff167a3236cd5ad0f8356eb72,Replaced use of deprecated method.,1,Rename Method,,
4249edc304327f2cd821d0b6ea7fa38182b0ed96,2012-11-10T19:16:10Z,https://github.com/scikit-learn/scikit-learn/commit/4249edc304327f2cd821d0b6ea7fa38182b0ed96,renamed datasets.cal_housing to datasets.california_housing,1,Rename Method,,
c8145ce603d253646c3524529b762f811768356d,2012-10-30T07:45:50Z,https://github.com/scikit-learn/scikit-learn/commit/c8145ce603d253646c3524529b762f811768356d,rename dependency -> dependence,1,Rename Method,,
df909c74f33318272dfc1d56166cbb9ad0ac9122,2012-10-30T07:45:34Z,https://github.com/scikit-learn/scikit-learn/commit/df909c74f33318272dfc1d56166cbb9ad0ac9122,rename dependency -> dependence,1,Rename Method,,
60c730d21e93652dedf8de8ab689c3f124be446a,2012-09-07T08:08:37Z,https://github.com/scikit-learn/scikit-learn/commit/60c730d21e93652dedf8de8ab689c3f124be446a,rename get_loss_function to _get_loss_function,1,Rename Method,,
63608c67ae3d51a7e4ab7ce7fbaf5b4f8615a0d5,2012-09-06T19:41:57Z,https://github.com/scikit-learn/scikit-learn/commit/63608c67ae3d51a7e4ab7ce7fbaf5b4f8615a0d5,refactored input validation; special loss function factory for huber and epsilon insensitive loss,1,Rename Method,,
c59ee33de7c4f82be8771ed68191a06fe841909c,2012-07-16T14:10:58Z,https://github.com/scikit-learn/scikit-learn/commit/c59ee33de7c4f82be8771ed68191a06fe841909c,Tree refactoring (20),1,Rename Method,,
3e5f2e5e0888028be3bedbd7f4d3851704d09812,2012-05-06T13:43:29Z,https://github.com/scikit-learn/scikit-learn/commit/3e5f2e5e0888028be3bedbd7f4d3851704d09812,"ENH backport ""assert_less"" and ""assert_greater"", rename ""assert_lower"" and use it everywhere :)",1,Rename Method,,
34f4c144442c48d6c5206d2a15dc02f1475b5f94,2012-03-20T09:30:28Z,https://github.com/scikit-learn/scikit-learn/commit/34f4c144442c48d6c5206d2a15dc02f1475b5f94,Sparse tests pass when using shrinkage Code cleaning and optimisation still to go,1,Rename Method,,
a04681bcb85fb85b8845b37a245bd7cd1203f44d,2012-02-13T10:24:48Z,https://github.com/scikit-learn/scikit-learn/commit/a04681bcb85fb85b8845b37a245bd7cd1203f44d,COSMIT rename _mkdataset function in SGD  At the request of @ogrisel.,1,Rename Method,,
36a4c37f7a1d007123e5db9327ede3511fe3faf8,2012-02-07T20:34:13Z,https://github.com/scikit-learn/scikit-learn/commit/36a4c37f7a1d007123e5db9327ede3511fe3faf8,major refactoring of sgd module::    - new dataset abstraction allows us to dump the sparse impl.,1,Rename Method,,
c912ab000866a8d0f1436c03e7efb8406c3ee746,2012-01-19T18:17:40Z,https://github.com/scikit-learn/scikit-learn/commit/c912ab000866a8d0f1436c03e7efb8406c3ee746,COSMIT refactor SGD code further  * push csr_matrix knowledge down to Cython level * remove lots of duplicate code * use improved atleast2d_or_csr  Mirrors the recent LinearSVC refactoring.  SGDRegressor input validation needs another look.,1,Rename Method,,
8126e5fc613d37d6ffa5244dbc66bde93634549e,2012-01-17T06:06:09Z,https://github.com/scikit-learn/scikit-learn/commit/8126e5fc613d37d6ffa5244dbc66bde93634549e,Rename _get_params() to get_params().,1,Rename Method,,
7599effd03e73de4f0bf742101275b0760a21fb0,2012-01-15T08:31:16Z,https://github.com/scikit-learn/scikit-learn/commit/7599effd03e73de4f0bf742101275b0760a21fb0,"replaced deprecated ""rvs"" to ""sample""",1,Rename Method,,
0f6c525d7e6f90522ce985dd033255279eed7d6b,2011-12-31T13:31:55Z,https://github.com/scikit-learn/scikit-learn/commit/0f6c525d7e6f90522ce985dd033255279eed7d6b,ENH: renamed fast_svd to randomized_svd + related improvements,1,Rename Method,,
fa50e6885a0d377e4df4beb163c6bec2159feda0,2011-09-13T14:50:30Z,https://github.com/scikit-learn/scikit-learn/commit/fa50e6885a0d377e4df4beb163c6bec2159feda0,rename ari_score adjusted_rand_score,1,Rename Method,,
a6b21f9d3bdd2cdc952e2a41cbf44e2563b22194,2011-08-12T05:48:02Z,https://github.com/scikit-learn/scikit-learn/commit/a6b21f9d3bdd2cdc952e2a41cbf44e2563b22194,ENH: remove references to digits + format,1,Rename Method,,
8ec858397c8ec9b559aa67c638d93175cb198979,2011-08-11T11:59:09Z,https://github.com/scikit-learn/scikit-learn/commit/8ec858397c8ec9b559aa67c638d93175cb198979,"rename coding_method, transform_method to fit/transform_algorithm",1,Rename Method,,
032f76dec46e34f83b19c26191c348f1904dc578,2011-08-03T12:28:45Z,https://github.com/scikit-learn/scikit-learn/commit/032f76dec46e34f83b19c26191c348f1904dc578,Complete rewriting of samples_generator.py  This commit include the following changes: - Functions have been renamed to `make_*` for consistency. - Interfaces have been standardized. - Documentation has been improved and completed. - `make_classification`: new function replacing `test_dataset_classif`. This fixes issue #240. - `make_blobs`: samples are now balanced between centers. - `make_friedman1`: the output function was incorrect. - `make_friedman2`: new function added. - `make_friedman3`: new function added. - `make_sparse_correlated`: a `seed` parameter is now used. - `make_s_curve`: the `noise` parameter is now actually used. - `make_regression_dataset` becomes make_regression and `test_dataset_reg` is removed to avoid redundancy and confusion. - Various cosmits.,1,Rename Method,,
32d78bdbf7e9d9ba27606bcef7d48d42ac4bb523,2011-07-29T10:39:59Z,https://github.com/scikit-learn/scikit-learn/commit/32d78bdbf7e9d9ba27606bcef7d48d42ac4bb523,"cleaned up tests, added count_nonzero to fixes",1,Rename Method,,
8ac81f2787c9b2ee302a38b8c3bc1617b874ca1d,2011-07-26T18:56:37Z,https://github.com/scikit-learn/scikit-learn/commit/8ac81f2787c9b2ee302a38b8c3bc1617b874ca1d,"speed tweaks in Floyd-Warshall, and renamed graph_search->shortest_path",1,Rename Method,,
130b84d724af3d5dc218ac1be084030b9e02302e,2011-07-22T22:30:21Z,https://github.com/scikit-learn/scikit-learn/commit/130b84d724af3d5dc218ac1be084030b9e02302e,Rename f_chi2 to chi2,1,Rename Method,,
993fbe7dc3d92b0a60f8881775e8967fa50da0b7,2011-06-27T20:11:25Z,https://github.com/scikit-learn/scikit-learn/commit/993fbe7dc3d92b0a60f8881775e8967fa50da0b7,Used @fabianp's ridge refactoring,1,Rename Method,,
f68b50aa892e7d06d5382ff1a459aff2e13554d7,2011-06-27T18:24:06Z,https://github.com/scikit-learn/scikit-learn/commit/f68b50aa892e7d06d5382ff1a459aff2e13554d7,Renamed online dict_learning appropriately,1,Rename Method,,
849ff59cde6b8300fa1554d1bdde00306187bacb,2011-06-24T11:10:20Z,https://github.com/scikit-learn/scikit-learn/commit/849ff59cde6b8300fa1554d1bdde00306187bacb,"renaming for consistency, tests for PatchExtractor",1,Rename Method,,
43bcf61b8a7cb6be684dfca8d8c1a8e3a3abb65b,2011-05-21T12:32:43Z,https://github.com/scikit-learn/scikit-learn/commit/43bcf61b8a7cb6be684dfca8d8c1a8e3a3abb65b,ENH: refactored shuffle to address the resampling with replacement case + more tests,1,Rename Method,,
54361ad36232c0a66b133cd64fa775ddfa259fd7,2011-05-19T11:51:28Z,https://github.com/scikit-learn/scikit-learn/commit/54361ad36232c0a66b133cd64fa775ddfa259fd7,Text chapter: load_files renamed load_filenames  Name was changed in scikit-learn commit 5b806e,1,Rename Method,,
637c70038cb063c7492c381389ba606997c9faec,2011-03-19T17:39:45Z,https://github.com/scikit-learn/scikit-learn/commit/637c70038cb063c7492c381389ba606997c9faec,renamed load_* to fetch_* when network connection is potentially involved,1,Rename Method,,
a3bc7eafcfac13f8037a1453762c59eeef75b094,2011-02-28T15:58:00Z,https://github.com/scikit-learn/scikit-learn/commit/a3bc7eafcfac13f8037a1453762c59eeef75b094,"ENH : factorizing img_to_graph and grid_to_graph there was no bug before but an obscure img_to_graph(mask, mask) that is now replaced by grid_to_graph (makes a connectivity structure for a grid of pixels/voxels)",1,Rename Method,,
5b806ea408c975965be2cbe7cbbcdea2a660486a,2011-02-27T11:08:35Z,https://github.com/scikit-learn/scikit-learn/commit/5b806ea408c975965be2cbe7cbbcdea2a660486a,better name: rename load_files to load_filenames,1,Rename Method,,
f8554f54ff362de1ea49bdd77f357882e36833e8,2011-01-26T17:02:31Z,https://github.com/scikit-learn/scikit-learn/commit/f8554f54ff362de1ea49bdd77f357882e36833e8,PLS: simplify API + som additionnal test,1,Rename Method,,
4cffab4e8377a2f5d6c3748a0c0eb9bd91b3c2ba,2010-12-10T14:05:50Z,https://github.com/scikit-learn/scikit-learn/commit/4cffab4e8377a2f5d6c3748a0c0eb9bd91b3c2ba,renamed explained_variance_score to r2_score in linear_model  Signed-off-by: Fabian Pedregosa <fabian.pedregosa@inria.fr>,1,Rename Method,,
4d8dff6b11c665e9b206c6a5dfede0faf8781bf7,2010-11-24T18:00:10Z,https://github.com/scikit-learn/scikit-learn/commit/4d8dff6b11c665e9b206c6a5dfede0faf8781bf7,metrics.explained_variance was renamed to metrics.explained_variance_score so that I needed to modify this example.,1,Rename Method,,
60f72c91f7bc701a705965af5de925ba7effefcf,2010-11-19T13:10:01Z,https://github.com/scikit-learn/scikit-learn/commit/60f72c91f7bc701a705965af5de925ba7effefcf,Rename predict_margin --> decision_function.,1,Rename Method,,
6e474fe7dffea57adea8d5fba4677f0c0ccb2b49,2010-11-14T09:51:02Z,https://github.com/scikit-learn/scikit-learn/commit/6e474fe7dffea57adea8d5fba4677f0c0ccb2b49,Modification of the score function. The score function now evaluates the deviation between the predicted targets and the true ones. This is for convenience only because it allows then to use the distributing capacity of the cross_val module. The old score function is renamed with the more explicit name: `reduced_likelihood_function` (see eg the DACE documentation).,1,Rename Method,,
601ffe94ea62fa4cd436092c6e230233bc811634,2010-10-13T04:20:00Z,https://github.com/scikit-learn/scikit-learn/commit/601ffe94ea62fa4cd436092c6e230233bc811634,Rename roc to roc_curve.,1,Rename Method,,
06c74d2b7c1ff9a24eb6fce5321eaaaa0a1c83df,2010-09-29T12:12:58Z,https://github.com/scikit-learn/scikit-learn/commit/06c74d2b7c1ff9a24eb6fce5321eaaaa0a1c83df,Refactor svm tests.,1,Rename Method,,
c75f88e5da0a40a78b685af2711b8bfb045d02dc,2010-07-27T10:02:26Z,https://github.com/scikit-learn/scikit-learn/commit/c75f88e5da0a40a78b685af2711b8bfb045d02dc,Cosmit: rename grid to iter_grid,1,Rename Method,,
26ca669b1c710892aa68b32a8de87d45e1d514de,2010-07-06T16:15:14Z,https://github.com/scikit-learn/scikit-learn/commit/26ca669b1c710892aa68b32a8de87d45e1d514de,"changed ""train"" -> ""fit"".  Removed HMMGMM for now.",1,Rename Method,,
5735f269f80cf4c5d0a8ce829cbe6d4e999668d7,2010-07-06T14:41:06Z,https://github.com/scikit-learn/scikit-learn/commit/5735f269f80cf4c5d0a8ce829cbe6d4e999668d7,"cleanup hmm module: made properties compatible with Python 2.5, etc.",1,Rename Method,,
af0a717a19f0e53fe3a59225da9eec9ab5aeea7e,2010-06-23T13:56:10Z,https://github.com/scikit-learn/scikit-learn/commit/af0a717a19f0e53fe3a59225da9eec9ab5aeea7e,GLM refactoring: put explained_variance_ as a public field.  and move the method to private.,1,Rename Method,,
27d3900dceac69273f9208e983752a5338574a58,2010-06-23T12:58:43Z,https://github.com/scikit-learn/scikit-learn/commit/27d3900dceac69273f9208e983752a5338574a58,Refactoring in the glm module.  Rename compute_rsquared to explained_variance and use it in Lasso & ElasticNet __str__ method. They are also (optionally) printed in the *_path methods via a verbose argument.  Also added documentation and implement intercept in LeastAngleRegression.,1,Rename Method,,
db526d2adee6b36818f23a5d0f1e62be245f41f1,2010-06-02T13:04:28Z,https://github.com/scikit-learn/scikit-learn/commit/db526d2adee6b36818f23a5d0f1e62be245f41f1,Rename train --> fit in gmm,1,Rename Method,,
449cc00244e7f4f965d722dd6d986868c21f0012,2010-04-29T06:59:48Z,https://github.com/scikit-learn/scikit-learn/commit/449cc00244e7f4f965d722dd6d986868c21f0012,"Refactoring on the svm module.  Cleanup innecessary code in svm module, add docstring. Also simplify the bindings and avoid creating new objects in the wrap functions, pass arrays by reference whenever possible.  Change some names: SVC.rho_ --> SVC.intercept_  Also added tests.  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@710 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8",1,Rename Method,,
8de51b7072ee9ecd59c65f3e57ee6e035917409e,2010-03-12T13:06:08Z,https://github.com/scikit-learn/scikit-learn/commit/8de51b7072ee9ecd59c65f3e57ee6e035917409e,"Refactoring of the bayes module.  Some code is duplicate with the module glm, we should merge all common code.  From: Fabian Pedregosa <fabian.pedregosa@inria.fr>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@517 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8",1,Rename Method,,
78ae432d526634de679253dfbb48c09f0e9c0cf1,2010-01-06T11:13:16Z,https://github.com/scikit-learn/scikit-learn/commit/78ae432d526634de679253dfbb48c09f0e9c0cf1,Rename methods of the Scaler class.  From: cdavid <cdavid@cb17146a-f446-4be1-a4f7-bd7c5bb65646>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@314 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8,1,Rename Method,,
c14e5e085bb3a4604df119aa92ee4e20a0c3a30a,2010-01-05T16:06:00Z,https://github.com/scikit-learn/scikit-learn/commit/c14e5e085bb3a4604df119aa92ee4e20a0c3a30a,Refactor update step for EM (split diag and full case in subfunction)  From: cdavid <cdavid@cb17146a-f446-4be1-a4f7-bd7c5bb65646>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@125 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8,1,Rename Method,,
c4c0ceff096473cb4e47ef2f067640bcdf0b32e0,2023-08-17T16:23:34Z,https://github.com/huggingface/transformers/commit/c4c0ceff096473cb4e47ef2f067640bcdf0b32e0,add util for ram efficient loading of model when using fsdp (#25107)  * add util for ram efficient loading of model when using fsdp  * make fix-copies  * fixes 😅  * docs  * making it further easier to use  * rename the function  * refactor to handle fsdp ram efficiency in `from_pretrained`  * fixes  * fixes  * fixes  * update  * fixes  * revert `load_pretrained_model_only_on_rank0`  * resolve `load_from_checkpoint`,1,Rename Method,,
dc4449918d3d8f1814053d474e88251938513408,2023-06-20T15:54:55Z,https://github.com/huggingface/transformers/commit/dc4449918d3d8f1814053d474e88251938513408,Rename test to be more accurate (#24374),1,Rename Method,,
ac2bc50a10522f15671e351150e03ecd6268da1e,2023-04-18T09:12:30Z,https://github.com/huggingface/transformers/commit/ac2bc50a10522f15671e351150e03ecd6268da1e,"TTS fine-tuning for SpeechT5 (#21824)  * wrong argument name  * append eos_token_id  * all tokenizers need mask and ctc_blank tokens  * remove reduction factor from feature extractor  * add proper TTS loss  * did shifting the wrong way around  * mask out padded portions  * remove logits again (don't really need it)  * fix unit tests  * fixup  * pad also returns the decoder attention mask, since that's useful to have  * clean up feature extractor logic  * pad can handle TTS task too  * remove stop_labels from loss calculation  * simplify logic  * fixup  * do -100 masking properly  * small STFT optimization (calculate mel filterbanks only once)  * replace torchaudio fbanks with audio_utils  * remove torchaudio dependency  * simplify & speed up the STFT  * don't serialize window and mel filters  * output cross attentions when generating speech  * add guided attention loss  * fix failing test  * Update src/transformers/models/speecht5/feature_extraction_speecht5.py  Co-authored-by: Sanchit Gandhi <93869735+sanchit-gandhi@users.noreply.github.com>  * Update src/transformers/models/speecht5/modeling_speecht5.py  Co-authored-by: Sanchit Gandhi <93869735+sanchit-gandhi@users.noreply.github.com>  * change type annotation of attention_mask to LongTensor  * extract loss into class  * remove unused frame_signal_scale argument  * use config object in loss class  * fix type annotations in doc comments  * change optional to just bool  * implement missing tokenizer method  * add deprecation warning  * Update src/transformers/models/speecht5/feature_extraction_speecht5.py  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * Update src/transformers/models/speecht5/feature_extraction_speecht5.py  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * add deprecation warning for stop_labels  ---------  Co-authored-by: Sanchit Gandhi <93869735+sanchit-gandhi@users.noreply.github.com> Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>",1,Rename Method,,
773314ab8070db69cdd07d615108b83259e7415d,2022-09-16T19:01:57Z,https://github.com/huggingface/transformers/commit/773314ab8070db69cdd07d615108b83259e7415d,replace logger.warn by logger.warning (#19068),1,Rename Method,,
780253ce3d7b8f4ea09a92d7dfe8e3a16d549e20,2022-08-18T11:56:27Z,https://github.com/huggingface/transformers/commit/780253ce3d7b8f4ea09a92d7dfe8e3a16d549e20,Rename method to avoid clash with property (#18677),1,Rename Method,,
f47afefb210a120545a5e9745292aaf6c316d246,2022-06-21T15:55:26Z,https://github.com/huggingface/transformers/commit/f47afefb210a120545a5e9745292aaf6c316d246,Use 5e-5 For BigBird PT/Flax equivalence tests (#17780)  * rename to check_pt_flax_outputs  * update check_pt_flax_outputs  * use 5e-5 for BigBird PT/Flax test  Co-authored-by: ydshieh <ydshieh@users.noreply.github.com>,1,Rename Method,,
da2bd2ae968afa768837ee5e72f4f86a4651e59b,2022-06-21T12:23:36Z,https://github.com/huggingface/transformers/commit/da2bd2ae968afa768837ee5e72f4f86a4651e59b,[CodeParrot] Near-deduplication with jaccard similarity (#17054)  * deduplication draft  * update style  * update style test  * dummy test main  * rename modules  * rename functions  * return extremes in deduplicate_clusters  * update style  * cast str for gzip  * update doc string  * time processing  * use dataset map to compute minhash  * fill value for short token  * remove da map method  * update style  * use share object to multiprocess  * update style  * use f-string and minor fix  Co-authored-by: Leandro von Werra <lvwerra@users.noreply.github.com> Co-authored-by: Loubna Ben Allal <44069155+loubnabnl@users.noreply.github.com>  * update style  * use module parameters  * change ds_dedup to ds_filter  * save ds_dedup  * mv test to script tests  * make jaccard threshold a parameter of deduplicate_dataset  * update style  * add doc strings  * update style  * add doc string for DuplicationIndex  * save files into data dir  * update readme  * Update examples/research_projects/codeparrot/README.md  Co-authored-by: Loubna Ben Allal <44069155+loubnabnl@users.noreply.github.com>  * make near deduplication optional  * move near deduplication in README  * Update examples/research_projects/codeparrot/README.md  Co-authored-by: Leandro von Werra <lvwerra@users.noreply.github.com>  * use f string  Co-authored-by: Leandro von Werra <lvwerra@users.noreply.github.com> Co-authored-by: Loubna Ben Allal <44069155+loubnabnl@users.noreply.github.com>,1,Rename Method,,
36d46479934c18eeb83599e75ade685159eb62d4,2022-06-16T15:27:58Z,https://github.com/huggingface/transformers/commit/36d46479934c18eeb83599e75ade685159eb62d4,Refine Bf16 test for deepspeed (#17734)  * Refine BF16 check in CPU/GPU  * Fixes  * Renames,1,Rename Method,,
fea94d6790dcb19294ebcc629cf8191340e8ab4c,2022-04-25T19:12:51Z,https://github.com/huggingface/transformers/commit/fea94d6790dcb19294ebcc629cf8191340e8ab4c,Replace deprecated logger.warn with warning (#16876),1,Rename Method,,
2109afae710f7eb3b33056e61ade09b2dba8cfc4,2022-04-11T16:21:45Z,https://github.com/huggingface/transformers/commit/2109afae710f7eb3b33056e61ade09b2dba8cfc4,Rename the method test_torchscript (#16693)  Co-authored-by: ydshieh <ydshieh@users.noreply.github.com>,1,Rename Method,,
c4deb7b3ae64f6a4bd0e86cdbd3985de4d24b46e,2022-03-30T16:46:51Z,https://github.com/huggingface/transformers/commit/c4deb7b3ae64f6a4bd0e86cdbd3985de4d24b46e,Feature Extractor accepts `segmentation_maps` (#15964)  * feature extractor accepts  * resolved conversations  * added examples in test for ADE20K  * num_classes -> num_labels  * Apply suggestions from code review  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * resolving conversations  * resolving conversations  * removed ADE  * CI  * minor changes in conversion script  * reduce_labels in feature extractor  * minor changes  * correct preprocess for instace segmentation maps  * minor changes  * minor changes  * CI  * debugging  * better padding  * going to update labels inside the model  * going to update labels inside the model  * minor changes  * tests  * removed changes in feature_extractor_utils  * conversation  * conversation  * example in feature extractor  * more docstring in modeling  * test  * make style  * doc  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>,1,Rename Method,,
867f3950fa908632ddb3564873293b620d73c2dc,2022-03-25T13:12:23Z,https://github.com/huggingface/transformers/commit/867f3950fa908632ddb3564873293b620d73c2dc,Rename master to main for notebooks links and leftovers (#16397),1,Rename Method,,
baab5e7cdf04c5b2cd209de4e9af6cb2c51a30d2,2022-03-02T16:13:54Z,https://github.com/huggingface/transformers/commit/baab5e7cdf04c5b2cd209de4e9af6cb2c51a30d2,TF generate refactor - Sample (#15793)  * Add TF logits wrappers   * Add sample method  * add tests for TF logit wrappers  * TF generate sample tests now run on CPU  Co-authored-by: Matt <Rocketknight1@users.noreply.github.com>,1,Rename Method,,
cb7ed6e083365226819cf4d9370c757d5fda1256,2022-02-10T10:18:41Z,https://github.com/huggingface/transformers/commit/cb7ed6e083365226819cf4d9370c757d5fda1256,Add Tensorflow handling of ONNX conversion (#13831)  * Add TensorFlow support for ONNX export  * Change documentation to mention conversion with Tensorflow  * Refactor export into export_pytorch and export_tensorflow  * Check model's type instead of framework installation to choose between TF and Pytorch  Co-authored-by: Lysandre Debut <lysandre@huggingface.co> Co-authored-by: Alberto Bégué <alberto.begue@della.ai> Co-authored-by: lewtun <lewis.c.tunstall@gmail.com>,1,Rename Method,,
7d6285a921a23c06169e2d90c94faa0d92d00d78,2021-07-05T22:49:47Z,https://github.com/huggingface/transformers/commit/7d6285a921a23c06169e2d90c94faa0d92d00d78,[Wav2Vec2] Flax - Adapt wav2vec2 script (#12520)  * fix_torch_device_generate_test  * remove @  * adapt flax pretrain script,1,Rename Method,,
ebe54135890bf06d88609cfbbd26de02f12e387b,2021-06-22T18:13:23Z,https://github.com/huggingface/transformers/commit/ebe54135890bf06d88609cfbbd26de02f12e387b,[trainer] 2 bug fixes and a rename (#12309)  * bug fixes and a rename  * add extended DDP test,1,Rename Method,,
f3558bbcfdfff25abe0137d00f8b4f88fb58eed3,2021-06-18T13:13:45Z,https://github.com/huggingface/transformers/commit/f3558bbcfdfff25abe0137d00f8b4f88fb58eed3,Depreciate pythonic Mish and support PyTorch 1.9 version of Mish (#12240)  * Moved Mish to Torch 1.9 version  * Run black formatting,1,Rename Method,,
2056f26e853574034e426d97e4f803b47f8c7159,2021-06-07T15:41:27Z,https://github.com/huggingface/transformers/commit/2056f26e853574034e426d97e4f803b47f8c7159,Extend pipelines for automodel tupels (#12025)  * fix_torch_device_generate_test  * remove @  * finish  * refactor  * add test  * fix test  * Attempt at simplification.  * Small fix.  * Fixing non existing AutoModel for TF.  * Naming.  * Remove extra condition.  Co-authored-by: patrickvonplaten <patrick.v.platen@gmail.com>,1,Rename Method,,
2c73b9309974bc0157fd5937a495fe5c964199f9,2021-06-04T15:58:23Z,https://github.com/huggingface/transformers/commit/2c73b9309974bc0157fd5937a495fe5c964199f9,[Deepspeed] Assert on mismatches between ds and hf args (#12021)  * wip  * add mismatch validation + test  * renames  * Update docs/source/main_classes/deepspeed.rst  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * renames  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>,1,Rename Method,,
50595a333635cd73c2d10e6135db8ed9201708f3,2021-04-21T16:34:38Z,https://github.com/huggingface/transformers/commit/50595a333635cd73c2d10e6135db8ed9201708f3,Remove boiler plate code (#11340)  * remove boiler plate code  * adapt roberta  * correct docs  * finish refactor,1,Rename Method,,
cd56f3fe7eae4a53a9880e3f5e8f91877a78271c,2021-03-31T14:01:30Z,https://github.com/huggingface/transformers/commit/cd56f3fe7eae4a53a9880e3f5e8f91877a78271c,Merge trainers (#10975)  * Replace is_sagemaker_distributed_available  * Merge SageMakerTrainer into Trainer  * Test with shorter condition  * Put back deleted line  * Deprecate SageMakerTrainer and SageMakerTrainingArguments  * Apply suggestions from code review  Co-authored-by: Philipp Schmid <32632186+philschmid@users.noreply.github.com>  Co-authored-by: Philipp Schmid <32632186+philschmid@users.noreply.github.com>,1,Rename Method,,
6f840990a79d32634c82db534c047a5c4b549df8,2021-03-15T13:11:42Z,https://github.com/huggingface/transformers/commit/6f840990a79d32634c82db534c047a5c4b549df8,"split seq2seq script into summarization & translation (#10611)  * split seq2seq script, update docs  * needless diff  * fix readme  * remove test diff  * s/summarization/translation  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * cr  * fix arguments & better mbart/t5 refs  * copyright  Co-authored-by: Suraj Patil <surajp815@gmail.com>  * reword readme  Co-authored-by: Suraj Patil <surajp815@gmail.com>  * s/summarization/translation  * short script names  * fix tests  * fix isort, include mbart doc  * delete old script, update tests  * automate source prefix  * automate source prefix for translation  * s/translation/trans  Co-authored-by: Stas Bekman <stas00@users.noreply.github.com>  * fix script name (short version)  * typos  Co-authored-by: Stas Bekman <stas00@users.noreply.github.com>  * exact parameter  Co-authored-by: Stas Bekman <stas00@users.noreply.github.com>  * remove superfluous source_prefix calls in docs  * rename scripts & warn for source prefix  * black  * flake8  Co-authored-by: theo <theo@matussie.re> Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com> Co-authored-by: Suraj Patil <surajp815@gmail.com> Co-authored-by: Stas Bekman <stas00@users.noreply.github.com>",1,Rename Method,,
378142afdff17adab48d41d567c7f0100cf7ae23,2020-10-28T17:42:31Z,https://github.com/huggingface/transformers/commit/378142afdff17adab48d41d567c7f0100cf7ae23,Rename add_start_docstrings_to_callable (#8120),1,Rename Method,,
3e31e7f9563debe36620f4a07e0b0cc93c3b736e,2020-10-20T08:39:13Z,https://github.com/huggingface/transformers/commit/3e31e7f9563debe36620f4a07e0b0cc93c3b736e,[testing] rename skip targets + docs (#7863)  * rename skip targets + docs  * fix quotes  * style  * Apply suggestions from code review  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * small improvements  * fix  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>,1,Rename Method,,
61518e2df32e4f540967f2f1fc6f43462287a68d,2020-08-26T22:59:20Z,https://github.com/huggingface/transformers/commit/61518e2df32e4f540967f2f1fc6f43462287a68d,[s2s] run_eval.py QOL improvements and cleanup(#6746),1,Rename Method,,
e983da0e7d91c100e6e35efcb8a69c8cd41d6e09,2020-08-13T08:29:06Z,https://github.com/huggingface/transformers/commit/e983da0e7d91c100e6e35efcb8a69c8cd41d6e09,"cleanup tf unittests: part 2 (#6260)  * cleanup torch unittests: part 2  * remove trailing comma added by isort, and which breaks flake  * one more comma  * revert odd balls  * part 3: odd cases  * more [""key""] -> .key refactoring  * .numpy() is not needed  * more unncessary .numpy() removed  * more simplification",1,Rename Method,,
be1520d3a3c09d729649c49fa3163bd938b6a238,2020-08-11T19:57:07Z,https://github.com/huggingface/transformers/commit/be1520d3a3c09d729649c49fa3163bd938b6a238,rename prepare_translation_batch -> prepare_seq2seq_batch (#6103),1,Rename Method,,
443b0cad96a7fee62ae7c229536f01ddd7f41241,2020-07-13T10:09:49Z,https://github.com/huggingface/transformers/commit/443b0cad96a7fee62ae7c229536f01ddd7f41241,rename the function to match the rest of the test convention (#5692),1,Rename Method,,
d697b6ca751e7727e92d4fa1de35e5e62fd541fa,2020-07-01T15:43:32Z,https://github.com/huggingface/transformers/commit/d697b6ca751e7727e92d4fa1de35e5e62fd541fa,[Longformer] Major Refactor (#5219)  * refactor naming  * add small slow test  * refactor  * refactor naming  * rename selected to extra  * big global attention refactor  * make style  * refactor naming  * save intermed  * refactor functions  * finish function refactor  * fix tests  * fix longformer  * fix longformer  * fix longformer  * fix all tests but one  * finish longformer  * address sams and izs comments  * fix transpose,1,Rename Method,,
c0d9dd3ba96fa4f83a9c3c566dff01d7a0a6608b,2020-03-11T10:06:56Z,https://github.com/huggingface/transformers/commit/c0d9dd3ba96fa4f83a9c3c566dff01d7a0a6608b,refactored code a bit and made more generic,1,Rename Method,,
4f2164e40e803677869865b140b2b3f5a96d4bcd,2019-12-03T15:14:02Z,https://github.com/huggingface/transformers/commit/4f2164e40e803677869865b140b2b3f5a96d4bcd,"First cleanup step, changing function names and passing parameters all the way through without using args. Identical output as before.",1,Rename Method,,
61ed8890052eb628fe969ed440a38ff82577595c,2019-10-08T14:30:58Z,https://github.com/huggingface/transformers/commit/61ed8890052eb628fe969ed440a38ff82577595c,remove old seq2seq file,1,Rename Method,,
bf503158c558d11cf6ab6ce8cf2e91e3e81b479a,2019-09-19T08:55:06Z,https://github.com/huggingface/transformers/commit/bf503158c558d11cf6ab6ce8cf2e91e3e81b479a,Sentence -> Sequence. Removed output_mask from the special token addition methods.,1,Rename Method,,
4d47f4985dfb09237b6e11b5eafb0b1935f8c634,2019-06-26T10:52:44Z,https://github.com/huggingface/transformers/commit/4d47f4985dfb09237b6e11b5eafb0b1935f8c634,"slight refactoring, add abstract class for model loading",1,Rename Method,,
0ac07a2fc45e5613c5f6fa5cfabe5e2e49f555a9,2021-02-05T00:12:37Z,https://github.com/tensorflow/tensorflow/commit/0ac07a2fc45e5613c5f6fa5cfabe5e2e49f555a9,Retire AutoPolicyThis is part of the effort to refactor distributed variables. Auto is somewhatconfusing and adds additional implementation complexity.PiperOrigin-RevId: 355733796Change-Id: I7446c3ed706624178fcb26c9b992632a93b939f6,1,Rename Class,Rename Method,
f196a243eae4b51bff9cc1df033e342d546ebe72,2020-10-16T18:43:26Z,https://github.com/tensorflow/tensorflow/commit/f196a243eae4b51bff9cc1df033e342d546ebe72,"Graduate experimental_hints to options in all_reduce/reduce/batch_reduceThe CollectiveHints class is also renamed to CommunicationOptions. The communication enum is added to it.CommunicationOptions stays experimental since the detailed options may change, but it's rather clear we need an options argument for these cross device communications.PiperOrigin-RevId: 337547832Change-Id: I376171672698d5923b4e52f2567d4a584c8e21b6",1,Rename Class,,
746af76e4f6c00915a1852a24e5a9fecfc8d9d7a,2020-10-14T02:57:19Z,https://github.com/tensorflow/tensorflow/commit/746af76e4f6c00915a1852a24e5a9fecfc8d9d7a,"Refactor collective utils to be of one replicaWe used to have build_collective_* that launches collective on all replicas. However each replica is independent and it can simplify the utils if it only launches on one replica.This is mainly to prepare for switching to Collective V2 ops and reduce the use of merge_call in MirroredStrategy/MultiWorkerMirroredStrategy. For the former, it will be easier after this change. For the latter, we can directly call CollectiveReplicaLauncher.all_reduce from ReplicaContext.all_reduce without the need of merge_call in MS/MWMS.Note that the original CollecticeKeys is outdated. Now instance key is scoped under each group key, and is no longer global.PiperOrigin-RevId: 337007588Change-Id: I111efad0ecbe829260c8e4d2f555c6b2dc1d4c05",1,Rename Class,,
39284c4ebb542a33266c4b1a71f893ebc9bcc533,2020-08-13T18:57:03Z,https://github.com/tensorflow/tensorflow/commit/39284c4ebb542a33266c4b1a71f893ebc9bcc533,rename ListKeys to StackKeys,1,Rename Class,,
ca59e0b5d745970e0c4ffcb07b6586e2b266cc4e,2020-07-07T14:57:14Z,https://github.com/tensorflow/tensorflow/commit/ca59e0b5d745970e0c4ffcb07b6586e2b266cc4e,Slightly refactor the source-to-source translation API to better support non-Python outputs.PiperOrigin-RevId: 319982764Change-Id: I49017145719330596b55b0f9190eccf29a9a46c4,1,Rename Class,,
8fe0c349539a02a043eac289566b479655346914,2020-06-30T00:40:32Z,https://github.com/tensorflow/tensorflow/commit/8fe0c349539a02a043eac289566b479655346914,"Rename generic base class, Make typevar bound to DType",1,Rename Class,,
6acbd6b91236a9b914155a0473158f58fa8a39bd,2020-06-24T02:00:26Z,https://github.com/tensorflow/tensorflow/commit/6acbd6b91236a9b914155a0473158f58fa8a39bd,rename to reorder_data_discarding_ops,1,Rename Class,,
e323183bf62993da23eb52c18944a4670aa5ce53,2019-09-30T21:35:03Z,https://github.com/tensorflow/tensorflow/commit/e323183bf62993da23eb52c18944a4670aa5ce53,"Rename LossScalingGradientTape to LossScaleGradientTape.This makes it more consistent with LossScale and LossScaleOptimizer.Since LossScalingGradientTape is not yet in a stable release, no need to worry about breaking anyone.PiperOrigin-RevId: 272067559",1,Rename Class,,
a50ea28cf5fe08004c88c3eb8a6c9579c5856d9d,2019-07-25T19:01:42Z,https://github.com/tensorflow/tensorflow/commit/a50ea28cf5fe08004c88c3eb8a6c9579c5856d9d,Retire obsolete transformations. The old side effect guards is replaced with the more robust automatic_control_deps. This change also introduces a more generic function-wide context manager that will be used for other state tracking tasks.PiperOrigin-RevId: 259993278,1,Rename Class,,
c5c183971b3cb42b123474e1e8a50a99c930b8db,2019-07-12T21:19:17Z,https://github.com/tensorflow/tensorflow/commit/c5c183971b3cb42b123474e1e8a50a99c930b8db,"[tf.data] `Structure` vs. `TypeSpec` cleanup.This CL:- removes `tf.data.experimental.*Structure` from the V2 API- renames `DatasetStructure` to `DatasetSpec` in the `dataset_ops` module- renames `OptionalStructure` to `OptionalSpec` in the `optional_ops` module- renames `TensorStructure`, `SparseTensorStructure`, `RaggedTensorStructure`, and `TensorArrayStructure` to `_TensorStructure`, `_SparseTensorStructure`, `_RaggedTensorStructure`, and `_TensorArrayStructure` respectively in the `structure` module- replaces all occurrences of `DatasetStructure`, `OptionalStructure`, `TensorStructure`, `SparseTensorStructure`, `RaggedTensorStructure`, and `TensorArrayStructure` with `DatasetSpec`, `OptionalSpec`, `TensorSpec`, `SparseTensorSpec`, `RaggedTensorSpec`, and `TensorArraySpec` respectivelyPiperOrigin-RevId: 257867342",1,Rename Class,,
0e018ac4b9e1a42097e4c16c0f569edf227ecd5e,2019-06-25T04:45:56Z,https://github.com/tensorflow/tensorflow/commit/0e018ac4b9e1a42097e4c16c0f569edf227ecd5e,"Makes the a-normal form transformation in Pyct configurable as to which nodes are converted to variables and which are not.Configuration is sensitive to the type of the node that might be replaced with a variable reference, as well as the type of its parent and the parent's field name for it.  In principle, the user can also define their own predicates for whether to transform or not.PiperOrigin-RevId: 254898808",1,Rename Class,,
3908ff3b2c74c0e7499252cb4796d81f990884e6,2019-04-29T20:12:14Z,https://github.com/tensorflow/tensorflow/commit/3908ff3b2c74c0e7499252cb4796d81f990884e6,Internal cleanupPiperOrigin-RevId: 245809228,1,Rename Class,,
b47498b90e4f776f44040cdf598dc7a1cca0b25a,2019-04-08T17:45:23Z,https://github.com/tensorflow/tensorflow/commit/b47498b90e4f776f44040cdf598dc7a1cca0b25a,"[XLA:Python] Rename LocalBuffer to Buffer. The ""Local"" prefix is confusing given the class can be backed by an XRT buffer.PiperOrigin-RevId: 242491857",1,Rename Class,,
57250b34cc6400bd67de8970daebbc20498476b7,2019-04-01T15:06:07Z,https://github.com/tensorflow/tensorflow/commit/57250b34cc6400bd67de8970daebbc20498476b7,Refactor saved model integration tests so there is a single py_binary as data.PiperOrigin-RevId: 241325783,1,Rename Class,,
4e0f3b2d1cdc3a7623dfc1b3401af50ee4ef1207,2019-03-11T22:40:06Z,https://github.com/tensorflow/tensorflow/commit/4e0f3b2d1cdc3a7623dfc1b3401af50ee4ef1207,Split SavedModel test.PiperOrigin-RevId: 237898655,1,Rename Class,,
72b4dc9de26eac52c267499ab15127c2af29706f,2019-02-25T16:43:07Z,https://github.com/tensorflow/tensorflow/commit/72b4dc9de26eac52c267499ab15127c2af29706f,Rename ReplicaLocalVariable to SyncOnReadVariable.PiperOrigin-RevId: 235536186,1,Rename Class,,
445d52f1b3c22b04e25a44bd289b784eec282929,2019-02-13T17:48:30Z,https://github.com/tensorflow/tensorflow/commit/445d52f1b3c22b04e25a44bd289b784eec282929,"[XLA:Python] Rename CompiledLocalComputation/CompiledXrtComputation to LocalExecutable/XrtExecutable. Rename LocalComputation* to Computation* (there is nothing Local about it any more).Split the two roles of the Python LocalComputation class into Computation (an uncompiled computation that can be compiled) and Executable (a compiled computation that can be executed).While in principle this is a significant API change, in practice JAX (the only known user) does not refer to any of these classes by name.PiperOrigin-RevId: 233772418",1,Rename Class,,
10b4e7755c9c3c94cc9adc2d0bd0ffe975d718d7,2019-01-10T06:08:58Z,https://github.com/tensorflow/tensorflow/commit/10b4e7755c9c3c94cc9adc2d0bd0ffe975d718d7,Rename PolymorphicFunction to Function,1,Rename Class,,
07b238033996f813381f1e1a0410c877c13c6c94,2019-01-10T04:41:40Z,https://github.com/tensorflow/tensorflow/commit/07b238033996f813381f1e1a0410c877c13c6c94,Rename Function to ConcreteFunction,1,Rename Class,,
f84227cac2abe03818cecd80ac02b86b8090e376,2018-12-21T23:41:01Z,https://github.com/tensorflow/tensorflow/commit/f84227cac2abe03818cecd80ac02b86b8090e376,Rename test,1,Rename Class,,
04e95d6b4c67920cc7e442b89a150a88b86fea08,2018-11-26T23:36:50Z,https://github.com/tensorflow/tensorflow/commit/04e95d6b4c67920cc7e442b89a150a88b86fea08,[tf.data] Test and benchmark cleanup.PiperOrigin-RevId: 222899136,1,Rename Class,,
5b61eed60089e1b28093ecc180034bc7ca307e3a,2018-11-15T04:23:35Z,https://github.com/tensorflow/tensorflow/commit/5b61eed60089e1b28093ecc180034bc7ca307e3a,"[tf.data] Duplicate the internal `Dataset` class into `DatasetV1` and `DatasetV2`.The implementation of `tf.data.Dataset` now depends on the version ofTensorFlow: in 1.x we export `DatasetV1` and in 2.x we export `DatasetV2`.Currently, the internal `dataset_ops.Dataset` symbol maps to `DatasetV1`, butthis will change after all internal tests are updated to 2.x compatibility.This change also removes the deprecated `Dataset.from_sparse_tensor_slices()`method from `DatasetV2`, since its replacement has long been available in`Dataset.from_tensor_slices()`.PiperOrigin-RevId: 221560852",1,Rename Class,,
0359d0dd15980a8f564ea045783b802e84bf3c56,2018-11-06T07:01:16Z,https://github.com/tensorflow/tensorflow/commit/0359d0dd15980a8f564ea045783b802e84bf3c56,"Consolidate summary V1 python op definitions and testsWith this change, tensorflow/python/summary/summary.py contains all the existing python op definitions.  Tests remain split with summary_test.py in the same directory testing the API and separate (newly v1-named) tests in tensorflow/python/kernel_tests to test the serialized proto formats.PiperOrigin-RevId: 220230494",1,Rename Class,,
a6478312ef296ba9684931135851e9c7bb460444,2018-10-01T17:36:07Z,https://github.com/tensorflow/tensorflow/commit/a6478312ef296ba9684931135851e9c7bb460444,Replace the tf.name_scope call with an internal context manager that can contain additional boilerplate later on. Unfortunately it could not be extended to include the error handling.PiperOrigin-RevId: 215238369,1,Rename Class,,
85258e06edf424492905fd032b02ff4d420b9da1,2018-09-27T02:28:14Z,https://github.com/tensorflow/tensorflow/commit/85258e06edf424492905fd032b02ff4d420b9da1,Rename TocoConverter to TFLiteConverter.PiperOrigin-RevId: 214710175,1,Rename Class,,
3c83ef9fbc8dc23ab0878cffa13ecbfd07ac70e5,2018-08-14T06:08:15Z,https://github.com/tensorflow/tensorflow/commit/3c83ef9fbc8dc23ab0878cffa13ecbfd07ac70e5,CLN: rename UnsafeDiv => DivNoNan,1,Rename Class,,
209efdd2bcc4d7f0d5aeda77fb11f04c37d484e6,2018-08-01T05:40:31Z,https://github.com/tensorflow/tensorflow/commit/209efdd2bcc4d7f0d5aeda77fb11f04c37d484e6,Rename coordinator context to worker context.PiperOrigin-RevId: 206882388,1,Rename Class,,
162304f9da4114f5ed3f0e4c27929413e7abc965,2018-07-22T19:48:00Z,https://github.com/tensorflow/tensorflow/commit/162304f9da4114f5ed3f0e4c27929413e7abc965,[tf.data / Bigtable] Renamed BigTable class to BigtableTable for clarityThis removes the confusion between BigTable and Bigtable naming. Also cleanedup all other uses of BigTable in error messages.PiperOrigin-RevId: 205586899,1,Rename Class,,
7b71b0cfd9f7b4ceb17295cba5b651a04764c37b,2018-02-27T21:20:03Z,https://github.com/tensorflow/tensorflow/commit/7b71b0cfd9f7b4ceb17295cba5b651a04764c37b,"Checkpointable: Move the checkpoint-grouping utility out of the unit test fileRenames Saver -> CheckpointableSaver in preparation for exposing the necessarysymbols in tf.contrib.eager.There's a pending change for Optimizers, and Asim is handling Layers/Model. Oncethose are checked in, we should be able to save/restore everything in the eagerexamples (or at least the mnist one...). Still plenty more to makeCheckpointable, but it should be usable at that point.PiperOrigin-RevId: 187221803",1,Rename Class,,
6898a5689083fb9e78d02a0d3a66595f8c41729f,2018-02-12T22:37:41Z,https://github.com/tensorflow/tensorflow/commit/6898a5689083fb9e78d02a0d3a66595f8c41729f,Rename op name in comments to reflect renamed op names. NFC.PiperOrigin-RevId: 185437550,1,Rename Class,,
3b354016e9e23edc28bd4ca78f8714fdb006760e,2017-10-04T19:47:05Z,https://github.com/tensorflow/tensorflow/commit/3b354016e9e23edc28bd4ca78f8714fdb006760e,Rename SavedModelExporter to LatestExporter.PiperOrigin-RevId: 171048345,1,Rename Class,,
d4a55893b53e0a78c1c0a99c2e21b1d1b30e8932,2017-08-22T02:33:25Z,https://github.com/tensorflow/tensorflow/commit/d4a55893b53e0a78c1c0a99c2e21b1d1b30e8932,Change CudnnCompatibleLSTMCell to wrap LSTMBlockCell* Remove old CudnnCompatbileLSTMCell* Rename old CudnnCOmpatibileLSTMBLockCell to CudnnCompatbileLSTMCell* Move the classes up.PiperOrigin-RevId: 166009408,1,Rename Class,,
4f54336348fb40fb5eea2166b949f4457f447ef5,2017-07-12T19:59:50Z,https://github.com/tensorflow/tensorflow/commit/4f54336348fb40fb5eea2166b949f4457f447ef5,Rename TpuEstimator to TPUEstimator and TpuConfig to TPUConfig to follow PEP8naming conventions.PiperOrigin-RevId: 161704561,1,Rename Class,,
8cc451c2a599ab0ce127875832c20e0155553a9d,2017-03-27T21:48:35Z,https://github.com/tensorflow/tensorflow/commit/8cc451c2a599ab0ce127875832c20e0155553a9d,[contrib seq2seq] Rename DynamicAttentionWrapper to AttentionWrapperChange: 151374177,1,Rename Class,,
b083c1b69ca681a43e83b808791694439e12d1b6,2017-03-15T00:47:06Z,https://github.com/tensorflow/tensorflow/commit/b083c1b69ca681a43e83b808791694439e12d1b6,Rename DynamicAttentionCellWrapper to just DynamicAttentionWrapper.Change: 150138792,1,Rename Class,,
5f600c2b1daa004d45b4d63df112f85be1ee5e4b,2017-02-10T03:21:29Z,https://github.com/tensorflow/tensorflow/commit/5f600c2b1daa004d45b4d63df112f85be1ee5e4b,"Refactor some code in the new seq2seq api:1. Rename samplers to helpers and move them to helper.py.2. Remove the redundant name ""Basic"" from all helpers' names.3. Rename SamplingDecoder to BasicDecoder.Change: 147112283",1,Rename Class,,
240761bf55d4e69c343dd7906e45a11844edfb03,2016-12-21T18:25:49Z,https://github.com/tensorflow/tensorflow/commit/240761bf55d4e69c343dd7906e45a11844edfb03,Rename SyncReplicasOptimizerV2 to SyncReplicasOptimizerChange: 142676422,1,Rename Class,,
3cd41cf72a998ac800f91e1dc507e4e8638330ab,2016-11-09T00:54:57Z,https://github.com/tensorflow/tensorflow/commit/3cd41cf72a998ac800f91e1dc507e4e8638330ab,Rename tf.Tensor to tf.Output- Swap the alias direction and fix tests broken by the swap- Export Output in tensorflow.__all__Change: 138583261,1,Rename Class,,
3834227d9f63a0dcab2d08e1b6d5c284c670e5dd,2016-10-10T16:32:23Z,https://github.com/tensorflow/tensorflow/commit/3834227d9f63a0dcab2d08e1b6d5c284c670e5dd,Remove a public notion of BaseDistribution.Change: 135684199,1,Rename Class,,
892deb2d7816af281b57a73a095886f75a259266,2016-09-13T16:20:37Z,https://github.com/tensorflow/tensorflow/commit/892deb2d7816af281b57a73a095886f75a259266,"1. Rename batch_matrix_* ops to matrix_*. Specifically, this applies tobatch_matrix_band_partbatch_matrix_diagbatch_matrix_diag_partbatch_matrix_set_diagbatch_matrix_transpose2. Improve organization of the list of math ops a bit.Change: 133007928",1,Rename Class,,
b9e62874c6d220cbfa8607692f059b2f579f4a71,2016-08-31T19:42:05Z,https://github.com/tensorflow/tensorflow/commit/b9e62874c6d220cbfa8607692f059b2f579f4a71,Rename sum_of_squares to mean_squared_error. Ditto for pairwise version.Change: 131861030,1,Rename Class,,
b4f549761e066b0a3bef05174076ebb565bcde18,2016-08-12T06:26:16Z,https://github.com/tensorflow/tensorflow/commit/b4f549761e066b0a3bef05174076ebb565bcde18,Rename LSTMFusedCell to LSTMBlockCellChange: 130072031,1,Rename Class,,
208774482d1e041e874b768e27af93f42e199958,2016-06-12T04:46:33Z,https://github.com/tensorflow/tensorflow/commit/208774482d1e041e874b768e27af93f42e199958,Bayesflow: minor cleanups of the stochastic graph API for accuracy.Change: 124658385,1,Rename Class,Rename Method,
1db1272f7d75131559fa15cc5013ff46735f9c58,2016-05-25T22:25:35Z,https://github.com/tensorflow/tensorflow/commit/1db1272f7d75131559fa15cc5013ff46735f9c58,Rename tf.contrib.distributions.Gaussian -> tf.contrib.distributions.NormalChange: 123260073,1,Rename Class,Rename Method,
b3470493f49f1232ed51435c607c09b26f87cc57,2016-04-25T19:49:30Z,https://github.com/tensorflow/tensorflow/commit/b3470493f49f1232ed51435c607c09b26f87cc57,"Expose DeviceSpec class in the Python framework API.* Rename Device to DeviceSpec to avoid confusion with tf.device.* Move tensorflow.python.framework.device.from_string helper function to be a staticmethod of DeviceSpec.This allows Python code to check the validity of device specs, canonicalize them, merge them, etc.Change: 120736225",1,Rename Class,,
9edd13a9c96edd9b7fdca71f694bb045f265ad66,2016-01-06T20:55:10Z,https://github.com/tensorflow/tensorflow/commit/9edd13a9c96edd9b7fdca71f694bb045f265ad66,Rename deconv2d to conv2d_transpose and expose publiclydeconv2d is a misleading name for an operation which is exactly the transposeof conv2d.  conv2d_transpose is much better.Fixes #256.Change: 111529902,1,Rename Class,Rename Method,
fbe7873fc0f43090e2df52b85867b8b6179516ca,2017-02-28T17:04:00Z,https://github.com/keras-team/keras/commit/fbe7873fc0f43090e2df52b85867b8b6179516ca,sum -> add,1,Rename Class,,
38a6dae44a507d816d5cdb0fb2f3329f21ad9f2b,2017-02-28T02:51:43Z,https://github.com/keras-team/keras/commit/38a6dae44a507d816d5cdb0fb2f3329f21ad9f2b,Multiply -> Product (#5546)  * Multiply -> Product  * Update merge_test.py  * Update merge.py  * Update merge_test.py  * Update merge.py  * Update merge.py,1,Rename Class,,
313ebae4d2db59d1ac202b82284e496e5756aa47,2015-12-08T06:28:05Z,https://github.com/keras-team/keras/commit/313ebae4d2db59d1ac202b82284e496e5756aa47,renaming mean -> average pooling,1,Rename Class,,
044d00516ccd6572c0d6ab6d54587155b02a3b86,2018-11-07T19:56:09Z,https://github.com/pytorch/pytorch/commit/044d00516ccd6572c0d6ab6d54587155b02a3b86,"Rename DistBackend -> Backend (#11830)Summary:Also add docs for get_backend, Backend, and reduce_opfixes #11803cc The controller you requested could not be found. pietern apaszkePull Request resolved: https://github.com/pytorch/pytorch/pull/11830Differential Revision: D9927991Pulled By: SsnLfbshipit-source-id: a2ffb70826241ba84264f36f2cb173e00b19af48",1,Rename Class,,
15758bca55bb4c1e5804e6dc08524b749938c45f,2020-06-17T00:17:32Z,https://github.com/pytorch/pytorch/commit/15758bca55bb4c1e5804e6dc08524b749938c45f,"Refactor LSTM tests, [Remove randomness in weights] (#40101)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/40101Create three tests for LSTMs:1. test_qlstm: Test to check numerics of quantized LSTM operator.2. test_lstm_api: To check the LSTM module and compareit with the quantized LSTM op3. test_quantized_rnn: Check the dynamic quantization workflow, scriptability and serialization of quantizedLSTMghstack-source-id: 105997268(Note: this ignores all push blocking failures!)Test Plan:buck test caffe2/test:quantization -- 'test_lstm_api \(quantization\.test_quantized_module\.TestDynamicQuantizedModule\)' --print-passing-detailsbuck test caffe2/test:quantization -- 'test_quantized_rnn \(quantization\.test_quantize\.TestPostTrainingDynamic\)'buck test caffe2/test:quantization -- 'test_qlstm \(quantization\.test_quantized_op\.TestDynamicQuantizedRNNOp\)' --print-passing-detailsDifferential Revision: D22070826fbshipit-source-id: 46c333e19b9eab8fa5cab6f132e89b80a635791a",1,Rename Class,,
162ef02db6a2f9ff3a7de4e6c4a3f3a36752bb91,2019-10-02T20:59:28Z,https://github.com/pytorch/pytorch/commit/162ef02db6a2f9ff3a7de4e6c4a3f3a36752bb91,"Rename distributed autograd test to avoid ""test"" prefix (#27161)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/27161If the base class starts with ""Test"", pytest would detect it as atest class to run. However, the base class does not have a proper`setUp` method to launch processes. As a result, when I executethe following command, I run into test failures:py.test test_dist_autograd_fork.py -k test -vsoutputs:```test/test_dist_autograd_fork.py::TestDistAutograd::test_autograd_context FAILEDtest/test_dist_autograd_fork.py::TestDistAutograd::test_autograd_send_function FAILEDtest/test_dist_autograd_fork.py::TestDistAutograd::test_rpc_complex_args FAILEDtest/test_dist_autograd_fork.py::DistAutogradTestWithFork::test_autograd_context PASSEDtest/test_dist_autograd_fork.py::DistAutogradTestWithFork::test_autograd_send_function PASSEDtest/test_dist_autograd_fork.py::DistAutogradTestWithFork::test_rpc_complex_args PASSED```Test Plan: Imported from OSSDifferential Revision: D17694165Pulled By: mrshenlifbshipit-source-id: 0b8fcb99c76b5139b765831079f083c3122f618a",1,Rename Class,,
1fb2abc7ad7af65fc4fcaa549ce695a580a68054,2021-04-14T15:59:38Z,https://github.com/pytorch/pytorch/commit/1fb2abc7ad7af65fc4fcaa549ce695a580a68054,"ns for fx: rename SugraphTypeRelationship to SubgraphTypeRelationship (#55155)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/55155Fixes typo in enum name, no logic changeTest Plan:CIImported from OSSReviewed By: jerryzh168Differential Revision: D27504625fbshipit-source-id: 21605dadb48225987f1da5ad5f6c30b0183278f2",1,Rename Class,,
230b68168b6ab5e6496a8425bceef1dbe576d45d,2020-04-23T17:19:55Z,https://github.com/pytorch/pytorch/commit/230b68168b6ab5e6496a8425bceef1dbe576d45d,[quant] Refactor test files (#36964)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/36964Rename and restructure quantization related testshttps://github.com/pytorch/pytorch/issues/31625Test Plan:.Imported from OSSDifferential Revision: D21192509fbshipit-source-id: 148c93e86e0ea68ab18a067fe74a8035a29a1e4e,1,Rename Class,,
4011597dd4d6070d02a92d18e237debc0d65e922,2022-12-08T15:32:36Z,https://github.com/pytorch/pytorch/commit/4011597dd4d6070d02a92d18e237debc0d65e922,"[Composable API] Refactor `test_fully_shard.py` to use common models (#90386)  Unlike for FSDP, where we already diverged to using per-test-file models, let us try to use the same set of models for the composable API effort. This can improve debugging efficiency because we know which module structures we support and which we do not _across all of our composable APIs_.  This PR had to perform some surgery for `test_materialize_meta_module`. Writing a correct parameter initialization function for meta device initialization is not easy, and we should revisit this. The old implementation, which followed the style of the previous unit tests--namely, using `module.to_empty()`--is actually incorrect for nested FSDP applications because `module.to_empty()` will re-initialize already materialized parameters and the module materialization proceeds bottom up. The existing unit test in `test_fsdp_meta.py` passes because it sets every parameter to ones (`self.weight.fill_(1)`), which is idempotent to re-initialization. Pull Request resolved: https://github.com/pytorch/pytorch/pull/90386 Approved by: https://github.com/mrshenli",1,Rename Class,,
47c57e8804318d4de5cf3c7a224ed84de947c7f5,2020-07-22T20:33:46Z,https://github.com/pytorch/pytorch/commit/47c57e8804318d4de5cf3c7a224ed84de947c7f5,rename TestFuser to TestTEFuser (#41542)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/41542Reviewed By: jamesr66aDifferential Revision: D22579606Pulled By: Krovatkinfbshipit-source-id: f65b2cae996b42d55ef864bc0b424d9d43d8a2e2,1,Rename Class,,
4858a6bc6fcd71d9af4ce956a3b6a58b01889fd2,2016-12-13T22:50:46Z,https://github.com/pytorch/pytorch/commit/4858a6bc6fcd71d9af4ce956a3b6a58b01889fd2,"snapshot -> checkpointSummary:This renames the ""Snapshot"" op name to ""Checkpoint"" as we discussed earlier.The early Snapshot name is still available, but we should move to the new name andeventually deprecate the old name.The Python SnapshotManager should be also changed, cc azzoliniReviewed By: dzhulgakovDifferential Revision: D4272021fbshipit-source-id: 4b8e029354416530dfbf0d538bfc91a0f61e0296",1,Rename Class,,
5973b44d9e6db0cfeab9bd6254106a38058cf1e7,2020-09-03T17:26:53Z,https://github.com/pytorch/pytorch/commit/5973b44d9e6db0cfeab9bd6254106a38058cf1e7,Rename NewCriterionTest to CriterionTest. (#44056)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/44056Test Plan: Imported from OSSReviewed By: zou3519Differential Revision: D23482573Pulled By: gchananfbshipit-source-id: dde0f1624330dc85f48e5a0b9d98fb55fdb72f68,1,Rename Class,,
5d34b7955bd3b0b1f1412ba8dafc3979c9314c53,2021-07-02T18:12:30Z,https://github.com/pytorch/pytorch/commit/5d34b7955bd3b0b1f1412ba8dafc3979c9314c53,[sparsity][refactor] Changing linear row/col control (#60850)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/60850  Test Plan: ``` python test/test_ao_sparsity.py ```  ``` python test/test_ao_sparsity.py ```  Differential Revision: D29465900 D29465900  Reviewed By: raghuramank100  Pulled By: z-a-f  fbshipit-source-id: 412f50da857f377898fea79d378ae54a049b81fe,1,Rename Class,,
655f1ea176c25dda88e96ffb05e4d84df7d0257d,2020-06-16T07:39:47Z,https://github.com/pytorch/pytorch/commit/655f1ea176c25dda88e96ffb05e4d84df7d0257d,"Refactor LSTM tests (#38851)Summary:Create three tests for LSTMs:1. test_qlstm: Test to check numerics of quantized LSTM operator.2. test_lstm_api: To check the LSTM module and compareit with the quantized LSTM op3. test_quantized_rnn: Check the dynamic quantization workflow, scriptability and serialization of quantizedLSTMPull Request resolved: https://github.com/pytorch/pytorch/pull/38851ghstack-source-id: 105945574(Note: this ignores all push blocking failures!)Test Plan:buck test caffe2/test:quantization -- 'test_lstm_api \(quantization\.test_quantized_module\.TestDynamicQuantizedModule\)' --print-passing-detailsbuck test caffe2/test:quantization -- 'test_quantized_rnn \(quantization\.test_quantize\.TestPostTrainingDynamic\)'buck test caffe2/test:quantization -- 'test_qlstm \(quantization\.test_quantized_op\.TestDynamicQuantizedRNNOp\)' --print-passing-detailsDifferential Revision: D21628596fbshipit-source-id: 4aeda899f2e5f14bfbe3d82096cb4ce89c725fa1",1,Rename Class,,
76307667ca864ff59fbe4821d1f6086312203780,2019-04-26T00:55:50Z,https://github.com/pytorch/pytorch/commit/76307667ca864ff59fbe4821d1f6086312203780,"Use the QTensor with QReLU (#19312)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/19312Replaces the tuple hack with the QTensor. Please, note this can be landed ONLY after #18960 (D14810261) is landed.Reviewed By: raghuramank100Differential Revision: D14819460fbshipit-source-id: 75ca649304b1619cb3cfe845962c9f226b8f884a",1,Rename Class,,
7961812c4d497f47833948b70f3ade47973c637e,2023-05-05T21:29:05Z,https://github.com/pytorch/pytorch/commit/7961812c4d497f47833948b70f3ade47973c637e,Rename ForceInPlace to InPlaceHint. (#99764)  The name makes more sense since it's a hint to scheduler.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/99764 Approved by: https://github.com/wanchaol,1,Rename Class,,
853112bbfc05d2295c3f8f735648c00aeba506e5,2021-04-21T22:57:07Z,https://github.com/pytorch/pytorch/commit/853112bbfc05d2295c3f8f735648c00aeba506e5,[7/n] [torch/elastic] Rename _Rendezvous to _RendezvousState (#56535)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/56535This PR renames the `_Rendezvous` class to `_RendezvousState` in preparation of the upcoming changes.ghstack-source-id: 126979138Test Plan: Run the existing unit tests.Reviewed By: H-HuangDifferential Revision: D27889894fbshipit-source-id: 027d26aa5e1acd5bba3ad2e58b140428a4a176b2,1,Rename Class,,
a6a31bcd47094ecaa3a0a44644b86db985a051a3,2020-06-30T15:16:32Z,https://github.com/pytorch/pytorch/commit/a6a31bcd47094ecaa3a0a44644b86db985a051a3,Enable `out_dims` for vmap frontend API (#40576)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/40576`out_dims` specifies where in the output tensors the vmapped dimensionshould appear. We implement this by simply creating a view with thebatch dimension moved to the desired position.`out_dims` must either:- be int (use the same value for all outputs)- be Tuple[int] (so the user specifies one out_dim per output).(See the vmap docstring for what we advertise out_dims to do).I also renamed `TestVmap` to `TestVmapAPI` to make it clearer that weare testing the API here and not specific operators (which will go intotheir own test class).Test Plan: - `pytest test/test_vmap.py -v`Differential Revision: D22288086Pulled By: zou3519fbshipit-source-id: c8666cb1a0e22c54473d8045477e14c2089167cf,1,Rename Class,,
bef6e45f8b36924b383c02118d1f30f70675c3c4,2017-04-23T10:23:37Z,https://github.com/pytorch/pytorch/commit/bef6e45f8b36924b383c02118d1f30f70675c3c4,rename ModelHelperBaseSummary:rename ModelHelperBase to Model.This is the result of running:  find . -type f -exec sed -i 's/ModelHelperBase/ModelHelper/g' {} +We had 19 results when fbgs ModelHelperBase. Here is 20 instances because I added 1 test in model_helpers_test.pyReviewed By: salexspbDifferential Revision: D4928337fbshipit-source-id: bc4c12b60b90c167e717de50ea9fe17521e142e3,1,Rename Class,,
c1e2fa8189ee1df58d0131b14758353c51064305,2023-04-22T05:39:20Z,https://github.com/pytorch/pytorch/commit/c1e2fa8189ee1df58d0131b14758353c51064305,"[dtensor] add StrategyType and TupleStrategy (#99435)  This PR refactors the current StrategyList. It introduces a StrategyType, which is the base class of Strategy, and it have two sub strategies:  1. Refactor the previous StrategyList to OpStrategy 2. Add TupleStrategy, the new strategy added to deal with tuple cases where it could return multiple different OpStrategy for an op.  This would help support a more complicated op and unblocks compile mode FSDP Pull Request resolved: https://github.com/pytorch/pytorch/pull/99435 Approved by: https://github.com/mrshenli",1,Rename Class,,
f6739ec8e8f9e6355e29a6df93ed20aa05e4b8a6,2020-06-17T20:38:51Z,https://github.com/pytorch/pytorch/commit/f6739ec8e8f9e6355e29a6df93ed20aa05e4b8a6,"[quant][graphmode] Refactor dynamic quant tests (#40127)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/40127Reland PR.Similar to static quant, break it up into op level tests and tests for jit passesTest Plan:python test/test_quantization.py TestQuantizeScriptPTDQOpspython test/test_quantization.py TestDynamicQuantizeScriptJitPassesImported from OSSDifferential Revision: D22081259fbshipit-source-id: cef8f78f89ef8789683b52508379ae1b9ad00700",1,Rename Class,Move Method,
fa4c77e39bb387a3378380ca7a5b0a01051fbf95,2023-03-24T05:04:02Z,https://github.com/pytorch/pytorch/commit/fa4c77e39bb387a3378380ca7a5b0a01051fbf95,"Rename PyOperator to HigherOrderOperator (#97493)  Twice this week I have had people confuse ""operator defined with Python operator registration aka torch.library"" and ""PyOperator which is used to define control flow operators and other operators that cannot be represented in JIT schema.""  Renaming PyOperator for clarity.  Signed-off-by: Edward Z. Yang <ezyang@meta.com>  Pull Request resolved: https://github.com/pytorch/pytorch/pull/97493 Approved by: https://github.com/SherlockNoMad",1,Rename Class,,
ff454cc4290c0940171ff0c1a79f9273c8d01c99,2020-08-21T21:51:47Z,https://github.com/pytorch/pytorch/commit/ff454cc4290c0940171ff0c1a79f9273c8d01c99,[quant][grapphmode][fx][test][refactor] Refactor quantized add test (#43372)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/43372So that adding more binary op tests are easierTest Plan: Imported from OSSReviewed By: z-a-fDifferential Revision: D23257046fbshipit-source-id: 661acd4c38abdc892c9db8493b569226b13e0d0d,1,Rename Class,,
d916cf05d467e8ae1a2faee66d5224a962713ab5,2020-04-10T02:16:15Z,https://github.com/pytorch/pytorch/commit/d916cf05d467e8ae1a2faee66d5224a962713ab5,[quant][test] Split TestQuantizeScript to two TestCase (#36354)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/36354TestQuantizeScript is splitted to- TestQuantizeScriptJitPasses- TestQuantizeScriptPTSQOps (post training static quantization ops)Test Plan:.Imported from OSSDifferential Revision: D20956731fbshipit-source-id: 860cd24ea3f49450126ce2d872894492bdc822d8,1,Rename Class,,
ddeaa743826779814957224c39ab71ef3bfd8d03,2020-06-16T20:12:56Z,https://github.com/pytorch/pytorch/commit/ddeaa743826779814957224c39ab71ef3bfd8d03,"[quant][graphmode] Refactor dynamic quant tests (#40039)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/40039Similar to static quant, break it up into op level tests and tests for jit passesTest Plan:python test/test_quantization.py TestQuantizeScriptPTDQOpspython test/test_quantization.py TestDynamicQuantizeScriptJitPassesImported from OSSDifferential Revision: D22071278fbshipit-source-id: 54292addcfbc00f7af960fb333921db2ff9fda04",1,Rename Class,Extract Class,
07f6586695f4a8cfe038d5e8f22b2591fe240071,2023-07-25T16:30:37Z,https://github.com/scikit-learn/scikit-learn/commit/07f6586695f4a8cfe038d5e8f22b2591fe240071,MNT SLEP6 move common metadata routing test objects (#26894),1,Rename Class,,
5b45d1fa7faad53db1a0fac9b15d23cb22375031,2022-10-13T17:16:49Z,https://github.com/scikit-learn/scikit-learn/commit/5b45d1fa7faad53db1a0fac9b15d23cb22375031,MAINT `PairwiseDistancesReduction`: Rename some symbols and files (#24623)  Co-authored-by: Olivier Grisel <olivier.grisel@ensta.org> Co-authored-by: Thomas J. Fan <thomasjpfan@gmail.com>,1,Rename Class,,
6ab950ec081044a1f32c2d082772635bb56144d8,2022-03-09T10:50:25Z,https://github.com/scikit-learn/scikit-learn/commit/6ab950ec081044a1f32c2d082772635bb56144d8,MNT Refactor KMeans and MiniBatchKMeans to inherit from a common base class (#22723)  Co-authored-by: Thomas J. Fan <thomasjpfan@gmail.com> Co-authored-by: Julien Jerphanion <git@jjerphan.xyz>,1,Rename Class,,
93382cc41fb95abbbf534aed4c4cf2405c38d601,2018-06-22T08:01:39Z,https://github.com/scikit-learn/scikit-learn/commit/93382cc41fb95abbbf534aed4c4cf2405c38d601,Rename `MICEImputer` to `ChainedImputer` (#11314),1,Rename Class,,
63a2f0a02bf155b161704da57a961c348f29fd7b,2018-02-20T00:59:52Z,https://github.com/scikit-learn/scikit-learn/commit/63a2f0a02bf155b161704da57a961c348f29fd7b,MAINT Rename GraphLasso to GraphicalLasso (#10078),1,Rename Class,,
1578eddef469927ef40ffe3f6936e47c9ed22d23,2016-09-14T01:11:04Z,https://github.com/scikit-learn/scikit-learn/commit/1578eddef469927ef40ffe3f6936e47c9ed22d23,TST move test naming and use inspect,1,Rename Class,Move Class,
a7d748b1defe944aefb3a2214a1b46b4ec2db376,2016-08-26T02:34:33Z,https://github.com/scikit-learn/scikit-learn/commit/a7d748b1defe944aefb3a2214a1b46b4ec2db376,Rename `TimeSeriesCV` to `TimeSeriesSplit` (#7245)  * rename TimeSeriesCV to TimeSeriesSplit  * Add TimeSeriesSplit  * Add whats new,1,Rename Class,,
cf7bc7b035efaefea7dc523e814a65cc3d0c5514,2015-09-07T07:56:19Z,https://github.com/scikit-learn/scikit-learn/commit/cf7bc7b035efaefea7dc523e814a65cc3d0c5514,"ENH: rename to LabelKFold  COSMIT: doc, pep8, etc  Refactor code",1,Rename Class,,
9d14f7352e6579b39512d5ce9545e070aafd5ab3,2015-08-03T15:45:16Z,https://github.com/scikit-learn/scikit-learn/commit/9d14f7352e6579b39512d5ce9545e070aafd5ab3,ENH: Renames CallableTransformer -> FunctionTransformer.  Makes `pass_y` an argument to FunctionTransformer to indicate that the labels should be passed to the wrapped function.,1,Rename Class,,
62325cbb58130c1b1fcf999083e184b4359732cb,2015-06-08T11:07:03Z,https://github.com/scikit-learn/scikit-learn/commit/62325cbb58130c1b1fcf999083e184b4359732cb,MAINT merge _check_cv into check_cv as indices argument is removed in 0.17,1,Rename Class,,
a21957e85ce9978b60b22748beffe84dfddc0b4e,2014-12-29T16:36:25Z,https://github.com/scikit-learn/scikit-learn/commit/a21957e85ce9978b60b22748beffe84dfddc0b4e,rename ensure_symmetric -> test_symmetric,1,Rename Class,,
47f58d4212cca050df33d592b34288993ce5e955,2013-11-25T21:35:05Z,https://github.com/scikit-learn/scikit-learn/commit/47f58d4212cca050df33d592b34288993ce5e955,rename GBM_MSE to FriedmanMSE add friedman_mse to regression criterions in tree.py,1,Rename Class,,
c2a2bfe45b16bf6cca9055674b8b68da57af8ead,2013-10-20T13:58:04Z,https://github.com/scikit-learn/scikit-learn/commit/c2a2bfe45b16bf6cca9055674b8b68da57af8ead,Rename RANSAC to RANSACRegressor,1,Rename Class,,
f95502df456fd2510687463d68de3d5a1d073d50,2013-08-25T09:33:38Z,https://github.com/scikit-learn/scikit-learn/commit/f95502df456fd2510687463d68de3d5a1d073d50,API: rename to agglomerative clustering,1,Rename Class,,
4333ec7762ee83f3e9d7c30ea7347095236e5425,2013-08-25T09:28:33Z,https://github.com/scikit-learn/scikit-learn/commit/4333ec7762ee83f3e9d7c30ea7347095236e5425,API: rename to agglomerative clustering,1,Rename Class,,
6789f59fe053ecd8fb68a509cef84bdef8939ffb,2013-07-25T17:19:25Z,https://github.com/scikit-learn/scikit-learn/commit/6789f59fe053ecd8fb68a509cef84bdef8939ffb,Clean up and rename Hungarian algorithm,1,Rename Class,,
0eb5c0658e9c1ca568bc901a99ab0739de9dade6,2013-07-25T17:19:16Z,https://github.com/scikit-learn/scikit-learn/commit/0eb5c0658e9c1ca568bc901a99ab0739de9dade6,split spectral biclustering into two classes,1,Rename Class,,
2d86899f0e85893f40a1c7aae2c1fee668c4a85a,2013-07-24T15:27:19Z,https://github.com/scikit-learn/scikit-learn/commit/2d86899f0e85893f40a1c7aae2c1fee668c4a85a,ENH Rename RestrictedBolzmannMachine to BernoulliRBM,1,Rename Class,,
9a8845e91349effcd39f8b9caccc3f1459780bd0,2013-05-21T03:53:12Z,https://github.com/scikit-learn/scikit-learn/commit/9a8845e91349effcd39f8b9caccc3f1459780bd0,ENH Create FeatureSelectionMixin for shared [inverse_]transform code  Also rename FeatureSelectionMixin -> SelectorMixin -> _LearntSelectorMixin And rename sklearn.feature_selection.{selector_mixin -> from_model},1,Rename Class,,
19ed9b01651c9bd8735c117d79b652132dbb4fcd,2013-02-03T19:04:23Z,https://github.com/scikit-learn/scikit-learn/commit/19ed9b01651c9bd8735c117d79b652132dbb4fcd,"ENH refactor univariate feature selection  Gets rid of ""duplicate p-values"" warning with filters that don't actually use p-values.",1,Rename Class,,
b5cc3bad87695dd1f264956bea5dd97b656fdde3,2013-02-03T14:49:40Z,https://github.com/scikit-learn/scikit-learn/commit/b5cc3bad87695dd1f264956bea5dd97b656fdde3,COSMIT rename AsScorer to Scorer,1,Rename Class,,
d4eb8196e9c9f7f3ee9fe2a5e01a3db9ca30a6fc,2012-12-09T13:14:09Z,https://github.com/scikit-learn/scikit-learn/commit/d4eb8196e9c9f7f3ee9fe2a5e01a3db9ca30a6fc,ENH renamed class NystromKernelApproximation to Nystrom (it is in the kernel_approximation module). Also improvements to example docstring,1,Rename Class,,
607c136480506459a039543d19ca90911128c039,2012-11-19T14:03:04Z,https://github.com/scikit-learn/scikit-learn/commit/607c136480506459a039543d19ca90911128c039,Rename to dummy.DummyClassifier.,1,Rename Class,,
6ab3b5b2bef4bea6c91569e82abade8d7dd425f4,2012-11-15T19:20:45Z,https://github.com/scikit-learn/scikit-learn/commit/6ab3b5b2bef4bea6c91569e82abade8d7dd425f4,MISC rename RandomForestEmbedding to RandomTreesEmbedding,1,Rename Class,,
ef4d208e086b2f808ba262465373dcfd3a28c6df,2012-11-14T09:40:19Z,https://github.com/scikit-learn/scikit-learn/commit/ef4d208e086b2f808ba262465373dcfd3a28c6df,MISC renamed RandomForestHasher to RandomForestEmbedding,1,Rename Class,,
bf96a1418d496d2b9696bdfb78fda104674eb9a8,2012-10-13T17:29:00Z,https://github.com/scikit-learn/scikit-learn/commit/bf96a1418d496d2b9696bdfb78fda104674eb9a8,ENH : cleanup FactorAnalysis object,1,Rename Class,,
c0a057843c3432184b411cd5d2994e11b33d4ac8,2012-09-23T16:31:15Z,https://github.com/scikit-learn/scikit-learn/commit/c0a057843c3432184b411cd5d2994e11b33d4ac8,ENH rename Scaler to StandardScaler everywhere,1,Rename Class,,
dc943722de01ba9ab7c3955759950ed755257fc8,2012-09-17T19:06:36Z,https://github.com/scikit-learn/scikit-learn/commit/dc943722de01ba9ab7c3955759950ed755257fc8,"COSMIT refactor linear classifiers  Factored out the common code to LinearSVC, LogisticRegression, Perceptron and SGDClassifier into a LinearClassifierMixin.",1,Rename Class,,
cd7404706c0a2e1003a7d818f21cac6c37747aea,2012-05-08T22:32:27Z,https://github.com/scikit-learn/scikit-learn/commit/cd7404706c0a2e1003a7d818f21cac6c37747aea,MISC: clean up top-level namespace,1,Rename Class,,
81c222f26522b1b2af5014e07e76b0b6cebba50f,2012-04-01T16:26:37Z,https://github.com/scikit-learn/scikit-learn/commit/81c222f26522b1b2af5014e07e76b0b6cebba50f,ENH: refactored the HMM tests to ease PY3K transition,1,Rename Class,,
87fda3423465c40f2d13b5238142a0941f217148,2012-03-26T16:08:17Z,https://github.com/scikit-learn/scikit-learn/commit/87fda3423465c40f2d13b5238142a0941f217148,Merge pull request #730 from jaquesgrobler/rename_EllipticEnvelope  Made old EllipticEnvelop deprecated class,1,Rename Class,,
f56ffb542acd22e44e5bcd7060809adb526b87ba,2012-03-26T15:16:58Z,https://github.com/scikit-learn/scikit-learn/commit/f56ffb542acd22e44e5bcd7060809adb526b87ba,Made old EllipticEnvelop deprecated class -renamed to **EllipticEnvelope** -Examples updated,1,Rename Class,,
03f088758c59acbdc39eba63deac8a55633ff5a8,2012-03-10T17:27:45Z,https://github.com/scikit-learn/scikit-learn/commit/03f088758c59acbdc39eba63deac8a55633ff5a8,wip: refactor ``fit_stage``; fix feature importances regression; tests still not green (performance regression on Example 12.7).,1,Rename Class,,
c0541fa03bc9af9d3616cee9920b161adcd01008,2012-03-07T14:48:56Z,https://github.com/scikit-learn/scikit-learn/commit/c0541fa03bc9af9d3616cee9920b161adcd01008,Renamed Vectorizer to TfidfVectorizer + deprecation warning,1,Rename Class,,
167f34080eb24451518a7e40c0f32f28b88abcc5,2011-09-17T15:55:16Z,https://github.com/scikit-learn/scikit-learn/commit/167f34080eb24451518a7e40c0f32f28b88abcc5,renamed MiniBatchDictionaryLearning,1,Rename Class,,
d7e64beb01682e5dc006b4af33f76b48c280f1ce,2011-05-25T18:12:13Z,https://github.com/scikit-learn/scikit-learn/commit/d7e64beb01682e5dc006b4af33f76b48c280f1ce,Merge pull request #184 from larsmans/amitibo-naive-bayes  Multinomial Naive Bayes + rename GNB to GaussianNB,1,Rename Class,,
943439d4b0b3e66159f264217efe8ee4e30748f9,2011-05-23T14:21:44Z,https://github.com/scikit-learn/scikit-learn/commit/943439d4b0b3e66159f264217efe8ee4e30748f9,"rename MultinomialNB params, rename GNB GaussianNB",1,Rename Class,,
f57b26ea9d391023847485f8db54f44f31493e19,2011-04-11T18:05:00Z,https://github.com/scikit-learn/scikit-learn/commit/f57b26ea9d391023847485f8db54f44f31493e19,[MiniBatchKMeans] Starting refactoring code after the review  - Renamed BatchKMeans in MiniBatchKMeans - Implemented the partial_fit method - Updated examples for the new API,1,Rename Class,,
39d65f2cbab543847f88ec7345c659fc3726eb6f,2011-04-07T16:06:57Z,https://github.com/scikit-learn/scikit-learn/commit/39d65f2cbab543847f88ec7345c659fc3726eb6f,"Rename BaseCovariance as EmpiricalCovariance + reviews comments.  I still use a function for computing the empirical covariance matrix since it is useful for dealing with 1-dimensional covariances (that have to be reshaped). Plus, it corresponds to the scheme used for the LedoitWolf, ShrunkCovariance and OAS classes (an object + an external function computing the covariance estimate).",1,Rename Class,,
239cf8b270bd06627b4720e14a2f4b08592f81f5,2011-04-05T19:59:59Z,https://github.com/scikit-learn/scikit-learn/commit/239cf8b270bd06627b4720e14a2f4b08592f81f5,refactoring,1,Rename Class,,
491861a1985c4bf3fb207a447248bc0b3206e326,2011-04-02T16:54:52Z,https://github.com/scikit-learn/scikit-learn/commit/491861a1985c4bf3fb207a447248bc0b3206e326,Renamed NMF to ProjectedGradientNMF,1,Rename Class,,
0ec58871c6095823a2b2387a362fc7c1da4beb95,2011-04-01T14:10:51Z,https://github.com/scikit-learn/scikit-learn/commit/0ec58871c6095823a2b2387a362fc7c1da4beb95,[feature_extraction] Refactor text/* to text.py,1,Rename Class,,
ecd7190f09cc98329290b8c7185106f83fb1b450,2011-02-17T09:37:34Z,https://github.com/scikit-learn/scikit-learn/commit/ecd7190f09cc98329290b8c7185106f83fb1b450,"Neighbors refactoring.  Rename NeighborsBarycenter --> NeighborsRegressor, Neighbors --> NeighborsClassifier.  Also added parameter mode for NeighborRegressor (and updated examples and doc describing it).",1,Rename Class,,
f79b27d9f437446223176c4d145ac514a9e99bb4,2011-02-15T08:33:34Z,https://github.com/scikit-learn/scikit-learn/commit/f79b27d9f437446223176c4d145ac514a9e99bb4,Rename SparseTransformerMixin to CoefSelectTransformerMixin.,1,Rename Class,,
33a1e3c16adef970d07787c597621350dcc32859,2011-01-28T03:17:04Z,https://github.com/scikit-learn/scikit-learn/commit/33a1e3c16adef970d07787c597621350dcc32859,Rename _RidgeLOO to _RidgeGCV.,1,Rename Class,,
1ff5724cc89ea3e72c6d349be5390dbc7d8d9648,2011-01-22T22:37:20Z,https://github.com/scikit-learn/scikit-learn/commit/1ff5724cc89ea3e72c6d349be5390dbc7d8d9648,ENH : refactoring Ward feature agglomeration to make it work with Pipeline,1,Rename Class,,
6827dd2940bddca207e267374346d3ae331bd612,2011-01-20T14:22:59Z,https://github.com/scikit-learn/scikit-learn/commit/6827dd2940bddca207e267374346d3ae331bd612,Rename to RidgeClassifierCV.,1,Rename Class,,
7fceccb5fece0292e23672ad5f061762fa95cabd,2010-12-03T10:28:32Z,https://github.com/scikit-learn/scikit-learn/commit/7fceccb5fece0292e23672ad5f061762fa95cabd,Merge branch 'sgd-rename',1,Rename Class,,
fe662553eacb7ea2ae160fd3af9190114eda7cc0,2010-11-30T11:14:30Z,https://github.com/scikit-learn/scikit-learn/commit/fe662553eacb7ea2ae160fd3af9190114eda7cc0,finalized sgd module renaming. renamed ClassifierSGD to SGDClassifier (same for Regressor) updated setup.py files updated examples updated docs,1,Rename Class,,
7525e14b31dc93c926b9e2154b1c83daf460af68,2010-10-21T03:44:45Z,https://github.com/scikit-learn/scikit-learn/commit/7525e14b31dc93c926b9e2154b1c83daf460af68,Remove Sparse prefix from class names.,1,Rename Class,,
5aa60987d0d8bba683e02db4aadebcab3621824f,2010-09-17T19:45:23Z,https://github.com/scikit-learn/scikit-learn/commit/5aa60987d0d8bba683e02db4aadebcab3621824f,merge textextract branch from mblondel,1,Rename Class,,
d2400647beef6686841a2b6ac9a2377fbe12c7f2,2010-08-31T13:04:06Z,https://github.com/scikit-learn/scikit-learn/commit/d2400647beef6686841a2b6ac9a2377fbe12c7f2,"Refactoring and doc for svm module.  Make Base classes private (for autocomplete friendliness), change order of parameters (hide less important ones), and remove not relevant ones.",1,Rename Class,,
782aa4a2b2ad043d3efbfc5da7881782ba9659bd,2010-07-29T08:15:01Z,https://github.com/scikit-learn/scikit-learn/commit/782aa4a2b2ad043d3efbfc5da7881782ba9659bd,Cosmit: rename MixinClassif to ClassifMixin,1,Rename Class,,
28c57f78494045191719c158343fa8615cf53705,2010-06-10T11:52:38Z,https://github.com/scikit-learn/scikit-learn/commit/28c57f78494045191719c158343fa8615cf53705,"Refactoring in glm module.  Make (nearly) all objects inherit from LinearModel, and add intercept to some models.  Also added doc to rst file.",1,Rename Class,,
97aeb8db461b5a85f193b9e207d830b91a96aa85,2010-03-15T08:02:41Z,https://github.com/scikit-learn/scikit-learn/commit/97aeb8db461b5a85f193b9e207d830b91a96aa85,Refactor svm model.  Change name class SVM -> SVC  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@531 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8,1,Rename Class,,
03954dac274ed3f1fec122e51a3f8ded159ed355,2010-03-09T13:40:40Z,https://github.com/scikit-learn/scikit-learn/commit/03954dac274ed3f1fec122e51a3f8ded159ed355,"Rename of SVM classes.  Separate different types of support vectors in different classes.  See issue 29 [1] for a complete discussion of the API  Also, add benchmarks for this module.  [1] https://sourceforge.net/apps/trac/scikit-learn/ticket/29  From: Fabian Pedregosa <fabian.pedregosa@inria.fr>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@509 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8",1,Rename Class,,
c6a2621316f5073b309983eec803e704e3aef0b6,2010-03-06T10:52:19Z,https://github.com/scikit-learn/scikit-learn/commit/c6a2621316f5073b309983eec803e704e3aef0b6,"Flat is better than nested  Refactoring: rename svm module to avoid namespace nesting. Also added copyrigth to libsvm original files, and improve comments.  From: Fabian Pedregosa <fabian.pedregosa@inria.fr>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@507 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8",1,Rename Class,,
4f88104c371fb3946127b3936bb4adb58c78611c,2010-01-06T10:02:45Z,https://github.com/scikit-learn/scikit-learn/commit/4f88104c371fb3946127b3936bb4adb58c78611c,Rename NumpyTestCase to TestCase.  From: cdavid <cdavid@cb17146a-f446-4be1-a4f7-bd7c5bb65646>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@267 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8,1,Rename Class,,
99bc40c7af129b689e0abc6de3288524637b7dae,2010-01-06T09:17:21Z,https://github.com/scikit-learn/scikit-learn/commit/99bc40c7af129b689e0abc6de3288524637b7dae,Simplify Kernal Api names  From: cdavid <cdavid@cb17146a-f446-4be1-a4f7-bd7c5bb65646>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@234 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8,1,Rename Class,,
9179e3b55bd6df90143b2939d84a7a9982b23959,2010-01-05T17:08:23Z,https://github.com/scikit-learn/scikit-learn/commit/9179e3b55bd6df90143b2939d84a7a9982b23959,Code cleanup. Disabled tests that are failing due to NumPy defect.  From: fullung <fullung@cb17146a-f446-4be1-a4f7-bd7c5bb65646>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@189 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8,1,Rename Class,,
a9dd12434642abe681e4b623facd7eb461750e3f,2023-02-28T07:10:29Z,https://github.com/huggingface/transformers/commit/a9dd12434642abe681e4b623facd7eb461750e3f,Rename `MobileViTModelTest` to `TFMobileViTModelTest` (#21825)  Let's give TF a bit more love ❤️ 🙏  Co-authored-by: ydshieh <ydshieh@users.noreply.github.com>,1,Rename Class,,
c236a621729edb92dbb3e1dedd448be76cb82211,2023-02-16T19:59:27Z,https://github.com/huggingface/transformers/commit/c236a621729edb92dbb3e1dedd448be76cb82211,"[CLAP] Add CLAP to the library (#21370)  * add model like clip  * update  * text model ok  * clap text works  * some refactor  - `CLAPVision` to `CLAPAudio` - refactor kwargs of audio modules  * more refactor  * more refactor  * more refactor  * correct fusion  * more refactor  * new modules  * add basic processor  * fixup  * remove whisper copioed from  * audio logits match  * add doc  * correct filters mel and add maxlength  * style  * few fixes  * forward passes  * fixup  * fixup  * some clean up  * remove mels form the dictionnary  * pad after the repeat  * update padding when dsmaller  * fix padding  * style  * use swin patch merging  * use copied from swin  * processor with any tokenizer  * more copied from  * some clean up  * more refactor  * fix mel when rand_trunc  * style  * remove unused imports  * update processing  * remove image processing tests  * add testing fiel  * fixmodeling issues  * replace with `is_longer`  * clap in serialization  * more refactor  * `make fixup`  * make fixup  * fix feature extractor  * update test feature extractor  * `make fixup`  * clean up config  * more clean up  * more cleanup  * update tests  * refactor tests and inits  * removeCLAP vision config  * remove CLAP from image procssing auto and dummy vision objects  * update inits  * style  * re order classes in modeling clap  * Use roberta tokenizer as the other weights are not open sourced  * small cleaup  * remove tokenization CLAP  * processor tokenizr is roberta  * update feature extraction doc  * remove vclap from model zero shot  * update f_min and f_max to frequency_xx  * some changes  - fix modeling keys - add `is_longer` in the forward pass - make fixup  * make fixup  * consistent behavior ebtween rand_crop and fusion  * add numpy resize and bilinear and documentation  * move resizing to image utils  * clean feature extraction  * import resize from correct file  * resize in image transforms  * update  * style  * style  * nit  * remove unused arguments form the feature extractor  * style  * few fixes + make fixup  * oops  * fix more tests  * add zero shot audio classification pipeline  * update zeroshot classification pipeline  * fixup  * fix copies  * all CI tests pass  * make fixup + fix docs  * fix docs  * fix docs  * update tests pip;eline  * update zero shot pipeline  * update feature extraction clap  * update tokenization auto  * use nested simplify  * update pipeline tests  * Apply suggestions from code review  Co-authored-by: Arthur <48595927+ArthurZucker@users.noreply.github.com>  * split in two lines  * fixes  * refactor  * clean up  * add integration tests  * update config docstring  * style  * update processor  * fix processor test  * fix feat extractor tests  * update docs  * Apply suggestions from code review  Co-authored-by: Arthur <48595927+ArthurZucker@users.noreply.github.com>  * fix readmes  * fix tips  * Update src/transformers/models/auto/configuration_auto.py  * update doc and remove todo -> properly explained  * fix idx and typo  * typoe  * cleanup config  * cleanup tests, styles and doc  * ignore docstyle on image transform  * add conversion script  * remove the `clap` indx in favor of `CLAP`  * update __init  * nits  * Update src/transformers/pipelines/__init__.py  * fix bug  * clarifiy config  * fix copy  * fix init  * Apply suggestions from code review  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * fix model output  * fix comment  * make fixup  * make fixup  * rename to `Clap`  * replace to `Clap`  * replace to `Clap`  * repo consistency  * again repo-consistency  * make fixup  * Apply suggestions from code review  Co-authored-by: Sanchit Gandhi <93869735+sanchit-gandhi@users.noreply.github.com>  * add config  * changes  * update conversion  * Apply suggestions from code review  Co-authored-by: Sanchit Gandhi <93869735+sanchit-gandhi@users.noreply.github.com>  * remove unused function  * update based on code reviews  * style  * more comments  * cleanup  * clean up  * style  * apply suggestions  * Empty commit  * pipeline will be added in a different PR  * update calls to audio utils functions  * update pipeline init  * style  * style  * styling again  * use pad  * fix repo-consistency  * update utils and add doc for audio utils  * clean up resize by using torch. update inits accordingly  * style  * CLap's  tokenizer is RobertA  * add audio utils to internal toctreee  * update totctree  * style  * update documentation and normalize naming accross audio utils and feature extraction clap  * style  * clean up  * update doc and typos  * fix doctest  * update modelin code, got rid of a lot of reshaping  * style on added doc audio utils  * update modeling clap  * style  * Apply suggestions from code review  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * docstringvariables with CLAP  * rename key  * update modeling CLAP  * update audio utils docstring  * update processing clap  * fix readmes  * fix toctree  * udpate configuration clap  * fix init  * make fixup  * fix  * fix  * update naming  * update  * update checkpoint path  * Apply suggestions from code review  * Major refactoring  * Update src/transformers/models/clap/configuration_clap.py  * merge  ---------  Co-authored-by: younesbelkada <younesbelkada@gmail.com> Co-authored-by: Younes Belkada <49240599+younesbelkada@users.noreply.github.com> Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com> Co-authored-by: Sanchit Gandhi <93869735+sanchit-gandhi@users.noreply.github.com>",1,Rename Class,,
6eae3f780156e6ebe8f079f54974508db835d906,2022-12-08T15:55:48Z,https://github.com/huggingface/transformers/commit/6eae3f780156e6ebe8f079f54974508db835d906,Add `BackboneMixin` (#20660)  * add BackboneBaseModel  * add BackboneBaseModel  * Rename to BackboneMixin  * remove nn.Module  Co-authored-by: ydshieh <ydshieh@users.noreply.github.com>,1,Rename Class,,
d21c97cc0faa955a933b8123d53b452bd3ee93d9,2022-11-21T15:21:28Z,https://github.com/huggingface/transformers/commit/d21c97cc0faa955a933b8123d53b452bd3ee93d9,add MobileNetV1 model (#17799)  * add model files etc for MobileNetV2  rename files for MobileNetV1  initial implementation of MobileNetV1  fix conversion script  cleanup  write docs  tweaks  fix conversion script  extract hidden states  fix test cases  make fixup  fixup it all  remove main from doc link  fixes  fix tests  fix up  use google org  fix weird assert  * fixup  * use google organization for checkpoints,1,Rename Class,,
f71895a633becd6eec8bdb69070c88029ae390e6,2022-06-28T12:04:19Z,https://github.com/huggingface/transformers/commit/f71895a633becd6eec8bdb69070c88029ae390e6,Move logic into pixelshuffle layer (#17899)  * Move all pixelshuffle logic into layer  * Rename layer  * Use correct input to function,1,Rename Class,,
bad358398a6c55aa7db0378bd4681ce5584266e3,2022-05-17T21:42:14Z,https://github.com/huggingface/transformers/commit/bad358398a6c55aa7db0378bd4681ce5584266e3,Add support for pretraining recurring span selection to Splinter (#17247)  * Add SplinterForSpanSelection for pre-training recurring span selection.  * Formatting.  * Rename SplinterForSpanSelection to SplinterForPreTraining.  * Ensure repo consistency  * Fixup changes  * Address SplinterForPreTraining PR comments  * Incorporate feedback and derive multiple question tokens per example.  * Update src/transformers/models/splinter/modeling_splinter.py  Co-authored-by: Patrick von Platen <patrick.v.platen@gmail.com>  * Update src/transformers/models/splinter/modeling_splinter.py  Co-authored-by: Patrick von Platen <patrick.v.platen@gmail.com>  Co-authored-by: Jean Vancoppenole <jean.vancoppenolle@retresco.de> Co-authored-by: Tobias Günther <tobias.guenther@retresco.de> Co-authored-by: Tobias Günther <github@tobigue.de> Co-authored-by: Patrick von Platen <patrick.v.platen@gmail.com>,1,Rename Class,,
01562dac7ea980c20f93f321d9cc8bcc457919f9,2022-04-28T17:11:54Z,https://github.com/huggingface/transformers/commit/01562dac7ea980c20f93f321d9cc8bcc457919f9,Rename a class to reflect framework pattern AutoModelXxx -> TFAutoModelXxx (#16993),1,Rename Class,,
aa6cfe9c4b073b2c058a78fc2d26fe3fbe0ad70b,2022-03-24T19:44:15Z,https://github.com/huggingface/transformers/commit/aa6cfe9c4b073b2c058a78fc2d26fe3fbe0ad70b,Rename to SemanticSegmenterOutput (#15849)  Co-authored-by: Niels Rogge <nielsrogge@Nielss-MacBook-Pro.local>,1,Rename Class,,
600496fa509e5cc7245e0594e60142b9ab565c73,2021-12-28T19:33:23Z,https://github.com/huggingface/transformers/commit/600496fa509e5cc7245e0594e60142b9ab565c73,[Wav2Vec2] Rename model's feature extractor to feature encoder (#14959)  * rename classes  * clean up more namings  * remove bogus file  * Apply suggestions from code review  * Apply suggestions from code review  * replace more names  * more regex replace  * make style  * correct  * correct more  * make style  * finish  * correct more in wav2vec2  * make style  * improve freeze_extractor  * add aliases  * add tf aliases,1,Rename Class,,
25156eb296ae88c7b810235a368c953b7a4b9af9,2021-11-29T09:19:11Z,https://github.com/huggingface/transformers/commit/25156eb296ae88c7b810235a368c953b7a4b9af9,Rename ImageGPT (#14526)  * Rename  * Add MODEL_FOR_CAUSAL_IMAGE_MODELING_MAPPING,1,Rename Class,,
7ec596ecda9a2d7b1729a1a7d39760e0a4237a9a,2021-06-01T20:24:52Z,https://github.com/huggingface/transformers/commit/7ec596ecda9a2d7b1729a1a7d39760e0a4237a9a,[DeepSpeed] decouple `DeepSpeedConfigHF` from `Trainer` (#11966)  * decouple DeepSpeedConfigHF from Trainer  * add LoggingLevel ctx manager; add new test  * cleanup  * add docs  * Apply suggestions from code review  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * implemented suggested renames  * formatter workaround  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>,1,Rename Class,,
edca520d0fd8f23e6a5dbf98c209f8da0e3e293c,2021-04-13T15:45:24Z,https://github.com/huggingface/transformers/commit/edca520d0fd8f23e6a5dbf98c209f8da0e3e293c,Refactor GPT2 (#11225)  * refactor GPT2  * fix mlp and head pruning  * address Sylvains comments  * apply suggestion from code review  Co-authored-by: Lysandre Debut <lysandre@huggingface.co>,1,Rename Class,,
9a06b6b11bdfc42eea08fa91d0c737d1863c99e3,2021-03-09T09:16:59Z,https://github.com/huggingface/transformers/commit/9a06b6b11bdfc42eea08fa91d0c737d1863c99e3,[FeatureExtractorSavingUtils] Refactor PretrainedFeatureExtractor (#10594)  * save first version  * finish refactor  * finish refactor  * correct naming  * correct naming  * shorter names  * Update src/transformers/feature_extraction_common_utils.py  Co-authored-by: Lysandre Debut <lysandre@huggingface.co>  * change name  * finish  Co-authored-by: Lysandre Debut <lysandre@huggingface.co>,1,Rename Class,,
bf9056442ac58218da7623da2a0f7f4cd02689ad,2021-01-07T22:10:16Z,https://github.com/huggingface/transformers/commit/bf9056442ac58218da7623da2a0f7f4cd02689ad,"Removing duplicated code for Translation,Summarization and Text2TextGeneration pipelines (#9433)  * Merging all duplicated codes for Text2TextPipeline while preserving backward compat.  * Fixing TranslationPipeline Hierarchy + return_name  * torch import guard.  * Update isort version.  * Remove code from other PR disentanglement.  * Removed named example to something more agnostic.",1,Rename Class,,
221d4c63a338b7a672c1b2a115cf42492b72c375,2020-09-11T07:57:53Z,https://github.com/huggingface/transformers/commit/221d4c63a338b7a672c1b2a115cf42492b72c375,clean naming (#7068),1,Rename Class,,
22933e661fe789874ef58b13d3a9bb2554ba5891,2020-08-29T22:03:08Z,https://github.com/huggingface/transformers/commit/22933e661fe789874ef58b13d3a9bb2554ba5891,[bart] rename self-attention -> attention (#6708),1,Rename Class,,
857e0a0d3ba39be6259961524a730d3f106cec9c,2020-03-05T22:41:18Z,https://github.com/huggingface/transformers/commit/857e0a0d3ba39be6259961524a730d3f106cec9c,Rename BartForMaskedLM -> BartForConditionalGeneration (#3114)  * improved documentation,1,Rename Class,,
955d7ecb570b178187075c7c31fcd9be2e3a3428,2019-12-16T13:34:54Z,https://github.com/huggingface/transformers/commit/955d7ecb570b178187075c7c31fcd9be2e3a3428,Refactored Pipeline with dedicated argument handler.,1,Rename Class,,
3b0d2fa30eb9756c888b4ed36213350d4b6e70e3,2019-10-30T09:54:46Z,https://github.com/huggingface/transformers/commit/3b0d2fa30eb9756c888b4ed36213350d4b6e70e3,rename seq2seq to encoder_decoder,1,Rename Class,,
770b15b58ceb66a5da72d8030e9aff05fd50848a,2019-10-08T15:32:28Z,https://github.com/huggingface/transformers/commit/770b15b58ceb66a5da72d8030e9aff05fd50848a,rename class in __init__,1,Rename Class,,
8abfee9ec327aea0005a7ad367639217ca7dd215,2019-10-08T14:30:58Z,https://github.com/huggingface/transformers/commit/8abfee9ec327aea0005a7ad367639217ca7dd215,rename Bert2Bert -> Bert2Rnd,1,Rename Class,,
dda1adad6de0874e337ec04e52c4c291c0abfb59,2019-10-07T14:31:46Z,https://github.com/huggingface/transformers/commit/dda1adad6de0874e337ec04e52c4c291c0abfb59,rename BertLayer to BertEncoderLayer,1,Rename Class,,
8ca767f13c988f27126bcc99a10bce1671c032de,2019-07-15T11:49:07Z,https://github.com/huggingface/transformers/commit/8ca767f13c988f27126bcc99a10bce1671c032de,clean up optimization,1,Rename Class,,
bb7557d3ab96f139997bfaa70ff2b4a6c18994e0,2019-04-21T11:48:33Z,https://github.com/huggingface/transformers/commit/bb7557d3ab96f139997bfaa70ff2b4a6c18994e0,#NAME?,1,Rename Class,,
1ba05efd26213c3f26e9b0cd6765f988f4da731a,2021-05-19T16:55:04Z,https://github.com/pytorch/pytorch/commit/1ba05efd26213c3f26e9b0cd6765f988f4da731a,[Reducer] Remove some unused variables (#58524)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/58524  Per title ghstack-source-id: 129311600  Test Plan: CI  Reviewed By: SciPioneer  Differential Revision: D28528223  fbshipit-source-id: 239a15de4b602e35ed9b15b8a4bea3c28b61de12,1,Remove Unused Variable,,
912322968440a22438ef9a59f307fef38435cfd5,2021-05-20T20:06:30Z,https://github.com/pytorch/pytorch/commit/912322968440a22438ef9a59f307fef38435cfd5,Cleanup functional.py after lu_unpack was removed (#58669)  Summary: Remove code in functional.py that became unused after PR https://github.com/pytorch/pytorch/commit/c790fd2bf89f16de25e5918e67b3e5fb6288c4cb  Pull Request resolved: https://github.com/pytorch/pytorch/pull/58669  Reviewed By: driazati  Differential Revision: D28572377  Pulled By: heitorschueroff  fbshipit-source-id: c90d80ead5f3d69100667488bc6b14ef54b95b54,1,Remove Unused Variable,,
986a88056cf7b949034d653997726b9bcf9ad514,2021-06-22T22:44:33Z,https://github.com/pytorch/pytorch/commit/986a88056cf7b949034d653997726b9bcf9ad514,Remove some unused variables (#60411)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/60411  Test Plan: Sandcastle  Reviewed By: ngimel  Differential Revision: D29221207  fbshipit-source-id: da6ad44036291a98f0b36b260062d077a7c2691b,1,Remove Unused Variable,,
c50c77b444812d6f28bb7a9071ca0eb643ab6f78,2021-06-14T17:33:48Z,https://github.com/pytorch/pytorch/commit/c50c77b444812d6f28bb7a9071ca0eb643ab6f78,remove unused variables (#59912)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/59912  Reviewed By: soulitzer  Differential Revision: D29100518  Pulled By: albanD  fbshipit-source-id: b86a4aa9050e4fa70a0872c1d8799e5953cd2bc8,1,Remove Unused Variable,,
553bb01df965d30ebfb3ef4dad68f911764b71d6,2023-04-01T05:38:36Z,https://github.com/pytorch/pytorch/commit/553bb01df965d30ebfb3ef4dad68f911764b71d6,[quant][pt2e][refactor] Remove extra arguments of _maybe_insert_observers_before_graph_output (#98029)  Summary: This PR allows _maybe_insert_observers_before_graph_output to be reused by pt2e flow  Test Plan: python test/test_quantization.py TestQuantizeFx python test/test_quantization.py TestQuantizeFxOps python test/test_quantization.py TestQuantizeFxModels  Reviewers:  Subscribers:  Tasks:  Tags: Pull Request resolved: https://github.com/pytorch/pytorch/pull/98029 Approved by: https://github.com/vkuzo,1,Remove Parameter,,
7dde61ce46b00b675fc3d3e489fd9855459a4b09,2023-03-31T23:59:43Z,https://github.com/pytorch/pytorch/commit/7dde61ce46b00b675fc3d3e489fd9855459a4b09,[quant][pt2e][refactor] Remove extra arguments of `_maybe_insert_output_observer_for_node` (#97959)  Summary: The goal is for this function to be reused by the pt2e flow  Test Plan: python test/test_quantization.py TestQuantizeFx  Reviewers:  Subscribers:  Tasks:  Tags: Pull Request resolved: https://github.com/pytorch/pytorch/pull/97959 Approved by: https://github.com/andrewor14,1,Remove Parameter,,
f78b44b2d92a3722c8e0516fdda14a6b6ded57bb,2023-03-31T05:07:58Z,https://github.com/pytorch/pytorch/commit/f78b44b2d92a3722c8e0516fdda14a6b6ded57bb,[quant][pt2e][refactor] Refactor prepare to remove the use of qconfig in `_maybe_insert_input_observer_for_arg_or_kwarg` (#97948)  Summary: The goal is for this function to be reused by quantize_pt2e  Test Plan: python test/test_quantization.py TestQuantizeFx  Reviewers:  Subscribers:  Tasks:  Tags:  Differential Revision: [D44558929](https://our.internmc.facebook.com/intern/diff/D44558929) Pull Request resolved: https://github.com/pytorch/pytorch/pull/97948 Approved by: https://github.com/andrewor14,1,Remove Parameter,,
4c3495896e77a5a4ebfeff717feb3d04681d27e7,2015-06-23T16:24:08Z,https://github.com/keras-team/keras/commit/4c3495896e77a5a4ebfeff717feb3d04681d27e7,Remove time_distributed_softmax in favour of softmax  There is no reason to have two different functions for this! The softmax function can just be configured to always perform the softmax across the trailing dimension (i.e. nb_dimensions),1,Remove Middle Man,,
0d2c3d19ac9a2885c24bd40621157d53bc9fb681,2021-02-15T19:10:09Z,https://github.com/tensorflow/tensorflow/commit/0d2c3d19ac9a2885c24bd40621157d53bc9fb681,"Remove unused ""sess"" variables from tests; NFCPiperOrigin-RevId: 357594586Change-Id: Ia8c8274d12181aa59f2c46f8d7c8c3599aaffe74",1,Remove Dead Code,,
b7a0e1960bfad660cdbcf09aae5593c44726faba,2021-02-12T17:50:46Z,https://github.com/tensorflow/tensorflow/commit/b7a0e1960bfad660cdbcf09aae5593c44726faba,removed test_util based parent class,1,Remove Dead Code,,
f987ff6bcd1734075ad143a3870307b5e62001a5,2021-02-11T00:37:15Z,https://github.com/tensorflow/tensorflow/commit/f987ff6bcd1734075ad143a3870307b5e62001a5,"Remove ""dummy queue"" which is never closed.  This is causing workers to hang when a training job stops early (e.g., using tuner along with tf.estimator.parameterized_train_and_evaluate or with TFX).PiperOrigin-RevId: 356855978Change-Id: Id28441865b4a0bd598a515e2550ef4a23a564d24",1,Remove Dead Code,,
ebd56094d3e40809f8684cd35dce6a509e7bdc26,2021-02-08T10:44:51Z,https://github.com/tensorflow/tensorflow/commit/ebd56094d3e40809f8684cd35dce6a509e7bdc26,Remove unnecessary set_model overwrite in BackupAndRestore calllback,1,Remove Dead Code,,
0408dab085b39f19f1fbd496418691413b418e69,2021-02-04T00:21:57Z,https://github.com/tensorflow/tensorflow/commit/0408dab085b39f19f1fbd496418691413b418e69,Remove redundant test.testCollectiveGroupSizeOne already exists intensorflow/python/kernel_tests/collective_ops_test.py.PiperOrigin-RevId: 355506777Change-Id: I3472e1063d66c5b38a8d80296b670ee70feb197b,1,Remove Dead Code,,
f7d0a77b539d47bbbffa9702c1e7329de79551ac,2021-02-02T20:02:23Z,https://github.com/tensorflow/tensorflow/commit/f7d0a77b539d47bbbffa9702c1e7329de79551ac,An internal change.PiperOrigin-RevId: 355220346Change-Id: I78e8d291cf2a6168ec5ba9b2679f8292fc1271e6,1,Remove Dead Code,,
dae2088a7c65c51d681506f326bbdd3cdddd65ae,2021-01-29T20:16:14Z,https://github.com/tensorflow/tensorflow/commit/dae2088a7c65c51d681506f326bbdd3cdddd65ae,remove unused imports,1,Remove Dead Code,,
3db793ee031f2abede180043b016c085f1d8c26b,2021-01-27T19:25:19Z,https://github.com/tensorflow/tensorflow/commit/3db793ee031f2abede180043b016c085f1d8c26b,"Remove the workaround that sets PerReplica spec to dynamic batchIt's no longer needed as we stopped reusing collective instance keys. Note that we still modifies element_spec to have a dynamic batch for multi worker strategies when partial batch is enabled, so that element_spec is compatible with the data produced.PiperOrigin-RevId: 354132185Change-Id: I3857b4bb25c825befdd1f7c667437dc3bbf4ba50",1,Remove Dead Code,,
65248147f44ce3512144e42c121743374d099f30,2021-01-22T22:01:33Z,https://github.com/tensorflow/tensorflow/commit/65248147f44ce3512144e42c121743374d099f30,"#PRIVATE_TF_API_USAGE_CLEANUP Remove the definition of gather_trainable_weights(), as there is no reference in the codebase.PiperOrigin-RevId: 353314486Change-Id: I81e6a1ade60bbcffe557092c7824baa2aa7c860d",1,Remove Dead Code,,
98a4bb7a39608275b90bcd221bc51103afadeb10,2021-01-22T20:25:38Z,https://github.com/tensorflow/tensorflow/commit/98a4bb7a39608275b90bcd221bc51103afadeb10,"#PRIVATE_TF_API_USAGE_CLEANUP Remove the test cases on object_meta(), as there is no real reference to this tf private api.PiperOrigin-RevId: 353295828Change-Id: I235ae68ce517abc0ab601da8f372270eb1212f55",1,Remove Dead Code,,
101b68041c31c1372ca9b29a2dfee188680ad3e7,2021-01-22T18:51:14Z,https://github.com/tensorflow/tensorflow/commit/101b68041c31c1372ca9b29a2dfee188680ad3e7,"#PRIVATE_TF_API_USAGE_CLEANUP Remove the usage of gather_non_trainable_weights. There is no reference to this method, so we just delete the method.PiperOrigin-RevId: 353274439Change-Id: I876eac533fd6a68912900118b4159651741e7978",1,Remove Dead Code,,
3161e2b0e7eae741bc9bbb4f94ca48a3fbd03d0e,2021-01-21T17:48:18Z,https://github.com/tensorflow/tensorflow/commit/3161e2b0e7eae741bc9bbb4f94ca48a3fbd03d0e,refactor list_files_benchmark,1,Remove Dead Code,,
6dc9dc2334e83a83553c855dda9c4a6d9d0a5dc1,2021-01-11T22:24:05Z,https://github.com/tensorflow/tensorflow/commit/6dc9dc2334e83a83553c855dda9c4a6d9d0a5dc1,Remove unneeded lines.There's no need to keep a separate set to track the seen nodes (`visited_nodes` because `path` is already effectively filtering out the duplicate nodes)PiperOrigin-RevId: 351235385Change-Id: I5004076b6b3e32d70261b3af04a4872236034887,1,Remove Dead Code,,
bdea9387862989fa3a7fad286df205cf28129ea6,2021-01-11T19:12:08Z,https://github.com/tensorflow/tensorflow/commit/bdea9387862989fa3a7fad286df205cf28129ea6,Remove the instance check of _UnreadVariable (private tf api) in Keras.PiperOrigin-RevId: 351194027Change-Id: I373b1fe4df9f68d0ceb019f22222f05496a57375,1,Remove Dead Code,,
2b654ed216752967ad21b048458d40ed4ab01ed2,2021-01-11T19:53:16Z,https://github.com/tensorflow/tensorflow/commit/2b654ed216752967ad21b048458d40ed4ab01ed2,remove redundant tests,1,Remove Dead Code,,
4544864a34d075ced39afe3c46d22f0a97ec5784,2021-01-11T18:47:29Z,https://github.com/tensorflow/tensorflow/commit/4544864a34d075ced39afe3c46d22f0a97ec5784,Remove irrelevant warnings.- tf.train is not longer part of the API.- `Sequence`-based generator training is a LTS API and should not print warning when used the way it's intended to be used.PiperOrigin-RevId: 351188267Change-Id: Ibf8e47f4cc475351df732f91a8cb2105fc42ea13,1,Remove Dead Code,,
6b302ae1a07fd3610055ba07dd5e7379a346d4c4,2021-01-05T17:45:07Z,https://github.com/tensorflow/tensorflow/commit/6b302ae1a07fd3610055ba07dd5e7379a346d4c4,Remove duplicate testsPiperOrigin-RevId: 350159389Change-Id: I6dcff0f8ceaf5bad4f3be67af7245d555a1f04bc,1,Remove Dead Code,,
a43b679356fff8f3214dcee514b9857914202565,2020-12-23T01:36:24Z,https://github.com/tensorflow/tensorflow/commit/a43b679356fff8f3214dcee514b9857914202565,[tf.data] Simplify make_csv_dataset tests.PiperOrigin-RevId: 348719304Change-Id: I774ae232efaa415ff13f39496e532dbd7fc56545,1,Remove Dead Code,,
928116bb70f07e9197e87db0d22866bc43ad8ef9,2020-12-10T13:04:08Z,https://github.com/tensorflow/tensorflow/commit/928116bb70f07e9197e87db0d22866bc43ad8ef9,Remove debug print,1,Remove Dead Code,,
3616708cb866365301d8e67b43b32b46d94b08a0,2020-12-08T17:28:33Z,https://github.com/tensorflow/tensorflow/commit/3616708cb866365301d8e67b43b32b46d94b08a0,Remove shutdown from tpu embedding tests.PiperOrigin-RevId: 346342510Change-Id: If67289f163dbb24c64fa5af2be6d7a1fce837088,1,Remove Dead Code,,
1feb592358c3ab4dfe89ea7848993c8201b860c8,2020-12-01T03:18:05Z,https://github.com/tensorflow/tensorflow/commit/1feb592358c3ab4dfe89ea7848993c8201b860c8,Remove the usage of _DefaultDistributionStrategy in keras.PiperOrigin-RevId: 344934166Change-Id: I7787e3ab2500796ec3bbe3e0f4a307f559be77b2,1,Remove Dead Code,,
ae3c3cf7733336d046373809bc5280e82a3509cd,2020-12-01T00:31:21Z,https://github.com/tensorflow/tensorflow/commit/ae3c3cf7733336d046373809bc5280e82a3509cd,Remove the redundant strategy related methods in keras model.PiperOrigin-RevId: 344912644Change-Id: I0f184d7417f3b9c3028d4b413c3e8adf894df0a1,1,Remove Dead Code,,
db3b92e8130ec1a98a4d3cffa0b2655188a92e73,2020-11-30T23:53:21Z,https://github.com/tensorflow/tensorflow/commit/db3b92e8130ec1a98a4d3cffa0b2655188a92e73,Remove obsolete tf.contrib.summary.create_db_writer()PiperOrigin-RevId: 344905494Change-Id: I4a06426ee8f9eb51c9ce303702ba88c7c53ed264,1,Remove Dead Code,,
8ca95300057c175ff63f0b5acd2ca17dc5f13a08,2020-11-24T22:03:58Z,https://github.com/tensorflow/tensorflow/commit/8ca95300057c175ff63f0b5acd2ca17dc5f13a08,"Remove enable collective ops testsWe now have multi worker unit tests so these are already covered. We should testthe API, not the implementation.PiperOrigin-RevId: 344128126Change-Id: I83e237e0620d65b7b6cfc84df2c686bd6b55a019",1,Remove Dead Code,,
05d8bfb1bbc62b7d34f84a7a8a29b5c525651d15,2020-11-17T18:00:56Z,https://github.com/tensorflow/tensorflow/commit/05d8bfb1bbc62b7d34f84a7a8a29b5c525651d15,"Do not tie the eager step container to GradientTape creation/deletion.I believe the only use that cared about the step container was TensorArray/Stack, which we don't use in tf.function anymore.Deleting the step container is causing memory issues for TPU compile kernels running asynchronously, which don't care about it in eager but reference it to fix Session-related issues.Alternatively we can reference count the step container. But if we can just start removing the concept from eager that'd be even better. It's marked as an internal-only API for kernels, and tying it to GradientTape lifetime seems a bit questionable anyway.PiperOrigin-RevId: 342886741Change-Id: I4303c77afdf8d414568e3d9c4cc3b3fbf317b7b3",1,Remove Dead Code,,
1086e0653e009a1a0d685157befad31f2b760c01,2020-11-10T20:10:37Z,https://github.com/tensorflow/tensorflow/commit/1086e0653e009a1a0d685157befad31f2b760c01,Remove outdated MWMS testsWe already have similar coverage via all the correctness tests.PiperOrigin-RevId: 341670424Change-Id: I719fefc0248a77aae87f6d30ee69173ccfb8d563,1,Remove Dead Code,,
215aab70e4716f0d691d29fa81a1251764eb56da,2020-11-09T21:32:49Z,https://github.com/tensorflow/tensorflow/commit/215aab70e4716f0d691d29fa81a1251764eb56da,Remove usage of default_graph_seed internal TF symbol from Keras.PiperOrigin-RevId: 341474366Change-Id: I221cc471ddcc086981c8597f8b49cd94f55330f6,1,Remove Dead Code,,
650b7211319fcf6749ef58d6ec212a01530c4404,2020-10-29T02:25:57Z,https://github.com/tensorflow/tensorflow/commit/650b7211319fcf6749ef58d6ec212a01530c4404,"When capturing tensors in a while_loop gradient graph, do not attempt to capture those tensors in the forward graph first. We had added this to _WhileBodyGradFuncGraph.capture to support custom_gradient but it is not really necessary and causes trouble in higher order derivatives.Some more cleanup:1. Remove special handling for capturing resource tensor using an allowlisted flag. Now we support capturing tensors that are not present in the forward graph from the forward graph as a first class feature.2. Remove duplicate code for handling capture of loop invariant tensors in the forward graph.3. Rename popped_tensor_lists to internal_capture_to_output which is more appropriate.PiperOrigin-RevId: 339584488Change-Id: Iea4591cfb32e5e7e973213d926233c8bbfb30bbd",1,Remove Dead Code,,
861d3e482bd2ab7e449a2aed54f70fb9ea145d61,2020-10-28T22:04:09Z,https://github.com/tensorflow/tensorflow/commit/861d3e482bd2ab7e449a2aed54f70fb9ea145d61,Removed a flaky test.PiperOrigin-RevId: 339545685Change-Id: Ife8a0ee6a91825e094f3fdea5a3779da083b751b,1,Remove Dead Code,,
6fe275889b28a78018c75efd310538af9dae3018,2020-10-22T23:36:14Z,https://github.com/tensorflow/tensorflow/commit/6fe275889b28a78018c75efd310538af9dae3018,Remove redundant mask reset in the RNN layer call().The reset is done in parent layer call().PiperOrigin-RevId: 338573148Change-Id: I81ff8c8851b49c5a41e697ebfe9f20db494aaa50,1,Remove Dead Code,,
d119ff9af89a69c991d26f7afbe1c7ee511aeb8e,2020-10-19T22:47:26Z,https://github.com/tensorflow/tensorflow/commit/d119ff9af89a69c991d26f7afbe1c7ee511aeb8e,"Remove Policy.should_cast_variables property.The RFC does have this property (https://github.com/tensorflow/community/pull/293) but I don't think this property is very useful, and there are no uses of it within Google outside Keras, so it should be removed.PiperOrigin-RevId: 337950640Change-Id: I64c27589e87e4bf8f3f9c7fe38150703d914e804",1,Remove Dead Code,,
52a388a6b75abdab8033b550eaeeaa1c19eb21b3,2020-10-16T05:26:19Z,https://github.com/tensorflow/tensorflow/commit/52a388a6b75abdab8033b550eaeeaa1c19eb21b3,Remove unused code in tests.PiperOrigin-RevId: 337447002Change-Id: I61c4dedb3cb0c5438b1602ab57c091d018f91fc1,1,Remove Dead Code,,
cbed8f06640af96cf0157c6e98926e9cde2e1a87,2020-10-16T00:47:04Z,https://github.com/tensorflow/tensorflow/commit/cbed8f06640af96cf0157c6e98926e9cde2e1a87,Remove now-dead Python 2 code.PiperOrigin-RevId: 337418961Change-Id: I352ca12ca9d5a561d6fd2b0145fe48814c8cc369,1,Remove Dead Code,,
8a77ace2ac87df7a4bcadf0fe2943d02a6aeea9b,2020-10-06T07:49:03Z,https://github.com/tensorflow/tensorflow/commit/8a77ace2ac87df7a4bcadf0fe2943d02a6aeea9b,Remove tests that use a replica context scope with no strategy specified. This does not seem like a usage that we need to test.PiperOrigin-RevId: 335587250Change-Id: I34a8d12474b2e399ef9a07881cdf7104a7af52f0,1,Remove Dead Code,,
8938132366f5fd3b111fc2ce9b53caf8f1ebfa89,2020-10-05T23:30:16Z,https://github.com/tensorflow/tensorflow/commit/8938132366f5fd3b111fc2ce9b53caf8f1ebfa89,PSv2: Remove unused `Closure._set_output_remote_values_aborted` method.PiperOrigin-RevId: 335525002Change-Id: Ib0f44b73853f4cbdcdc208cad7c6fec1893ade14,1,Remove Dead Code,,
b2aea759529c80296da9083460ef35ba85e954c6,2020-10-01T23:46:06Z,https://github.com/tensorflow/tensorflow/commit/b2aea759529c80296da9083460ef35ba85e954c6,remove unused import,1,Remove Dead Code,,
381dadbf32dfd6bf06cb1b3da3c30bdc5218e53c,2020-09-28T19:12:14Z,https://github.com/tensorflow/tensorflow/commit/381dadbf32dfd6bf06cb1b3da3c30bdc5218e53c,"Remove some of the usages of ops.EagerTensor from Keras. Specifically, the no-op usages (v1 keras code never runs when there are EagerTensors, so it never needs to be checked for v1 only code)PiperOrigin-RevId: 334210496Change-Id: I0b2e070dcf38e3ba349241a5fb8941c47e7ee6ff",1,Remove Dead Code,,
25567bd8418c01cc23a169a369d7e9b156d2bcc5,2020-09-22T19:25:38Z,https://github.com/tensorflow/tensorflow/commit/25567bd8418c01cc23a169a369d7e9b156d2bcc5,Remove debugging prints,1,Remove Dead Code,,
0462de5b544ed4731aa2fb23946ac22c01856b80,2020-09-18T22:52:05Z,https://github.com/tensorflow/tensorflow/commit/0462de5b544ed4731aa2fb23946ac22c01856b80,"Validate `data_splits` for `tf.StringNGrams`.Without validation, we can cause a heap buffer overflow which results in data leakage and/or segfaults.PiperOrigin-RevId: 332543478Change-Id: Iee5bda24497a195d09d122355502480830b1b317",1,Remove Dead Code,,
07071fe37d064a2ab7ba68431d71f0ae62edea21,2020-09-16T03:20:32Z,https://github.com/tensorflow/tensorflow/commit/07071fe37d064a2ab7ba68431d71f0ae62edea21,Remove the ds related util function that is never used.PiperOrigin-RevId: 331914923Change-Id: I9d38c6694011bb3409dca4292931f90260a15bc9,1,Remove Dead Code,,
67548eff5989de2b0255f2af75a07f8b9d4ea12c,2020-09-15T20:58:47Z,https://github.com/tensorflow/tensorflow/commit/67548eff5989de2b0255f2af75a07f8b9d4ea12c,Remove `tf.keras.utils.HDF5Matrix` as its deprecation date is overdue.PiperOrigin-RevId: 331848144Change-Id: I72dbb6bf9aef527edf35b6d18278a5c1cf53fcda,1,Remove Dead Code,,
ef03f3a824684566161fc295e99b5aed831e3298,2020-09-15T20:10:14Z,https://github.com/tensorflow/tensorflow/commit/ef03f3a824684566161fc295e99b5aed831e3298,Remove `tf.keras.experimental.terminate_keras_multiprocessing_pools` as its deprecation date is overdue.PiperOrigin-RevId: 331837651Change-Id: I1fc0bd8919b04e0b498fa80e057946bdc08ed551,1,Remove Dead Code,,
627520ec70937d277cd209bd7c0ff7f00e1731c9,2020-09-14T17:08:03Z,https://github.com/tensorflow/tensorflow/commit/627520ec70937d277cd209bd7c0ff7f00e1731c9,Remove `tf.keras.utils.convert_all_kernels_in_model` as its deprecation date is overdue.PiperOrigin-RevId: 331570917Change-Id: I60183861ac4e04acad041c631c541189a6f9bfe8,1,Remove Dead Code,,
fcfe64be4ca16c98b6e4a480c3207a3d9c3648e5,2020-09-08T23:45:54Z,https://github.com/tensorflow/tensorflow/commit/fcfe64be4ca16c98b6e4a480c3207a3d9c3648e5,Remove the unnecessary import based on`https://github.com/tensorflow/tensorflow/pull/42539#discussion_r485189850`.,1,Remove Dead Code,,
e9669d3b681fdbaa91c9a8512aa9575cf994cf9d,2020-09-03T23:15:05Z,https://github.com/tensorflow/tensorflow/commit/e9669d3b681fdbaa91c9a8512aa9575cf994cf9d,Remove `print` in benchmarks.PiperOrigin-RevId: 330013459Change-Id: Ia50c6d7b65608b4f59623b4a4b5f38780477d390,1,Remove Dead Code,,
c74b95e7716168d296c044877536569cc7571c6c,2020-08-25T22:56:22Z,https://github.com/tensorflow/tensorflow/commit/c74b95e7716168d296c044877536569cc7571c6c,Remove experimental mirroring policy APIs.Mirroring has been enabled by default for a long time. All the runtimecode that inspected the flag has long been removed. This is justcleaning up some leftover code.PiperOrigin-RevId: 328421064Change-Id: I193b67f1f12f96ebb8b6822a780d88f4b82e77af,1,Remove Dead Code,,
7d6b0856f9f6265f850b74ea4fd65969ed469d92,2020-08-24T19:10:20Z,https://github.com/tensorflow/tensorflow/commit/7d6b0856f9f6265f850b74ea4fd65969ed469d92,Remove cache_key_context None case,1,Remove Dead Code,,
dd09b57f7a5b2c0a3cda745414a1ae356da9ce0c,2020-08-18T20:50:36Z,https://github.com/tensorflow/tensorflow/commit/dd09b57f7a5b2c0a3cda745414a1ae356da9ce0c,Remove helper function,1,Remove Dead Code,,
63b709413a3a009adf088425d45906d7c6ba5375,2020-08-17T14:19:19Z,https://github.com/tensorflow/tensorflow/commit/63b709413a3a009adf088425d45906d7c6ba5375,Remove unnecessary assignment in in BaseResourceVariable,1,Remove Dead Code,,
ccdb409311c964dae895b04ffdd26bfa3ad60b0b,2020-08-12T18:00:57Z,https://github.com/tensorflow/tensorflow/commit/ccdb409311c964dae895b04ffdd26bfa3ad60b0b,"Remove distributed_coordinator from v2 kerasdistributed_coordinator is not needed for TF2 multi worker training. It's still needed for TF1.If I understand ModelVersionSelector correctly, training.Model is actually only for TF2.WorkerTrainingState is only used in BackupAndRestore callback, which is a TF2 only symbol.PiperOrigin-RevId: 326268093Change-Id: Ie90df74c4cfc5336934770daacdeb08e7fc81482",1,Remove Dead Code,,
eefd4652dc797495a2f6c25dcc009d83e75f6955,2020-08-11T21:56:59Z,https://github.com/tensorflow/tensorflow/commit/eefd4652dc797495a2f6c25dcc009d83e75f6955,removed unused import,1,Remove Dead Code,,
96cbf4354851e255b664d4cfd9f5c0bb9c001941,2020-08-05T20:21:17Z,https://github.com/tensorflow/tensorflow/commit/96cbf4354851e255b664d4cfd9f5c0bb9c001941,Remove duplicate symbols and usages for utility functions.PiperOrigin-RevId: 325087800Change-Id: Ic15366260a57ef22da72c587c45d78e5094d8a41,1,Remove Dead Code,,
640cdad89f7d3d2ab392526f2859e4f3e3f78721,2020-07-30T03:49:34Z,https://github.com/tensorflow/tensorflow/commit/640cdad89f7d3d2ab392526f2859e4f3e3f78721,Remove unused helper in values_test.pyPiperOrigin-RevId: 323927733Change-Id: I4ff7e83d9f7419430259e488456a61f440a061ac,1,Remove Dead Code,,
08b81eceedf62f68bc572d198126888075b190dd,2020-07-29T21:51:51Z,https://github.com/tensorflow/tensorflow/commit/08b81eceedf62f68bc572d198126888075b190dd,"Remove usages of `smart_cond` module from Keras.We have a version of smart_cond in keras/utils/tf_utils.py, removing that and adding smart_cond from smart_cond TF module to keras/utils/control_flow_util.pyPiperOrigin-RevId: 323873456Change-Id: Ieb9ea7a7bea86e3ebcdcea4455b0d0c2f8111882",1,Remove Dead Code,,
d21a236a62d5539a1b72c89edbaa0304fe13a49b,2020-07-27T19:47:52Z,https://github.com/tensorflow/tensorflow/commit/d21a236a62d5539a1b72c89edbaa0304fe13a49b,Removed initial accumulator value fields since they are unused.PiperOrigin-RevId: 323420206Change-Id: Ib1fb128d20485a689042eda8b360811334a2643e,1,Remove Dead Code,,
d8891649b204c1b2df0bf76fdf9c8b3e56c25578,2020-07-24T17:01:26Z,https://github.com/tensorflow/tensorflow/commit/d8891649b204c1b2df0bf76fdf9c8b3e56c25578,removed unnecessary import,1,Remove Dead Code,,
6f7084becc90e777476caeacc7a41f9aa6fee034,2020-07-24T12:14:56Z,https://github.com/tensorflow/tensorflow/commit/6f7084becc90e777476caeacc7a41f9aa6fee034,removed type mismatch tests,1,Remove Dead Code,,
e286f3d5c5cf7b3466b4b1053f711d4ae754f7eb,2020-07-22T00:17:20Z,https://github.com/tensorflow/tensorflow/commit/e286f3d5c5cf7b3466b4b1053f711d4ae754f7eb,simplify,1,Remove Dead Code,,
7b6e259f0c4bd47edc37401b4524e73d43a5da7b,2020-07-21T20:08:13Z,https://github.com/tensorflow/tensorflow/commit/7b6e259f0c4bd47edc37401b4524e73d43a5da7b,Remove unused cache_recursive_attributePiperOrigin-RevId: 322425784Change-Id: Ib9b13395c21135969d3b74237fd6f3385891861f,1,Remove Dead Code,,
17485039233b5f3e3adfaffb5822e10248ee5464,2020-07-18T03:03:24Z,https://github.com/tensorflow/tensorflow/commit/17485039233b5f3e3adfaffb5822e10248ee5464,remove unused loss var in momentum_test.pyremove unused loss var in momentum_test.py in `testSparseNesterovMomentum`,1,Remove Dead Code,,
02ca05721ecaac4b2f0ed4f29cc4b690523795e0,2020-07-16T18:50:22Z,https://github.com/tensorflow/tensorflow/commit/02ca05721ecaac4b2f0ed4f29cc4b690523795e0,removed unused imports,1,Remove Dead Code,,
7b71c07139b7dcfc9f33e1da5eaeca6258ffa9d1,2020-07-14T00:01:11Z,https://github.com/tensorflow/tensorflow/commit/7b71c07139b7dcfc9f33e1da5eaeca6258ffa9d1,Remove deprecated experimental_run_v2 method.PiperOrigin-RevId: 321062994Change-Id: I749202fd68e7c63832ce946f88748aba98364397,1,Remove Dead Code,,
f2dac51412d01305910722d837a3f6917fba4a54,2020-07-07T23:05:16Z,https://github.com/tensorflow/tensorflow/commit/f2dac51412d01305910722d837a3f6917fba4a54,Remove the staled test case from checkpointing_test.PiperOrigin-RevId: 320080398Change-Id: I395b6a58bf771ec8ae444f613d8ef3f711fa4919,1,Remove Dead Code,,
876b655af4714d5283e142e10dec456168dd84e8,2020-06-29T19:26:29Z,https://github.com/tensorflow/tensorflow/commit/876b655af4714d5283e142e10dec456168dd84e8,removed import,1,Remove Dead Code,,
4b5ef9c84402d0ff6f6ec82c1f4883a0f51d1644,2020-06-29T19:09:02Z,https://github.com/tensorflow/tensorflow/commit/4b5ef9c84402d0ff6f6ec82c1f4883a0f51d1644,"remove context, change import",1,Remove Dead Code,,
35bd17b6717384cf587aa7cc271d693a111d4a11,2020-06-29T16:24:23Z,https://github.com/tensorflow/tensorflow/commit/35bd17b6717384cf587aa7cc271d693a111d4a11,Remove TensorLike and changes to types/core.py,1,Remove Dead Code,,
b6be4f36eb5dd93d6d10c5bf7ca26101639a9494,2020-06-26T18:43:57Z,https://github.com/tensorflow/tensorflow/commit/b6be4f36eb5dd93d6d10c5bf7ca26101639a9494,"Remove explicit line ""experimental_new_converter = True"" the converter launched and is now the default.PiperOrigin-RevId: 318513201Change-Id: If2d4221abfea4467c11b91ca00a83f765d8c6fad",1,Remove Dead Code,,
85eac59cd1e7d401918a5daa7eb21e18b95e5e44,2020-06-26T05:29:03Z,https://github.com/tensorflow/tensorflow/commit/85eac59cd1e7d401918a5daa7eb21e18b95e5e44,"Remove explicit line ""experimental_new_converter = True"" the converter launched and is now the default.PiperOrigin-RevId: 318413489Change-Id: I0e07c1616a6b717debfb84fbc650093f3f0f6437",1,Remove Dead Code,,
49efec606f4886ae477c4c30b4157beec92f5b3e,2020-06-26T03:18:40Z,https://github.com/tensorflow/tensorflow/commit/49efec606f4886ae477c4c30b4157beec92f5b3e,"Remove explicit line ""experimental_new_converter = True"" the converter launched and is now the default.PiperOrigin-RevId: 318401041Change-Id: If14b594d3d2a1997dfbdd615b55db0a06ff22809",1,Remove Dead Code,,
dc8d42922b9ff89e717f130515c968186ec4504c,2020-06-19T10:33:01Z,https://github.com/tensorflow/tensorflow/commit/dc8d42922b9ff89e717f130515c968186ec4504c,Remove unnecessary control_dependencies,1,Remove Dead Code,,
8ad5bc80e71921c3c2530d93d3856ba59e524c60,2020-06-19T09:50:24Z,https://github.com/tensorflow/tensorflow/commit/8ad5bc80e71921c3c2530d93d3856ba59e524c60,Remove unnecessary assert,1,Remove Dead Code,,
653131dd38e9bbde2b9163d756ca4d9cfa69e1a5,2020-06-17T18:32:39Z,https://github.com/tensorflow/tensorflow/commit/653131dd38e9bbde2b9163d756ca4d9cfa69e1a5,Remove automatic control dep wrapping from layers in v2.PiperOrigin-RevId: 316929712Change-Id: Ic1a7d125776eeb0c7654e321dd6f2351c8656a16,1,Remove Dead Code,,
8950c470bb11a9b94c0dd08d73156008dfac60c9,2020-06-16T08:54:26Z,https://github.com/tensorflow/tensorflow/commit/8950c470bb11a9b94c0dd08d73156008dfac60c9,Remove automatic control dep wrapping from layers in v2.PiperOrigin-RevId: 316638920Change-Id: Iad14b1a4b0b14052f34784401b375a14b49a7641,1,Remove Dead Code,,
f8410051b094aa686640f4325ebb134ceb13ca2d,2020-06-15T23:14:45Z,https://github.com/tensorflow/tensorflow/commit/f8410051b094aa686640f4325ebb134ceb13ca2d,"Remove a test of Keras implementation details that are subject to change. Specifically, the test checks that nested layers in a functional model have their _keras_history updated when that model is used to construct a bigger functional model.In the future this incidental internal-implementation-specific-behavior will break.PiperOrigin-RevId: 316566350Change-Id: Ifb1e5ab04aafbbaa45e420ed34238059b16bcbdc",1,Remove Dead Code,,
07c8612582189fe09c90ef9be46817221b33088f,2020-06-11T22:45:57Z,https://github.com/tensorflow/tensorflow/commit/07c8612582189fe09c90ef9be46817221b33088f,"numpy_ops: Remove convert_to_tensor, ShardedNdArray and tensor_to_ndarray fromthe module.PiperOrigin-RevId: 315993646Change-Id: If6277bfc27638b3874407a120622afaf04b24744",1,Remove Dead Code,,
4f2d979e1c833f96d9b9ae7bfa3d5d2e6d81b61a,2020-06-09T00:16:38Z,https://github.com/tensorflow/tensorflow/commit/4f2d979e1c833f96d9b9ae7bfa3d5d2e6d81b61a,Routine dead code clean-up.PiperOrigin-RevId: 315385914Change-Id: I5c3be3a2b221d65197a375dbee99731ddc130438,1,Remove Dead Code,,
67099d08529a00f48ee8a444f471067bedcc2f5b,2020-06-07T08:33:06Z,https://github.com/tensorflow/tensorflow/commit/67099d08529a00f48ee8a444f471067bedcc2f5b,"Remove dependency on TF during pip package building.Unfortunately, the minimal import triggers a full import of TF, and causesbreakages due to not all TF dependencies being available. It also makes thesetup very heavy.PiperOrigin-RevId: 315139999Change-Id: I521b55cefd34b3a90d1e7f340d64bf56aca7ab09",1,Remove Dead Code,,
ed0eb69b76f9ff7ac952a3f36692d2c86929a6bf,2020-05-21T05:08:24Z,https://github.com/tensorflow/tensorflow/commit/ed0eb69b76f9ff7ac952a3f36692d2c86929a6bf,Remove some unused methods.PiperOrigin-RevId: 312617087Change-Id: I60618ee25984825997c204740c12eddefbf9d398,1,Remove Dead Code,,
489c8de9af23fa77d5a5a198e4a3eb5fcd1e60fa,2020-05-19T03:42:25Z,https://github.com/tensorflow/tensorflow/commit/489c8de9af23fa77d5a5a198e4a3eb5fcd1e60fa,[tf.data] Remove several unnecessary lines in the test.PiperOrigin-RevId: 312208396Change-Id: I52acdc04caea09ac83b4c9ac12378c818af650e6,1,Remove Dead Code,,
d6dd56f74f228227dc9781bd389147df61d3784e,2020-05-15T15:26:04Z,https://github.com/tensorflow/tensorflow/commit/d6dd56f74f228227dc9781bd389147df61d3784e,Remove original fn call,1,Remove Dead Code,,
237864e2bbff608c9267a66b6f1437cb43fdaafd,2020-05-06T23:13:14Z,https://github.com/tensorflow/tensorflow/commit/237864e2bbff608c9267a66b6f1437cb43fdaafd,[XLA:Python] Remove xla_client.Buffer class.The only remaining method was Buffer.from_pyval. Callers should useLocalClient.buffer_from_pyval instead.PiperOrigin-RevId: 310248281Change-Id: I3cca4e5ea85b7632ac5ef2f40fec488e50fe0fc8,1,Remove Dead Code,,
80b094c6b35eca21e48d17f7916be780bd302363,2020-05-06T22:10:39Z,https://github.com/tensorflow/tensorflow/commit/80b094c6b35eca21e48d17f7916be780bd302363,[XLA:Python] Remove xla_client.transfer_to_infeed and transfer_from_outfeed.Callers should use the methods on Device instead.PiperOrigin-RevId: 310236311Change-Id: Ic5d97d10b9598cf1ba404dc643745e334dd35c35,1,Remove Dead Code,,
bf687433298f29af2ee7fc1068329b50ed310693,2020-05-01T18:56:12Z,https://github.com/tensorflow/tensorflow/commit/bf687433298f29af2ee7fc1068329b50ed310693,Remove extra debug print statement,1,Remove Dead Code,,
862a62d6b4009ab29e666e2e5c6b498c1a8b68a5,2020-04-30T22:50:27Z,https://github.com/tensorflow/tensorflow/commit/862a62d6b4009ab29e666e2e5c6b498c1a8b68a5,"Remove Layer._supports_ragged_inputs property.This property made it more difficult to create a Layer that supportsRaggedTensors, since by default every user-created Layer class was assumed tonot work with RaggedTensors.Instead, an error message is added to common built-in Layer subclasses that don'tsupport RaggedTensors.PiperOrigin-RevId: 309315394Change-Id: Id587d99cfaa4890c41aee49ec437f96108b4fbc7",1,Remove Dead Code,,
159e2e06c82a0ea8df6efba4e5a0ed1292dab3c6,2020-04-29T18:38:18Z,https://github.com/tensorflow/tensorflow/commit/159e2e06c82a0ea8df6efba4e5a0ed1292dab3c6,"[XLA:Python] Remove the xla_client Backend class.After recent changes, the Backend wrapper around the C++ PyLocalClient class does nothing useful. We can instead use the C++ class directly.PiperOrigin-RevId: 309063889Change-Id: I2a4c8607dc1a5d6157d02fab863ed1a97ae04f5c",1,Remove Dead Code,,
56000c5d70dfc514c3331dea10123963a404c0d3,2020-04-26T19:49:34Z,https://github.com/tensorflow/tensorflow/commit/56000c5d70dfc514c3331dea10123963a404c0d3,Remove unused pybind for sparsification.PiperOrigin-RevId: 308519086Change-Id: I8d52624a39e3c013dd302a1978ccc3ed075829f1,1,Remove Dead Code,,
bda06c20e0d4efdb981cafb98797dfb18f8fb996,2020-04-24T17:55:11Z,https://github.com/tensorflow/tensorflow/commit/bda06c20e0d4efdb981cafb98797dfb18f8fb996,"[XLA:Python] Delete xla_client.{Computation,ComputationBuilder}.The replacements are XlaComputation and XlaBuilder, which are direct bindings around the underlying C++ classes.PiperOrigin-RevId: 308284928Change-Id: I485effef76ce6defa4bba86d5c32164adf7a54a5",1,Remove Dead Code,,
104d1ad66ad4fd6afb4fa62169dc5a08e520ba84,2020-04-23T22:10:11Z,https://github.com/tensorflow/tensorflow/commit/104d1ad66ad4fd6afb4fa62169dc5a08e520ba84,[tf.data] Remove invalid test.PiperOrigin-RevId: 308138762Change-Id: I917bed98222e734d6c4361b9867939f7a2e2c209,1,Remove Dead Code,,
d76bc7d03e69af05b1de6f6285a8640c469cd030,2020-04-23T16:27:28Z,https://github.com/tensorflow/tensorflow/commit/d76bc7d03e69af05b1de6f6285a8640c469cd030,Minor cleanup of dead code.PiperOrigin-RevId: 308068025Change-Id: I402d251a18bde7935fe316fe950133d6f9682700,1,Remove Dead Code,,
6d068076b9c06451dbf186878037c1e7a8fc1efe,2020-04-22T22:51:38Z,https://github.com/tensorflow/tensorflow/commit/6d068076b9c06451dbf186878037c1e7a8fc1efe,"Minor cleanup for the network inits.1. Do not special case the 'name' param in the Network, and let Layer handle it.2. Network doesn't need to set auto_cast by itself since the Layer is already handing it.3. Remove _init_call_fn_args() since its already done in Layer.init.4. Remove _graph field which seems to be never used.5. Remove other fields which has the same default value as in Layer.PiperOrigin-RevId: 307919370Change-Id: I5999af1ea837c1b516b0c399860cbd32c78aac13",1,Remove Dead Code,,
88692052ad3e056a36f3da6d359ef72ffc783beb,2020-04-14T18:15:43Z,https://github.com/tensorflow/tensorflow/commit/88692052ad3e056a36f3da6d359ef72ffc783beb,Remove unused math_ops import to pass CI testSigned-off-by: Yong Tang <yong.tang.github@outlook.com>,1,Remove Dead Code,,
cf69aea2825ecdfb4c72ec0322cd36ec69d060cd,2020-04-02T16:20:34Z,https://github.com/tensorflow/tensorflow/commit/cf69aea2825ecdfb4c72ec0322cd36ec69d060cd,Remove dead or duplicate code.PiperOrigin-RevId: 304414674Change-Id: Ie1bcd80b4d3236172be62fdf98d2a72dceca6e0f,1,Remove Dead Code,,
56e44425b6927d33fc246ab0f0c19ad766c4c541,2020-04-02T15:54:39Z,https://github.com/tensorflow/tensorflow/commit/56e44425b6927d33fc246ab0f0c19ad766c4c541,Minor clean-up: remove useless assignment statements.  (The variables are never used after these assignment statements.)PiperOrigin-RevId: 304409703Change-Id: Ibe1ea64d3c0c3a18fc8d092fd484d770086a8cd6,1,Remove Dead Code,,
367629f45afb7b876fc87d8aa4b4cdcc9be32547,2020-03-30T15:34:43Z,https://github.com/tensorflow/tensorflow/commit/367629f45afb7b876fc87d8aa4b4cdcc9be32547,Remove old exceptions as post removal datePiperOrigin-RevId: 303746718Change-Id: Ie44c59dc00a84a58d6c68312e39ec47d51da34be,1,Remove Dead Code,,
ce592f32ee51bf2fd0e9c0659aae3a226aa75c00,2020-03-30T01:25:43Z,https://github.com/tensorflow/tensorflow/commit/ce592f32ee51bf2fd0e9c0659aae3a226aa75c00,remove the added api on loss_scale,1,Remove Dead Code,,
802560bdf29938e3b3a11aab5fef72128d9149c6,2020-03-27T06:58:30Z,https://github.com/tensorflow/tensorflow/commit/802560bdf29938e3b3a11aab5fef72128d9149c6,Remove a duplicate check.PiperOrigin-RevId: 303271481Change-Id: Iac308aac8c71da9fffa179fae2f910d25993c405,1,Remove Dead Code,,
a234904bf07fafa7a5103f520155f2ad577c6394,2020-03-24T22:11:12Z,https://github.com/tensorflow/tensorflow/commit/a234904bf07fafa7a5103f520155f2ad577c6394,Remove the keras cell check from legacy RNN code.This will remove dependency from TF to Keras.PiperOrigin-RevId: 302756389Change-Id: I10f181c0df713bdce40cc5c02d80eefb7f7a7ea3,1,Remove Dead Code,,
b5c725611842a2abb3d504947a7895341c231d76,2020-03-23T23:59:53Z,https://github.com/tensorflow/tensorflow/commit/b5c725611842a2abb3d504947a7895341c231d76,"Internal cleanup: retire support for converting whole classes, which is not supported in TF2 and is unlikely to have real uses.PiperOrigin-RevId: 302550027Change-Id: I0127d56a3cc45ea38205df9a88480a75d25ea39c",1,Remove Dead Code,,
1bf7b2f0cf2802c741480530a05937a2b56bb591,2020-03-23T23:33:29Z,https://github.com/tensorflow/tensorflow/commit/1bf7b2f0cf2802c741480530a05937a2b56bb591,Remove the unnecessary type check from legacy RNN code.PiperOrigin-RevId: 302544931Change-Id: I591db053c5835529a7cf9a4e1180e0d77299c145,1,Remove Dead Code,,
28c22acb3a4bbc056b92d38524dc20c76b1b3c0b,2020-03-23T20:26:12Z,https://github.com/tensorflow/tensorflow/commit/28c22acb3a4bbc056b92d38524dc20c76b1b3c0b,Remove unneeded symbols from python layers.The input_spec should be exported via tf_export already in keras.PiperOrigin-RevId: 302504252Change-Id: I73aa4cc9d8adadb23b1f5aa455ddfd1008e2080e,1,Remove Dead Code,,
e7bbb424808eb7ebbeb959b993496adafd024609,2020-03-23T20:26:06Z,https://github.com/tensorflow/tensorflow/commit/e7bbb424808eb7ebbeb959b993496adafd024609,Remove the unnecessary type check from legacy RNN code.PiperOrigin-RevId: 302504219Change-Id: I3724c843c1fabbb9d8bbf52073b1b3417eae5fde,1,Remove Dead Code,,
503f3418ca31b1e26bff1a21e7119fe6f80528c9,2020-03-22T13:26:51Z,https://github.com/tensorflow/tensorflow/commit/503f3418ca31b1e26bff1a21e7119fe6f80528c9,Remove expired forward compatibility horizonsThis PR removes expired forward compatibility statements that will always evaluate to `True`.,1,Remove Dead Code,,
ce3925cf580435b09ee7cc4156e998dba3a8d2d9,2020-03-19T16:18:57Z,https://github.com/tensorflow/tensorflow/commit/ce3925cf580435b09ee7cc4156e998dba3a8d2d9,Remove test to un-red nightly builds as suggested in b/151378056PiperOrigin-RevId: 301829065Change-Id: I88a9d159faa9169de2854e69cc116af29943c74e,1,Remove Dead Code,,
7fb2f93d40a9a6e98fed29c296d40c537b92c148,2020-03-19T04:59:57Z,https://github.com/tensorflow/tensorflow/commit/7fb2f93d40a9a6e98fed29c296d40c537b92c148,"remove bidi rnn seq_len test, we didn't support seq_len anyway in tflite kernel anywayPiperOrigin-RevId: 301737256Change-Id: I6bf748c78abe99075aeb30ec20a1ca265ab6717c",1,Remove Dead Code,,
d8bccdb1b8e90e07bf7cb4232f9e120e28492d4b,2020-03-18T18:33:00Z,https://github.com/tensorflow/tensorflow/commit/d8bccdb1b8e90e07bf7cb4232f9e120e28492d4b,"[XLA:Python] Remove PyLocalBuffer.make_tuple and PyLocalBuffer.destructure() from the API.Since Execute() now supports tupling and untupling, we no longer need tuples in the Python API.This change is in preparation for changing the aliasing behavior of Execute().PiperOrigin-RevId: 301631669Change-Id: Idec8c5ebf0025052d6c0cef523f2c77c92e89e0a",1,Remove Dead Code,,
14afcf097b2b2f7c6d9254c7209c14d901099282,2020-03-12T17:47:54Z,https://github.com/tensorflow/tensorflow/commit/14afcf097b2b2f7c6d9254c7209c14d901099282,remove build from image layers.PiperOrigin-RevId: 300579390Change-Id: I986ef0b9a3391de936969401425edb7da34eed16,1,Remove Dead Code,,
eea8c2791585771e442b0f1f7260d15396212bea,2020-03-10T21:16:05Z,https://github.com/tensorflow/tensorflow/commit/eea8c2791585771e442b0f1f7260d15396212bea,Clean-up: remove unused importPiperOrigin-RevId: 300175620Change-Id: I5b0aaa36f9eaad088f28fd8d4ba818f1374ac3e7,1,Remove Dead Code,,
3fa6494763ca892748c8ea6ce1ed5f557c3da2aa,2020-03-10T20:42:32Z,https://github.com/tensorflow/tensorflow/commit/3fa6494763ca892748c8ea6ce1ed5f557c3da2aa,Remove unused code left-over from forking ragged_tensor_test.py -> row_partition_test.py.PiperOrigin-RevId: 300168669Change-Id: I6d2d7bcab1ffcb106d21138e952d005d9a3ad04d,1,Remove Dead Code,,
6f968a3a59b2d11ac74e0c0d9921dc3d660e765c,2020-03-09T23:22:10Z,https://github.com/tensorflow/tensorflow/commit/6f968a3a59b2d11ac74e0c0d9921dc3d660e765c,Remove all the save model related code in base_layer.They are not applicable for the v1 tf.layers case.PiperOrigin-RevId: 299962368Change-Id: I7c6f4fb76ff3e5aa83d4fc0db817ed4e1b73a827,1,Remove Dead Code,,
b7014702fde795b37a7d1d98c98086c60abf7a65,2020-02-27T21:31:01Z,https://github.com/tensorflow/tensorflow/commit/b7014702fde795b37a7d1d98c98086c60abf7a65,Remove passing experimental_run_tf_function in most tests.The experimental_run_tf_function parameter no longer has any effect.I didn't remove the functionality from testing_util.py and keras_parameterized.py to run with experimental_run_tf_function being True and False. I will remove that functionality in a future change.PiperOrigin-RevId: 297674422Change-Id: I5b1e67f78b4c3b60242241fb4dc2018f0ace6013,1,Remove Dead Code,,
0d3dea3d956c2e159f0817bef8912a10b7bb661f,2020-02-25T07:03:37Z,https://github.com/tensorflow/tensorflow/commit/0d3dea3d956c2e159f0817bef8912a10b7bb661f,Remove constant folding grappler optimization from MLIR conversion pipelinePiperOrigin-RevId: 297049260Change-Id: I04090b402166eddfefbfa75b8232f86c506adfa4,1,Remove Dead Code,,
b133ca5e06af8947d80a8123b77a94dc09caa468,2020-02-25T02:29:07Z,https://github.com/tensorflow/tensorflow/commit/b133ca5e06af8947d80a8123b77a94dc09caa468,Remove constant folding grappler optimization from MLIR conversion pipelinePiperOrigin-RevId: 297018032Change-Id: Ief0b4ea0988f65916f0580685bad6e3681bd24e2,1,Remove Dead Code,,
edda1d191fa92ac0fd7462a1deede6bd8a563861,2020-02-24T20:05:44Z,https://github.com/tensorflow/tensorflow/commit/edda1d191fa92ac0fd7462a1deede6bd8a563861,Remove exposure to internals from __init__.py. We do not need to expose the internal shared objects.PiperOrigin-RevId: 296944399Change-Id: I4eced8fa01f1455800bc24deef306e1e1136e606,1,Remove Dead Code,,
9f8fe8d154ff912cf83af763bdf1dec6da6ed73f,2020-02-24T06:47:30Z,https://github.com/tensorflow/tensorflow/commit/9f8fe8d154ff912cf83af763bdf1dec6da6ed73f,Remove the prompt to check if XLA should be enabled. It is always enabled now.PiperOrigin-RevId: 296819597Change-Id: Iddf49190d6f2fa7572e305fb6925cf31ee6fc7e6,1,Remove Dead Code,,
3e8aabf2db7dad080d1016c2f6249bed23121ccb,2020-02-19T23:05:29Z,https://github.com/tensorflow/tensorflow/commit/3e8aabf2db7dad080d1016c2f6249bed23121ccb,Remove obsolete code. Replace the last places using it with the new version.PiperOrigin-RevId: 296066537Change-Id: I8f6748d9d2ea497822f4f65fa4301d2dd67db89c,1,Remove Dead Code,,
6b68396a8279e00676c75d685ada2f74398d3c08,2020-02-11T18:48:26Z,https://github.com/tensorflow/tensorflow/commit/6b68396a8279e00676c75d685ada2f74398d3c08,Remove is_tensor_like property from DistributedValues class.PiperOrigin-RevId: 294472673Change-Id: Ifbd6d61aa31dbb1a692654ac3c0491c2be6253bc,1,Remove Dead Code,,
17ee98ec2cf9cbf99037dbb8c465bbe46bf8214f,2020-02-06T06:33:08Z,https://github.com/tensorflow/tensorflow/commit/17ee98ec2cf9cbf99037dbb8c465bbe46bf8214f,Remove CategoryLookup in favor of IndexLookup.PiperOrigin-RevId: 293524803Change-Id: I5cb63d4c4e53852f71a9e113bcc8d9278d0dba19,1,Remove Dead Code,,
032d74b2527b910821c06e73963311151d7f630a,2020-01-29T01:04:53Z,https://github.com/tensorflow/tensorflow/commit/032d74b2527b910821c06e73963311151d7f630a,Remove all remaining references to matrix_triangular_solve_with_broadcast.PiperOrigin-RevId: 292045093Change-Id: Ide06b9345c7226c5e0797e44e2eaab878c047589,1,Remove Dead Code,,
24078b1fc3ace6a5596a0214b8e4ce31f24d3bf0,2020-01-22T18:15:59Z,https://github.com/tensorflow/tensorflow/commit/24078b1fc3ace6a5596a0214b8e4ce31f24d3bf0,Remove all the tests from tensorflow/tools/docs.These modules are deprecated.The replacements are in tensorflow_docs/api_generatorPiperOrigin-RevId: 290978101Change-Id: I19b471728a05f006b3f023e1592f3f23a51e37e2,1,Remove Dead Code,,
96d2d82553068b681d114de34257ec4ca63317ae,2020-01-22T10:26:21Z,https://github.com/tensorflow/tensorflow/commit/96d2d82553068b681d114de34257ec4ca63317ae,[XLA:Python] Remove PyLocalClient::(De)SerializeExecutable virtual methods.PiperOrigin-RevId: 290915533Change-Id: I566bea2e1067d3971b2b1ab934e2f77d0a8be903,1,Remove Dead Code,,
51eef22e24107cb772ab996d499bbfcb7509f310,2020-01-21T22:40:53Z,https://github.com/tensorflow/tensorflow/commit/51eef22e24107cb772ab996d499bbfcb7509f310,Remove stale forward compatPiperOrigin-RevId: 290825929Change-Id: Ic0cb75857f6d9fdf8332364a98ac174bbd625703,1,Remove Dead Code,,
8b9901e411ba9d3f7cf1fa4908452b4bfa51fe88,2019-12-17T22:17:11Z,https://github.com/tensorflow/tensorflow/commit/8b9901e411ba9d3f7cf1fa4908452b4bfa51fe88,"Remove unused import and do not use ""is"" for string comparison",1,Remove Dead Code,,
f9e38a46fc7600e5f188d64b821e6bb00fdde1b5,2020-01-09T22:34:37Z,https://github.com/tensorflow/tensorflow/commit/f9e38a46fc7600e5f188d64b821e6bb00fdde1b5,remove unused import,1,Remove Dead Code,,
22bc36a8ee2c2f865dd1a64664252712b6eb2f92,2020-01-08T22:52:11Z,https://github.com/tensorflow/tensorflow/commit/22bc36a8ee2c2f865dd1a64664252712b6eb2f92,Remove debug print statements,1,Remove Dead Code,,
b00d66ebe0248fcaff164997638c8890b5b5c17c,2020-01-07T18:41:39Z,https://github.com/tensorflow/tensorflow/commit/b00d66ebe0248fcaff164997638c8890b5b5c17c,Swap out modules in py2 mode in a cleaner fashion.PiperOrigin-RevId: 288526813Change-Id: I86efd4d804c0c873856307cf4a969270eb7bbae8,1,Remove Dead Code,,
e19c92334cebaa79298743d7e489985064d2ed41,2020-01-06T19:00:27Z,https://github.com/tensorflow/tensorflow/commit/e19c92334cebaa79298743d7e489985064d2ed41,"Remove useless hasattr check in Layer.get_config.The hasattr(self, 'dtype') check would only fail if super().__init__ is not called. If not called, Layer.get_config and most other methods already raise errors anyway.PiperOrigin-RevId: 288333917Change-Id: I1962be09c9c4686c76120298411f3156b561f734",1,Remove Dead Code,,
31b0dc568f23966c8e5fc576a08825e5b039aca4,2019-12-29T16:23:20Z,https://github.com/tensorflow/tensorflow/commit/31b0dc568f23966c8e5fc576a08825e5b039aca4,"tridiagonal_solve: Remove stale forward compatibility checks`forward_compatible(2019, 10, 18)` always evaluates to `True` so a bit of stale code can be removed.",1,Remove Dead Code,,
5ba099efd135c3efb37a28eed273a9432cbbc5c7,2019-12-23T22:18:01Z,https://github.com/tensorflow/tensorflow/commit/5ba099efd135c3efb37a28eed273a9432cbbc5c7,"Remove variable tracking from `zeros` and `ones` keras.backend functions.If these functions creates a new variable, `variable` function called from each of these functions already tracks that.PiperOrigin-RevId: 286942519Change-Id: I55f9605b33b258df3fd65b4dac10415db183b680",1,Remove Dead Code,,
9798f84fa9d938b1999a83bb3a4f4e8ff9f3ab69,2019-12-21T07:18:05Z,https://github.com/tensorflow/tensorflow/commit/9798f84fa9d938b1999a83bb3a4f4e8ff9f3ab69,Remove `colocate_with` function from FTRL optimizer for use with DistributionStrategy.PiperOrigin-RevId: 286689345Change-Id: Icc266c62e623227865ebd75399f77adb86794eed,1,Remove Dead Code,,
7e1680206aad51f47b5737c6b22b82d6c9ae07d9,2019-12-19T18:36:39Z,https://github.com/tensorflow/tensorflow/commit/7e1680206aad51f47b5737c6b22b82d6c9ae07d9,Remove expired forward compatible check on dropoutPiperOrigin-RevId: 286419581Change-Id: I25d7f0121d1ebaf972f28e682bac25879b928be2,1,Remove Dead Code,,
05e93d61315f43445ddbbef6d023760f75cf38fe,2019-12-17T17:35:15Z,https://github.com/tensorflow/tensorflow/commit/05e93d61315f43445ddbbef6d023760f75cf38fe,remove repetition,1,Remove Dead Code,,
d02266ff21959e08b875cfb92477e0e865140aaa,2019-12-17T15:20:28Z,https://github.com/tensorflow/tensorflow/commit/d02266ff21959e08b875cfb92477e0e865140aaa,Remove distribution strategy device map code.PiperOrigin-RevId: 285974579Change-Id: Ib83e53d6e34a7def18f5ac55c4d2838ca91b799e,1,Remove Dead Code,,
f87a18ca9af22e072f4ad2d23d79134cd8a00457,2019-12-10T01:06:34Z,https://github.com/tensorflow/tensorflow/commit/f87a18ca9af22e072f4ad2d23d79134cd8a00457,"Remove name-based Variable handling in keras Lambda layers, and add detailed exceptions and warnings for unsafe corner cases.PiperOrigin-RevId: 284666677Change-Id: Iad99d68b2d20298694e7d39dbf1ce6ae9bbf28c5",1,Remove Dead Code,,
167f9de5f4039d6140a04a2286e63d78bdd1b5ae,2019-12-09T23:21:00Z,https://github.com/tensorflow/tensorflow/commit/167f9de5f4039d6140a04a2286e63d78bdd1b5ae,remove the expired forward_compatible check on random_opPiperOrigin-RevId: 284646197Change-Id: I1851fb67ce53bf135103f1ed15afd9124a893618,1,Remove Dead Code,,
3461d949be44486bf4b074e02385bf745fe5b41c,2019-12-06T21:19:07Z,https://github.com/tensorflow/tensorflow/commit/3461d949be44486bf4b074e02385bf745fe5b41c,Remove import tensorflow from gen_tftrt_model.py,1,Remove Dead Code,,
14a0c12dc2eb6398414df4b92d47455ac37ff4fd,2019-11-29T23:54:44Z,https://github.com/tensorflow/tensorflow/commit/14a0c12dc2eb6398414df4b92d47455ac37ff4fd,Remove some stale forward compatibility datesPiperOrigin-RevId: 283092973Change-Id: Ia708a9c04a032e1222c7d56ad4936e263424fbdd,1,Remove Dead Code,,
0e215ba70eb2dc8a6c9b5c2c96ee332b8fed5d81,2019-11-15T20:54:08Z,https://github.com/tensorflow/tensorflow/commit/0e215ba70eb2dc8a6c9b5c2c96ee332b8fed5d81,Simplify AutoCastDistributedVariable,1,Remove Dead Code,,
00291d8d29df3e5224fc07dd1fb0c852d26fb206,2019-11-15T20:53:31Z,https://github.com/tensorflow/tensorflow/commit/00291d8d29df3e5224fc07dd1fb0c852d26fb206,Remove unused _clone_with_new_values function,1,Remove Dead Code,,
dd7bd5a182758409a4ea5aaf1dc24fb438ecfdef,2019-11-12T16:34:11Z,https://github.com/tensorflow/tensorflow/commit/dd7bd5a182758409a4ea5aaf1dc24fb438ecfdef,Remove obsolete example parsing implementations from parsing_ops.py.PiperOrigin-RevId: 279975973Change-Id: I6be82a6859c2e102384340b544e4447f65f1d059,1,Remove Dead Code,,
024bd55717a25477662a6c662b0e3b44ab49f61e,2019-10-29T18:45:10Z,https://github.com/tensorflow/tensorflow/commit/024bd55717a25477662a6c662b0e3b44ab49f61e,"Remove the channel dimension checking in call(), as it seems to break the tracing in autograph/tf.function.PiperOrigin-RevId: 277330874Change-Id: I16856b228d064e9fe08bef913b34f7aef15905a7",1,Remove Dead Code,,
213379298df0a2dcf695643c3501fb9091bfbcf1,2019-10-28T20:41:24Z,https://github.com/tensorflow/tensorflow/commit/213379298df0a2dcf695643c3501fb9091bfbcf1,Remove layer from keras.__init__.pyPiperOrigin-RevId: 277133404Change-Id: Iff8cc6a605c0ac57d944ea91a2c1dd71d56385af,1,Remove Dead Code,,
5fc194159e3b0cf644a33fdd2df21549d3c6e973,2019-10-14T20:43:11Z,https://github.com/tensorflow/tensorflow/commit/5fc194159e3b0cf644a33fdd2df21549d3c6e973,"Remove the primals= argument from tf.custom_gradientIt's not possible to use correctly at the moment, and has not been in a release. For now we should just document the correct way to do it manually.PiperOrigin-RevId: 274650536",1,Remove Dead Code,,
5b6d7ecc0be827552bea0a7af5095c88f90ae75b,2019-10-14T19:11:33Z,https://github.com/tensorflow/tensorflow/commit/5b6d7ecc0be827552bea0a7af5095c88f90ae75b,Remove all the immediate python module in __init__ and move them to API gen.PiperOrigin-RevId: 274630337,1,Remove Dead Code,,
378ee86ecbd2254a929d2630187c410199685abc,2019-10-11T22:29:40Z,https://github.com/tensorflow/tensorflow/commit/378ee86ecbd2254a929d2630187c410199685abc,Remove not needed interleave_ops importSigned-off-by: Yong Tang <yong.tang.github@outlook.com>,1,Remove Dead Code,,
94ac0af6c420e8433338a3c2c08dba7b930fb970,2019-10-10T23:25:25Z,https://github.com/tensorflow/tensorflow/commit/94ac0af6c420e8433338a3c2c08dba7b930fb970,function.py & def_function.py unused code cleanup.PiperOrigin-RevId: 274063252,1,Remove Dead Code,,
402ccb1803480d5596c507ecada11c68214b5d55,2019-10-10T18:25:09Z,https://github.com/tensorflow/tensorflow/commit/402ccb1803480d5596c507ecada11c68214b5d55,"Remove the __init__ content for keras/saving.All the direct dependencies has been changed to use explicit import, rather than rely on the __init__ shortcut.PiperOrigin-RevId: 274001008",1,Remove Dead Code,,
fb2c518a8d970ec03bfb4f1019c3a39984689b59,2019-10-08T03:03:03Z,https://github.com/tensorflow/tensorflow/commit/fb2c518a8d970ec03bfb4f1019c3a39984689b59,Remove unused circular dependenciesPiperOrigin-RevId: 273434114,1,Remove Dead Code,,
84f9d53683484cefd6c87bb4655f3d658a02171a,2019-10-03T21:44:09Z,https://github.com/tensorflow/tensorflow/commit/84f9d53683484cefd6c87bb4655f3d658a02171a,Remove deprecated APIs from CompositeTensorPiperOrigin-RevId: 272745538,1,Remove Dead Code,,
cc38e56e03c9995cd103e592315337879998e312,2019-10-03T18:50:10Z,https://github.com/tensorflow/tensorflow/commit/cc38e56e03c9995cd103e592315337879998e312,Temporarily remove functools32 import as it is causing some benchmark tests to break.We should reinstate this as it is provides the functionality of caching the opt_einsum contraction order for performance improvements.PiperOrigin-RevId: 272708800,1,Remove Dead Code,,
31a51431d4b27ae9879d3594d710adfc0b2c32fc,2019-09-27T17:28:06Z,https://github.com/tensorflow/tensorflow/commit/31a51431d4b27ae9879d3594d710adfc0b2c32fc,Remove unnecessary use of ObjectIdentitySetPiperOrigin-RevId: 271598384,1,Remove Dead Code,,
0bb0c1d0be2d250d97e73cbf27d88f5f97d1c535,2019-09-26T10:26:11Z,https://github.com/tensorflow/tensorflow/commit/0bb0c1d0be2d250d97e73cbf27d88f5f97d1c535,Removed deprecated (private) Operation methodsPiperOrigin-RevId: 271315681,1,Remove Dead Code,,
af0194f2dbd5b33fce6a072fcd804172681c3934,2019-09-20T19:15:21Z,https://github.com/tensorflow/tensorflow/commit/af0194f2dbd5b33fce6a072fcd804172681c3934,Removed unused ops.RegisterShapePiperOrigin-RevId: 270323505,1,Remove Dead Code,,
bdfb540d8baea02b32a7810570edf62f13a1ab98,2019-09-20T00:45:02Z,https://github.com/tensorflow/tensorflow/commit/bdfb540d8baea02b32a7810570edf62f13a1ab98,"Remove unused import and two import formsargparse was imported with both 'import' and 'import from' and string import was unused,PiperOrigin-RevId: 270164488",1,Remove Dead Code,,
4de15da21dda4762f352a8adf6c818ced370432c,2019-09-20T00:45:02Z,https://github.com/tensorflow/tensorflow/commit/4de15da21dda4762f352a8adf6c818ced370432c,"Remove unused import and two import formsargparse was imported with both 'import' and 'import from' and string import was unused,PiperOrigin-RevId: 270164488",1,Remove Dead Code,,
fea67be540eb99381359fa7afaeb97d1f74dbff5,2019-09-19T16:22:03Z,https://github.com/tensorflow/tensorflow/commit/fea67be540eb99381359fa7afaeb97d1f74dbff5,Removed unused Tensor._get_input_ops_without_shapesPiperOrigin-RevId: 270056230,1,Remove Dead Code,,
205bf5260c83d752fad1b859932e0ac4e38d32a2,2019-09-18T22:31:08Z,https://github.com/tensorflow/tensorflow/commit/205bf5260c83d752fad1b859932e0ac4e38d32a2,Removed internal calls to @RegisterShape and related APIsAll of that code is effectively dead since shape inference happens in C++.PiperOrigin-RevId: 269904930,1,Remove Dead Code,,
022a1fe13d2bab88a9a088908f19fdace8cbb4ed,2019-09-17T14:44:44Z,https://github.com/tensorflow/tensorflow/commit/022a1fe13d2bab88a9a088908f19fdace8cbb4ed,Removed Context._tld.modeIt has zero usages outside of Context and duplicates Context._tld.is_eagerPiperOrigin-RevId: 269566898,1,Remove Dead Code,,
907d2c1d7bf72826e902bc5f4e42383d127b194d,2019-09-06T19:11:36Z,https://github.com/tensorflow/tensorflow/commit/907d2c1d7bf72826e902bc5f4e42383d127b194d,remove compat check for adagrad v2.PiperOrigin-RevId: 267647400,1,Remove Dead Code,,
e5501319770ca94e4e580df1b116e1893e0972de,2019-09-03T18:41:42Z,https://github.com/tensorflow/tensorflow/commit/e5501319770ca94e4e580df1b116e1893e0972de,"Remove SavedModel-specific methods from base Layer and Model, and add documentation for updating the serialization implementation.PiperOrigin-RevId: 266978650",1,Remove Dead Code,,
81f89491e52f8a95ab25e219fa1f3594f78b731d,2019-08-31T07:48:12Z,https://github.com/tensorflow/tensorflow/commit/81f89491e52f8a95ab25e219fa1f3594f78b731d,Removed unused context.namescopeIf this change breaks you switch to tf.name_scope.PiperOrigin-RevId: 266523285,1,Remove Dead Code,,
fd4ece49c9ec143a9d689df6d8c1b26857936794,2019-08-28T20:59:33Z,https://github.com/tensorflow/tensorflow/commit/fd4ece49c9ec143a9d689df6d8c1b26857936794,"Removed StackFrame.func_start_lineno and Operation.traceback_with_start_linesThey were only referenced inside tfprof and, as far as I can tell, never usedin the tfprof UI.PiperOrigin-RevId: 265987217",1,Remove Dead Code,,
35e5ec9e9e31db8a6c531ddcfb559491f314cd04,2019-08-28T20:03:27Z,https://github.com/tensorflow/tensorflow/commit/35e5ec9e9e31db8a6c531ddcfb559491f314cd04,"Remove MPI code from TF main repo, since it was moved togithub.com/tensorflow/networking.PiperOrigin-RevId: 265974964",1,Remove Dead Code,,
3af471cd27c7c78ecfae2f0dcaa895d6f3e329fe,2019-08-28T19:39:08Z,https://github.com/tensorflow/tensorflow/commit/3af471cd27c7c78ecfae2f0dcaa895d6f3e329fe,Further clean up TPUClusterResolverPiperOrigin-RevId: 265969707,1,Remove Dead Code,,
7b0523809e862446cca2e3d194583a909bd0862b,2019-08-27T20:49:08Z,https://github.com/tensorflow/tensorflow/commit/7b0523809e862446cca2e3d194583a909bd0862b,Remove outdated examples.PiperOrigin-RevId: 265757996,1,Remove Dead Code,,
705f4abf425e610834f572eb47e50cd7af9a0450,2019-08-26T21:59:30Z,https://github.com/tensorflow/tensorflow/commit/705f4abf425e610834f572eb47e50cd7af9a0450,Remove LinearOperator.graph_parents calls from contrib/distributions/...  This will allowgraph_parents to be removed from linear operators.PiperOrigin-RevId: 265547774,1,Remove Dead Code,,
0b66dbff483e6d6283774de8d902b6ff0eaf3f13,2019-08-17T05:40:37Z,https://github.com/tensorflow/tensorflow/commit/0b66dbff483e6d6283774de8d902b6ff0eaf3f13,Remove redundant variable _calibration_data_collected; inline _calibrate() function; fix python formatting issues.,1,Remove Dead Code,,
b83a2dcdeee3aea350a8e91b460dfcae717af9d5,2019-08-17T04:03:10Z,https://github.com/tensorflow/tensorflow/commit/b83a2dcdeee3aea350a8e91b460dfcae717af9d5,Remove Eager from v1 profiler model_analyzer_testPiperOrigin-RevId: 263900281,1,Remove Dead Code,,
0c9c859a7332c4d700ca131dd77944751d2feedc,2019-08-16T16:47:23Z,https://github.com/tensorflow/tensorflow/commit/0c9c859a7332c4d700ca131dd77944751d2feedc,Remove MetadataListener and StepStats from EagerContextPiperOrigin-RevId: 263789105,1,Remove Dead Code,,
e25bfcaf2e481b5d25b1c681668bd4c28b631300,2019-08-16T06:26:01Z,https://github.com/tensorflow/tensorflow/commit/e25bfcaf2e481b5d25b1c681668bd4c28b631300,Remove UT because it's more like an integration test.,1,Remove Dead Code,,
98bd8489240aee52bdbd5c4222a5cfd32cd2fc08,2019-08-12T22:38:48Z,https://github.com/tensorflow/tensorflow/commit/98bd8489240aee52bdbd5c4222a5cfd32cd2fc08,Remove unused import in nn_impl.py,1,Remove Dead Code,,
4411b77626488f543dc10e0fd41d35af25fef6ae,2019-08-08T22:28:48Z,https://github.com/tensorflow/tensorflow/commit/4411b77626488f543dc10e0fd41d35af25fef6ae,Executor api clean up:1. Remove async_wait() and async_clear_error() in EagerContext.2. Allow getting current executor from EagerContext.3. Remove StartAsync() method in EagerExecutor.PiperOrigin-RevId: 262445965,1,Remove Dead Code,,
14c769393ed48882f055a945a86f8cd6f4b6564b,2019-08-08T05:25:07Z,https://github.com/tensorflow/tensorflow/commit/14c769393ed48882f055a945a86f8cd6f4b6564b,Remove obsolete test.PiperOrigin-RevId: 262284312,1,Remove Dead Code,,
4e699d94c84f1123f36a331926ca77af3f86b474,2019-08-08T00:09:59Z,https://github.com/tensorflow/tensorflow/commit/4e699d94c84f1123f36a331926ca77af3f86b474,Remove tf_export from TraceMe Python API.PiperOrigin-RevId: 262247599,1,Remove Dead Code,,
2ede1adb28e56a20608d10fec30c22a55f0ccc54,2019-07-31T01:07:46Z,https://github.com/tensorflow/tensorflow/commit/2ede1adb28e56a20608d10fec30c22a55f0ccc54,"Remove the dataset peeking part for sample weight mode, which currentlydoes nothing.The sample weight mode has been covered by existing tests, and its fineto just delete unused code.PiperOrigin-RevId: 260836403",1,Remove Dead Code,,
8887a3c11b97796b5f812cd4b5d25a0a5b828177,2019-07-27T00:45:14Z,https://github.com/tensorflow/tensorflow/commit/8887a3c11b97796b5f812cd4b5d25a0a5b828177,Safely remove the compile override for WideDeep.PiperOrigin-RevId: 260245700,1,Remove Dead Code,,
8eadaa47160123624480a24bb0f60c33aba9a1af,2019-07-26T22:08:46Z,https://github.com/tensorflow/tensorflow/commit/8eadaa47160123624480a24bb0f60c33aba9a1af,Removed exception handling test for reciprocal_no_nan().,1,Remove Dead Code,,
3a93e33d54afef127378bee1c5efeac2a98fd04b,2019-07-26T19:16:43Z,https://github.com/tensorflow/tensorflow/commit/3a93e33d54afef127378bee1c5efeac2a98fd04b,Remove deprecated run_as argument for convert.PiperOrigin-RevId: 260190100,1,Remove Dead Code,,
5f01e19d0463f19c59060bfece6b516f23bb8e69,2019-07-12T22:24:18Z,https://github.com/tensorflow/tensorflow/commit/5f01e19d0463f19c59060bfece6b516f23bb8e69,Removed use_function_backup parameter.,1,Remove Dead Code,,
990f5cc727a7cdc3749761913db977256abb73d6,2019-07-12T22:24:18Z,https://github.com/tensorflow/tensorflow/commit/990f5cc727a7cdc3749761913db977256abb73d6,Removed use_function_backup parameter.,1,Remove Dead Code,,
4ab0dc888714f049f734ee51b163c46da40ac9a9,2019-06-20T20:07:21Z,https://github.com/tensorflow/tensorflow/commit/4ab0dc888714f049f734ee51b163c46da40ac9a9,Remove tearDown.PiperOrigin-RevId: 254256277,1,Remove Dead Code,,
e346de45380e07a65b320ea05e282db3f0063a7d,2019-06-20T17:25:09Z,https://github.com/tensorflow/tensorflow/commit/e346de45380e07a65b320ea05e282db3f0063a7d,"Remove caching in enter_eager_name_scopeIt does not seem to have any effect# Before>>> ctx.scope_name = ""Module/NestedModule/Memory/Layer/"">>> %%timeitname_scope_cache.clear()enter_eager_name_scope(ctx, ""foobar"")1000000 loops, best of 3: 1.59 ?s per loop# After>>> %%timeitname_scope_cache.clear()enter_eager_name_scope(ctx, ""foobar"")1000000 loops, best of 3: 1.29 ?s per loopPiperOrigin-RevId: 254223019",1,Remove Dead Code,,
b7555d118e51c1a786509c939aeac6f87a91a6b1,2019-02-28T17:11:41Z,https://github.com/tensorflow/tensorflow/commit/b7555d118e51c1a786509c939aeac6f87a91a6b1,Remove unused import,1,Remove Dead Code,,
e8b06fd872fd868ef873cb39de0d894ddf5ee322,2019-06-11T20:40:48Z,https://github.com/tensorflow/tensorflow/commit/e8b06fd872fd868ef873cb39de0d894ddf5ee322,Remove tf.distribute.Strategy Keras model-to-estimator tests;they have been moved to the Estimator repo.PiperOrigin-RevId: 252688853,1,Remove Dead Code,,
d7bbf82a642b3278ba04b0c9cf7c9ee0919dd6bc,2019-05-29T03:16:35Z,https://github.com/tensorflow/tensorflow/commit/d7bbf82a642b3278ba04b0c9cf7c9ee0919dd6bc,Remove more unused attributes,1,Remove Dead Code,,
331b0f2eff95d45444135be1dd77899371fecdcb,2019-05-29T03:09:48Z,https://github.com/tensorflow/tensorflow/commit/331b0f2eff95d45444135be1dd77899371fecdcb,Remove unused attribute,1,Remove Dead Code,,
3986d0e353e446474be9383b88ec356ef8b192b9,2019-05-24T00:22:44Z,https://github.com/tensorflow/tensorflow/commit/3986d0e353e446474be9383b88ec356ef8b192b9,Remove dead code,1,Remove Dead Code,,
94017e5893ad1fc54ca68541a7875e9ebf40cd3b,2019-05-20T19:50:47Z,https://github.com/tensorflow/tensorflow/commit/94017e5893ad1fc54ca68541a7875e9ebf40cd3b,Remove unused import in image_ops_impl.py,1,Remove Dead Code,,
df8dddb7efed2b119aad487839b92cd1cf8b852e,2019-05-13T21:21:23Z,https://github.com/tensorflow/tensorflow/commit/df8dddb7efed2b119aad487839b92cd1cf8b852e,"[XLA:Python] Remove some backward compatibility code from the Python API.Preceding changes have already broken compatibility with older JAX releases, so we can remove this compatibility code also.PiperOrigin-RevId: 248009182",1,Remove Dead Code,,
ba6f9075464c95187262a8d2e6d467297358ee5d,2019-05-02T18:16:01Z,https://github.com/tensorflow/tensorflow/commit/ba6f9075464c95187262a8d2e6d467297358ee5d,"Remove tests calling deprecated custom Cholesky gradient kernel, which is no longer in use and causes msan errors.PiperOrigin-RevId: 246354053",1,Remove Dead Code,,
b9e90fc635f9ef7800293d75c44f15512e0541ee,2019-04-30T00:08:55Z,https://github.com/tensorflow/tensorflow/commit/b9e90fc635f9ef7800293d75c44f15512e0541ee,Remove matmul_with_broadcast.PiperOrigin-RevId: 245854116,1,Remove Dead Code,,
ef1abaf219a09b9506e596baf0cee53e836c88e6,2019-04-29T15:54:28Z,https://github.com/tensorflow/tensorflow/commit/ef1abaf219a09b9506e596baf0cee53e836c88e6,Code cleanup: remove dead code.PiperOrigin-RevId: 245754859,1,Remove Dead Code,,
46d3bfb9ea2c59043bf4110b8e353f4bb5a65fe9,2019-04-26T22:12:53Z,https://github.com/tensorflow/tensorflow/commit/46d3bfb9ea2c59043bf4110b8e353f4bb5a65fe9,"Cleanup, no functional change. Remove unused function in while_v2.PiperOrigin-RevId: 245495631",1,Remove Dead Code,,
408cea8c638a9873c8a23887fadf74314bd2a0b9,2019-04-23T23:09:53Z,https://github.com/tensorflow/tensorflow/commit/408cea8c638a9873c8a23887fadf74314bd2a0b9,Remove backend.mean() from result tensors in eager mode.PiperOrigin-RevId: 244944948,1,Remove Dead Code,,
5aa52f33d305c61843df381b5b039531290bbd7f,2019-04-18T21:53:50Z,https://github.com/tensorflow/tensorflow/commit/5aa52f33d305c61843df381b5b039531290bbd7f,Remove irrelevant callbacks warning with distribute strategies.PiperOrigin-RevId: 244263923,1,Remove Dead Code,,
de3bc59d57cebff93b45855d30111b832edd1350,2019-04-12T21:22:49Z,https://github.com/tensorflow/tensorflow/commit/de3bc59d57cebff93b45855d30111b832edd1350,Remove deprecated methods from the TF v2 version of`tf.distribute.StrategyExtended`.  All implementations currently use thev1 version of `StrategyExtended` until we can transition callers off ofthose deprecated APIs.PiperOrigin-RevId: 243332161,1,Remove Dead Code,,
9b5ccf4f33334bad67c6668077a97ccb4a9a0183,2019-04-11T15:24:07Z,https://github.com/tensorflow/tensorflow/commit/9b5ccf4f33334bad67c6668077a97ccb4a9a0183,Remove tf.config.gpu.* APIsAn alternate API is being developed that supports the functionalityprovided by these APIs. Since these APIs have not yet been released thenshould be safe to remove.PiperOrigin-RevId: 243072975,1,Remove Dead Code,,
0f93dc43c4797f27dd2aa14bb298dab420965acc,2019-04-10T20:52:43Z,https://github.com/tensorflow/tensorflow/commit/0f93dc43c4797f27dd2aa14bb298dab420965acc,Removes a now-broken keras LayerNorm test that relied on the recently-removed params_axis argument to work.PiperOrigin-RevId: 242934109,1,Remove Dead Code,,
ddd6b0828a127d9678a75f91dc05fb444a8f3998,2019-04-01T16:52:32Z,https://github.com/tensorflow/tensorflow/commit/ddd6b0828a127d9678a75f91dc05fb444a8f3998,Removed a test that does not apply anymore.,1,Remove Dead Code,,
862d821b8ad4d8a51f4fea2ad2bcc2045e2e11b3,2019-03-28T16:47:36Z,https://github.com/tensorflow/tensorflow/commit/862d821b8ad4d8a51f4fea2ad2bcc2045e2e11b3,removed redundent code,1,Remove Dead Code,,
c510b79d5cf8c59874c092aa05b8d25b4d6baef1,2019-03-27T17:37:54Z,https://github.com/tensorflow/tensorflow/commit/c510b79d5cf8c59874c092aa05b8d25b4d6baef1,Removed a setter for tf.TensorShape.dimsTo the best of my knowledge it is not used anywhere internally and canbe safely removed. External users are encouraged to replace  shape.dims = ...with  shape = tf.TensorShape(...)PiperOrigin-RevId: 240592991,1,Remove Dead Code,,
f022617bdaaf3d4801664a266892b2db1bd73f9a,2019-03-26T20:42:44Z,https://github.com/tensorflow/tensorflow/commit/f022617bdaaf3d4801664a266892b2db1bd73f9a,"Remove the unused --tf_xla_fusion_only flagI'm not a 100% sure that no one uses this.  Thanks to Justin's work, passing--tf_xla_fusion_only to TF_XLA_FLAGS will now be an error so this won't be asilent regression.PiperOrigin-RevId: 240418379",1,Remove Dead Code,,
24f9b333820e8349fc8a77bbfe33f401395417c9,2019-03-26T00:47:42Z,https://github.com/tensorflow/tensorflow/commit/24f9b333820e8349fc8a77bbfe33f401395417c9,"Remove checks on no. casts in dropout test- The dropout subgraph changes between TF versions, which affects the  required number of casts.",1,Remove Dead Code,,
73cb55b411ddd96f783491c6e7ca51527c79b4c8,2019-03-20T12:03:16Z,https://github.com/tensorflow/tensorflow/commit/73cb55b411ddd96f783491c6e7ca51527c79b4c8,Remove _default_values_start_index in FunctionSpec - not needed.PiperOrigin-RevId: 239375931,1,Remove Dead Code,,
1af9cd33396595b035b02cc9ae288cc4682a4ae9,2019-03-20T07:50:41Z,https://github.com/tensorflow/tensorflow/commit/1af9cd33396595b035b02cc9ae288cc4682a4ae9,"Use sorted deps in tensorflow/core/grappler/optimizers/data/BUILD, and remove unused import in test",1,Remove Dead Code,,
fea13a48df3ac1be2f9aab25eb0035b98f494dea,2019-03-15T01:25:38Z,https://github.com/tensorflow/tensorflow/commit/fea13a48df3ac1be2f9aab25eb0035b98f494dea,Remove deprecated arguments from the exported API declarations.PiperOrigin-RevId: 238561912,1,Remove Dead Code,,
bacd851cf8281b3a87d782bbaf1888df571337a6,2019-03-13T18:35:13Z,https://github.com/tensorflow/tensorflow/commit/bacd851cf8281b3a87d782bbaf1888df571337a6,Internal cleanupPiperOrigin-RevId: 238269657,1,Remove Dead Code,,
2590dc34ca3ad61e29e5d098eb3cd44e2861c91d,2019-03-13T16:56:18Z,https://github.com/tensorflow/tensorflow/commit/2590dc34ca3ad61e29e5d098eb3cd44e2861c91d,Remove legacy reference to calib_graph_to_infer_graph().PiperOrigin-RevId: 238244926,1,Remove Dead Code,,
4b3efe8dff0afba0dc356bb5720ce17336d4bf3d,2019-03-13T01:11:33Z,https://github.com/tensorflow/tensorflow/commit/4b3efe8dff0afba0dc356bb5720ce17336d4bf3d,Internal cleanup.PiperOrigin-RevId: 238139311,1,Remove Dead Code,,
83873bd1cbd85f5b993a26aa77fbba2b594bdfc9,2019-03-08T20:26:52Z,https://github.com/tensorflow/tensorflow/commit/83873bd1cbd85f5b993a26aa77fbba2b594bdfc9,1. Remove make_fit_function and make_eval_function from Keras training.2. Some cleanup/simplifications.PiperOrigin-RevId: 237498087,1,Remove Dead Code,,
7756b484dc1c361edf441330f392ecb00df191e7,2019-03-07T16:26:51Z,https://github.com/tensorflow/tensorflow/commit/7756b484dc1c361edf441330f392ecb00df191e7,Remove obsolete tests. Consolidate the removed keras_test into the existing one.PiperOrigin-RevId: 237251861,1,Remove Dead Code,,
80aaa339819bda86471784c2636a4d82a36907ea,2019-03-06T00:03:10Z,https://github.com/tensorflow/tensorflow/commit/80aaa339819bda86471784c2636a4d82a36907ea,Remove special condition on canonicalization. The code path where this was necessary no longer exists.PiperOrigin-RevId: 236939023,1,Remove Dead Code,,
55240a22f10a9a6cf3cf8ba3d35e16d88f5925f6,2019-03-04T19:55:34Z,https://github.com/tensorflow/tensorflow/commit/55240a22f10a9a6cf3cf8ba3d35e16d88f5925f6,Remove logloss v2 as this is a duplication of bce with probabilities.PiperOrigin-RevId: 236696942,1,Remove Dead Code,,
2ffb59543ae84ea03dfe09f39736ef5033bb649f,2019-03-03T17:07:12Z,https://github.com/tensorflow/tensorflow/commit/2ffb59543ae84ea03dfe09f39736ef5033bb649f,Remove unused _MixedPrecisionVariable classPiperOrigin-RevId: 236543548,1,Remove Dead Code,,
64b4879c93f84343ea37c6d4c1caba0d3427e940,2019-02-28T02:27:39Z,https://github.com/tensorflow/tensorflow/commit/64b4879c93f84343ea37c6d4c1caba0d3427e940,Remove unnecessary uses of use_gpu for testsPiperOrigin-RevId: 236034198,1,Remove Dead Code,,
39b741fd9a3183d2eaac94c1ce420922333a86c1,2019-02-27T02:00:18Z,https://github.com/tensorflow/tensorflow/commit/39b741fd9a3183d2eaac94c1ce420922333a86c1,Remove dead codePiperOrigin-RevId: 235830086,1,Remove Dead Code,,
d813ad7dfce22489dfdddad1dea8160ad3d712bf,2019-02-25T17:59:28Z,https://github.com/tensorflow/tensorflow/commit/d813ad7dfce22489dfdddad1dea8160ad3d712bf,Remove health check from TpuClusterResolver.PiperOrigin-RevId: 235549420,1,Remove Dead Code,,
e866995aff7d0e59a5506665e44e323465cbe17d,2019-02-25T17:06:45Z,https://github.com/tensorflow/tensorflow/commit/e866995aff7d0e59a5506665e44e323465cbe17d,"Remove implicit name scoping from `tf.Module`s.After attempting to integrate `tf.Module` into existing codebases (e.g.`tf.keras`) we've found that the automatic name scoping is too invasive (e.g.changing op and variable names) and it is desirable to disable it ~everywhere.We propose that name scoping for `tf.Module` becomes opt-in:>>> class MyModule(tf.Module):......   @tf.Module.with_name_scope...   def auto_name_scope(self, x):...     if not hasattr(self, 'w'):...       self.w = tf.Variable(1., name='w')...     return x * self.w......   def manual_name_scope(self, x):...     if not hasattr(self, 'w'):...       with self.name_scope:...         self.w = tf.Variable(1., name='w')...     return x * self.w......   def no_name_scope(self, x):...     if not hasattr(self, 'w'):...       self.w = tf.Variable(1., name='w')...     return x * self.wWe will move opt-out name scoping into Sonnet:>>> class MyModule(snt.Module):......   def auto_name_scope(self, x):...     if not hasattr(self, 'w'):...       self.w = tf.Variable(1., name='w')...     return x * self.w......   @snt.no_name_scope...   def no_name_scope(self, x):...     if not hasattr(self, 'w'):...       self.w = tf.Variable(1., name='w')...     return x * self.wIn TF2 name scopes are cosmetic and this should be less of a big deal. We mightconsider encouraging users who want to filter on names to instead use flattento extract a state dictionary for their objects (c.f.https://github.com/tensorflow/community/pull/56#discussion_r255048762).I have moved the automatic name scoping logic (Metaclass etc) and associatedtests into Sonnet 2.PiperOrigin-RevId: 235540184",1,Remove Dead Code,,
ebcc4f6887df1ad1a2ffdb2dc2da1f541e24e2af,2019-02-25T15:30:03Z,https://github.com/tensorflow/tensorflow/commit/ebcc4f6887df1ad1a2ffdb2dc2da1f541e24e2af,Replace usage of tf.saved_model.load() with the public symbol on saved modelintegration tests.PiperOrigin-RevId: 235526039,1,Remove Dead Code,,
41ba16dcfba6a0939e9eb32e0fcf913096502b30,2019-02-21T17:00:34Z,https://github.com/tensorflow/tensorflow/commit/41ba16dcfba6a0939e9eb32e0fcf913096502b30,Remove unused import,1,Remove Dead Code,,
7ad52b94ac379fc535b3a01ae982d57d52b48e44,2019-02-21T01:13:06Z,https://github.com/tensorflow/tensorflow/commit/7ad52b94ac379fc535b3a01ae982d57d52b48e44,Remove the assert for debug. Sorry forgot to remove itPiperOrigin-RevId: 234900338,1,Remove Dead Code,,
2a237266572861de1869ec9b92c236d3dc34cbc2,2019-02-19T10:12:56Z,https://github.com/tensorflow/tensorflow/commit/2a237266572861de1869ec9b92c236d3dc34cbc2,Remove unused import of itertools,1,Remove Dead Code,,
01cf864bb0d82370c259866c0735c0358e33377c,2019-02-14T01:35:57Z,https://github.com/tensorflow/tensorflow/commit/01cf864bb0d82370c259866c0735c0358e33377c,Remove the old TRT INT8 converson logic.PiperOrigin-RevId: 233864708,1,Remove Dead Code,,
d98406b2d52abfa8010437da7456da24d68976e2,2019-02-14T00:32:49Z,https://github.com/tensorflow/tensorflow/commit/d98406b2d52abfa8010437da7456da24d68976e2,Remove unused class in export test file.PiperOrigin-RevId: 233854489,1,Remove Dead Code,,
d97ce58d0da919ac6497ca267182f8659625392c,2019-02-13T18:46:14Z,https://github.com/tensorflow/tensorflow/commit/d97ce58d0da919ac6497ca267182f8659625392c,Remove unused variable.PiperOrigin-RevId: 233784859,1,Remove Dead Code,,
d67977598e7fd722cc00a29ab5a8c674f5103042,2019-02-12T07:16:51Z,https://github.com/tensorflow/tensorflow/commit/d67977598e7fd722cc00a29ab5a8c674f5103042,Remove unnecessary import which users don't always depend on.PiperOrigin-RevId: 233547217,1,Remove Dead Code,,
969e17fc37f595dbb372af4ce8308f991a96608c,2019-02-09T23:36:25Z,https://github.com/tensorflow/tensorflow/commit/969e17fc37f595dbb372af4ce8308f991a96608c,Remove a code block that is never executed.PiperOrigin-RevId: 233235142,1,Remove Dead Code,,
a1f69b47a5f0cd18b3d918a72efb3323a6b2227e,2019-02-08T17:08:46Z,https://github.com/tensorflow/tensorflow/commit/a1f69b47a5f0cd18b3d918a72efb3323a6b2227e,Remove unnecessary use of six.iterkeysThis PR replaces unnecessary use of `for key in six.iterkeys(d)` with `for key in d` to improve readability.,1,Remove Dead Code,,
78840bb8646aed747e9bf643a11ed2fa77b4bbf6,2019-02-06T20:01:19Z,https://github.com/tensorflow/tensorflow/commit/78840bb8646aed747e9bf643a11ed2fa77b4bbf6,Remove flaky timing check.PiperOrigin-RevId: 232718485,1,Remove Dead Code,,
56f29b4deb1d5fca7a10e1af7251fe7361d206fd,2019-02-05T19:24:47Z,https://github.com/tensorflow/tensorflow/commit/56f29b4deb1d5fca7a10e1af7251fe7361d206fd,"Remove owned_* methods.Users who want this functionality can do so by subclassing tf.Module andimplemeting the methods themselves using `_flatten`. For example:```class MyModule(tf.Module):  @property  def owned_variables(self):    is_variable = lambda v: isinstance(v, tf.Variable)    return tuple(self._flatten(recursive=False, predicate=is_variable))```PiperOrigin-RevId: 232523894",1,Remove Dead Code,,
288bb2633081a8e12a23465190ebb937de250ad5,2019-02-05T05:51:58Z,https://github.com/tensorflow/tensorflow/commit/288bb2633081a8e12a23465190ebb937de250ad5,remove unused,1,Remove Dead Code,,
cbebae641b9d6bd8a6db9e1f8489f0edbf116bf2,2019-02-04T13:21:05Z,https://github.com/tensorflow/tensorflow/commit/cbebae641b9d6bd8a6db9e1f8489f0edbf116bf2,Remove unnecessary default case handling,1,Remove Dead Code,,
827d9b2c2abe25518ea7cf37aa54b5a39123f297,2019-01-29T13:01:32Z,https://github.com/tensorflow/tensorflow/commit/827d9b2c2abe25518ea7cf37aa54b5a39123f297,Remove duplicate function which is now natively in nest.PiperOrigin-RevId: 231385811,1,Remove Dead Code,,
9eca1a045a8233958e7e8be494ed8e0ab5a712d6,2019-01-27T04:31:04Z,https://github.com/tensorflow/tensorflow/commit/9eca1a045a8233958e7e8be494ed8e0ab5a712d6,Remove decorator transformer in preparation for a more comprehensive solution.PiperOrigin-RevId: 231084903,1,Remove Dead Code,,
d1afaa4c1472d38a7230d68e312c9ea37f834cc5,2019-01-25T07:18:26Z,https://github.com/tensorflow/tensorflow/commit/d1afaa4c1472d38a7230d68e312c9ea37f834cc5,Remove import of tensorflow.,1,Remove Dead Code,,
0eeb360d8f04fd93b799a07bedbea6e6e899f55e,2019-01-17T00:12:52Z,https://github.com/tensorflow/tensorflow/commit/0eeb360d8f04fd93b799a07bedbea6e6e899f55e,Remove dead code block from normalization layerPiperOrigin-RevId: 229645644,1,Remove Dead Code,,
f497b36f3250a4e26051be3f3616e7ad233f3cc8,2019-01-11T00:17:39Z,https://github.com/tensorflow/tensorflow/commit/f497b36f3250a4e26051be3f3616e7ad233f3cc8,Remove the experimental initialize and finalize API.PiperOrigin-RevId: 228797485,1,Remove Dead Code,,
245925078f574983593e42154091e07c311e30bd,2019-01-09T19:45:24Z,https://github.com/tensorflow/tensorflow/commit/245925078f574983593e42154091e07c311e30bd,Remove the implementation of TPU Strategy initialize and finalizePiperOrigin-RevId: 228558184,1,Remove Dead Code,,
46137ebafbb56857622403115ba99051d896351d,2019-01-09T00:25:48Z,https://github.com/tensorflow/tensorflow/commit/46137ebafbb56857622403115ba99051d896351d,Remove disabled test (should live with pasta).PiperOrigin-RevId: 228421179,1,Remove Dead Code,,
73b6e92b4b3faf0c20687af3ba63989fc5234f13,2019-01-04T22:35:23Z,https://github.com/tensorflow/tensorflow/commit/73b6e92b4b3faf0c20687af3ba63989fc5234f13,Remove usage of the initialize and finalize apiPiperOrigin-RevId: 227915547,1,Remove Dead Code,,
cea2e9c4fab95890873114bf60a5f19facca0c2f,2019-01-04T21:17:37Z,https://github.com/tensorflow/tensorflow/commit/cea2e9c4fab95890873114bf60a5f19facca0c2f,"Removed set_shape overrides from ResourceVariable subclasses.These are essentially no-ops and allow for reads returning tensors inconsistentwith variable shape:    >>> import tensorflow as tf    >>> tf.enable_eager_execution()    >>> v = tf.Variable(0)    >>> t = v.assign(42)    >>> t.set_shape((100500, ))    >>> t.shape    (100500, )    >>> tf.convert_to_tensor(t)    <tf.Tensor: id=9, shape=(), dtype=int32, numpy=42>PiperOrigin-RevId: 227903155",1,Remove Dead Code,,
560e4dd67fa8f9b0b99b940e35d039cf6c40194a,2019-01-03T00:20:44Z,https://github.com/tensorflow/tensorflow/commit/560e4dd67fa8f9b0b99b940e35d039cf6c40194a,Remove unused imports,1,Remove Dead Code,,
276a456b3551a329881e0104edf8ea848d446033,2019-01-02T21:25:11Z,https://github.com/tensorflow/tensorflow/commit/276a456b3551a329881e0104edf8ea848d446033,Remove unused imports,1,Remove Dead Code,,
bd312687ad05ad36b5ed0589b0303df848bea266,2018-12-11T18:52:07Z,https://github.com/tensorflow/tensorflow/commit/bd312687ad05ad36b5ed0589b0303df848bea266,Remove unneeded import,1,Remove Dead Code,,
5b2a39b431b293bf6ff5ada29c211d5bce5459d8,2018-12-05T20:14:00Z,https://github.com/tensorflow/tensorflow/commit/5b2a39b431b293bf6ff5ada29c211d5bce5459d8,Remove an unused import,1,Remove Dead Code,,
f8f17cebcc89921b5f1a204dab1f9fdb47b120c1,2018-12-03T18:30:47Z,https://github.com/tensorflow/tensorflow/commit/f8f17cebcc89921b5f1a204dab1f9fdb47b120c1,Remove python-side colocation device check that only matches on strings instead of actual devices.PiperOrigin-RevId: 223818954,1,Remove Dead Code,,
672840616bd8b65ed9089ae687a714abfd87f63e,2018-11-28T23:17:45Z,https://github.com/tensorflow/tensorflow/commit/672840616bd8b65ed9089ae687a714abfd87f63e,Remove unused imports,1,Remove Dead Code,,
ebbf59ebc154a0dea65cda4a8ef56416189b43fb,2018-11-28T17:11:50Z,https://github.com/tensorflow/tensorflow/commit/ebbf59ebc154a0dea65cda4a8ef56416189b43fb,Remove methods from tf.Variable which in RefVariable are to be deprecated and aren't supported in Resource VariablePiperOrigin-RevId: 223178585,1,Remove Dead Code,,
fbd5472f477c277aa1e4044d4f7e29b4ae958542,2018-11-28T02:02:07Z,https://github.com/tensorflow/tensorflow/commit/fbd5472f477c277aa1e4044d4f7e29b4ae958542,Remove metric value and update op return type check.Fixes tensorflow#23731PiperOrigin-RevId: 223091282,1,Remove Dead Code,,
733ea8ac2c71989988cea7662a3acae4240362c7,2018-11-27T10:54:59Z,https://github.com/tensorflow/tensorflow/commit/733ea8ac2c71989988cea7662a3acae4240362c7,"Removed duplicated _Overload* methods in variablesPrior to this change all variable classes (Variable, RefVariable andResourceVariable) had their own copy/pasted implementation of_OverloadOperator and _OverloadAllOperators. This was unnecessary sincea single implementation in the base class would work just as well.The change also fixes the __name__ and __module__ of the operatorwrapper functions.PiperOrigin-RevId: 222963169",1,Remove Dead Code,,
968bb07ccc1871368addc2fbe07f61f1a91183a3,2018-11-26T20:04:09Z,https://github.com/tensorflow/tensorflow/commit/968bb07ccc1871368addc2fbe07f61f1a91183a3,Remove flags module from v2 API. Use argparse or absl if you need flag parsing.PiperOrigin-RevId: 222863846,1,Remove Dead Code,,
781a8f2e2093c38ff8e7dff94eb432cd948e54b0,2018-11-21T20:34:35Z,https://github.com/tensorflow/tensorflow/commit/781a8f2e2093c38ff8e7dff94eb432cd948e54b0,Remove pywrap_tensorflow from available symbols in Tensorflow v2PiperOrigin-RevId: 222446280,1,Remove Dead Code,,
0dff427f4ebee8486db686cef28a8d17c4c663e5,2018-11-19T20:28:22Z,https://github.com/tensorflow/tensorflow/commit/0dff427f4ebee8486db686cef28a8d17c4c663e5,Removed unnecessary iterator class from PartitionedVariableNote that PartitionedVariable is still iterable.PiperOrigin-RevId: 222119232,1,Remove Dead Code,,
c698e2b0ad81218e3d6358059703defae7b30e7b,2018-11-19T17:01:22Z,https://github.com/tensorflow/tensorflow/commit/c698e2b0ad81218e3d6358059703defae7b30e7b,"Remove invalid/misleading test.The test removed in this commit was invalid and only accidentallypassed because self.cached_session() forces placement of all operationson CPU (since use_gpu defaults to False).The implementation of Variables.initialized_value() creates a tf.condwhich is not forcefully colocated with the variable, hence running thistest with ""self.cached_session(use_gpu=True)"" would fail with:AssertionError: '/device:CPU:0' != ''This test was made invalid byhttps://github.com/tensorflow/tensorflow/commit/b25d1c7d3e9f30925aa132ba62e79d281191a3dc(see changes to tensorflow/python/ops/variables.py)I don't think the test was actually useful, so removing it altogether.PiperOrigin-RevId: 222084451",1,Remove Dead Code,,
5c4fe7b6680df500cf129306e08b86ff3128c5f4,2018-11-16T17:48:36Z,https://github.com/tensorflow/tensorflow/commit/5c4fe7b6680df500cf129306e08b86ff3128c5f4,Remove dead code.USE_C_SHAPES has been forced True for a while now(June: commit 1d74a69443f741e69f9f52cb6bc2940b4d4ae3b7August: commit a473f435cf7345cb9dc2efacb471a7f318141a9b)PiperOrigin-RevId: 221808148,1,Remove Dead Code,,
1f151edc6cf1bd508c93b9bbf3ee3c20995247cd,2018-11-13T19:53:36Z,https://github.com/tensorflow/tensorflow/commit/1f151edc6cf1bd508c93b9bbf3ee3c20995247cd,Remove dead code._USE_C_SHAPES has been forced True for a while now.(June: commit 1d74a69443f741e69f9f52cb6bc2940b4d4ae3b7August: commit a473f435cf7345cb9dc2efacb471a7f318141a9b)PiperOrigin-RevId: 221306957,1,Remove Dead Code,,
42b1f9c7cab16165fb6f111d367de07cd552f76f,2018-11-11T20:24:01Z,https://github.com/tensorflow/tensorflow/commit/42b1f9c7cab16165fb6f111d367de07cd552f76f,"Remove manual learning phase usage tracking.Now we always feed the learning phase value with fit/evaluate/predictif it's a placeholder, independently of whether it's used or not.This results in reduced code complexity and brittleness.PiperOrigin-RevId: 221007984",1,Remove Dead Code,,
c631042f73c21ee84d8f2f16982d8e4c03d803e8,2018-11-09T21:33:31Z,https://github.com/tensorflow/tensorflow/commit/c631042f73c21ee84d8f2f16982d8e4c03d803e8,Remove unused `PerIterationDataset`.PiperOrigin-RevId: 220855814,1,Remove Dead Code,,
235e719c4d228e99e8859ed5da9d3301e375ea35,2018-11-09T00:21:09Z,https://github.com/tensorflow/tensorflow/commit/235e719c4d228e99e8859ed5da9d3301e375ea35,"Remove references to ""prefetch_on_device"" from callers.PiperOrigin-RevId: 220720696",1,Remove Dead Code,,
cae143f88aa17afdc39c4a91e2905a4472e4df75,2018-11-06T01:05:47Z,https://github.com/tensorflow/tensorflow/commit/cae143f88aa17afdc39c4a91e2905a4472e4df75,Remove shuffle from inputPiperOrigin-RevId: 220199936,1,Remove Dead Code,,
4826fdcedd7f89bc7793f9a7bb6dece7ae1f942a,2018-10-23T23:58:46Z,https://github.com/tensorflow/tensorflow/commit/4826fdcedd7f89bc7793f9a7bb6dece7ae1f942a,Remove dead code._USE_C_SHAPES has been forced True for a while now(June: commit 1d74a69443f741e69f9f52cb6bc2940b4d4ae3b7August: commit a473f435cf7345cb9dc2efacb471a7f318141a9b)PiperOrigin-RevId: 218432421,1,Remove Dead Code,,
af14e4cf353a985de636a644bdb4a858e96707d4,2018-10-23T22:10:26Z,https://github.com/tensorflow/tensorflow/commit/af14e4cf353a985de636a644bdb4a858e96707d4,Removed graph and session setup from unit test,1,Remove Dead Code,,
9fa2e774d3aa3f53592cf5e0d3fe26cb40e3d6a1,2018-10-23T01:47:25Z,https://github.com/tensorflow/tensorflow/commit/9fa2e774d3aa3f53592cf5e0d3fe26cb40e3d6a1,Removed unused import,1,Remove Dead Code,,
c2208eb373f1a4cceb7f2f53e902cdb319a6f42c,2018-10-19T20:18:39Z,https://github.com/tensorflow/tensorflow/commit/c2208eb373f1a4cceb7f2f53e902cdb319a6f42c,Delete the now-unused increment_var() internal DistributionStrategy function.PiperOrigin-RevId: 217920172,1,Remove Dead Code,,
60a0bfeb389e490e80d2effd1e518c7953783ac7,2018-10-10T17:20:21Z,https://github.com/tensorflow/tensorflow/commit/60a0bfeb389e490e80d2effd1e518c7953783ac7,Remove the tensorflow import from generated code.PiperOrigin-RevId: 216550899,1,Remove Dead Code,,
d37204edfaad3c7cbd361687422d40e2b9bb4d87,2018-10-06T03:19:10Z,https://github.com/tensorflow/tensorflow/commit/d37204edfaad3c7cbd361687422d40e2b9bb4d87,Remove unused python import,1,Remove Dead Code,,
7d66a720acb756291adc99ebe444c2c00bd37d84,2018-10-02T15:57:07Z,https://github.com/tensorflow/tensorflow/commit/7d66a720acb756291adc99ebe444c2c00bd37d84,Remove Ignite Dataset SSL tests by internal policy.,1,Remove Dead Code,,
03a18ca576410d49e8f0692464e35e900a54f59f,2018-10-01T17:01:20Z,https://github.com/tensorflow/tensorflow/commit/03a18ca576410d49e8f0692464e35e900a54f59f,Remove outdated integration test in preparation for update of keras_preprocessing.PiperOrigin-RevId: 215231309,1,Remove Dead Code,,
d614ab369b6c59433fa4750b38592f48ae1b5a45,2018-09-29T12:04:38Z,https://github.com/tensorflow/tensorflow/commit/d614ab369b6c59433fa4750b38592f48ae1b5a45,Remove unused imports.,1,Remove Dead Code,,
e2ce9787d9927e4a6574e6ac4606a47712320170,2018-09-24T16:21:45Z,https://github.com/tensorflow/tensorflow/commit/e2ce9787d9927e4a6574e6ac4606a47712320170,Remove unused compatibility code in Softmax implementation now that the forward compatibility window has expired.PiperOrigin-RevId: 214277870,1,Remove Dead Code,,
1ede512f8c185a1cc2bd88830eeca3165283f06d,2018-09-18T00:53:41Z,https://github.com/tensorflow/tensorflow/commit/1ede512f8c185a1cc2bd88830eeca3165283f06d,Remove some dead code after migration from python to C.PiperOrigin-RevId: 213372027,1,Remove Dead Code,,
3fe9c54b6181bc2bbfa535b28ecb7d3b74342bd8,2018-09-17T17:13:15Z,https://github.com/tensorflow/tensorflow/commit/3fe9c54b6181bc2bbfa535b28ecb7d3b74342bd8,Remove unnecessary import of callbacks,1,Remove Dead Code,,
9fcf40afede43c09243d06ba420ac44249067872,2018-09-14T05:44:30Z,https://github.com/tensorflow/tensorflow/commit/9fcf40afede43c09243d06ba420ac44249067872,CLN: remove unused import,1,Remove Dead Code,,
6bf71666feb2184771ec3d0d304329b50a9a4ad2,2018-09-12T15:23:00Z,https://github.com/tensorflow/tensorflow/commit/6bf71666feb2184771ec3d0d304329b50a9a4ad2,Remove compat.forward_compatible horizon checks for StaticRegexReplace.PiperOrigin-RevId: 212642629,1,Remove Dead Code,,
e3c334e57fba9afc0b0a3aa5f7787ee35e17ddf6,2018-09-12T06:59:44Z,https://github.com/tensorflow/tensorflow/commit/e3c334e57fba9afc0b0a3aa5f7787ee35e17ddf6,CLN: remove unnecessary math_ops.maximum,1,Remove Dead Code,,
39b2fb7cfef489424fead18ec5174d8e8b2a9a1a,2018-09-07T23:26:31Z,https://github.com/tensorflow/tensorflow/commit/39b2fb7cfef489424fead18ec5174d8e8b2a9a1a,Remove unnecessary function calls from data/util/nest.pyPiperOrigin-RevId: 212054927,1,Remove Dead Code,,
553ce1ff813fe7436ed3d6f194290e6703e2c179,2018-09-06T20:27:29Z,https://github.com/tensorflow/tensorflow/commit/553ce1ff813fe7436ed3d6f194290e6703e2c179,Remove unused and non public get_signature_def* methods from saved_model/signature_def_utilsPiperOrigin-RevId: 211858972,1,Remove Dead Code,,
9d76f6b2d0de14c03db97e36f8c51632d58701da,2018-09-01T06:04:44Z,https://github.com/tensorflow/tensorflow/commit/9d76f6b2d0de14c03db97e36f8c51632d58701da,Remove per-tower ready op since concat doesn't have a GPU kernel for DT_STRING.The current implementation queries the global collection for ready op. Therefore there is no need to have a per-tower ready op.PiperOrigin-RevId: 211187544,1,Remove Dead Code,,
eeb7a787566b9dbbf8855525f6fbbdf65b3e536e,2018-08-30T19:15:43Z,https://github.com/tensorflow/tensorflow/commit/eeb7a787566b9dbbf8855525f6fbbdf65b3e536e,Remove explicit tape watching in backprop tests.PiperOrigin-RevId: 210956690,1,Remove Dead Code,,
607004e583ecbd9fb788aaf9b360a8d85cf167ac,2018-08-27T20:12:23Z,https://github.com/tensorflow/tensorflow/commit/607004e583ecbd9fb788aaf9b360a8d85cf167ac,AGN: remove compute_gradient,1,Remove Dead Code,,
b07f8211409f2b2e46ab539291e824f2b7865885,2018-08-25T06:12:48Z,https://github.com/tensorflow/tensorflow/commit/b07f8211409f2b2e46ab539291e824f2b7865885,remove unused sparse_ops import,1,Remove Dead Code,,
a473f435cf7345cb9dc2efacb471a7f318141a9b,2018-08-23T20:07:16Z,https://github.com/tensorflow/tensorflow/commit/a473f435cf7345cb9dc2efacb471a7f318141a9b,"- Remove now unnecessary _use_c_api_hack()- Set _USE_C_SHAPES=True, the escape hatch to disable it should no longer be  neededPiperOrigin-RevId: 209985467",1,Remove Dead Code,,
f4df6cb3aebc64a8e9c2c2d2dc06fa039e188566,2018-08-22T13:24:05Z,https://github.com/tensorflow/tensorflow/commit/f4df6cb3aebc64a8e9c2c2d2dc06fa039e188566,Remove unused compat importSigned-off-by: Yong Tang <yong.tang.github@outlook.com>,1,Remove Dead Code,,
e687764a94abc17866213d505d1dbe5e4873e1b9,2018-08-20T23:05:56Z,https://github.com/tensorflow/tensorflow/commit/e687764a94abc17866213d505d1dbe5e4873e1b9,"Remove graph_callable.py and all references to it.Our APIs for creating functions are tfe.defun() and tfe.make_template();graph_callable is no longer needed.Additionally, change GraphModeFunction to accept a FuncGraph instead ofa CapturingGraph --- graph_callable was preventing us from doing this.This is part of ongoing hygiene work to help us think more clearly about the function APIs we'll want to provide. GraphModeFunction (which is renamed to GraphCallable here) previously had way too many attributes.PiperOrigin-RevId: 209502276",1,Remove Dead Code,,
fabf7a5c18555e52cef75643b4d4532ff70aa23e,2018-08-15T16:46:20Z,https://github.com/tensorflow/tensorflow/commit/fabf7a5c18555e52cef75643b4d4532ff70aa23e,Remove unused Estimator overrides.PiperOrigin-RevId: 208834294,1,Remove Dead Code,,
603b4b66b075eec7f1127ce8144dfa252a87bb47,2018-08-15T01:01:33Z,https://github.com/tensorflow/tensorflow/commit/603b4b66b075eec7f1127ce8144dfa252a87bb47,Remove set_build_strip_flag,1,Remove Dead Code,,
a802075bf3a54b1d3acf6dfca65ba902befd7bb2,2018-08-06T22:52:27Z,https://github.com/tensorflow/tensorflow/commit/a802075bf3a54b1d3acf6dfca65ba902befd7bb2,Internal cleanupPiperOrigin-RevId: 207623153,1,Remove Dead Code,,
a28ad4b26dbb8cb1e9cf2135f72f3f55ffabf037,2018-08-01T21:52:29Z,https://github.com/tensorflow/tensorflow/commit/a28ad4b26dbb8cb1e9cf2135f72f3f55ffabf037,Remove unused imports.PiperOrigin-RevId: 206998261,1,Remove Dead Code,,
24331e4fc0166d2adf3cf3b155844b5c77500a0c,2018-08-01T18:03:11Z,https://github.com/tensorflow/tensorflow/commit/24331e4fc0166d2adf3cf3b155844b5c77500a0c,Remove deprecated Recurrent class from RNN.PiperOrigin-RevId: 206956778,1,Remove Dead Code,,
5555187bed6d321b8dfed255a2254a9ebedfd4a4,2018-07-30T19:50:03Z,https://github.com/tensorflow/tensorflow/commit/5555187bed6d321b8dfed255a2254a9ebedfd4a4,Remove excessive split and concat.PiperOrigin-RevId: 206630163,1,Remove Dead Code,,
4027262f588466ee4a419c28521a5b53aad12e5a,2018-07-30T18:52:57Z,https://github.com/tensorflow/tensorflow/commit/4027262f588466ee4a419c28521a5b53aad12e5a,"De-dup few eager mode tests, remove some unused functions and params.PiperOrigin-RevId: 206621105",1,Remove Dead Code,,
c22b5c678a42474fbc9aab59345ac09eeb685c37,2018-07-29T09:20:45Z,https://github.com/tensorflow/tensorflow/commit/c22b5c678a42474fbc9aab59345ac09eeb685c37,CLN: remove unused import,1,Remove Dead Code,,
4134f7483054e995a2cdf9521c0b65e9518ca7dc,2018-07-10T16:44:36Z,https://github.com/tensorflow/tensorflow/commit/4134f7483054e995a2cdf9521c0b65e9518ca7dc,Remove the unused _like_rnncell function and prefer the assert_like_rnncellPiperOrigin-RevId: 203962361,1,Remove Dead Code,,
c9cb73604bbe12c79badb03c7f3e1ab817e2e25e,2018-07-10T10:33:23Z,https://github.com/tensorflow/tensorflow/commit/c9cb73604bbe12c79badb03c7f3e1ab817e2e25e,Remove unused imports,1,Remove Dead Code,,
1e0e804ca57791b48d394ad6f7fb536774e8c220,2018-07-09T23:42:11Z,https://github.com/tensorflow/tensorflow/commit/1e0e804ca57791b48d394ad6f7fb536774e8c220,"Remove unused _SlimRNNCell.This cell type has been private for a while, and neither used by internal code, nor exposed as a public API.PiperOrigin-RevId: 203853628",1,Remove Dead Code,,
11fda4459fc751506d51211480905de36c6d6f6c,2018-06-27T15:42:47Z,https://github.com/tensorflow/tensorflow/commit/11fda4459fc751506d51211480905de36c6d6f6c,"Remove unnecessary reparameterization_type specification for tf.distributions.Exponential.There is no need to manually specify that Exponential is reparameterized because the parent distribution, Gamma, is now reparameterized.PiperOrigin-RevId: 202315101",1,Remove Dead Code,,
92221c68cdcf27607969089e5b6c06fdeeae8ae8,2018-06-26T20:57:36Z,https://github.com/tensorflow/tensorflow/commit/92221c68cdcf27607969089e5b6c06fdeeae8ae8,Remove dead code from gradients_impl.py and gradients_test.py.PiperOrigin-RevId: 202188895,1,Remove Dead Code,,
1695dd95ee7750e355ac64d527ff75fb5ecbbdc7,2018-06-27T15:42:47Z,https://github.com/tensorflow/tensorflow/commit/1695dd95ee7750e355ac64d527ff75fb5ecbbdc7,"Remove unnecessary reparameterization_type specification for tf.distributions.Exponential.There is no need to manually specify that Exponential is reparameterized because the parent distribution, Gamma, is now reparameterized.PiperOrigin-RevId: 202315101",1,Remove Dead Code,,
1081683bf67f353dacc34c220c808a0080281f7f,2018-06-26T20:57:36Z,https://github.com/tensorflow/tensorflow/commit/1081683bf67f353dacc34c220c808a0080281f7f,Remove dead code from gradients_impl.py and gradients_test.py.PiperOrigin-RevId: 202188895,1,Remove Dead Code,,
5b1ba1d98c0b820d5b1b9633aef9494293b7e5fd,2018-06-25T18:28:14Z,https://github.com/tensorflow/tensorflow/commit/5b1ba1d98c0b820d5b1b9633aef9494293b7e5fd,Remove debugging codes,1,Remove Dead Code,,
4031d064542093868a82a924379da2dc739adbbd,2018-06-22T21:40:52Z,https://github.com/tensorflow/tensorflow/commit/4031d064542093868a82a924379da2dc739adbbd,"Remove hourglass imports for python/keras/engine/...Previously there was python/keras/engine/__init__.py, which required every import of Layer (for example) to also import Network (since Python will not import a file in a directory without running its __init__.py file).I'm working on adding automatic attribute tracking to Checkpointable (and Network) and so need to insert things between Layer and Network.PiperOrigin-RevId: 201743850",1,Remove Dead Code,,
4e1ba723c9d239edee0347a99ea394a83489637e,2018-06-22T14:14:49Z,https://github.com/tensorflow/tensorflow/commit/4e1ba723c9d239edee0347a99ea394a83489637e,CLN: clean code,1,Remove Dead Code,,
1a517b99b6c2c1abbe5390f87f4128db5e69e142,2018-06-20T20:38:15Z,https://github.com/tensorflow/tensorflow/commit/1a517b99b6c2c1abbe5390f87f4128db5e69e142,Remove a dead if block in control_flow_ops.py.PiperOrigin-RevId: 201407240,1,Remove Dead Code,,
f596bcc78639bb59894fd8e97779e6f53eeef190,2018-06-14T18:19:09Z,https://github.com/tensorflow/tensorflow/commit/f596bcc78639bb59894fd8e97779e6f53eeef190,Remove dead code from bulk_restore() but keep dead function parameter for backward-compatibility.PiperOrigin-RevId: 200587926,1,Remove Dead Code,,
58a2b88f570fbdf185da30e85515c8e02c290c13,2018-06-13T15:40:53Z,https://github.com/tensorflow/tensorflow/commit/58a2b88f570fbdf185da30e85515c8e02c290c13,Remove duplicate import in linear_equations.py (#19990)The line `from tensorflow.python.ops import linalg_ops`in linear_equations.py is a duplicate from the previousline. This fix removes the duplicate import.Signed-off-by: Yong Tang <yong.tang.github@outlook.com>,1,Remove Dead Code,,
e042e3e051d3bd6bfb63dfd4ad407a82f7d1dacc,2018-06-13T00:47:58Z,https://github.com/tensorflow/tensorflow/commit/e042e3e051d3bd6bfb63dfd4ad407a82f7d1dacc,Remove unused tf_export import,1,Remove Dead Code,,
537e8c7a28b6b793eb570c957c4e90bf81ce9c3b,2018-06-07T15:47:36Z,https://github.com/tensorflow/tensorflow/commit/537e8c7a28b6b793eb570c957c4e90bf81ce9c3b,Remove _USE_C_API staging from session.py.PiperOrigin-RevId: 199641205,1,Remove Dead Code,,
cf6e7096f5ffab77418ffd2e084972d99801d4f2,2018-06-07T00:34:06Z,https://github.com/tensorflow/tensorflow/commit/cf6e7096f5ffab77418ffd2e084972d99801d4f2,Remove _USE_C_API test_util methods now that the C API is enabled by default.This is in preparation for removing the _USE_C_API toggle altogether.PiperOrigin-RevId: 199561250,1,Remove Dead Code,,
b1e5c6e0a1cb131d64cd3b35c744693c0099f349,2018-06-06T22:07:21Z,https://github.com/tensorflow/tensorflow/commit/b1e5c6e0a1cb131d64cd3b35c744693c0099f349,Remove _USE_C_API staging in tests now that the C API is enabled by default.This is in preparation for removing the _USE_C_API toggle altogether.PiperOrigin-RevId: 199536151,1,Remove Dead Code,,
274f9510f68f237589df5c6a414e4b8e5ebcdba1,2018-06-05T15:13:07Z,https://github.com/tensorflow/tensorflow/commit/274f9510f68f237589df5c6a414e4b8e5ebcdba1,Remove _USE_C_API staging from ops.py.PiperOrigin-RevId: 199298594,1,Remove Dead Code,,
7eaef86f7766e7c0577614e646dc8d6a972b91f9,2018-06-04T16:55:17Z,https://github.com/tensorflow/tensorflow/commit/7eaef86f7766e7c0577614e646dc8d6a972b91f9,Remove unnecessary assertions,1,Remove Dead Code,,
72307dfb415e44d95bf72850bff7b7106385cda0,2018-06-02T15:29:59Z,https://github.com/tensorflow/tensorflow/commit/72307dfb415e44d95bf72850bff7b7106385cda0,Remove duplicate import of gen_decode_video_op_pySigned-off-by: Yong Tang <yong.tang.github@outlook.com>,1,Remove Dead Code,,
0303c029d99c4080a3929a8320d9972cc4b973d5,2018-06-02T15:28:04Z,https://github.com/tensorflow/tensorflow/commit/0303c029d99c4080a3929a8320d9972cc4b973d5,Remove duplicate importsInside ffmpeg/__init__.py the last import line:```from tensorflow.contrib.ffmpeg.ffmpeg_ops import decode_video```is a duplicate of the previous import. This fix removes the duplicate.Signed-off-by: Yong Tang <yong.tang.github@outlook.com>,1,Remove Dead Code,,
02ba49573008c22758fb90c8e26dde24406c1584,2018-05-30T01:17:19Z,https://github.com/tensorflow/tensorflow/commit/02ba49573008c22758fb90c8e26dde24406c1584,Remove unnecessary shape registration fn from cudnn rnn ops.The registered ones are the same as default.PiperOrigin-RevId: 198489529,1,Remove Dead Code,,
550251d0664a5c9f449a5f92c9c42917525a5547,2018-05-29T16:15:44Z,https://github.com/tensorflow/tensorflow/commit/550251d0664a5c9f449a5f92c9c42917525a5547,Clean up: remove useless super delegation.PiperOrigin-RevId: 198405670,1,Remove Dead Code,,
06ba7827cb4e781ab36e6bbc46cf34e3ea587335,2018-05-27T17:33:27Z,https://github.com/tensorflow/tensorflow/commit/06ba7827cb4e781ab36e6bbc46cf34e3ea587335,Remove unused function,1,Remove Dead Code,,
3f197bcc46938011f51b4d09dee8c5784822e4f9,2018-05-17T18:33:36Z,https://github.com/tensorflow/tensorflow/commit/3f197bcc46938011f51b4d09dee8c5784822e4f9,Remove C API staging from importer.py.PiperOrigin-RevId: 197024708,1,Remove Dead Code,,
a920b0439032ea21ad0fcc392f3914a6506ba0b9,2018-05-17T18:03:04Z,https://github.com/tensorflow/tensorflow/commit/a920b0439032ea21ad0fcc392f3914a6506ba0b9,"Remove duplicate `from six import text_type` in upload_test_benchmarks.pyThe `from six import text_type` was imported twice inupload_test_benchmarks.py, this fix removes the duplication.Signed-off-by: Yong Tang <yong.tang.github@outlook.com>",1,Remove Dead Code,,
d335efbaac98bfa974eea77bbc63d56101031477,2018-05-17T01:05:52Z,https://github.com/tensorflow/tensorflow/commit/d335efbaac98bfa974eea77bbc63d56101031477,Remove _USE_C_API staging in tests now that the C API is enabled by default.This is in preparation for removing the _USE_C_API toggle altogether.PiperOrigin-RevId: 196920890,1,Remove Dead Code,,
0c33e1ff58e121a0cf6acdb6aeb8de53cb3abf25,2018-05-17T01:03:01Z,https://github.com/tensorflow/tensorflow/commit/0c33e1ff58e121a0cf6acdb6aeb8de53cb3abf25,Remove _USE_C_API staging in tests now that the C API is enabled by default.This is in preparation for removing the _USE_C_API toggle altogether.PiperOrigin-RevId: 196920481,1,Remove Dead Code,,
4c1339a60768f606b1efc0f3662f8668e0e474ce,2018-05-14T22:32:44Z,https://github.com/tensorflow/tensorflow/commit/4c1339a60768f606b1efc0f3662f8668e0e474ce,Remove CuDNNRNN timing test.PiperOrigin-RevId: 196578043,1,Remove Dead Code,,
29cd3f96322f3d5326a2dbe6a9c502919159c9fc,2018-05-01T23:14:30Z,https://github.com/tensorflow/tensorflow/commit/29cd3f96322f3d5326a2dbe6a9c502919159c9fc,[tf.data] Remove debug code.,1,Remove Dead Code,,
5da0d0022e08e60a30b88e4ef28c7f864e50fd1e,2018-04-30T15:26:08Z,https://github.com/tensorflow/tensorflow/commit/5da0d0022e08e60a30b88e4ef28c7f864e50fd1e,[tf.data] Removed debug code.,1,Remove Dead Code,,
fe965a8502c1a6667ab209dfbfd8b84a6bfb45ee,2018-04-25T18:52:08Z,https://github.com/tensorflow/tensorflow/commit/fe965a8502c1a6667ab209dfbfd8b84a6bfb45ee,Removing remove_undocumented calls from tensorflow/python.PiperOrigin-RevId: 194274698,1,Remove Dead Code,,
bc78f9b060cece8e29a89f7dbcdedcadbc61891d,2018-04-20T21:32:07Z,https://github.com/tensorflow/tensorflow/commit/bc78f9b060cece8e29a89f7dbcdedcadbc61891d,internalEND_PUBLICBEGIN_PUBLICAutomated g4 rollback of changelist 193600682PiperOrigin-RevId: 193723856,1,Remove Dead Code,,
40e16d6301ee0c1334ce514350668a16d7debd9a,2018-04-18T22:47:12Z,https://github.com/tensorflow/tensorflow/commit/40e16d6301ee0c1334ce514350668a16d7debd9a,Remove duplicate code.PiperOrigin-RevId: 193430279,1,Remove Dead Code,,
75fd390fc14d50683c59a087c1f5541fc1fecaf5,2018-04-17T21:33:27Z,https://github.com/tensorflow/tensorflow/commit/75fd390fc14d50683c59a087c1f5541fc1fecaf5,"Remove duplicate imports in several placesWrote a script to scan throught the python files in the repo,and found the remaining duplicate imports in some python files like:``` from tensorflow.python.ops import random_ops-from tensorflow.python.ops import random_ops from tensorflow.python.util.deprecation import deprecated```This fix removed all of them for duplicate imports.Signed-off-by: Yong Tang <yong.tang.github@outlook.com>",1,Remove Dead Code,,
59367ba641fd33a78da38a42389d73d9f250dc36,2018-04-17T19:47:25Z,https://github.com/tensorflow/tensorflow/commit/59367ba641fd33a78da38a42389d73d9f250dc36,Remove duplicate import in compat.pyNoticed there are a couple of places in compat.py thathave duplicate import:```from tensorflow.python.util.tf_export import tf_exportfrom tensorflow.python.util.tf_export import tf_export```This fix remove duplicate imports.Signed-off-by: Yong Tang <yong.tang.github@outlook.com>,1,Remove Dead Code,,
345ccea1ea751e426a2d2d8e8d44455c43336d8c,2018-04-16T19:09:24Z,https://github.com/tensorflow/tensorflow/commit/345ccea1ea751e426a2d2d8e8d44455c43336d8c,Remove obsolete tests. Patch the unexpected print output in Python 3.PiperOrigin-RevId: 193078330,1,Remove Dead Code,,
8e1b323be4b5d56d531b2d5ee7a1fc573a2a0b5f,2018-04-11T15:30:18Z,https://github.com/tensorflow/tensorflow/commit/8e1b323be4b5d56d531b2d5ee7a1fc573a2a0b5f,Temporarily remove prelu from generated_examples_zip_testPiperOrigin-RevId: 192453411,1,Remove Dead Code,,
963ad0ff75d880861df20266652b263a9e32f0c7,2018-04-11T01:50:58Z,https://github.com/tensorflow/tensorflow/commit/963ad0ff75d880861df20266652b263a9e32f0c7,Remove BN workaround for resource variable gradients bug that was recently fixed.PiperOrigin-RevId: 192388867,1,Remove Dead Code,,
0d343fbb0e8c66622bc21aab39e225c6d895a78b,2018-04-01T02:42:10Z,https://github.com/tensorflow/tensorflow/commit/0d343fbb0e8c66622bc21aab39e225c6d895a78b,CLN: remove unused argument beta2_power,1,Remove Dead Code,,
42b42fcab0031e36105cb1db105b70cbcfa6b125,2018-03-30T21:00:02Z,https://github.com/tensorflow/tensorflow/commit/42b42fcab0031e36105cb1db105b70cbcfa6b125,Remove unused importsPiperOrigin-RevId: 191112880,1,Remove Dead Code,,
fd3baace5f494aff716fdb576bdaa6f91b40e16e,2018-03-22T23:05:22Z,https://github.com/tensorflow/tensorflow/commit/fd3baace5f494aff716fdb576bdaa6f91b40e16e,Remove cached tensors from LinearOperator.CSE should already ensure that tensors are deduped (i.e. multiple Cholesky's for the same matrix are not performed).This also makes it easier to use LinearOperators in tf.while_loop.PiperOrigin-RevId: 190141732,1,Remove Dead Code,,
fda633fb7187da8522ef79555d1267996fa983bc,2018-03-18T12:29:16Z,https://github.com/tensorflow/tensorflow/commit/fda633fb7187da8522ef79555d1267996fa983bc,remove test code,1,Remove Dead Code,,
20424e92417b520d7ea8c7323eee46538d2b909f,2018-03-17T01:30:24Z,https://github.com/tensorflow/tensorflow/commit/20424e92417b520d7ea8c7323eee46538d2b909f,CLN: remove the unused import: tf_export,1,Remove Dead Code,,
cc10ac9b7d593375a7cee0c167c20989dc29e8cf,2018-03-15T15:40:05Z,https://github.com/tensorflow/tensorflow/commit/cc10ac9b7d593375a7cee0c167c20989dc29e8cf,remove unnecessary lambda,1,Remove Dead Code,,
a3e9bc6338b80e67ffa7e92295448b60f2e516aa,2018-03-14T15:51:14Z,https://github.com/tensorflow/tensorflow/commit/a3e9bc6338b80e67ffa7e92295448b60f2e516aa,Removed stray/dead code that snuck in there in an earlier change.PiperOrigin-RevId: 189034502,1,Remove Dead Code,,
410647b29f7172ae8d4c525421a671907f505c86,2018-03-09T01:37:51Z,https://github.com/tensorflow/tensorflow/commit/410647b29f7172ae8d4c525421a671907f505c86,Remove no-longer-needed work-around for resource variables in Optimizer.PiperOrigin-RevId: 188419224,1,Remove Dead Code,,
b7e38a5f2a310599e9d4cab2bd95a43dd18018d6,2018-03-05T23:53:43Z,https://github.com/tensorflow/tensorflow/commit/b7e38a5f2a310599e9d4cab2bd95a43dd18018d6,Remove unnecessary density functions.distributions.py appropriately calls `log` or `exp` to compute missing cdf/prob functions.PiperOrigin-RevId: 187938200,1,Remove Dead Code,,
bce4f52b7201b943d544606dcca51ef4ba2b2c1a,2018-03-02T18:30:01Z,https://github.com/tensorflow/tensorflow/commit/bce4f52b7201b943d544606dcca51ef4ba2b2c1a,"tf.keras: Remove unnecessary ""with self.test_sesion()"" statements in tests.The test decorator that runs the test twice (once with eager execution enabled,once without) doesn't require the block, and this makes the code appear moreeager-friendly (as there is no concept of a session when eager execution isenabled).PiperOrigin-RevId: 187637008",1,Remove Dead Code,,
a5b336194f4fd1a26bcd5dfd159d6edf4dfdd081,2018-02-28T23:59:33Z,https://github.com/tensorflow/tensorflow/commit/a5b336194f4fd1a26bcd5dfd159d6edf4dfdd081,Remove record_gradient param from benchmark functionPiperOrigin-RevId: 187397610,1,Remove Dead Code,,
51115ee74ed5b64cc03f18d523d8d48f36ef27ba,2018-02-24T06:32:36Z,https://github.com/tensorflow/tensorflow/commit/51115ee74ed5b64cc03f18d523d8d48f36ef27ba,1. Removing ps_strategy.2. Modified estimator to take overriden device_fn from  if set.3. Removed ps_strategy related unit tests.,1,Remove Dead Code,,
db8c7e976f2cf259b87a9441db1cf371586046b6,2018-02-23T19:03:14Z,https://github.com/tensorflow/tensorflow/commit/db8c7e976f2cf259b87a9441db1cf371586046b6,Remove repeated defination due to auto-merge.,1,Remove Dead Code,,
e5496b556734bb1d8de85311092804e0150b3009,2018-02-21T13:27:17Z,https://github.com/tensorflow/tensorflow/commit/e5496b556734bb1d8de85311092804e0150b3009,Remove extraneous check for Eager mode (#17125)The check is already made once at the start of the method,1,Remove Dead Code,,
2d6a550ab4e54de12f03dd04a892562dd85425db,2018-02-16T21:46:47Z,https://github.com/tensorflow/tensorflow/commit/2d6a550ab4e54de12f03dd04a892562dd85425db,"Remove the __setattr__ override for VariablesWas slowing down the creation of _UnreadVariable objects. Adds CheckpointableBase without the __setattr__ override.It's tempting to just override __setattr__ in variables to try making it faster, but it's already just doing an isinstance check. Removing the override entirely seems to be the cleanest option.PiperOrigin-RevId: 186041147",1,Remove Dead Code,,
59a7de4ce8696adcd360f0c8a9fe4d5efa90e99d,2018-02-15T00:34:29Z,https://github.com/tensorflow/tensorflow/commit/59a7de4ce8696adcd360f0c8a9fe4d5efa90e99d,Remove dynamic shape check from Bernoulli.PiperOrigin-RevId: 185764927,1,Remove Dead Code,,
5fe3a9603a81f50d0b374bc26ad34bbd03f3b4c4,2018-02-09T22:52:24Z,https://github.com/tensorflow/tensorflow/commit/5fe3a9603a81f50d0b374bc26ad34bbd03f3b4c4,"[tf.data] Remove deprecated `tf.contrib.data.Dataset` class.This change removes the following class:* `tf.contrib.data.Dataset`.IF THIS BREAKS YOU: Replace `tf.contrib.data.Dataset` with `tf.data.Dataset`when constructing a dataset. Note that you may have to modify downstreamtransformations to use the core API. See ""tensorflow/contrib/data/README.md"" fordetails of how to update your code to use the core API.PiperOrigin-RevId: 185197005",1,Remove Dead Code,,
1287b1ce7d9af83326e8d6e8f9955d9bdd9c30ec,2018-02-08T18:39:32Z,https://github.com/tensorflow/tensorflow/commit/1287b1ce7d9af83326e8d6e8f9955d9bdd9c30ec,"[tf.data] Remove deprecated reader dataset classes in `tf.contrib.data`.This change removes the following classes:* `tf.contrib.data.FixedLengthRecordDataset`* `tf.contrib.data.TextLineDataset`* `tf.contrib.data.TFRecordDataset`IF THIS BREAKS YOU: Replace `tf.contrib.data` with `tf.data` when constructing a`FixedLengthRecordDataset`, `TextLineDataset`, or `TFRecordDataset`. Note thatyou may have to modify downstream transformations to use the core API. See""tensorflow/contrib/data/README.md"" for details of how to update your code to usethe core API.PiperOrigin-RevId: 185016587",1,Remove Dead Code,,
14ebbebc290510b6cfa491349862e6c5aca4200a,2018-02-08T00:24:34Z,https://github.com/tensorflow/tensorflow/commit/14ebbebc290510b6cfa491349862e6c5aca4200a,Remove tf.contrib.ndlstm as it is not maintained and barely used.Users can find an external implementation by the original author at:https://github.com/tmbarchive/tfndlstmPiperOrigin-RevId: 184914822,1,Remove Dead Code,,
163fd2ea39f550f45717dd70f26ebebdaf74411e,2018-02-08T00:21:13Z,https://github.com/tensorflow/tensorflow/commit/163fd2ea39f550f45717dd70f26ebebdaf74411e,"Remove obsolete BernoulliWithSigmoidProbs (#16846)As was pointed out by 9485, BernoulliWithSigmoidProbs is coveredby Bernoulli and is obsolete. This fix removes BernoulliWithSigmoidProbs.This fix closes 9485.Signed-off-by: Yong Tang <yong.tang.github@outlook.com>",1,Remove Dead Code,,
76b390539b296af43c9d3f4b5cfe0dfbf5b3cfd6,2018-01-31T09:26:29Z,https://github.com/tensorflow/tensorflow/commit/76b390539b296af43c9d3f4b5cfe0dfbf5b3cfd6,"Remove a failing test for gpu numbers when XLA is enabled.The test assumes that all devices are either CPU or GPU, which is not true when XLA is enabled.PiperOrigin-RevId: 183956872",1,Remove Dead Code,,
dce14f5d38a19b3a19c834a877acc0042f1e9fbd,2018-01-25T21:11:40Z,https://github.com/tensorflow/tensorflow/commit/dce14f5d38a19b3a19c834a877acc0042f1e9fbd,Remove calculation of unnecessary matrix columns in SVD gradient (#15801)* remove calculation of unnecessary matrix columns in svd gradient* simplify expression for svd gradient when compute_uv=False* assign Operation attribute to local variable,1,Remove Dead Code,,
f20f28beea3b68e9a0179bf2b669f4827b4b6ac7,2018-01-22T20:55:01Z,https://github.com/tensorflow/tensorflow/commit/f20f28beea3b68e9a0179bf2b669f4827b4b6ac7,Removes redundant variable assignment (#16286)Addresses alert raised by lgtm.com:https://lgtm.com/projects/g/tensorflow/tensorflow/snapshot/e6183fbeecf069148371be83988e8e5db2b14185/files/tensorflow/python/framework/constant_op.py#xb77a2f6647d782be:1,1,Remove Dead Code,,
fd6acdf9b690d550f19d6651025cc28ce910f506,2018-01-16T04:09:01Z,https://github.com/tensorflow/tensorflow/commit/fd6acdf9b690d550f19d6651025cc28ce910f506,[XLA] Remove RngBernoulli from the local Python XLA client.PiperOrigin-RevId: 182005780,1,Remove Dead Code,,
975afd7fe660cbe68b0f626f16bdfcd5c2f1b383,2018-01-15T10:22:52Z,https://github.com/tensorflow/tensorflow/commit/975afd7fe660cbe68b0f626f16bdfcd5c2f1b383,Remove lenient naming in tf.Saver.PiperOrigin-RevId: 181943238,1,Remove Dead Code,,
f49c976e2062858d8d0d12ee653f7287ddb03135,2018-01-05T18:40:54Z,https://github.com/tensorflow/tensorflow/commit/f49c976e2062858d8d0d12ee653f7287ddb03135,Deletes unnecessary lines of codeThe rest of this function changed sufficiently that these lines of code are not doing anything and can cause bugs.,1,Remove Dead Code,,
479b0fd7d547331778c47c6fccc8685278e5ba8e,2017-12-27T01:26:57Z,https://github.com/tensorflow/tensorflow/commit/479b0fd7d547331778c47c6fccc8685278e5ba8e,Remove unwrapping for function argument inspection in Estimator. (#15646)PiperOrigin-RevId: 180147476,1,Remove Dead Code,,
cabb248e9ef61f618575d03092c340f43216cd03,2017-12-26T19:07:00Z,https://github.com/tensorflow/tensorflow/commit/cabb248e9ef61f618575d03092c340f43216cd03,Remove unwrapping for function argument inspection in Estimator.PiperOrigin-RevId: 180147476,1,Remove Dead Code,,
3f5445b3432fdf775bdef289c10338cd20d10edc,2017-12-12T11:24:43Z,https://github.com/tensorflow/tensorflow/commit/3f5445b3432fdf775bdef289c10338cd20d10edc,Simplifying tfe function.pyPiperOrigin-RevId: 178740804,1,Remove Dead Code,,
65d23686c6404025d0554960d4cc4eda1bbd3c9d,2017-12-12T10:33:55Z,https://github.com/tensorflow/tensorflow/commit/65d23686c6404025d0554960d4cc4eda1bbd3c9d,Remove real-data shape check in GANEstimator. Fixes github issue #14257.PiperOrigin-RevId: 178737278,1,Remove Dead Code,,
e88855650435327899917afb6723db03a3d5469f,2017-12-01T21:14:21Z,https://github.com/tensorflow/tensorflow/commit/e88855650435327899917afb6723db03a3d5469f,Remove non-exposed copy of old SummaryWriterRELNOTES: N/APiperOrigin-RevId: 177631104,1,Remove Dead Code,,
8d84926f525dfd0728325e43cd39dbcb28fd3601,2017-11-23T00:42:07Z,https://github.com/tensorflow/tensorflow/commit/8d84926f525dfd0728325e43cd39dbcb28fd3601,Remove duplicated testConv1DTranspose,1,Remove Dead Code,,
9f63f6f4613f6fc556c245bd8b69052778f28dc2,2017-11-22T20:38:18Z,https://github.com/tensorflow/tensorflow/commit/9f63f6f4613f6fc556c245bd8b69052778f28dc2,Remove non-existing reference.,1,Remove Dead Code,,
cc003b7315b30a66567f749b35c120f5af768615,2017-11-21T23:27:22Z,https://github.com/tensorflow/tensorflow/commit/cc003b7315b30a66567f749b35c120f5af768615,Remove vestigial utils.setdefault function.PiperOrigin-RevId: 176570863,1,Remove Dead Code,,
6a4391c19bc8346df45862865cb4db3ba231bd86,2017-11-14T20:28:23Z,https://github.com/tensorflow/tensorflow/commit/6a4391c19bc8346df45862865cb4db3ba231bd86,Remove experimental tpu.outside_all_rewrites() API.PiperOrigin-RevId: 175718301,1,Remove Dead Code,,
d5f0634312e9426414687c0b718c931a256a082f,2017-11-09T07:08:57Z,https://github.com/tensorflow/tensorflow/commit/d5f0634312e9426414687c0b718c931a256a082f,"Remove `non-fused` version of `adjust_hue` as GPU kernel is already in place (#14187)Was looking into adding batch support for `tf.image.random_hue` (8926)and noticed that the `non-fused` version of `adjust_hue` was stillin place. The `non-fused` is for non-GPU support of `adjust_hue`.As GPU kernel for `AdjustHue` has already been added in PR 6818,I think it makes sense to remove the non-fused version. Besides,the env `TF_ADJUST_HUE_FUSED` seems no in use anyway.This fix removed `non-fused` version of `adjust_hue` as GPU kernelis already in place.Signed-off-by: Yong Tang <yong.tang.github@outlook.com>",1,Remove Dead Code,,
9db84049fe1d9c5c7c93d87b53528b8e8255afd9,2017-11-02T23:42:27Z,https://github.com/tensorflow/tensorflow/commit/9db84049fe1d9c5c7c93d87b53528b8e8255afd9,boosted_trees: some cleanups. - removed learner_config.num_classes in training_ops which is unnecessary. - replaced num_classes in gbdt_batch.py with logits_dimension where possible. - simplified prediction_ops_test.PiperOrigin-RevId: 174399706,1,Remove Dead Code,,
f53579308d996bbf069eba4ffab68fcc9f6e69f3,2017-11-02T18:23:42Z,https://github.com/tensorflow/tensorflow/commit/f53579308d996bbf069eba4ffab68fcc9f6e69f3,Remove legacy TextSummaryPluginAsset classThis no longer appears to be used since text_summary was migrated to use the new SummaryMetadata approach.PiperOrigin-RevId: 174354256,1,Remove Dead Code,,
6c4a769ab54599b2063745a601baef71006364e8,2017-11-01T18:44:34Z,https://github.com/tensorflow/tensorflow/commit/6c4a769ab54599b2063745a601baef71006364e8,"Delete duplicate label_image script.The version in examples/label_image is more complete (with image size and normalization options), so it can be used with `mobilenets`.Also: removed bazel from main tutorial instructions.PiperOrigin-RevId: 174212674",1,Remove Dead Code,,
6849ef8f6d82b29ff6f0286197e7596706f72cf4,2017-11-01T17:19:07Z,https://github.com/tensorflow/tensorflow/commit/6849ef8f6d82b29ff6f0286197e7596706f72cf4,internal change.PiperOrigin-RevId: 174197506,1,Remove Dead Code,,
2ccf3aba424405d82e69f03021435e48f54656fb,2017-10-31T23:20:19Z,https://github.com/tensorflow/tensorflow/commit/2ccf3aba424405d82e69f03021435e48f54656fb,Permanently remove several modules from tf.contrib.bayesflow.These modules are very infrequently used and will not be developed moving forward.Removing this code paves the way for remaining modules in tf.contrib.bayesflowto move to their own repo.PiperOrigin-RevId: 174110067,1,Remove Dead Code,,
32eb07bf7b4cf5c9f5ee14e1f4cbe18b1eba6c4d,2017-10-20T20:44:10Z,https://github.com/tensorflow/tensorflow/commit/32eb07bf7b4cf5c9f5ee14e1f4cbe18b1eba6c4d,"Simplify the graph generated for contrib/summaries in the""always summarize"" and ""never summarize"" cases by skipping the `cond`.PiperOrigin-RevId: 172928083",1,Remove Dead Code,,
93871a811eab7457f8e36ee4905234aa1a9ea8c8,2017-10-20T16:13:44Z,https://github.com/tensorflow/tensorflow/commit/93871a811eab7457f8e36ee4905234aa1a9ea8c8,Remove duplicated `smart_cond()` code.PiperOrigin-RevId: 172891249,1,Remove Dead Code,,
a23abe0c226ec1b99f8bddcb2fba65a46365684b,2017-10-19T19:20:03Z,https://github.com/tensorflow/tensorflow/commit/a23abe0c226ec1b99f8bddcb2fba65a46365684b,internal change.PiperOrigin-RevId: 172780953,1,Remove Dead Code,,
31587244e4821fbb4eebcf7847281a1df3da6a2a,2017-10-19T18:22:37Z,https://github.com/tensorflow/tensorflow/commit/31587244e4821fbb4eebcf7847281a1df3da6a2a,Remove sklearn from text_classification_cnn.py.PiperOrigin-RevId: 172772457,1,Remove Dead Code,,
45b115151e8b1fd88c8f525fb131e7980e6c726a,2017-10-13T19:19:39Z,https://github.com/tensorflow/tensorflow/commit/45b115151e8b1fd88c8f525fb131e7980e6c726a,Remove unnecessary reshape and get_shape from fused_batch_norm.PiperOrigin-RevId: 172130212,1,Remove Dead Code,,
88145023cea47b4a96cc04f8febe205d50a0d0d6,2017-10-09T23:24:05Z,https://github.com/tensorflow/tensorflow/commit/88145023cea47b4a96cc04f8febe205d50a0d0d6,Removing side outputs from tape code.They belong better in future function objects (simplifies tape move to C)PiperOrigin-RevId: 171603665,1,Remove Dead Code,,
6cf9ffeab4da4ad38bdf2afd803bf44cdc58d15d,2017-10-05T14:50:09Z,https://github.com/tensorflow/tensorflow/commit/6cf9ffeab4da4ad38bdf2afd803bf44cdc58d15d,"Removes use of _grad_fn_accepts_none_for_indices in magic_gradient_function.Leaves the one in imperative_grad, which seems to matter.PiperOrigin-RevId: 171152474",1,Remove Dead Code,,
0c65fa467d32de85ab803f761d433fc450242d25,2017-10-02T19:59:45Z,https://github.com/tensorflow/tensorflow/commit/0c65fa467d32de85ab803f761d433fc450242d25,"[tf.data] Remove `Iterator.dispose_op()`.Since implicit destruction works correctly, there is no need to dispose ofan iterator explicitly before closing a session.PiperOrigin-RevId: 170740862",1,Remove Dead Code,,
634823179b774f2b8443b82ca643591992ad8fb9,2017-09-29T21:41:23Z,https://github.com/tensorflow/tensorflow/commit/634823179b774f2b8443b82ca643591992ad8fb9,Remove (recently introduced) class layers.Network.Network has not been part of TensorFlow's public API for any release.Users should use keras.Model instead for now.PiperOrigin-RevId: 170534633,1,Remove Dead Code,,
818dc210881aadcce9013b693e071b96a6e1f1f6,2017-09-26T13:14:10Z,https://github.com/tensorflow/tensorflow/commit/818dc210881aadcce9013b693e071b96a6e1f1f6,Remove function declaration featurePiperOrigin-RevId: 170043510,1,Remove Dead Code,,
762b77373c82a89865d0f7ea21f88602529706f4,2017-09-13T18:34:47Z,https://github.com/tensorflow/tensorflow/commit/762b77373c82a89865d0f7ea21f88602529706f4,Remove cond for zero-shape in resample. random_poisson supports 0 shapes.PiperOrigin-RevId: 168570209,1,Remove Dead Code,,
affbc9b7b3733faea7f62182a56dbf75b3afeeef,2017-09-08T18:54:09Z,https://github.com/tensorflow/tensorflow/commit/affbc9b7b3733faea7f62182a56dbf75b3afeeef,Delete some unnecessary code.PiperOrigin-RevId: 168026197,1,Remove Dead Code,,
03ebcfdcc89912e737ca374412382eeabff49912,2017-09-08T00:51:29Z,https://github.com/tensorflow/tensorflow/commit/03ebcfdcc89912e737ca374412382eeabff49912,Disables unnecessary checks in TensorVSpace.PiperOrigin-RevId: 167938783,1,Remove Dead Code,,
fef3c4d38ae00992ed32103006fc07c6ec1a4f7a,2017-09-06T12:26:18Z,https://github.com/tensorflow/tensorflow/commit/fef3c4d38ae00992ed32103006fc07c6ec1a4f7a,Removed unused imports and reodered as alphabetically sorted modules,1,Remove Dead Code,,
675a9dcdbeb704d9b1e0cb90d802f7c2490de666,2017-08-22T01:08:36Z,https://github.com/tensorflow/tensorflow/commit/675a9dcdbeb704d9b1e0cb90d802f7c2490de666,"Delete a few cudnn rnn unittestsIn a large refactorization, trying to split changes intoreviewable chunks. This is one step. The equivalent tests wouldbe added back in future CLs very soon.PiperOrigin-RevId: 166002995",1,Remove Dead Code,,
db3587c45954338eb9eebe4962ee03aca04bdb42,2017-08-02T20:50:49Z,https://github.com/tensorflow/tensorflow/commit/db3587c45954338eb9eebe4962ee03aca04bdb42,"Slightly more idiomatic API for TensorForestEstimator, including being able to take feature columns to call transform.Also remove some unused code.PiperOrigin-RevId: 164032636",1,Remove Dead Code,,
0b182c3940a3d15d574da327ac705c2efa18a985,2017-08-02T20:50:49Z,https://github.com/tensorflow/tensorflow/commit/0b182c3940a3d15d574da327ac705c2efa18a985,"Slightly more idiomatic API for TensorForestEstimator, including being able to take feature columns to call transform.Also remove some unused code.PiperOrigin-RevId: 164032636",1,Remove Dead Code,,
50d48d606c3b2c08eef249b6fe4f543a51ca8455,2017-07-25T19:41:23Z,https://github.com/tensorflow/tensorflow/commit/50d48d606c3b2c08eef249b6fe4f543a51ca8455,Remove duplicate import.PiperOrigin-RevId: 163108237,1,Remove Dead Code,,
1e8755a4dad2e7972de8f46941e40e5fb41ae0d3,2017-07-24T20:58:57Z,https://github.com/tensorflow/tensorflow/commit/1e8755a4dad2e7972de8f46941e40e5fb41ae0d3,tfdbg: remove gen_debug_opsReplace it with a new hidden op: array_ops.DebugGradientIdentityPiperOrigin-RevId: 162983526,1,Remove Dead Code,,
efeec4d3dde40ea9a6a4337504726c7f268842b5,2017-07-24T20:58:57Z,https://github.com/tensorflow/tensorflow/commit/efeec4d3dde40ea9a6a4337504726c7f268842b5,tfdbg: remove gen_debug_opsReplace it with a new hidden op: array_ops.DebugGradientIdentityPiperOrigin-RevId: 162983526,1,Remove Dead Code,,
c5db6c26041db2352617640a93388901c06e2afa,2017-07-24T16:10:22Z,https://github.com/tensorflow/tensorflow/commit/c5db6c26041db2352617640a93388901c06e2afa,Remove old TensorForest implementation.PiperOrigin-RevId: 162944683,1,Remove Dead Code,,
28c642d73446057dd19bed86d9749a0c1b27a201,2017-07-20T17:45:08Z,https://github.com/tensorflow/tensorflow/commit/28c642d73446057dd19bed86d9749a0c1b27a201,"Remove trig.py in favor of math_ops.{sinh,asinh,cosh,acosh}.The math_ops functions seems to be numerically stable enough for our purposes, as will be faster.PiperOrigin-RevId: 162634739",1,Remove Dead Code,,
daa67ad176013aa31b30a40d30dc92efe9270b20,2017-07-19T02:40:38Z,https://github.com/tensorflow/tensorflow/commit/daa67ad176013aa31b30a40d30dc92efe9270b20,Remove unittest import (#11596),1,Remove Dead Code,,
e9bea40511b1fe5d2e1e7761f640943d0e17a7df,2017-07-07T22:19:40Z,https://github.com/tensorflow/tensorflow/commit/e9bea40511b1fe5d2e1e7761f640943d0e17a7df,Refactor Keras Sequence utility.Correct Keras version number.PiperOrigin-RevId: 161252947,1,Remove Dead Code,,
9999dd321a3b8ec8f0c6d8a3aae3682c45c57976,2017-07-01T11:27:07Z,https://github.com/tensorflow/tensorflow/commit/9999dd321a3b8ec8f0c6d8a3aae3682c45c57976,Replace sync_replicas_optimizer_test's `create_local_cluster` with the standard implementation.PiperOrigin-RevId: 160731226,1,Remove Dead Code,,
cd15cb8206d19dde403e9e9c2293fa9dea7ec9ee,2017-06-29T23:57:04Z,https://github.com/tensorflow/tensorflow/commit/cd15cb8206d19dde403e9e9c2293fa9dea7ec9ee,Remove unused internal facility for loss functions to colocate logit computations with the weights.PiperOrigin-RevId: 160592547,1,Remove Dead Code,,
01de9af282476a5c1e9b86a1d864d0a793cac0b7,2017-06-12T19:33:10Z,https://github.com/tensorflow/tensorflow/commit/01de9af282476a5c1e9b86a1d864d0a793cac0b7,Remove experimental decordarator.PiperOrigin-RevId: 158748337,1,Remove Dead Code,,
3cb3cc6d426112f432db62db6f493ea00ce31e0f,2017-06-09T23:47:29Z,https://github.com/tensorflow/tensorflow/commit/3cb3cc6d426112f432db62db6f493ea00ce31e0f,Remove duplicate line from bad merge.PiperOrigin-RevId: 158580028,1,Remove Dead Code,,
79099d67761b3e56d1c3764cd34f97401571a211,2017-06-02T18:43:58Z,https://github.com/tensorflow/tensorflow/commit/79099d67761b3e56d1c3764cd34f97401571a211,Removes default thresholds from BinaryLogisticHead and adds predict and evaluate tests for DNNClassifier.PiperOrigin-RevId: 157856471,1,Remove Dead Code,,
40411cd5c68e4f91a1fc0d5861fac88b404329bb,2017-06-02T00:06:15Z,https://github.com/tensorflow/tensorflow/commit/40411cd5c68e4f91a1fc0d5861fac88b404329bb,"Refactor projector plugin to only use tf public methods.Remove all reference to the PluginAsset system, which is deprecated.Part of an ongoing effort to have TensorBoard only consume the publicTensorFlow api.PiperOrigin-RevId: 157784016",1,Remove Dead Code,,
24b58c36ce9b824cae5152fad4ea0bbd59fe0931,2017-05-25T20:37:17Z,https://github.com/tensorflow/tensorflow/commit/24b58c36ce9b824cae5152fad4ea0bbd59fe0931,Removes unused contrib package feeder.PiperOrigin-RevId: 157146520,1,Remove Dead Code,,
b6d7be1cc2f6d03a519ad1bce615b71d6fa7eed4,2017-05-19T18:42:05Z,https://github.com/tensorflow/tensorflow/commit/b6d7be1cc2f6d03a519ad1bce615b71d6fa7eed4,Remove duplicate method definition in tensor_shape.py,1,Remove Dead Code,,
7fa0cf39f854d5fdaaa19ad6425dfed02f5fea64,2017-05-08T00:31:50Z,https://github.com/tensorflow/tensorflow/commit/7fa0cf39f854d5fdaaa19ad6425dfed02f5fea64,Unveil type check part in _VerifyGeneratedGradients that was not actu?(#9529)* unveil type check part in _VerifyGeneratedGradients that was not actually used* remove the block that's not getting used,1,Remove Dead Code,,
8154a077e8e6b41c191650125129a9b333cfcfd7,2017-04-27T22:47:40Z,https://github.com/tensorflow/tensorflow/commit/8154a077e8e6b41c191650125129a9b333cfcfd7,[TF:XLA] Remove temporary registrations for control flow operators on XLA_ devices.The registrations seem to be causing more trouble than they are worth.Change: 154480448,1,Remove Dead Code,,
a362e0d0554f684862746c4c6f88d34308681795,2017-04-27T15:44:35Z,https://github.com/tensorflow/tensorflow/commit/a362e0d0554f684862746c4c6f88d34308681795,Removed legacy rnn constructors (#9389)* Removed legacy rnn constructors* Remove unused _get_dropout_and_num_units,1,Remove Dead Code,,
da64460f75ae3c116baa708686b60bf924a4277b,2017-04-11T23:59:42Z,https://github.com/tensorflow/tensorflow/commit/da64460f75ae3c116baa708686b60bf924a4277b,Remove boston_input_fn_with_queuesince it is not used.,1,Remove Dead Code,,
c76241258a566b82ac3cdd57fdfaab353d89b8f1,2017-04-05T21:35:02Z,https://github.com/tensorflow/tensorflow/commit/c76241258a566b82ac3cdd57fdfaab353d89b8f1,Remove Keras config file saving.Change: 152306552,1,Remove Dead Code,,
e018a983a5abb5d849f1ec5393fb0834c7d78c8f,2017-04-05T20:28:15Z,https://github.com/tensorflow/tensorflow/commit/e018a983a5abb5d849f1ec5393fb0834c7d78c8f,Removed dead code in Estimator.Change: 152297597,1,Remove Dead Code,,
a094d3d5f5a755ddeb2c95aa9622cec1c39f1f70,2017-03-29T01:26:42Z,https://github.com/tensorflow/tensorflow/commit/a094d3d5f5a755ddeb2c95aa9622cec1c39f1f70,Decrease volume of spammy logs.Remove unused _monitored_train.Change: 151526705,1,Remove Dead Code,,
dbca4f78380d56c0b144daa058decaea2bbf55ff,2017-03-25T21:03:33Z,https://github.com/tensorflow/tensorflow/commit/dbca4f78380d56c0b144daa058decaea2bbf55ff,"Remove pandas imports, and use convert_to_tensor, as suggested in the review.This fix removes pandas imports, and use convert_to_tensor,as suggested in the review.Signed-off-by: Yong Tang <yong.tang.github@outlook.com>",1,Remove Dead Code,,
490a2235fb609de91cda3bae8a9aa808b4a014d1,2017-03-17T18:07:17Z,https://github.com/tensorflow/tensorflow/commit/490a2235fb609de91cda3bae8a9aa808b4a014d1,Remove the unnecessary RTLD_GLOBAL dlopen flag in the remaining tests.Change: 150460215,1,Remove Dead Code,,
bb7cadbc5a886fded011a65776a42ea2b37498c3,2017-03-17T17:09:44Z,https://github.com/tensorflow/tensorflow/commit/bb7cadbc5a886fded011a65776a42ea2b37498c3,Removes an unnecessary check that blocks using multihead with custom heads.Change: 150452316,1,Remove Dead Code,,
524cc3ea35e68a5a62154a247734188a7c4ea9e5,2017-03-09T16:53:00Z,https://github.com/tensorflow/tensorflow/commit/524cc3ea35e68a5a62154a247734188a7c4ea9e5,"Delete AUC metrics from MultiClassHead. This removed AUC metrics from DNNClassifier, LinearClassifier and DNNLinearCombinedClassifier when n_classes > 2.Change: 149656850",1,Remove Dead Code,,
21bdcf587e6c0806e01b2187e6d6e54f0236b4e0,2017-03-07T19:50:17Z,https://github.com/tensorflow/tensorflow/commit/21bdcf587e6c0806e01b2187e6d6e54f0236b4e0,Removed references to dynamic_rnn_estimator.RNNKeys.Change: 149446004,1,Remove Dead Code,,
42da3010fa615a505e0784b3378daf5f3e1d1c0e,2017-03-01T17:12:14Z,https://github.com/tensorflow/tensorflow/commit/42da3010fa615a505e0784b3378daf5f3e1d1c0e,Remove disribution.is_continuous property.Most of its usefulness is determined by the reparameterization type.  In thefuture we'll be adding a distribution Domain object / property to betterdescribe the domain of the values a distribution may take on.Change: 148894335,1,Remove Dead Code,,
d155821b212064d032a06208d684ddc47c8199af,2017-02-19T01:00:16Z,https://github.com/tensorflow/tensorflow/commit/d155821b212064d032a06208d684ddc47c8199af,Remove unused topn code.Change: 147940756,1,Remove Dead Code,,
5a60bb88a05fe6c615476c029aa2afcce4d6e9d6,2017-02-14T21:42:11Z,https://github.com/tensorflow/tensorflow/commit/5a60bb88a05fe6c615476c029aa2afcce4d6e9d6,Remove unused debug_utils import in stepper.py.,1,Remove Dead Code,,
fc4e26d69eb74f46b30c48d59cf6000fd2045560,2017-02-14T19:44:31Z,https://github.com/tensorflow/tensorflow/commit/fc4e26d69eb74f46b30c48d59cf6000fd2045560,Remove generator.py changes from cherrypicks.,1,Remove Dead Code,,
74514bffc4bbac7e6717e1079aca055b1c837229,2017-02-10T02:26:13Z,https://github.com/tensorflow/tensorflow/commit/74514bffc4bbac7e6717e1079aca055b1c837229,clean_up_node has been removedChange: 147108608,1,Remove Dead Code,,
be4ec67b51f206b689d56367a3b6081a6fc43561,2017-01-28T15:28:18Z,https://github.com/tensorflow/tensorflow/commit/be4ec67b51f206b689d56367a3b6081a6fc43561,[TF:XLA] Remove two concat gradient test cases that took an unreasonably long time to run.Change: 145884708,1,Remove Dead Code,,
37bfbfbde2f3db46773210c068803a04fd282374,2017-02-01T23:02:54Z,https://github.com/tensorflow/tensorflow/commit/37bfbfbde2f3db46773210c068803a04fd282374,Remove code duplication between contrib metrics and core metrics and delete unused methods in contrib metrics.Change: 146294596,1,Remove Dead Code,,
a9a39787ca13c40585dc8139787e3b8ccd2e1734,2017-01-28T15:28:18Z,https://github.com/tensorflow/tensorflow/commit/a9a39787ca13c40585dc8139787e3b8ccd2e1734,[TF:XLA] Remove two concat gradient test cases that took an unreasonably long time to run.Change: 145884708,1,Remove Dead Code,,
59757b7afd5dd08d5651ca966f03511bb2aad7bd,2017-01-25T22:09:48Z,https://github.com/tensorflow/tensorflow/commit/59757b7afd5dd08d5651ca966f03511bb2aad7bd,Remove continuous_eval_predicate_fn from Experiment class.Change: 145594656,1,Remove Dead Code,,
d97706437932443ae22082ada49d3ac054b77304,2017-01-25T04:15:43Z,https://github.com/tensorflow/tensorflow/commit/d97706437932443ae22082ada49d3ac054b77304,"Remove serialize_tensorboard script and TensorBoard demo-instance support.(I think the right way to create demo TensorBoard instances is to simply run a TensorBoard in the cloud, rather than keep maintaining this mocked-out backend.Change: 145502706",1,Remove Dead Code,,
761405e7202e1bec875f1ca7d1a7660ebbb3dafb,2017-01-24T23:14:28Z,https://github.com/tensorflow/tensorflow/commit/761405e7202e1bec875f1ca7d1a7660ebbb3dafb,"Remove http.py and http_test.py for real this time, as they are replaced byhttp_util.Change: 145474384",1,Remove Dead Code,,
d5017d3afbac7ea5e1c1180a8c57432d905a4ad2,2017-01-20T05:22:05Z,https://github.com/tensorflow/tensorflow/commit/d5017d3afbac7ea5e1c1180a8c57432d905a4ad2,Remove unused properties from Experiment.Change: 145047259,1,Remove Dead Code,,
7fde84958753a6d4330ddc50c25f80dfcde9dc8a,2017-01-18T21:52:35Z,https://github.com/tensorflow/tensorflow/commit/7fde84958753a6d4330ddc50c25f80dfcde9dc8a,Refactor SVM estimator to inherit from Estimator and delete unused methods.Change: 144877397,1,Remove Dead Code,,
5b8a0d5eb467183a91bb8f1a551bbc85f1af08a6,2017-01-02T16:31:15Z,https://github.com/tensorflow/tensorflow/commit/5b8a0d5eb467183a91bb8f1a551bbc85f1af08a6,Remove old array_ops import in seq2seq_ops,1,Remove Dead Code,,
45210f9be77e0cb87d5a4b519ef811b8fd704ab4,2017-01-02T14:36:24Z,https://github.com/tensorflow/tensorflow/commit/45210f9be77e0cb87d5a4b519ef811b8fd704ab4,Remove deprecated array_ops,1,Remove Dead Code,,
7ff06bc92905013e99df68d18d24de5114c5d32b,2017-01-10T22:47:39Z,https://github.com/tensorflow/tensorflow/commit/7ff06bc92905013e99df68d18d24de5114c5d32b,"Remove all remaining tf.pack,tf.unpack references and remove tf.pack/tf.unpackop.Change: 144130931",1,Remove Dead Code,,
fcc319a076e32e4e629313c202c0d156f4d3173e,2017-01-04T21:15:14Z,https://github.com/tensorflow/tensorflow/commit/fcc319a076e32e4e629313c202c0d156f4d3173e,Remove unused FLAGS variable.Change: 143587587,1,Remove Dead Code,,
012800e2368de26f677f4cf0093ef8c7b51c3070,2017-01-04T15:18:16Z,https://github.com/tensorflow/tensorflow/commit/012800e2368de26f677f4cf0093ef8c7b51c3070,Change for internal compatibility.,1,Remove Dead Code,,
2c0fa4ee3096421a75302b7b773625455889e505,2017-01-03T23:26:14Z,https://github.com/tensorflow/tensorflow/commit/2c0fa4ee3096421a75302b7b773625455889e505,Remove unused FLAGS.Change: 143492886,1,Remove Dead Code,,
e121667dc609de978a223c56ee906368d2c4ceef,2016-12-30T06:46:24Z,https://github.com/tensorflow/tensorflow/commit/e121667dc609de978a223c56ee906368d2c4ceef,Remove so many more hourglass importsChange: 143230429,1,Remove Dead Code,,
1829cf14c41a4372b604cedae17ecdaf12f1f037,2016-12-17T01:43:00Z,https://github.com/tensorflow/tensorflow/commit/1829cf14c41a4372b604cedae17ecdaf12f1f037,Remove tf.complex_abs from the TensorFlow Python API. tf.abs should be used for both real and complex tensors.Change: 142316271,1,Remove Dead Code,,
5866e065bc95c1d7de8a27413b368016941889a6,2016-12-15T00:30:24Z,https://github.com/tensorflow/tensorflow/commit/5866e065bc95c1d7de8a27413b368016941889a6,Remove hourglass imports from kernel_testsChange: 142080137,1,Remove Dead Code,,
f6917c6514aadae9b3fbd2ad7a0ece8f2f9f659f,2016-12-14T20:38:08Z,https://github.com/tensorflow/tensorflow/commit/f6917c6514aadae9b3fbd2ad7a0ece8f2f9f659f,Remove contrib.specs AutoFunctionThis does clever things with the TensorFlow namespaces which we can'tmaintain.Change: 142050311,1,Remove Dead Code,,
552a64130924f16d448f655a8a325c839ad6cbcc,2016-12-12T19:54:33Z,https://github.com/tensorflow/tensorflow/commit/552a64130924f16d448f655a8a325c839ad6cbcc,Remove deprecated weight and target args.Change: 141792366,1,Remove Dead Code,,
ed62a180ef3a9c6a91aae15c77503dec466ece21,2016-12-12T06:39:57Z,https://github.com/tensorflow/tensorflow/commit/ed62a180ef3a9c6a91aae15c77503dec466ece21,Remove hourglass import from python/debug testsChange: 141726783,1,Remove Dead Code,,
44e903fab1f88ec33fc243a033fc3bd8b9de6af8,2016-12-10T00:51:55Z,https://github.com/tensorflow/tensorflow/commit/44e903fab1f88ec33fc243a033fc3bd8b9de6af8,Remove duplicate extract method,1,Remove Dead Code,,
930b138978e8960921f4123b6097751077206bc3,2016-12-08T00:34:38Z,https://github.com/tensorflow/tensorflow/commit/930b138978e8960921f4123b6097751077206bc3,Remove tf.select op. tf.where now supports tf.select functionality andtf.select is deprecated.Change: 141374194,1,Remove Dead Code,,
878f5fcb8103cfc7e28bd86f7d0c722e053588d1,2016-12-07T18:26:42Z,https://github.com/tensorflow/tensorflow/commit/878f5fcb8103cfc7e28bd86f7d0c722e053588d1,Remove remaining uses of tf.reverse() and remove tf.reverse()from API. On a subsequent commit tf.reverse() will be reintroduced buttaking a list of integer axes to reverse.Change: 141325033,1,Remove Dead Code,,
aad7ec38fc6eabe327df28dcdb56af2eb6392fdb,2016-12-07T01:48:53Z,https://github.com/tensorflow/tensorflow/commit/aad7ec38fc6eabe327df28dcdb56af2eb6392fdb,Remove some unnecessary code.Change: 141252675,1,Remove Dead Code,,
059ccad4d4bac851da9fa9694c23dd49a4089bc6,2016-12-07T00:27:14Z,https://github.com/tensorflow/tensorflow/commit/059ccad4d4bac851da9fa9694c23dd49a4089bc6,"Remove tf.SyncReplicasOptimizer, which will be replaced bytf.SyncReplicasOptimizerV2Change: 141243546",1,Remove Dead Code,,
74d7a5bdf1cc9ddbc7f924a8a1569344a05b05ad,2016-12-06T00:28:04Z,https://github.com/tensorflow/tensorflow/commit/74d7a5bdf1cc9ddbc7f924a8a1569344a05b05ad,Refactor DNNRegressor and DNNLinearCombinedRegressor to use head. Also delete deprecated weights_ and bias_ methods.Change: 141116469,1,Remove Dead Code,,
f55786c1fcd7204618964fc3e1f0f5fe86a8e53a,2016-11-30T01:15:19Z,https://github.com/tensorflow/tensorflow/commit/f55786c1fcd7204618964fc3e1f0f5fe86a8e53a,Remove net_lib since the tests that were using it are using portpicker libraryinstead now.Change: 140548344,1,Remove Dead Code,,
fafc8b79a116dad4deb06de55afa81790e896e12,2016-11-29T21:04:22Z,https://github.com/tensorflow/tensorflow/commit/fafc8b79a116dad4deb06de55afa81790e896e12,"Redirecting TF-Slim evaluation to new, merged evaluation loop. Removed timeout test.Change: 140516090",1,Remove Dead Code,,
824c9f11fcd1f3b1b341a5bb830d2b463c8fbb15,2016-11-22T18:27:44Z,https://github.com/tensorflow/tensorflow/commit/824c9f11fcd1f3b1b341a5bb830d2b463c8fbb15,Remove partitioned variable benchmark.Change: 139925599,1,Remove Dead Code,,
6eaef79cae1bf6114c03b11946927683a370579d,2016-11-18T21:02:59Z,https://github.com/tensorflow/tensorflow/commit/6eaef79cae1bf6114c03b11946927683a370579d,remove encoder state tensor conversion,1,Remove Dead Code,,
eabf41b7cc8ab515b556bc91b4f282d1d671c1a7,2016-11-16T18:04:44Z,https://github.com/tensorflow/tensorflow/commit/eabf41b7cc8ab515b556bc91b4f282d1d671c1a7,Remove explicit calls to call_cpp_shape_fn from third_party/tensorflow/python.Change: 139345066,1,Remove Dead Code,,
e8167643ce20f5f94c1508ed8d23cd164a16ee0b,2016-11-15T00:06:36Z,https://github.com/tensorflow/tensorflow/commit/e8167643ce20f5f94c1508ed8d23cd164a16ee0b,"Remove unneeded call_cpp_shape_fn call, since it is now the default.Change: 139134328",1,Remove Dead Code,,
d455720e820c234a263ac0d26842045354e2f107,2016-11-14T17:43:25Z,https://github.com/tensorflow/tensorflow/commit/d455720e820c234a263ac0d26842045354e2f107,Remove tf.image.per_image_whitening() (which has been replaced withtf.image.per_image_standardization).Change: 139083060,1,Remove Dead Code,,
28e43ab2e001b625d6467d188fb3bf026531f97b,2016-11-11T07:01:29Z,https://github.com/tensorflow/tensorflow/commit/28e43ab2e001b625d6467d188fb3bf026531f97b,Remove unused decorator utils import,1,Remove Dead Code,,
8c54f1870ee062055615d5641a5cb6cbdcabd657,2016-11-10T03:07:12Z,https://github.com/tensorflow/tensorflow/commit/8c54f1870ee062055615d5641a5cb6cbdcabd657,Remove deprecated copy of checkpoints lib,1,Remove Dead Code,,
d8c94dba8f53626077b21f90df309577827a0f18,2016-11-01T23:18:39Z,https://github.com/tensorflow/tensorflow/commit/d8c94dba8f53626077b21f90df309577827a0f18,Remove weight_parameters from OpStats and graph_metrics.Change: 137885496,1,Remove Dead Code,,
c944d1a96e1fbc48d689381cf93e91946087ee01,2016-10-24T18:17:39Z,https://github.com/tensorflow/tensorflow/commit/c944d1a96e1fbc48d689381cf93e91946087ee01,Remove deprecated ignore_mask field from streaming metrics.Change: 137056449,1,Remove Dead Code,,
f1530933e97e8fa830c74f17fdea9fff48ef3a94,2016-10-19T00:27:00Z,https://github.com/tensorflow/tensorflow/commit/f1530933e97e8fa830c74f17fdea9fff48ef3a94,"Simplify EventAccumulator graph logic.When the EventAccumulator encounters a MetaGraphDef, it updates the _graph property. So there is no need to check when the Graph() method is called.Change: 136541160",1,Remove Dead Code,,
83f2fe11b30c4111084f1d99f23396e8d01b45b7,2016-10-17T16:51:36Z,https://github.com/tensorflow/tensorflow/commit/83f2fe11b30c4111084f1d99f23396e8d01b45b7,"Remove `stratified_sample_unknown_dist`, since `stratified_sample` supports an unknown data distribution.Change: 136361350",1,Remove Dead Code,,
7523effd05321da1f423cb8cad9e0e739c6e997b,2016-10-13T21:40:42Z,https://github.com/tensorflow/tensorflow/commit/7523effd05321da1f423cb8cad9e0e739c6e997b,Remove InferredFeatureColumnsTest.Change: 136088267,1,Remove Dead Code,,
48da07d60c20f47868eb1fdc752d42b74cce95f8,2016-10-12T18:07:09Z,https://github.com/tensorflow/tensorflow/commit/48da07d60c20f47868eb1fdc752d42b74cce95f8,Remove deprecated loss fns.Change: 135937566,1,Remove Dead Code,,
5f072e3cab9b697419a00d33eb75d842af1d826e,2016-10-06T22:39:31Z,https://github.com/tensorflow/tensorflow/commit/5f072e3cab9b697419a00d33eb75d842af1d826e,Remove an obsolete assertion in tf.learn's graph_actions.Reasons for removal:(1) We should use exceptions instead of assertions.(2) It becomes a false alarm when Saver's write_version arg is switched to V2.Change: 135414487,1,Remove Dead Code,,
9a863139a335084ad167e1daf02bbf35ba5b2b88,2016-10-06T17:45:30Z,https://github.com/tensorflow/tensorflow/commit/9a863139a335084ad167e1daf02bbf35ba5b2b88,Removed tf.learn.SessionRunHook in favor of tf.train.SessionRunHook.Change: 135376729,1,Remove Dead Code,,
023f01093dd61c1b9e86ea48a83d16488e77da15,2016-10-01T04:35:23Z,https://github.com/tensorflow/tensorflow/commit/023f01093dd61c1b9e86ea48a83d16488e77da15,"Remove non-batch methods from operator_pd_cholesky if they have been merged with batch.Recent changes to tensorflow linear algebra Ops merged batch/non-batch Ops.This makes their separation un-necessary in OperatorPDCholesky.  Note that OperatorPDBase will still ""dispatch based on batch""since [non]batch-specific implementations still exist for matmul, and will probablyexist for some subset of Ops/Operators.OperatorPDBase calls the _batch* method if the non-batch method does not exist, so this change will leave the _batch* methods as-is.Change: 134859101",1,Remove Dead Code,,
80ae2fd61ec0e39f688eeebe5e83f977bbef7bd8,2016-09-20T15:05:56Z,https://github.com/tensorflow/tensorflow/commit/80ae2fd61ec0e39f688eeebe5e83f977bbef7bd8,removing deprecated functions that are no longer in usesplit_squeezeexpand_concatbatch_normalizeChange: 133706393,1,Remove Dead Code,,
6132ae00e0914937d8416f37b969689148461d79,2016-09-19T17:43:49Z,https://github.com/tensorflow/tensorflow/commit/6132ae00e0914937d8416f37b969689148461d79,Remove unnecessary imports in some python files.Change: 133602571,1,Remove Dead Code,,
139fefbe5edc203ed9a52847636d58026fe1bfd5,2016-09-18T04:55:13Z,https://github.com/tensorflow/tensorflow/commit/139fefbe5edc203ed9a52847636d58026fe1bfd5,Remove deprecated argument moving_average_decay.Change: 133501226,1,Remove Dead Code,,
018948d23e96c6147a6e8deb68279115b0a7b425,2016-09-16T20:58:51Z,https://github.com/tensorflow/tensorflow/commit/018948d23e96c6147a6e8deb68279115b0a7b425,Remove write graph calls in SavedModel tests.Change: 133424282,1,Remove Dead Code,,
91a70cbf1c627117b70a3d2dd4c612779369e293,2016-09-13T05:13:30Z,https://github.com/tensorflow/tensorflow/commit/91a70cbf1c627117b70a3d2dd4c612779369e293,Remove autoencoder estimator (#4325),1,Remove Dead Code,,
e1e311f3b6998bb08f3ff4cc7c70e017baa07ff2,2016-09-12T19:52:27Z,https://github.com/tensorflow/tensorflow/commit/e1e311f3b6998bb08f3ff4cc7c70e017baa07ff2,Remove _SelectShape function that is no longer needed - missed this whenremoving delegation in previous change.Change: 132907013,1,Remove Dead Code,,
c9b03c7266da529847eb8895e24cbe8ced9d0cd0,2016-09-09T06:31:27Z,https://github.com/tensorflow/tensorflow/commit/c9b03c7266da529847eb8895e24cbe8ced9d0cd0,"As a part of efforts to remove uses of use_gpu parameter to tf test session,remove usages from sparse_tensor_dense_matmul_op_test.Change: 132643587",1,Remove Dead Code,,
6c110d3984f771a95925b663436168a87585191b,2016-09-02T17:21:47Z,https://github.com/tensorflow/tensorflow/commit/6c110d3984f771a95925b663436168a87585191b,"Remove NoGradient for ops which could have gradients defined but don't.Some ops (notably ops which implement a gradient themselves) had NoGradientdefined, which meant that attempts to compute their gradient would implicitlyreturn 0. This CL changes this implicit behavior to one that produces an errorduring graph construction when taking the gradient of one of these ops.Change: 132076657",1,Remove Dead Code,,
1d712465f268631ff4f9db0f7c524386bf578f5e,2016-09-01T00:35:27Z,https://github.com/tensorflow/tensorflow/commit/1d712465f268631ff4f9db0f7c524386bf578f5e,Remove redundant code.,1,Remove Dead Code,,
d67ce6c449fabb3bebccd85815d9d291f114e6e4,2016-08-15T04:12:39Z,https://github.com/tensorflow/tensorflow/commit/d67ce6c449fabb3bebccd85815d9d291f114e6e4,Remove duplicated NanLossDuringTrainingError in graph_action (#3784),1,Remove Dead Code,,
3c749df76e153d473ff271657867e9b370c2ac3b,2016-08-12T00:27:05Z,https://github.com/tensorflow/tensorflow/commit/3c749df76e153d473ff271657867e9b370c2ac3b,Remove home directory testChange: 130052215,1,Remove Dead Code,,
313b87d80287c768a9189638a47c32dd5842e0c4,2016-08-11T19:13:59Z,https://github.com/tensorflow/tensorflow/commit/313b87d80287c768a9189638a47c32dd5842e0c4,Remove feature column inference for Estimators.This feature was marked for removal on 2016-08-01.Change: 130016968,1,Remove Dead Code,,
3938bc3321173e111985f05947c72edf4e11eca9,2016-08-05T00:08:32Z,https://github.com/tensorflow/tensorflow/commit/3938bc3321173e111985f05947c72edf4e11eca9,"Remove ""for use_gpu"" loop from image_ops_test.Change: 129391444",1,Remove Dead Code,,
68ba6b666d6ccda66f08e595f722af93243490be,2016-07-30T05:06:09Z,https://github.com/tensorflow/tensorflow/commit/68ba6b666d6ccda66f08e595f722af93243490be,Removed unused imports from examples,1,Remove Dead Code,,
6d4ead2bf0e97766c4d468a2ea3c635df411c980,2016-07-26T17:06:32Z,https://github.com/tensorflow/tensorflow/commit/6d4ead2bf0e97766c4d468a2ea3c635df411c980,Remove unused _get_optimizer method.Change: 128483670,1,Remove Dead Code,,
81a7dcd5dc5be797aebe51de8b052dbb6654e1a9,2016-07-20T15:28:46Z,https://github.com/tensorflow/tensorflow/commit/81a7dcd5dc5be797aebe51de8b052dbb6654e1a9,Removed unneeded max_depth parameter and flag.Change: 127948244,1,Remove Dead Code,,
93ed4127fdd3c041f41d3ccc6299757ad5ad50a7,2016-07-13T14:00:25Z,https://github.com/tensorflow/tensorflow/commit/93ed4127fdd3c041f41d3ccc6299757ad5ad50a7,Remove the unused/orphaned code in python/package/default.,1,Remove Dead Code,,
b607f38f10f28ede585a5942a7be737ec73474aa,2016-07-11T17:48:50Z,https://github.com/tensorflow/tensorflow/commit/b607f38f10f28ede585a5942a7be737ec73474aa,TensorForestEstimator - removed unused continue_training and changed to use config in constructor (#3244)* TensorForestEstimator - removed unused continue_training and changed to use config in constructor* Removed unused verbose in TensorForestEstimator constructor,1,Remove Dead Code,,
24311ae1e6958eef264a4a1b29e186724e6bde2d,2016-07-01T23:08:33Z,https://github.com/tensorflow/tensorflow/commit/24311ae1e6958eef264a4a1b29e186724e6bde2d,Remove dead code from Supervisor and SessionManager.Change: 126456805,1,Remove Dead Code,,
67d3c915a8dc5103a2c6e71a5c358a6fb33d9673,2016-06-16T03:15:44Z,https://github.com/tensorflow/tensorflow/commit/67d3c915a8dc5103a2c6e71a5c358a6fb33d9673,Move CTC out of contrib and document.Change: 125022295,1,Remove Dead Code,,
269c99bd283013704973ce16d240e09fb33ddf8a,2016-06-14T00:31:14Z,https://github.com/tensorflow/tensorflow/commit/269c99bd283013704973ce16d240e09fb33ddf8a,Experiment: remove local_train_step flag as it's unexpected and not needed.Estimator: add more error checking for monitors.TensorSignature: fix issue with single tensor been return as dict from create_example_parser_from_signatures function.Change: 124788980,1,Remove Dead Code,,
88c9c51ec26b9f5cc3a75659e3598e103da8e5ec,2016-05-25T05:17:20Z,https://github.com/tensorflow/tensorflow/commit/88c9c51ec26b9f5cc3a75659e3598e103da8e5ec,tf.learn: Remove unused trainer.py.Change: 123180545,1,Remove Dead Code,,
13548f50087decc3de3480a330f8672cfbd1c304,2016-05-21T17:19:48Z,https://github.com/tensorflow/tensorflow/commit/13548f50087decc3de3480a330f8672cfbd1c304,Remove an unnecessary test that was flaking.Change: 122911909,1,Remove Dead Code,,
d11bcebb3072149451872c5c779ac7c67612dc4f,2016-05-17T00:08:42Z,https://github.com/tensorflow/tensorflow/commit/d11bcebb3072149451872c5c779ac7c67612dc4f,Remove unused SupervisorParams.Change: 122476242,1,Remove Dead Code,,
f3434312259ef7cb7a1953510c2a5c0199823a18,2016-05-17T00:08:42Z,https://github.com/tensorflow/tensorflow/commit/f3434312259ef7cb7a1953510c2a5c0199823a18,Remove unused SupervisorParams.Change: 122476242,1,Remove Dead Code,,
cfe40671f22698cabbafeca307b450d4d2e58907,2016-05-16T21:21:31Z,https://github.com/tensorflow/tensorflow/commit/cfe40671f22698cabbafeca307b450d4d2e58907,Remove a vast swathe of duplicated code.Change: 122458182,1,Remove Dead Code,,
85c0af6d0e38096e707761a26fd5bfcd2b781abd,2016-05-13T21:08:11Z,https://github.com/tensorflow/tensorflow/commit/85c0af6d0e38096e707761a26fd5bfcd2b781abd,Remove distributions' __init__ which was accidentally copied overChange: 122294212,1,Remove Dead Code,,
05577fcfa9d390a361598641a8722cbb8916c3bc,2016-04-28T18:48:17Z,https://github.com/tensorflow/tensorflow/commit/05577fcfa9d390a361598641a8722cbb8916c3bc,remove unused os import (#2147),1,Remove Dead Code,,
6231769d174c868333f8839c6163a4b9d62b16da,2016-04-20T16:23:52Z,https://github.com/tensorflow/tensorflow/commit/6231769d174c868333f8839c6163a4b9d62b16da,Remove the sharded_uniform_unit_scaling_initializer in favor of adding a new`full_shape` attribute to the original version.Change: 120343942,1,Remove Dead Code,,
d70c765817b1c53aef924cff87c0d8161f3e9f2f,2016-04-20T03:27:34Z,https://github.com/tensorflow/tensorflow/commit/d70c765817b1c53aef924cff87c0d8161f3e9f2f,Remove duplicate Cholesky gradient registration,1,Remove Dead Code,,
871ee0159e723df788f463d42444b1f654be4c1f,2016-04-13T20:18:27Z,https://github.com/tensorflow/tensorflow/commit/871ee0159e723df788f463d42444b1f654be4c1f,Remove RNNCell's input_size property.Change: 119777914,1,Remove Dead Code,,
3e3193c3ad065f31e0cd10d2ff0c155f691d5966,2016-03-30T18:00:09Z,https://github.com/tensorflow/tensorflow/commit/3e3193c3ad065f31e0cd10d2ff0c155f691d5966,Remove unused import.Change: 118590392,1,Remove Dead Code,,
f7a0b752131dc145191521730779e096864efc1d,2016-03-15T07:59:31Z,https://github.com/tensorflow/tensorflow/commit/f7a0b752131dc145191521730779e096864efc1d,Remove unused file,1,Remove Dead Code,,
aae44380256166127ece6f5010d4656556f5c60d,2016-02-08T06:41:02Z,https://github.com/tensorflow/tensorflow/commit/aae44380256166127ece6f5010d4656556f5c60d,Remove duplicate import,1,Remove Dead Code,,
b2852622ab9a555089ed7a7fa65c6064265d670d,2016-02-08T06:40:01Z,https://github.com/tensorflow/tensorflow/commit/b2852622ab9a555089ed7a7fa65c6064265d670d,Remove duplicate import,1,Remove Dead Code,,
434b79ec286c13bc0fb8b65ff824cf7ea3ee0c3e,2016-02-05T16:45:20Z,https://github.com/tensorflow/tensorflow/commit/434b79ec286c13bc0fb8b65ff824cf7ea3ee0c3e,Remove vocab_size argument for model_with_buckets.Change: 113952458,1,Remove Dead Code,,
5c13ef6db13d28ca48a70fa2d68cc928d5cb1b41,2016-01-25T17:54:42Z,https://github.com/tensorflow/tensorflow/commit/5c13ef6db13d28ca48a70fa2d68cc928d5cb1b41,"Replace make_tensor_shape_proto with TensorShape.as_protoAlso remove the deprecated TensorShape.as_dimension_list function, and removethe to_proto argument to as_list.  Both features were used only to make protos,and that is better done directly with the as_proto method to avoid leakingabstractions.This brings us one step closer to hiding tf.tensor_util.Change: 112960305",1,Remove Dead Code,,
c42490367c403b1836338523ce81eb2f8ac05647,2016-01-06T13:09:20Z,https://github.com/tensorflow/tensorflow/commit/c42490367c403b1836338523ce81eb2f8ac05647,Removes the need for IndexedSlicesWithoutDenseShapeValue. Tests for feeding and fetching IndexedSlices without dense shapes now reuse IndexedSlicesValue.Change-Id: I84eb7289d262797275e6eaa08b5e5daf4d99fe3d,1,Remove Dead Code,,
68398ab8ab5bef9e84e13eea238f9432ce1f0d96,2016-01-02T01:47:05Z,https://github.com/tensorflow/tensorflow/commit/68398ab8ab5bef9e84e13eea238f9432ce1f0d96,"Use pandas for examples, removed csv import",1,Remove Dead Code,,
753f680cb10f4a3dcf71ea6de03752e09ebc2afa,2015-12-21T21:31:53Z,https://github.com/tensorflow/tensorflow/commit/753f680cb10f4a3dcf71ea6de03752e09ebc2afa,"Remove the explicit `g=<graph>` argument from `OpDefLibrary.apply_op()`.This addresses a possible clash between op inputs or attrs named ""g"",which would result in the keyword argument for the op/attr beinginterpreted as a graph override. Since use of the default graph is nowpervasive, there is no particular reason to keep this optionalargument, since none of the generated op wrappers invoke it.Fixes #553.Change: 110692645",1,Remove Dead Code,,
7986951334ddee5b1fa9e88fe64d6d031f7ea90c,2015-12-21T04:23:31Z,https://github.com/tensorflow/tensorflow/commit/7986951334ddee5b1fa9e88fe64d6d031f7ea90c,Remove extra imports,1,Remove Dead Code,,
3e617e3ade1fa55562868c2e2bf8bc07f9b09a79,2015-12-15T02:41:23Z,https://github.com/tensorflow/tensorflow/commit/3e617e3ade1fa55562868c2e2bf8bc07f9b09a79,Print when pandas not installed and removed unnecessary imports,1,Remove Dead Code,,
642924ce2711e493772d9451e99d68c1b98f4e1b,2015-11-19T03:55:45Z,https://github.com/tensorflow/tensorflow/commit/642924ce2711e493772d9451e99d68c1b98f4e1b,removed handling for batch_size - shuffling is still useful,1,Remove Dead Code,,
49e56890042bdfa1dfdb4db4dddae77cc7114abb,2023-05-15T15:11:04Z,https://github.com/keras-team/keras/commit/49e56890042bdfa1dfdb4db4dddae77cc7114abb,Remove unused args // adam,1,Remove Dead Code,,
f8c2982b523401586574833faf46455bc8bb5b6c,2023-05-15T14:53:19Z,https://github.com/keras-team/keras/commit/f8c2982b523401586574833faf46455bc8bb5b6c,Remove unused args,1,Remove Dead Code,,
cbbe8eb53001ccffe9f02d08ecdaf22997879d19,2023-04-07T00:18:12Z,https://github.com/keras-team/keras/commit/cbbe8eb53001ccffe9f02d08ecdaf22997879d19,Remove ineffective statement  PiperOrigin-RevId: 522477719,1,Remove Dead Code,,
0e0d77fd5f1544545980e9388bb0264751e01997,2023-02-28T20:49:11Z,https://github.com/keras-team/keras/commit/0e0d77fd5f1544545980e9388bb0264751e01997,remove not needed stuff,1,Remove Dead Code,,
810fd3c203dbae8bb1f888ebc91cdd31ff30cf34,2023-02-15T00:20:13Z,https://github.com/keras-team/keras/commit/810fd3c203dbae8bb1f888ebc91cdd31ff30cf34,removed redundant dtype,1,Remove Dead Code,,
d2a6b9e0efdd01dd1bc6cf0bb52336d0009aba6c,2023-02-09T19:56:04Z,https://github.com/keras-team/keras/commit/d2a6b9e0efdd01dd1bc6cf0bb52336d0009aba6c,Remove tf-lite deps from tensorflow_core.  PiperOrigin-RevId: 508436607,1,Remove Dead Code,,
d3d523d35a11479bc455981e5e7f792119a7bbd2,2023-01-09T20:49:22Z,https://github.com/keras-team/keras/commit/d3d523d35a11479bc455981e5e7f792119a7bbd2,Remove extra brackets,1,Remove Dead Code,,
30e8b0373a57fa29e605a1896f90e7b3c4e279d2,2022-12-20T08:04:17Z,https://github.com/keras-team/keras/commit/30e8b0373a57fa29e605a1896f90e7b3c4e279d2,Remove unused import from tensorflow.  PiperOrigin-RevId: 496583538,1,Remove Dead Code,,
cb297a63ee109004e42e579062e86af5dd0ce186,2022-12-13T02:40:24Z,https://github.com/keras-team/keras/commit/cb297a63ee109004e42e579062e86af5dd0ce186,Remove _map_resources() from all Trackable-derived classes  PiperOrigin-RevId: 494886914,1,Remove Dead Code,,
330eb89a9a94e2621cfa03e813e3d252e91ee15a,2022-10-28T15:21:18Z,https://github.com/keras-team/keras/commit/330eb89a9a94e2621cfa03e813e3d252e91ee15a,Remove unused `amsgrad` argument in SGD,1,Remove Dead Code,,
b36a662e80e199606d0e872a48d71834a14f4618,2022-09-26T19:11:13Z,https://github.com/keras-team/keras/commit/b36a662e80e199606d0e872a48d71834a14f4618,Remove usage of ram:// temporary directory.  PiperOrigin-RevId: 476958090,1,Remove Dead Code,,
6888ae0d824830bb478fa4e513c7ac4baa47c7ff,2022-09-13T16:36:24Z,https://github.com/keras-team/keras/commit/6888ae0d824830bb478fa4e513c7ac4baa47c7ff,"Remove `keras.experimental.export_saved_model` API. It was deprecated in TF 1.15, which was 3 years ago. It was never a stable API in the first place (it was an `experimental` API) and had no backwards compatibility guarantee.  Consider upgrading to:  1. `model.save()` 2. `tf.saved_model.save()`  PiperOrigin-RevId: 474040485",1,Remove Dead Code,,
ba2a55f1521cfebb4c9931eec50cf92530df8190,2022-07-18T21:42:46Z,https://github.com/keras-team/keras/commit/ba2a55f1521cfebb4c9931eec50cf92530df8190,Remove reference to Slack.  PiperOrigin-RevId: 461719078,1,Remove Dead Code,,
1589a843bac4390c8377db05cbd6ae650b6210cc,2022-07-01T12:41:02Z,https://github.com/keras-team/keras/commit/1589a843bac4390c8377db05cbd6ae650b6210cc,Remove duplicate convert_to_tensor,1,Remove Dead Code,,
158fee33a100767ab1d2c3b69a49bdac8a277e69,2022-04-29T18:42:57Z,https://github.com/keras-team/keras/commit/158fee33a100767ab1d2c3b69a49bdac8a277e69,"Remove unnecessary overriding of default methods in the `LambdaCallback` class.  The `LambdaCallback` class overrides methods such as `on_batch_end` with a no-op lambda if no corresponding argument is provided. This is unnecessary because the no-op lambda is identical to the default method implementation on the superclass.  The current overriding behaviour prevents `LambdaCallback` from being used with parameter-server strategy distributed training. Overriding the default method with a no-op lambda means that `_implements_train_batch_hooks` always returns true (even if e.g. you provide only an `on_epoch_end` hook), so the `_disallow_batch_hooks_in_ps_strategy` check fails.  PiperOrigin-RevId: 445469475",1,Remove Dead Code,,
5ac8c9efea6b70fdc6ebd7981f19ac00463d1ad0,2022-04-13T23:32:07Z,https://github.com/keras-team/keras/commit/5ac8c9efea6b70fdc6ebd7981f19ac00463d1ad0,removed outdated test case,1,Remove Dead Code,,
b2344cb344af18e290619ac980376ea6272111c8,2022-04-11T23:36:05Z,https://github.com/keras-team/keras/commit/b2344cb344af18e290619ac980376ea6272111c8,removed simple testing function call,1,Remove Dead Code,,
15b01be02f91f73aaa685365c3fd7ee315fc9d40,2022-04-11T23:35:41Z,https://github.com/keras-team/keras/commit/15b01be02f91f73aaa685365c3fd7ee315fc9d40,removed simple testing function call,1,Remove Dead Code,,
258bf90b10d1bebb36ba10540fad8772aed6a930,2022-04-03T18:45:20Z,https://github.com/keras-team/keras/commit/258bf90b10d1bebb36ba10540fad8772aed6a930,Remove KerasSequenceAdapter's _size attribute,1,Remove Dead Code,,
5a767d922921d4d11a00611fd067f35c7c1a1627,2022-03-17T18:12:34Z,https://github.com/keras-team/keras/commit/5a767d922921d4d11a00611fd067f35c7c1a1627,"Remove the conditional import for tensorflow/dtensor.  And also remove the BUILD deps of dtensor, which is already included in the TF by default.  PiperOrigin-RevId: 435395712",1,Remove Dead Code,,
6bd6d0df856c2ebb386d37e953a2f2b2eb5abc3a,2022-02-18T09:04:33Z,https://github.com/keras-team/keras/commit/6bd6d0df856c2ebb386d37e953a2f2b2eb5abc3a,Remove experimental.PeepholeLSTMCell from the API.  PiperOrigin-RevId: 429503438,1,Remove Dead Code,,
8ecef127f70db723c158dbe9ed3268b3d610ab55,2022-02-17T23:01:06Z,https://github.com/keras-team/keras/commit/8ecef127f70db723c158dbe9ed3268b3d610ab55,"Remove experimental Keras mixed precision API.  The non-experimental mixed precision API was added in TensorFlow 2.4, and since then the experimental API has been deprecated. This change removes the experimental API.  Deserializing the now-removed PolicyV1 and LossScaleOptimizerV1 classes is still supported, if they were serialized with get_config() prior to this change. These classes are deserialized into the non-experimental Policy and LossScaleOptimizer classes, which has been the case since TensorFlow 2.4. Eventually, support for deserializing these classes may be removed.  PiperOrigin-RevId: 429410341",1,Remove Dead Code,,
59568edf69803a56d419cd211dd1ae6024d0195a,2022-02-16T18:00:08Z,https://github.com/keras-team/keras/commit/59568edf69803a56d419cd211dd1ae6024d0195a,Remove shape_tuple usage for keras_tensor  PiperOrigin-RevId: 429074611,1,Remove Dead Code,,
58c6cd769dd53e75a6954790f49463868c24890d,2022-02-14T18:50:09Z,https://github.com/keras-team/keras/commit/58c6cd769dd53e75a6954790f49463868c24890d,Remove the unused private function in keras base layer.  The active function used by keras now is _keras_tensor_symbolic_call()  PiperOrigin-RevId: 428553388,1,Remove Dead Code,,
0c959a0670a2bcb12dc7a1717ce7416ff1f7cc27,2022-02-12T02:36:04Z,https://github.com/keras-team/keras/commit/0c959a0670a2bcb12dc7a1717ce7416ff1f7cc27,"Remove deprecated TF1 Layer APIs `apply()`, `get_updates_for()`, `get_losses_for()`, and remove the `inputs` argument in the `add_loss()` method.  PiperOrigin-RevId: 428134172",1,Remove Dead Code,,
09c282e183493a6c9f3b537e4af02097b71b5226,2022-02-09T05:26:11Z,https://github.com/keras-team/keras/commit/09c282e183493a6c9f3b537e4af02097b71b5226,Keras saving/loading: Remove KerasObjectLoader._load_edges() which appears to be unused.  PiperOrigin-RevId: 427373809,1,Remove Dead Code,,
8ca59d5598cdcece9196b6943358f7cba37d0306,2022-01-27T06:07:41Z,https://github.com/keras-team/keras/commit/8ca59d5598cdcece9196b6943358f7cba37d0306,Remove legacy multi_gpu_utils (irrelevant since the introduction of distribution strategies).  PiperOrigin-RevId: 424519138,1,Remove Dead Code,,
26adeff60c3e36937e59ecfd1f8ef04dd4f0dc0f,2022-01-27T02:07:10Z,https://github.com/keras-team/keras/commit/26adeff60c3e36937e59ecfd1f8ef04dd4f0dc0f,Remove unused `types` folder.  PiperOrigin-RevId: 424486944,1,Remove Dead Code,,
c215f14d661de3e1587c26229d8f1a8cf0257563,2022-01-12T21:29:17Z,https://github.com/keras-team/keras/commit/c215f14d661de3e1587c26229d8f1a8cf0257563,"1. Remove redundant args from `update_step` of Adagrad and RMSprop optimizer. 2. Change the default value of `ema_overwrite_frequency` to None, as a magic number is hard to be justified. Also during our benchmarking, seems like this periodic overwriting is harmful to performance.  PiperOrigin-RevId: 421380718",1,Remove Dead Code,,
983df1fe3f66ab53c254ee37aa29a82554029d3d,2021-12-02T17:38:34Z,https://github.com/keras-team/keras/commit/983df1fe3f66ab53c254ee37aa29a82554029d3d,remove unused imports,1,Remove Dead Code,,
5c4074a820a08505cf87562f60d21adfdc2dfb05,2021-11-20T01:41:44Z,https://github.com/keras-team/keras/commit/5c4074a820a08505cf87562f60d21adfdc2dfb05,"Remove CategoryCrossing benchmark, update hashed crossing benchmark  We will use the new HashedCrossing layer to compare performance with feature_column.crossed_column  PiperOrigin-RevId: 411179350",1,Remove Dead Code,,
fd23f6671b088f19acdb5d148c8af1cd63583c9d,2021-09-21T14:32:14Z,https://github.com/keras-team/keras/commit/fd23f6671b088f19acdb5d148c8af1cd63583c9d,unnecessary casting and condition removed  unnecessary casting and condition removed,1,Remove Dead Code,,
97a8d25cd9bff86e32df52c9c7f840e11e272efe,2021-08-16T22:29:54Z,https://github.com/keras-team/keras/commit/97a8d25cd9bff86e32df52c9c7f840e11e272efe,"Remove reduction preprocessing layers  These were never exported, and are not needed, as the tf reduction ops can be used directly.  PiperOrigin-RevId: 391151201",1,Remove Dead Code,,
e6ba8373f8918f05e2454c8a2bd13221900cad70,2021-08-12T17:53:57Z,https://github.com/keras-team/keras/commit/e6ba8373f8918f05e2454c8a2bd13221900cad70,removed duplicate steps_per_execution variable  PiperOrigin-RevId: 390410210,1,Remove Dead Code,,
6f789cc4ba300d261dbe68c12f81074dd239c790,2021-08-06T18:42:43Z,https://github.com/keras-team/keras/commit/6f789cc4ba300d261dbe68c12f81074dd239c790,Remove legacy Conv1D -> conv1D downcasing.  PiperOrigin-RevId: 389223710,1,Remove Dead Code,,
e66bfdd14709fe0b39ee834194130d46c87c77eb,2021-08-04T03:41:47Z,https://github.com/keras-team/keras/commit/e66bfdd14709fe0b39ee834194130d46c87c77eb,Remove `Conv._convolution_op` assignment in constructor.  This was kept as a temporary measure to preserve backwards compatibility.  Going forward `Conv` layer subclasses should prefer `Conv.convolution_op()`.  PiperOrigin-RevId: 388606987,1,Remove Dead Code,,
967817c22657b31d4bb08f41e118e4118012284b,2021-07-01T03:01:41Z,https://github.com/keras-team/keras/commit/967817c22657b31d4bb08f41e118e4118012284b,Remove convert_to_list utility in base_preprocessing_layer  This was no longer used.  PiperOrigin-RevId: 382437002,1,Remove Dead Code,,
1232f05bce16db15ecac9c35b1b7604c22d208ae,2021-06-24T16:53:04Z,https://github.com/keras-team/keras/commit/1232f05bce16db15ecac9c35b1b7604c22d208ae,"Remove ""oss_optimizer"" identifier.  PiperOrigin-RevId: 381276605",1,Remove Dead Code,,
1abd9a1044dc5643a54a8a228de92852e4e488dd,2021-06-22T22:31:30Z,https://github.com/keras-team/keras/commit/1abd9a1044dc5643a54a8a228de92852e4e488dd,Remove reset_state from adapt  It is only support for Discretization and Normalization and not even tested on those classes. Removing it gives us a cleaner API interface for release.  PiperOrigin-RevId: 380906031,1,Remove Dead Code,,
73967df0f4dbd3d43d8d8d958fd0d016251d7059,2021-06-22T21:38:53Z,https://github.com/keras-team/keras/commit/73967df0f4dbd3d43d8d8d958fd0d016251d7059,Remove the forward compat check in keras metrics_utils code.  The date for forward compat already take effective.  PiperOrigin-RevId: 380894653,1,Remove Dead Code,,
f1c5826dbfdbc62ae6eea599d939b9da2f70f1ab,2021-06-20T19:52:38Z,https://github.com/keras-team/keras/commit/f1c5826dbfdbc62ae6eea599d939b9da2f70f1ab,remove parametrization in pickle_utils_test.py,1,Remove Dead Code,,
f4a382d66c12a7d20f9e7ad92be9a8e8bd4582bb,2021-06-15T21:01:02Z,https://github.com/keras-team/keras/commit/f4a382d66c12a7d20f9e7ad92be9a8e8bd4582bb,Remove deprecated methods of Sequential model.  PiperOrigin-RevId: 379568414,1,Remove Dead Code,,
9f671d06d3d2f042f9163924f8a8e9edb7caf4c9,2021-04-25T20:48:49Z,https://github.com/keras-team/keras/commit/9f671d06d3d2f042f9163924f8a8e9edb7caf4c9,Cleanup the bazelrc and remove unrelated items to keras.  PiperOrigin-RevId: 370356681,1,Remove Dead Code,,
461c7b1dc1797d2b05110837f5a4cd12886cc390,2021-01-22T22:02:09Z,https://github.com/keras-team/keras/commit/461c7b1dc1797d2b05110837f5a4cd12886cc390,"#PRIVATE_TF_API_USAGE_CLEANUP Remove the definition of gather_trainable_weights(), as there is no reference in the codebase.  PiperOrigin-RevId: 353314486",1,Remove Dead Code,,
77309a482b6d32b79230bbce35e4d0083d5f8bb1,2021-01-22T20:26:16Z,https://github.com/keras-team/keras/commit/77309a482b6d32b79230bbce35e4d0083d5f8bb1,"#PRIVATE_TF_API_USAGE_CLEANUP Remove the test cases on object_meta(), as there is no real reference to this tf private api.  PiperOrigin-RevId: 353295828",1,Remove Dead Code,,
a0351962dddbd374d7a996afbe5f3b23603d70f3,2021-01-22T18:51:52Z,https://github.com/keras-team/keras/commit/a0351962dddbd374d7a996afbe5f3b23603d70f3,"#PRIVATE_TF_API_USAGE_CLEANUP Remove the usage of gather_non_trainable_weights. There is no reference to this method, so we just delete the method.  PiperOrigin-RevId: 353274439",1,Remove Dead Code,,
d8446ef617f5bf90950f3934671fc09d5784ac97,2019-09-08T01:27:24Z,https://github.com/keras-team/keras/commit/d8446ef617f5bf90950f3934671fc09d5784ac97,"Remove deprecated example, fix conv filter example",1,Remove Dead Code,,
2bc43bff1e243f4031690277b67f60592c1edf58,2019-09-08T00:54:08Z,https://github.com/keras-team/keras/commit/2bc43bff1e243f4031690277b67f60592c1edf58,Remove deprecated example script,1,Remove Dead Code,,
d36c7b2d937aa85574b0ff993d6e8e8f15ccc6aa,2019-08-28T22:44:59Z,https://github.com/keras-team/keras/commit/d36c7b2d937aa85574b0ff993d6e8e8f15ccc6aa,Remove outdated tests,1,Remove Dead Code,,
72b55d20899fae554b453a9e67682bb26c2e60d2,2019-07-03T00:56:42Z,https://github.com/keras-team/keras/commit/72b55d20899fae554b453a9e67682bb26c2e60d2,Remove outdated integration test.,1,Remove Dead Code,,
1575b8c33bb1c391cd574ccfbc2812bd5bae54ec,2019-06-24T23:55:51Z,https://github.com/keras-team/keras/commit/1575b8c33bb1c391cd574ccfbc2812bd5bae54ec,Remove outdated test,1,Remove Dead Code,,
2d2fb47e321faa032c98e92d34e6215b6026f1f0,2019-06-24T20:31:02Z,https://github.com/keras-team/keras/commit/2d2fb47e321faa032c98e92d34e6215b6026f1f0,Remove deprecated applications adapter code,1,Remove Dead Code,,
f312e5acf16100c6e5c1ce4b37a66eed3e62e846,2019-06-07T22:05:54Z,https://github.com/keras-team/keras/commit/f312e5acf16100c6e5c1ce4b37a66eed3e62e846,Remove ignored applications files.,1,Remove Dead Code,,
91efaaa1d7486df71be30a54d82b907443d80bf1,2019-04-03T00:39:50Z,https://github.com/keras-team/keras/commit/91efaaa1d7486df71be30a54d82b907443d80bf1,Add kwarg and documentation for dilation_rate to DepthWiseConv2D (#12526)  * Add kwarg and documentation for dilation_rate to DepthWiseConv2D  * Add test coverage for dilation rate in DepthWiseConv2D  * removed dublicated code  * fix DeapthWiseConv2D compute_output_shape  * revert to previous indexing,1,Remove Dead Code,,
b23c9fe95de5b6425e2bf76641852f48174dd036,2019-04-03T00:20:51Z,https://github.com/keras-team/keras/commit/b23c9fe95de5b6425e2bf76641852f48174dd036,remove a redundant line (#12607)  `generated += next_char` is redundant,1,Remove Dead Code,,
0cd3b07eb5de1aaaad84d1ff7f7c2ed7dab4b23c,2019-01-08T23:16:36Z,https://github.com/keras-team/keras/commit/0cd3b07eb5de1aaaad84d1ff7f7c2ed7dab4b23c,Remove legacy environment variables (#11998),1,Remove Dead Code,,
bfa87eb1b0ab53c5f1efab1ec1d91377678046af,2018-12-17T15:19:38Z,https://github.com/keras-team/keras/commit/bfa87eb1b0ab53c5f1efab1ec1d91377678046af,Removed unused function in autogen.py (#11872)  ### Summary  This function isn't called or mentioned anywhere else in keras. We should remove it.  ### Related Issues  ### PR Overview  - [ ] This PR requires new unit tests [y/n] (make sure tests are included) - [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date) - [x] This PR is backwards compatible [y/n] - [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet),1,Remove Dead Code,,
b9f3b4a6c8b99335e2d3c0bb10b21d388a485ab6,2018-11-03T14:08:03Z,https://github.com/keras-team/keras/commit/b9f3b4a6c8b99335e2d3c0bb10b21d388a485ab6,Removed matplotlib from travis because it's not used in the tests. (#11557),1,Remove Dead Code,,
f2b261bc2555773bd88cbbeda976f98e244d02c1,2018-10-14T18:49:08Z,https://github.com/keras-team/keras/commit/f2b261bc2555773bd88cbbeda976f98e244d02c1,Removed some unused variables. (#11395),1,Remove Dead Code,,
22f20b97386652a24bf2e8e363bfa38ca66cb209,2018-10-09T16:42:06Z,https://github.com/keras-team/keras/commit/22f20b97386652a24bf2e8e363bfa38ca66cb209,Remove unused import.,1,Remove Dead Code,,
f130fa1bca288cb566b083620ba70cb89e2e5fdd,2018-09-20T13:10:34Z,https://github.com/keras-team/keras/commit/f130fa1bca288cb566b083620ba70cb89e2e5fdd,Removed completely the keras_test decorator. (#11182)  ### Summary  We already have a test wrapper in a `conftest.py` so we don't need that decorator anymore.  ### Related Issues  ### PR Overview  - [ ] This PR requires new unit tests [y/n] (make sure tests are included) - [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date) - [x] This PR is backwards compatible [y/n] - [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet),1,Remove Dead Code,,
cc3521ea93b0470e9ea11151a44c30b54d4d726a,2018-08-30T02:50:22Z,https://github.com/keras-team/keras/commit/cc3521ea93b0470e9ea11151a44c30b54d4d726a," [RELNOTES] Added the mode ""bilinear"" in the upscaling2D layer. (#10994)  * bilinear upsampling initial implementation  * bilinear interpolation docstrings added  * thano_backend.py fix bilinear interpolation ratio  * theano_backend.py pep8 & padding fix  * theano_backend.py remove border_mode as per review  * Added the mode ""bilinear"" in the upscaling2D layer. Theano only supports (2, 2) though.  * Added some details about what was possible with bilinear interpolation.  * Made the lines shorted in the resize implementation of tensorflow.  * Added a more meaningful error message for bilinear and CNTK.  * Used ' instead of "" for consistency.  * Parametrized the bilinear test.  * Removed unused import.  * Fix error messages.  * Parametrized tests.",1,Remove Dead Code,,
d8796e04f8f8a814eb8ae3206624b5c4b47362f3,2018-08-23T03:25:51Z,https://github.com/keras-team/keras/commit/d8796e04f8f8a814eb8ae3206624b5c4b47362f3,Removed duplicated backend test. (#10959),1,Remove Dead Code,,
38ce4657bad26cb359c2852b792478264d92ee9f,2018-08-22T17:02:44Z,https://github.com/keras-team/keras/commit/38ce4657bad26cb359c2852b792478264d92ee9f,Added in the documentation an example of custom layer with multiple inputs and outputs. (#10939)  * Added in the documentation an example of custom layer with multiple inputs and outputs.  * Removed two unused imports and added assertions to make it easier to understand that methods arguments are lists.,1,Remove Dead Code,,
c60f1e19dceacf77749a6215b1fc77f758f46327,2018-08-22T04:33:55Z,https://github.com/keras-team/keras/commit/c60f1e19dceacf77749a6215b1fc77f758f46327,Removed redundant tests in the backends. (#10953),1,Remove Dead Code,,
7205d903fbc079bb99fbae0e3c02e6d2b4d227f0,2018-08-05T23:53:56Z,https://github.com/keras-team/keras/commit/7205d903fbc079bb99fbae0e3c02e6d2b4d227f0,Removed some unused variables. (#10686)  * Removed some unused variables.  * Added a comment rather than removing the variable.,1,Remove Dead Code,,
75114feeac5ee6aa7679802ce7e5172c63565e2c,2018-07-19T17:32:06Z,https://github.com/keras-team/keras/commit/75114feeac5ee6aa7679802ce7e5172c63565e2c,Removed some unused variables and fixed a formatting error. (#10688)  * Removed some unused variables.  * Fixed the formatting of an error message.,1,Remove Dead Code,,
3dcd9c767ce6875fc8b69c74971ac8a552e23131,2018-07-12T08:58:03Z,https://github.com/keras-team/keras/commit/3dcd9c767ce6875fc8b69c74971ac8a552e23131,Remove duplicate calls to InputSpec (#10654),1,Remove Dead Code,,
b3cb261b22a73d195a527592b49ca57e8c9ac9f5,2018-07-11T13:23:18Z,https://github.com/keras-team/keras/commit/b3cb261b22a73d195a527592b49ca57e8c9ac9f5,Remove duplicate normalize_data_format (#10645)  ### Summary `normalize_data_format` was being called twice in `_Pooling2D`  ### Related Issues  ### PR Overview  - [n] This PR requires new unit tests [y/n] (make sure tests are included) - [n] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date) - [y] This PR is backwards compatible [y/n] - [n] This PR changes the current API [y/n] (all API changes need to be approved by fchollet),1,Remove Dead Code,,
468f080c98f06780c950e5a78c9eeeaf9fff002e,2018-07-04T04:21:51Z,https://github.com/keras-team/keras/commit/468f080c98f06780c950e5a78c9eeeaf9fff002e,Replace relu6 with ReLU layers (#10597)  * Remove unused relu6  * Remove doc for loading relu6,1,Remove Dead Code,,
c77267af5fff5642951ae4a2c9bb09fb6d698c30,2018-05-23T18:54:36Z,https://github.com/keras-team/keras/commit/c77267af5fff5642951ae4a2c9bb09fb6d698c30,Remove deprecated model.model from engine/saving (#10275),1,Remove Dead Code,,
ba6f4945858bdf02bf10fc833430fb77894693db,2018-05-08T22:05:31Z,https://github.com/keras-team/keras/commit/ba6f4945858bdf02bf10fc833430fb77894693db,Remove useless super delegation.,1,Remove Dead Code,,
ece9a009deb0202f4344881607426d651d89da38,2018-04-30T21:29:47Z,https://github.com/keras-team/keras/commit/ece9a009deb0202f4344881607426d651d89da38,Remove unused import,1,Remove Dead Code,,
a6542e845e9af539ba2def25b36e4afdc1162f0a,2018-01-19T01:06:16Z,https://github.com/keras-team/keras/commit/a6542e845e9af539ba2def25b36e4afdc1162f0a,Removed fit call from regularizers tests. (#9117)  * Removed fit call from regularizers tests.  * Changed fit to train_on_batch.,1,Remove Dead Code,,
e1a1e880d53fbbec97e8c3dfe1c82281a5761d44,2018-01-16T01:53:28Z,https://github.com/keras-team/keras/commit/e1a1e880d53fbbec97e8c3dfe1c82281a5761d44,Removed redundant os.path.expanduser call. (#8985)  * Removed redundant os.path.expanduser call.  * Changed to first expanduser then join.,1,Remove Dead Code,,
6f09be91e695d74f19aac084808b998ecf6eb24e,2018-01-12T23:24:06Z,https://github.com/keras-team/keras/commit/6f09be91e695d74f19aac084808b998ecf6eb24e,Remove unused variable,1,Remove Dead Code,,
d2c94474ac11da442dff4548c0fe325eeecc5561,2018-01-10T02:08:24Z,https://github.com/keras-team/keras/commit/d2c94474ac11da442dff4548c0fe325eeecc5561,Remove unused import.,1,Remove Dead Code,,
4c7143ef59a69c08fc3b09f8d12d93fdfbf497b8,2018-01-10T01:37:59Z,https://github.com/keras-team/keras/commit/4c7143ef59a69c08fc3b09f8d12d93fdfbf497b8,Remove print function in signature (#9030)  * Remove print function in signature  * Add docstrings,1,Remove Dead Code,,
58e702091c60aedb169df2292851fab42019cea7,2018-01-09T19:00:58Z,https://github.com/keras-team/keras/commit/58e702091c60aedb169df2292851fab42019cea7,"Refactor `Subtract`, `Concatenate`, and `Dot` (#9010)",1,Remove Dead Code,Expression,
b197ba91d7bd3c390b67cd67da2eb381b25a22b2,2018-01-05T01:20:21Z,https://github.com/keras-team/keras/commit/b197ba91d7bd3c390b67cd67da2eb381b25a22b2,Remove unused code.,1,Remove Dead Code,,
236c3ebed52f9eb224657206d7aebfc1c1478f72,2017-11-18T04:28:35Z,https://github.com/keras-team/keras/commit/236c3ebed52f9eb224657206d7aebfc1c1478f72,remove duplicated lines in example code (#8522),1,Remove Dead Code,,
fde40f288bae02b49c93e3a06419b5d59540c1d8,2017-11-03T18:52:52Z,https://github.com/keras-team/keras/commit/fde40f288bae02b49c93e3a06419b5d59540c1d8,Remove dead code.,1,Remove Dead Code,,
c2268794ab638dd1c4f85b67b582ceb08acfe3c1,2017-10-12T19:01:21Z,https://github.com/keras-team/keras/commit/c2268794ab638dd1c4f85b67b582ceb08acfe3c1,Remove redundant argument to range(). (#8108)  * Remove redundant argument to range.   All other range() invocations in this file follow this style.  * Remove redundant argument to range(),1,Remove Dead Code,,
f140638d8024aa7cfb634ba00792554a2b413dc9,2017-08-21T21:49:49Z,https://github.com/keras-team/keras/commit/f140638d8024aa7cfb634ba00792554a2b413dc9,Cleanup: remove unused `constraints` attribute in `Sequential` model.,1,Remove Dead Code,,
a6679b7077ff102a83d2706fea671eaa3a0bf349,2017-08-07T00:12:13Z,https://github.com/keras-team/keras/commit/a6679b7077ff102a83d2706fea671eaa3a0bf349,remove unnecessary function definition (#7542),1,Remove Dead Code,,
46b691e302e896053c4fd167ca4ec688d957b245,2017-07-30T00:20:55Z,https://github.com/keras-team/keras/commit/46b691e302e896053c4fd167ca4ec688d957b245,Remove legacy axis handling in TF backend.,1,Remove Dead Code,,
1b1e09a3665d71061bb5b62ca475d304634a85bf,2017-06-07T07:00:25Z,https://github.com/keras-team/keras/commit/1b1e09a3665d71061bb5b62ca475d304634a85bf,Remove duplicated batch_set_value in cntk_backend (#6878),1,Remove Dead Code,,
0bb4e0fad5b4bb3743c8a7d03c260b62a35e7045,2017-05-24T22:33:42Z,https://github.com/keras-team/keras/commit/0bb4e0fad5b4bb3743c8a7d03c260b62a35e7045,Remove unused import.,1,Remove Dead Code,,
a2c3fa2b96b8727bc060a28b210cabfacc342a83,2017-05-23T18:22:34Z,https://github.com/keras-team/keras/commit/a2c3fa2b96b8727bc060a28b210cabfacc342a83,Small clean ups (#6724)  * Remove unused variables  * progbar,1,Remove Dead Code,,
bfae0a61917f8cc7563db80051f89e178e8bfb1c,2017-05-07T21:46:26Z,https://github.com/keras-team/keras/commit/bfae0a61917f8cc7563db80051f89e178e8bfb1c,remove unused import in tests folder (#6534),1,Remove Dead Code,,
362bfdd65126e62addc459122e19a2523dcafa2f,2017-04-09T21:30:03Z,https://github.com/keras-team/keras/commit/362bfdd65126e62addc459122e19a2523dcafa2f,Removed unused util function.,1,Remove Dead Code,,
fe48b41c2228b64357bedd1942ab981ef2ad3cbc,2017-04-02T15:02:35Z,https://github.com/keras-team/keras/commit/fe48b41c2228b64357bedd1942ab981ef2ad3cbc,remove unused variables in cifar10_cnn (#6112),1,Remove Dead Code,,
c8282437a7f75f9c3af7a1b2ad57297be41863ff,2017-02-26T21:52:06Z,https://github.com/keras-team/keras/commit/c8282437a7f75f9c3af7a1b2ad57297be41863ff,Remove unused import.,1,Remove Dead Code,,
4101b5fdb2262b666ba7eb901f1776ef6579902a,2017-02-26T19:19:21Z,https://github.com/keras-team/keras/commit/4101b5fdb2262b666ba7eb901f1776ef6579902a,Remove legacy support code from TF backend.,1,Remove Dead Code,,
0c8e6319cff0b0b723aa1a7b8d8a0b3628558848,2017-02-23T21:53:54Z,https://github.com/keras-team/keras/commit/0c8e6319cff0b0b723aa1a7b8d8a0b3628558848,Remove some legacy features.,1,Remove Dead Code,,
ac2a7254c2c29b4c13fb97740f2aaaf46a0282dc,2017-02-22T00:41:17Z,https://github.com/keras-team/keras/commit/ac2a7254c2c29b4c13fb97740f2aaaf46a0282dc,Remove useless statement in Dense.,1,Remove Dead Code,,
26e6df8a98670802286978e1657526fe2afa61d5,2017-02-22T00:41:07Z,https://github.com/keras-team/keras/commit/26e6df8a98670802286978e1657526fe2afa61d5,Remove legacy code in TF backend.,1,Remove Dead Code,,
1c630c3e3c8969b40a47d07b9f2edda50ec69720,2017-01-18T01:42:29Z,https://github.com/keras-team/keras/commit/1c630c3e3c8969b40a47d07b9f2edda50ec69720,Remove legacy code from regularizers,1,Remove Dead Code,,
088dbe6866fd51f4e0e64866e442968c17abfa10,2017-01-11T23:07:00Z,https://github.com/keras-team/keras/commit/088dbe6866fd51f4e0e64866e442968c17abfa10,Remove unused util function,1,Remove Dead Code,,
c0d95fd6c2cd8ffc0738819825c3065e3c89977c,2017-01-06T17:25:03Z,https://github.com/keras-team/keras/commit/c0d95fd6c2cd8ffc0738819825c3065e3c89977c,Remove unused imports and unused variables (#4930),1,Remove Dead Code,,
ffe013033e7cb20b03129d346561e85b69e878a4,2016-12-28T20:31:49Z,https://github.com/keras-team/keras/commit/ffe013033e7cb20b03129d346561e85b69e878a4,Remove deprecated regularizers from wrappers,1,Remove Dead Code,,
4491212da4430181cd4d35cee5d341de87b3ac0d,2016-12-09T11:16:51Z,https://github.com/keras-team/keras/commit/4491212da4430181cd4d35cee5d341de87b3ac0d,Remove unnecessary import,1,Remove Dead Code,,
79ec9b8079e926104b444239cc9642cb269492dc,2016-11-29T21:22:34Z,https://github.com/keras-team/keras/commit/79ec9b8079e926104b444239cc9642cb269492dc,ACGAN : Remove lines with no effect (#4503)  * Remove lines with no effect  * pep8  * Update mnist_acgan.py,1,Remove Dead Code,,
c0b32a9a04c761e03e082d4ff955702c6aa17003,2016-11-25T09:20:10Z,https://github.com/keras-team/keras/commit/c0b32a9a04c761e03e082d4ff955702c6aa17003,Remove reference to legacy Graph model in tests.,1,Remove Dead Code,,
ce814302acee2c474a88b2f4bfcdc92ff866f94f,2016-11-25T07:29:45Z,https://github.com/keras-team/keras/commit/ce814302acee2c474a88b2f4bfcdc92ff866f94f,Remove support for legacy Graph model,1,Remove Dead Code,,
628bc6e03e1024f5d9aecd75db9465cb51cc9209,2016-11-25T04:21:56Z,https://github.com/keras-team/keras/commit/628bc6e03e1024f5d9aecd75db9465cb51cc9209,ACGAN: Remove unnecessary dimension in label input (#4501),1,Remove Dead Code,,
8d20bac7fa534383fde1054334110691a11735c9,2016-11-17T02:59:03Z,https://github.com/keras-team/keras/commit/8d20bac7fa534383fde1054334110691a11735c9,Remove extraneous batch_input_shape (#4393),1,Remove Dead Code,,
92e8a20761bedbde8fd56a02a165884e8132f045,2016-11-10T02:34:09Z,https://github.com/keras-team/keras/commit/92e8a20761bedbde8fd56a02a165884e8132f045,Remove unused set_input method,1,Remove Dead Code,,
cb3de665d18c579fa36fe8b6b2e2c084ace0bd12,2016-11-10T02:01:19Z,https://github.com/keras-team/keras/commit/cb3de665d18c579fa36fe8b6b2e2c084ace0bd12,Simplify tests,1,Remove Dead Code,,
b89a93faae8237561181f3d22b164de5b6dc728c,2016-10-17T04:58:35Z,https://github.com/keras-team/keras/commit/b89a93faae8237561181f3d22b164de5b6dc728c,Remove unused imports. (#4083),1,Remove Dead Code,,
79c133143297a37b630f791b02c88d58579e05ef,2016-10-14T16:16:56Z,https://github.com/keras-team/keras/commit/79c133143297a37b630f791b02c88d58579e05ef,Remove unused import statement (#4053),1,Remove Dead Code,,
2c96373a411b1a9754ccad16ab5d23b80ed35d25,2016-10-13T19:30:01Z,https://github.com/keras-team/keras/commit/2c96373a411b1a9754ccad16ab5d23b80ed35d25,remove another useless check,1,Remove Dead Code,,
731e1bb2063ceeeee9fac4eaab8a12a1ac68ba2c,2016-10-13T19:28:51Z,https://github.com/keras-team/keras/commit/731e1bb2063ceeeee9fac4eaab8a12a1ac68ba2c,remove a useless check,1,Remove Dead Code,,
4325843ef07b00eb3f234d5d3dd5c92205effe9f,2016-09-06T20:42:56Z,https://github.com/keras-team/keras/commit/4325843ef07b00eb3f234d5d3dd5c92205effe9f,Add Matthews correlation coefficient to metrics (#3689)  * Add Matthews correlation coefficient to metrics  I needed this for a Kaggle competition and it seemed useful in general so I thought I'd contribute it back.  * Enabled test for matthews metric  * Remove unnecessary cast garbage  * Addresses code review comments  * Renamed to matthews_corrcoef to be consistent with sklearn  * Update test_metrics.py  * pep8  * rename to mathews_correlation  * Update metrics.py  * Fixed typo,1,Remove Dead Code,,
46d5b197e022815c2074fbc94ca324d31d470dd0,2016-08-12T21:36:35Z,https://github.com/keras-team/keras/commit/46d5b197e022815c2074fbc94ca324d31d470dd0,Implement a fasttext example (#3446)  * Upload examples/imdb_fasttext.py which implement the fasttext model  * Remove Dropout and unnecessary imports  * Remove Dropout and unnecessary imports  * Remove Dropout and unnecessary imports,1,Remove Dead Code,,
c034262b7857a0738339b1747b052e51ae60dce0,2016-07-20T23:12:49Z,https://github.com/keras-team/keras/commit/c034262b7857a0738339b1747b052e51ae60dce0,Removed test for deprecated graph model,1,Remove Dead Code,,
2ac6811362aafdbf275c18d634ae6ba78cea406d,2016-07-19T21:53:50Z,https://github.com/keras-team/keras/commit/2ac6811362aafdbf275c18d634ae6ba78cea406d,Remove deprecated graph model test,1,Remove Dead Code,,
3bc80d3db4365674003bd30af1e0cc7859b6184b,2016-07-01T06:04:12Z,https://github.com/keras-team/keras/commit/3bc80d3db4365674003bd30af1e0cc7859b6184b,Remove unnecessary assert,1,Remove Dead Code,,
edbec2dbc93cbfc020a6bf8a99cccfd7e67d5096,2016-06-04T06:13:46Z,https://github.com/keras-team/keras/commit/edbec2dbc93cbfc020a6bf8a99cccfd7e67d5096,Remove bit of deprecated code,1,Remove Dead Code,,
3695bc2db5ed9aa1c1a2fe90160df83202c343e4,2016-05-13T18:06:08Z,https://github.com/keras-team/keras/commit/3695bc2db5ed9aa1c1a2fe90160df83202c343e4,"Remove references to ""join"" merge mode",1,Remove Dead Code,,
1c460e1e08ab2ff65678ca0d3b97b578e5afd931,2016-05-06T04:33:04Z,https://github.com/keras-team/keras/commit/1c460e1e08ab2ff65678ca0d3b97b578e5afd931,remove unused import statement in keras dir (#2638)  * remove unused import statement in keras dir  * rewrite import graph statement,1,Remove Dead Code,,
f26ce6e2368ce3b314642c2e02da18e0d5358cb2,2016-04-26T22:21:14Z,https://github.com/keras-team/keras/commit/f26ce6e2368ce3b314642c2e02da18e0d5358cb2,"Rewriting image augmenter   (#2446)  * Much better image data augmentor  * removed unnecessary functions  * shift origin to centre of the image for homographies  * init commit  * change to zoom_range  * Added scikit-image to extras_require in setup.py  * add zoom_range test, exception for invalid zoom_range  * add scikit-image to dependency  * fix fit and retain old functions for unit test  * use ndi insteadskimage in random_transform  * removed buggy code in random_rotations, shears etc  and replaced it with todos.  * remove sci-image, implement ndimage based methods, refactor random_transform  * random_zoom, array_to_img consider dim_ordering  * add random_channel_shift, support fill_mode and cval  * image doc, update test_image, PEP8  * fix channel shift clip  * fix doc, refine code  * detail explain of zoom range  * check coding style",1,Remove Dead Code,,
1db555a530ce433f39c9d8af0592e6e81468d6eb,2016-04-12T05:36:37Z,https://github.com/keras-team/keras/commit/1db555a530ce433f39c9d8af0592e6e81468d6eb,remove creation of np.asarray in to_categorical (#2268),1,Remove Dead Code,,
8c73c6f218abc2b7345bab8928e5c5bcf192f4d1,2016-04-07T00:20:43Z,https://github.com/keras-team/keras/commit/8c73c6f218abc2b7345bab8928e5c5bcf192f4d1,Simplify lstm example,1,Remove Dead Code,,
35c5fa911dcc304f39f0bc6c335d4f67ce082b79,2016-02-21T23:31:32Z,https://github.com/keras-team/keras/commit/35c5fa911dcc304f39f0bc6c335d4f67ce082b79,clean up,1,Remove Dead Code,,
c95f5d10c222c0e596135f6d32ee70f18f2958c6,2015-12-29T10:24:57Z,https://github.com/keras-team/keras/commit/c95f5d10c222c0e596135f6d32ee70f18f2958c6,Minor: remove duplicate code.,1,Remove Dead Code,,
485d451b62600d01bd728b2ae301ef233b5c4d7b,2015-12-22T17:33:32Z,https://github.com/keras-team/keras/commit/485d451b62600d01bd728b2ae301ef233b5c4d7b,Remove no-longer used util function.,1,Remove Dead Code,,
c2a7ccd1cc5b4a3b3a1a0f920c8a29073d32ce42,2015-12-17T19:02:40Z,https://github.com/keras-team/keras/commit/c2a7ccd1cc5b4a3b3a1a0f920c8a29073d32ce42,Remove unnecessary apology :),1,Remove Dead Code,,
090ac0d1387a9f370f18afbc25314eeec2568d0c,2015-12-15T06:46:04Z,https://github.com/keras-team/keras/commit/090ac0d1387a9f370f18afbc25314eeec2568d0c,remove incompatible tests,1,Remove Dead Code,,
8c1c86baf0220164c355198708a1c613d27d4132,2015-12-10T09:06:16Z,https://github.com/keras-team/keras/commit/8c1c86baf0220164c355198708a1c613d27d4132,remove unused import,1,Remove Dead Code,,
36a41720af85ec282054bd3db1d160d7e151e73c,2015-12-08T14:07:50Z,https://github.com/keras-team/keras/commit/36a41720af85ec282054bd3db1d160d7e151e73c,Remove tests in old structure,1,Remove Dead Code,,
6bfb3c648bb0b79d97916e1a53f130a2f6fbd5b7,2015-12-05T17:37:25Z,https://github.com/keras-team/keras/commit/6bfb3c648bb0b79d97916e1a53f130a2f6fbd5b7,Removed old MaxPool2D layer,1,Remove Dead Code,,
4b39b5f36b997868f9105d8bc76188f8837f50db,2015-11-29T00:34:06Z,https://github.com/keras-team/keras/commit/4b39b5f36b997868f9105d8bc76188f8837f50db,Remove deprecated code.,1,Remove Dead Code,,
8f2810bfeee98c6c01c6a76b481dafa24e142666,2015-10-31T14:32:01Z,https://github.com/keras-team/keras/commit/8f2810bfeee98c6c01c6a76b481dafa24e142666,Remove useless declaration,1,Remove Dead Code,,
8b24b3343fc5ca595df600c9e8394d8c2691fb0e,2015-10-24T18:20:32Z,https://github.com/keras-team/keras/commit/8b24b3343fc5ca595df600c9e8394d8c2691fb0e,Removed the unused import,1,Remove Dead Code,,
e975f8a691f76a87e3f00dacfa8235cac7282660,2015-07-24T00:32:41Z,https://github.com/keras-team/keras/commit/e975f8a691f76a87e3f00dacfa8235cac7282660,Remove deprecated methods,1,Remove Dead Code,,
3037183c1b0d850659c68571ea8256108b8fd2eb,2015-07-22T01:32:00Z,https://github.com/keras-team/keras/commit/3037183c1b0d850659c68571ea8256108b8fd2eb,Remove dot_utils,1,Remove Dead Code,,
da20a4ccd2cf5d9033358b55589a2f75a83d1dea,2015-06-26T20:57:37Z,https://github.com/keras-team/keras/commit/da20a4ccd2cf5d9033358b55589a2f75a83d1dea,remove a remaining instance of old naming,1,Remove Dead Code,,
31a303c38f42649972755fdacf6f27de62e79000,2015-06-25T18:10:25Z,https://github.com/keras-team/keras/commit/31a303c38f42649972755fdacf6f27de62e79000,Remove unused import,1,Remove Dead Code,,
3f3a1f0e9bc55630acac3efdafb3c1c9fa719dec,2015-06-22T19:49:53Z,https://github.com/keras-team/keras/commit/3f3a1f0e9bc55630acac3efdafb3c1c9fa719dec,Remove redundant masking in _step,1,Remove Dead Code,,
368ad61236efc708bcaee8d653f14a7e14a956a3,2015-06-14T21:09:06Z,https://github.com/keras-team/keras/commit/368ad61236efc708bcaee8d653f14a7e14a956a3,removed unnecessary check in fit/train,1,Remove Dead Code,,
2ae36f2bf556a35085e672a84d75286d17e1b0bf,2015-06-12T13:48:37Z,https://github.com/keras-team/keras/commit/2ae36f2bf556a35085e672a84d75286d17e1b0bf,Remove duplicate link to Initializations in docs,1,Remove Dead Code,,
4f9958452c84967eae7d0f2c833bb1b396f3ba48,2015-05-31T03:02:21Z,https://github.com/keras-team/keras/commit/4f9958452c84967eae7d0f2c833bb1b396f3ba48,Remove History callback (redundant),1,Remove Dead Code,,
1aaab7a228fdd6f3ef53e888e08bc2afd6b4213b,2015-05-25T19:09:45Z,https://github.com/keras-team/keras/commit/1aaab7a228fdd6f3ef53e888e08bc2afd6b4213b,remove duplicate calls to get_output,1,Remove Dead Code,,
926883ad108fe23867c29efc8e18687087113b0d,2015-05-25T08:51:47Z,https://github.com/keras-team/keras/commit/926883ad108fe23867c29efc8e18687087113b0d,remove duplicate calls to get_output,1,Remove Dead Code,,
4bb90a5bfd762269adeee772e233a733a6d318a9,2015-04-19T03:55:08Z,https://github.com/keras-team/keras/commit/4bb90a5bfd762269adeee772e233a733a6d318a9,Remove useless code,1,Remove Dead Code,,
0c1af0901d2f7386a1ddb25c61e84794d4ca641e,2016-03-12T01:29:17Z,https://github.com/keras-team/keras/commit/0c1af0901d2f7386a1ddb25c61e84794d4ca641e,"Remove class_mode, add support for acc in Graph",1,Remove Dead Code,,
009293ec5ca4e19d47db50005c946d4839bc2958,2020-02-21T04:09:14Z,https://github.com/pytorch/pytorch/commit/009293ec5ca4e19d47db50005c946d4839bc2958,"[pytorch][size] remove unused SparseCPUType from mobile build (#33517)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/33517I don't think any mobile model uses SparseCPU backend yet so we can skipgenerating dispatch code for this backend type.This will help reduce mobile code size with dynamic dispatch turned on,roughly ~100K for uncompressed iOS: D19616007 +413K v.s. D19616016 +319K.It probably doesn't affect much static dispatch build size as the unusedstatic dispatch methods will be stripped by linker in the end.ghstack-source-id: 98615810Test Plan: - CI & BuildSizeBotReviewed By: linbinyuDifferential Revision: D19978633fbshipit-source-id: 27bf6ada2ba98482084cf23724cf400b538b0a03",1,Remove Dead Code,,
0141a242fd54981c313c37744abd00ad0394dec4,2023-05-09T16:12:11Z,https://github.com/pytorch/pytorch/commit/0141a242fd54981c313c37744abd00ad0394dec4,"bsr_dense_bmm(): remove sparse_rowspace kernel and some dead code (#100876)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/100876 Approved by: https://github.com/cpuhrsch, https://github.com/Skylion007",1,Remove Dead Code,,
019914095e23add19ed219ed0fc7d961565c7730,2023-04-06T14:46:40Z,https://github.com/pytorch/pytorch/commit/019914095e23add19ed219ed0fc7d961565c7730,[Easy] remove unnecessary get_rank() in tests (#98445)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/98445 Approved by: https://github.com/wanchaol,1,Remove Dead Code,,
02c48cced963984e3403c6aaba7b106ff4ab85ef,2019-03-12T14:54:17Z,https://github.com/pytorch/pytorch/commit/02c48cced963984e3403c6aaba7b106ff4ab85ef,Remove (almost all) TensorOptions from native_functions.yaml (#17385)Summary:Stacked on top of https://github.com/pytorch/pytorch/pull/17386Brings us to 1014/1106 of writing.Pull Request resolved: https://github.com/pytorch/pytorch/pull/17385Differential Revision: D14248008Pulled By: cpuhrschfbshipit-source-id: 033e00de91e3edf7ae01ca03ebe436c0446b3b5c,1,Remove Dead Code,,
056a8e0d5cc6b53dd574b77eebf273ded646f81e,2021-06-26T00:47:10Z,https://github.com/pytorch/pytorch/commit/056a8e0d5cc6b53dd574b77eebf273ded646f81e,"Remove un-used parameter in _trilinear backward (#60673)  Summary: This argument is only important for speed and memory usage. So it is ok to ignore it during the backward. As discussed, we might want to change this to speed up backward in the future.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/60673  Reviewed By: soulitzer  Differential Revision: D29370125  Pulled By: albanD  fbshipit-source-id: ad50b3ea530aeb194f5a51845523b517a50f2c71",1,Remove Dead Code,,
078b6d5ad1414bb35f608d3bf07534e5e5e1d373,2018-03-26T18:07:10Z,https://github.com/pytorch/pytorch/commit/078b6d5ad1414bb35f608d3bf07534e5e5e1d373,"[layer model] remove duplicated init opsit saves some model init time, and reduce confusion.",1,Remove Dead Code,,
08bc3c6cbf6e6848b58ea1db83627d8a7f99f216,2020-03-15T16:54:02Z,https://github.com/pytorch/pytorch/commit/08bc3c6cbf6e6848b58ea1db83627d8a7f99f216,"Remove unnecessary import (#34778)Summary:https://github.com/pytorch/pytorch/issues/34563 accidentally introduced a lint error due to an unused import. This PR removes this import.Jit tests run as expected after this change:```> python test/test_jit.py.....Ran 2435 tests in 100.077sOK (skipped=140, expected failures=1)```Pull Request resolved: https://github.com/pytorch/pytorch/pull/34778Differential Revision: D20459708Pulled By: tugrulincefbshipit-source-id: bb742085fafc849ff3d9507d1557556e01fbeb4b",1,Remove Dead Code,,
0a1aaff0dea5953928cefc506b4f4d39e0cb8a4d,2021-09-07T04:26:08Z,https://github.com/pytorch/pytorch/commit/0a1aaff0dea5953928cefc506b4f4d39e0cb8a4d,Remove dead code from THC (THCApply.cuh) (#64559)  Summary: cc peterbell10  Pull Request resolved: https://github.com/pytorch/pytorch/pull/64559  Reviewed By: mruberry  Differential Revision: D30769526  Pulled By: ngimel  fbshipit-source-id: 034a5c778a2b902cffa57b76511fa0dcdea26825,1,Remove Dead Code,,
0bc7fef406447cbafe00b0337527ae37e315a064,2021-08-23T19:55:09Z,https://github.com/pytorch/pytorch/commit/0bc7fef406447cbafe00b0337527ae37e315a064,[Static Runtime] Remove unused fusion patterns (#63636)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/63636  Reviewed By: d1jang  Differential Revision: D30446573  fbshipit-source-id: 3abb7f697380f3b4e865b98c594de359b5e26b96,1,Remove Dead Code,,
0cd1ab82b0fcda0f791958a4069886bd3a0e14fd,2019-01-22T01:24:32Z,https://github.com/pytorch/pytorch/commit/0cd1ab82b0fcda0f791958a4069886bd3a0e14fd,"Remove dead code from setup.py, remove need for build target. (#16162)Summary:Now it is only necessary to use 'develop' or 'install' to build. Incremental cmake is on by default. `develop --cmake` forces it to rerun.The NinjaBuilder stuff is dead. It was used to make building _C.sofaster but now _C.so is just an empty stub file.Removed a bunch of custom build commands from setup.py that areno longer meaningful now that cmake handles most of the build.Removed unused targets in build_pytorch_lib.sh/batPull Request resolved: https://github.com/pytorch/pytorch/pull/16162Differential Revision: D13744155Pulled By: zdevitofbshipit-source-id: d836484782c65b7f8e8c7a82620886f7a7777892",1,Remove Dead Code,,
0d610b4821be73ba8a337440d244e37f9acb8600,2020-01-22T15:23:03Z,https://github.com/pytorch/pytorch/commit/0d610b4821be73ba8a337440d244e37f9acb8600,"Remove the support of build options like NO_*, WITH_* (#32447)Summary:We will now use USE_*, BUILD_* consistently. The backward compatibilityfor NO_* and WITH_* is hereby removed in this commit, as promised in thecomment (next release is beyond Feb 20):    # Before we run the setup_helpers, let's look for NO_* and WITH_* variables and hotpatch environment with the USE_*    # equivalent The use of NO_* and WITH_* is deprecated and will be removed in Feb 20, 2020.Pull Request resolved: https://github.com/pytorch/pytorch/pull/32447Differential Revision: D19515536Pulled By: ezyangfbshipit-source-id: 2f2c51e6d4674af690b190a1f0397b8f596b6a15",1,Remove Dead Code,,
0e7ab61a836ef979bd7c340c910c239ba125d47c,2016-09-04T02:11:31Z,https://github.com/pytorch/pytorch/commit/0e7ab61a836ef979bd7c340c910c239ba125d47c,Remove unnecessary files,1,Remove Dead Code,,
0e935008419585ae347906ed3be213302ae67f53,2018-11-16T00:09:05Z,https://github.com/pytorch/pytorch/commit/0e935008419585ae347906ed3be213302ae67f53,Remove async_polling (#13825)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/13825async_polling was an intermediate step towards async_scheduling and is not usedReviewed By: yinghaiDifferential Revision: D13019059fbshipit-source-id: eee6ba53e7f476ddb481afba3bf1768303864d32,1,Remove Dead Code,,
0f5c8edfd3d6b32d9f44a5fc609d98d901f5f336,2018-08-23T20:05:59Z,https://github.com/pytorch/pytorch/commit/0f5c8edfd3d6b32d9f44a5fc609d98d901f5f336,"Removes unused THCState code paths (#9735)Summary:To prepare THCState for refactoring into ATen, this PR removes unused THCState code paths. In particular, it:- Removes the UVA Allocator- Removes the THDefaultDeviceAllocator- Respects the 1 BLAS and 1 sparse handle per device reality- Removes kernel p2p access- Removes setting p2p access- Removes the GCHandler code path- Removes many unused THCState_... functions- Removes THCThreadLocal.h/.cppIt does not change the preexisting external behavior of any remaining function.Pull Request resolved: https://github.com/pytorch/pytorch/pull/9735Differential Revision: D9438558Pulled By: SsnLfbshipit-source-id: dde9acbec237a18bb6b75683e0526f7ff1c9a6ea",1,Remove Dead Code,,
0f64043b49ceea37f99b0e4ecbe5e0f8603e9e5d,2019-08-15T00:18:34Z,https://github.com/pytorch/pytorch/commit/0f64043b49ceea37f99b0e4ecbe5e0f8603e9e5d,"Remove the activation observer for default_qconfig (#24299)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/24299As suggested in https://github.com/pytorch/pytorch/pull/24232, we will remove the activation observer for dynamic quantization path.ghstack-source-id: 88287094Differential Revision: D16798590fbshipit-source-id: 07a245d5584b5b15c6895d9b09deef4a0605073a",1,Remove Dead Code,,
12b5bdc60194b4991d699a42a9ee5e56efa6e2f6,2020-07-07T07:31:19Z,https://github.com/pytorch/pytorch/commit/12b5bdc60194b4991d699a42a9ee5e56efa6e2f6,Remove unused Logger in get_matching_activations (#41023)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/41023Remove Logger in get_matching_activations since it's not used.ghstack-source-id: 107237046Test Plan:buck test mode/dev caffe2/test:quantization -- 'test_compare_weights_lstm_dynamic'buck test mode/dev caffe2/test:quantization -- 'test_compare_model_stub_lstm_dynamic'buck test mode/dev caffe2/test:quantization -- 'test_compare_model_outputs_lstm_dynamic'buck test mode/dev caffe2/test:quantization -- 'test_compare_weights_conv_static'buck test mode/dev caffe2/test:quantization -- 'test_compare_weights_linear_static'buck test mode/dev caffe2/test:quantization -- 'test_compare_weights_linear_dynamic'buck test mode/dev caffe2/test:quantization -- 'test_compare_model_stub_conv_static'buck test mode/dev caffe2/test:quantization -- 'test_compare_model_stub_linear_static'buck test mode/dev caffe2/test:quantization -- 'test_compare_model_stub_submodule_static'buck test mode/dev caffe2/test:quantization -- 'test_compare_model_stub_functional_static'buck test mode/dev caffe2/test:quantization -- 'test_compare_model_stub_linear_dynamic'buck test mode/dev caffe2/test:quantization -- 'test_compare_model_outputs_conv_static'buck test mode/dev caffe2/test:quantization -- 'test_compare_model_outputs_linear_static'buck test mode/dev caffe2/test:quantization -- 'test_compare_model_outputs_functional_static'buck test mode/dev caffe2/test:quantization -- 'test_compare_model_outputs_linear_dynamic'Differential Revision: D22394957fbshipit-source-id: 7d59e0f35e9f4c304b8487460d48236ee6e5a872,1,Remove Dead Code,,
183e158642c08623d2d17cabf3644b365e5e25a7,2017-02-22T01:09:59Z,https://github.com/pytorch/pytorch/commit/183e158642c08623d2d17cabf3644b365e5e25a7,"Remove Model API (unused)Summary: Removed Model API because no one {seems to,should} be using itReviewed By: YangqingDifferential Revision: D4575126fbshipit-source-id: 174d39e9aa46750f1fae8295f7e1e5452559af33",1,Remove Dead Code,,
1ac4692489a13eee602fffb091f39e446c25c294,2020-07-16T18:17:31Z,https://github.com/pytorch/pytorch/commit/1ac4692489a13eee602fffb091f39e446c25c294,Remove unnecessary test in rpc_test.py (#41218)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/41218This test doesn't assert anything and was accidentally committed aspart of a larger diff a few months ago.ghstack-source-id: 107882848Test Plan: CIReviewed By: ezyangDifferential Revision: D22469852fbshipit-source-id: 0baa23da56b08200e16cf66df514566223dd9b15,1,Remove Dead Code,,
1d948787b788252ebc10a1e246436b7fa57507fe,2022-12-17T02:20:36Z,https://github.com/pytorch/pytorch/commit/1d948787b788252ebc10a1e246436b7fa57507fe,Remove duplicate line (#91006)  Two [nearly](https://github.com/pytorch/pytorch/pull/90927) [identical](https://github.com/pytorch/pytorch/pull/90948) PRs both got merged without a reported merge conflicts? First time for everything Pull Request resolved: https://github.com/pytorch/pytorch/pull/91006 Approved by: https://github.com/kit1980,1,Remove Dead Code,,
1f87f15ba3cd46fe5474f7783ff80ef06950e157,2020-05-14T21:59:12Z,https://github.com/pytorch/pytorch/commit/1f87f15ba3cd46fe5474f7783ff80ef06950e157,Remove _reset_warning_registry (#38485)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/38485Python 2 has reached end-of-life and is no longer supported by PyTorch.This class does nothing in Python 3.Test Plan: CIReviewed By: ailzhangDifferential Revision: D21575260Pulled By: dreissfbshipit-source-id: 184696c9fa501e8d2517950b47cdbc90b2ae8053,1,Remove Dead Code,,
208b36f1090b15caf85467771238877298ee8952,2021-05-20T00:08:03Z,https://github.com/pytorch/pytorch/commit/208b36f1090b15caf85467771238877298ee8952,remove redundant getDispatchKeySetUnboxed(eligibleKeys) (#58535)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/58535  Test Plan: Imported from OSS  Reviewed By: bdhirsh  Differential Revision: D28531377  Pulled By: bhosmer  fbshipit-source-id: ade1427c8c9ada10ecdc69ef80c5d90be23f5787,1,Remove Dead Code,,
216f88d084f290020785d2719c20c0d3acc510aa,2023-02-13T16:33:40Z,https://github.com/pytorch/pytorch/commit/216f88d084f290020785d2719c20c0d3acc510aa,"ao migration: remove package test as this behavior is tested by other things (#94422)  Summary:  We have tests testing package level migration correctness for torch AO migration. After reading the code, I noticed that these tests are not testing anything additional on top of the function level tests we already have.  An upcoming user warning PR will break this test, and it doesn't seem worth fixing. As long as the function level tests pass, 100% of user functionality will be tested.  Removing this in a separate PR to keep PRs small.  Test plan:  ``` python test/test_quantization.py -k AOMigration ``` Pull Request resolved: https://github.com/pytorch/pytorch/pull/94422 Approved by: https://github.com/jcaip",1,Remove Dead Code,,
2180a0dc0c8cce28c11dea177f26802c84421724,2023-02-09T06:32:40Z,https://github.com/pytorch/pytorch/commit/2180a0dc0c8cce28c11dea177f26802c84421724,[FSDP][optim_state_dict] Remove the dead code (#94448)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/94448 Approved by: https://github.com/awgu,1,Remove Dead Code,,
21c420c32c0e60cb1136a076894008190fe43ea5,2018-07-05T22:14:49Z,https://github.com/pytorch/pytorch/commit/21c420c32c0e60cb1136a076894008190fe43ea5,Remove unused RowwiseArgMaxOp (#9119)Summary:Closes https://github.com/pytorch/pytorch/pull/9119Remove unused RowwiseArgMaxOpReviewed By: houseroadDifferential Revision: D8719826fbshipit-source-id: 57d78c8b93bc94a4634d806c7c2041f8c18678a5,1,Remove Dead Code,,
23fde77d3d14c1e3582ac1f8c1456b4f59a242d1,2019-08-29T22:42:31Z,https://github.com/pytorch/pytorch/commit/23fde77d3d14c1e3582ac1f8c1456b4f59a242d1,Remove Module._backend as it's not used anymore.Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/25342Test Plan: Imported from OSSDifferential Revision: D17101571Pulled By: gchananfbshipit-source-id: 2cda46fe197e26a1cacb5e912f535809973d306e,1,Remove Dead Code,,
2457d0ef4ff0aacc1fe598e6f3c9a6e9de99624f,2023-02-01T07:26:19Z,https://github.com/pytorch/pytorch/commit/2457d0ef4ff0aacc1fe598e6f3c9a6e9de99624f,[Dynamo][Easy] Remove duplicated code in builder.py (#93809)  Fixes #ISSUE_NUMBER  Pull Request resolved: https://github.com/pytorch/pytorch/pull/93809 Approved by: https://github.com/williamwen42,1,Remove Dead Code,,
252b6f2cbaa4321047a0bb6bf9d246aa60d27d5b,2021-10-06T21:20:31Z,https://github.com/pytorch/pytorch/commit/252b6f2cbaa4321047a0bb6bf9d246aa60d27d5b,[PyTorch][easy] Remove dead std::set in parseAliasAnnotation (#65712)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/65712  No reason for this to be here. ghstack-source-id: 139743362  Test Plan: fitsships  Reviewed By: dhruvbird  Differential Revision: D31215696  fbshipit-source-id: 238ea6633629831e54847ce82de23571cf476740,1,Remove Dead Code,,
27c7158166089db7329b9f0dea65da36e3785cda,2020-09-24T00:55:24Z,https://github.com/pytorch/pytorch/commit/27c7158166089db7329b9f0dea65da36e3785cda,"Remove __future__ imports for legacy Python2 supports (#45033)Summary:There is a module called `2to3` which you can target for future specifically to remove these, the directory of `caffe2` has the most redundant imports:```2to3 -f future -w caffe2```Pull Request resolved: https://github.com/pytorch/pytorch/pull/45033Reviewed By: seemethereDifferential Revision: D23808648Pulled By: bugrafbshipit-source-id: 38971900f0fe43ab44a9168e57f2307580d36a38",1,Remove Dead Code,,
291869d62508c8fd23e429e1d16bac5d66607cc4,2020-05-12T18:59:57Z,https://github.com/pytorch/pytorch/commit/291869d62508c8fd23e429e1d16bac5d66607cc4,"Remove unnecessary RPC profiling code after future merge (#38255)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/38255Now that the futures are consolidated afterhttps://github.com/pytorch/pytorch/pull/35154, there is no`torch.distributed.rpc.Future` and we do not need a special path. All futurescan now be profiled through the use of the jit operator defined inrecord_function_ops.cppAs a result, we also get rid of the record_function_ops.h file.RPC profiling tests are currently disabled, although I re-enabled them locallyto ensure that they still work with this change.ghstack-source-id: 103869855Test Plan: CIDifferential Revision: D21506091fbshipit-source-id: ad68341c9f2eab2dadc72fe6a6c59b05693434f2",1,Remove Dead Code,,
2a6850bf73b4beda1c8e6b4db6c0f29c4b02c037,2018-11-04T07:59:18Z,https://github.com/pytorch/pytorch/commit/2a6850bf73b4beda1c8e6b4db6c0f29c4b02c037,remove unnecessary files (#13537)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/13537plot_hist.py and dnnlowp_fc_perf_comparison.py were not supposed to be in operators/quantized/serverReviewed By: hx89Differential Revision: D12916259fbshipit-source-id: f5bc0c01a4924cad6f82eff624ba5f79becbea33,1,Remove Dead Code,,
2a698682e45fb67ea8b0fe0fc4c3909dbd5dbb35,2019-06-30T11:07:46Z,https://github.com/pytorch/pytorch/commit/2a698682e45fb67ea8b0fe0fc4c3909dbd5dbb35,Remove Type dispatch (#21964)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/21964ghimport-source-id: fdfb555ac4efbf31ae7d2c700a5aa44ad0cc4d7fTest Plan: Imported from OSSDifferential Revision: D15897424Pulled By: li-royfbshipit-source-id: 3cd6744254e34d70e6875ffde749b5cf959b663c,1,Remove Dead Code,,
31ae8117baec653f6d7688d33dbabc31be5378e1,2020-09-25T05:00:37Z,https://github.com/pytorch/pytorch/commit/31ae8117baec653f6d7688d33dbabc31be5378e1,"[RFC] Remove per-op-registration related code in caffe2/tools/codegen/gen.py (#45134)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/45134Per-Op-Registration was a mechanism used for mobile selective build v0. Since then, a new dispathing mechanism has been built for PyTorch, and this code path isn't used any more. Remove it to simplify understanding/updating the code-generator's code-flow.ghstack-source-id: 112723942Test Plan: `buck build` and sandcastle.Reviewed By: ezyangDifferential Revision: D23806632fbshipit-source-id: d93cd324650c541d9bfc8eeff2ddb2833b988ecc",1,Remove Dead Code,,
320ff3ad6405bada6f3541ba7ba772d153f93f82,2017-11-02T22:40:02Z,https://github.com/pytorch/pytorch/commit/320ff3ad6405bada6f3541ba7ba772d153f93f82,remove subtree of ATen since ATen is now inside pytorch,1,Remove Dead Code,,
340048b67c53f05a04def9e5a69403c7b49915c8,2020-03-30T06:45:48Z,https://github.com/pytorch/pytorch/commit/340048b67c53f05a04def9e5a69403c7b49915c8,[quant][graphmode] Remove unused patterns (#35385)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/35385Test Plan:python test/test_jit.pyImported from OSSDifferential Revision: D20655298fbshipit-source-id: bc5eda2640a809adb55d3d645c65fb02a6f2f444,1,Remove Dead Code,,
3578909671567a2640a97156b6d1adb337c202f1,2018-08-17T02:58:10Z,https://github.com/pytorch/pytorch/commit/3578909671567a2640a97156b6d1adb337c202f1,Remove unused code base for distributed training (#10282)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/10282This diff removes the unused/deprecated features from the code base.Reviewed By: manojkrisDifferential Revision: D9169859fbshipit-source-id: d6447b7916a7c687b44b20da868112e6720ba245,1,Remove Dead Code,,
364d92f9b6864ce284fa13519c7ca5c87460e477,2023-03-22T17:06:21Z,https://github.com/pytorch/pytorch/commit/364d92f9b6864ce284fa13519c7ca5c87460e477,"remove dead torch_pb.h library (#97323)  remove dead torch_pb.h library  Summary: This is only used in one place, ensure it still builds.  Test Plan: Rely on CI.  Reviewers: sahanp  Subscribers:  Tasks:  Tags:  --- Stack created with [Sapling](https://sapling-scm.com). Best reviewed with [ReviewStack](https://reviewstack.dev/pytorch/pytorch/pull/97323). * #97337 * #97336 * #97335 * #97334 * #97325 * #97324 * __->__ #97323 * #97322 Pull Request resolved: https://github.com/pytorch/pytorch/pull/97323 Approved by: https://github.com/malfet",1,Remove Dead Code,,
3894ed22a87258609ef22211b3cc9a9d6617af9b,2018-10-23T01:08:11Z,https://github.com/pytorch/pytorch/commit/3894ed22a87258609ef22211b3cc9a9d6617af9b,"Remove nullopt from native_parse.py (#12961)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/12961According to zdevito - this is not used at all, so we are removing it for safety.It is also possible that this native_parser.py will completely go away in thenear future.Reviewed By: zdevitoDifferential Revision: D10501616fbshipit-source-id: 3218708e6150d3c94d730fbd25ae1f7abb5718b5",1,Remove Dead Code,,
390c0ac403e05508e228aa3735b36ee5a9b01ebd,2021-08-11T01:41:13Z,https://github.com/pytorch/pytorch/commit/390c0ac403e05508e228aa3735b36ee5a9b01ebd,remove dead code (#63031)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/63031  Reviewed By: mruberry  Differential Revision: D30225094  Pulled By: ngimel  fbshipit-source-id: 3666a0fa120bea85225cd3ee04f89d64952d2862,1,Remove Dead Code,,
3a02ed822b13bf914f8f84fda241edb950c9312f,2019-12-12T15:40:59Z,https://github.com/pytorch/pytorch/commit/3a02ed822b13bf914f8f84fda241edb950c9312f,"Remove `insert_prepack_unpack` and `fold_prepack` for now (#30909)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/30909`fold_prepack` doesn't work anymore after we change `scale`, `zero_point`to be attributes, but since the freeze API is coming up, I don't want tospend time to make this work since this will be thrown away later.Test Plan:.Imported from OSSDifferential Revision: D18864537fbshipit-source-id: 649e6b91f2b04b8babacc0afb6bc1530ed7259d3",1,Remove Dead Code,,
3b6362d98e1f99e497b82fe005fec0ef11201e86,2019-06-06T20:32:40Z,https://github.com/pytorch/pytorch/commit/3b6362d98e1f99e497b82fe005fec0ef11201e86,Remove NodeExecStats and AllocatorMemoryUsed (#21419)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/21419Removed ```node_stats``` and unused importsReviewed By: orionrDifferential Revision: D15672824fbshipit-source-id: 6167c80c081d925f02a1d279f3af0e1b8de66752,1,Remove Dead Code,,
3c2cd8cc109c440c03a83c1a27a205dbab2bca91,2019-10-04T21:41:34Z,https://github.com/pytorch/pytorch/commit/3c2cd8cc109c440c03a83c1a27a205dbab2bca91,Some hipify script cleanups (#27375)Summary:continue https://github.com/pytorch/pytorch/issues/26363Pull Request resolved: https://github.com/pytorch/pytorch/pull/27375Differential Revision: D17764992Pulled By: bddppqfbshipit-source-id: ecc06521179677efcedb1d58ceda63df7d63627e,1,Remove Dead Code,,
3c9775fff89b5362a4d53f9f668707ed5f6d84ed,2018-08-24T17:39:14Z,https://github.com/pytorch/pytorch/commit/3c9775fff89b5362a4d53f9f668707ed5f6d84ed,"Remove nanopb since we've switched to protobuf (#10772)Summary:We no longer use nanopb in PyTorch (or Caffe2) so removing. All protobuf manipulation should go through standard protobuf, which is statically linked inside libcaffe2.so by default.cc zdevito pjh5 ezyang YangqingPull Request resolved: https://github.com/pytorch/pytorch/pull/10772Reviewed By: pjh5Differential Revision: D9465894Pulled By: orionrfbshipit-source-id: 8cdf9f1d3953b7a48478d381814d7107df447201",1,Remove Dead Code,,
3d2ce6053911b5885392a84bba963874133eae37,2021-05-07T21:00:59Z,https://github.com/pytorch/pytorch/commit/3d2ce6053911b5885392a84bba963874133eae37,[PyTorch] Remove dead get/setTLSCallbacks APIs (#56492)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/56492  These are documented as internal-only and aren't called. ghstack-source-id: 128354112  Test Plan: CI  Reviewed By: ilia-cher  Differential Revision: D27834789  fbshipit-source-id: 4a1aa320f952249db51945ff77563558fa884266,1,Remove Dead Code,,
3d39bd597654c5bcdaa57cb0843710a1ea45cd16,2023-04-26T21:23:21Z,https://github.com/pytorch/pytorch/commit/3d39bd597654c5bcdaa57cb0843710a1ea45cd16,"[dynamo] Remove redundant recompile call (#100084)  A single call to the `GraphModule.recompile` function occurs after the `GraphModule` has been constructed. https://github.com/pytorch/pytorch/blob/62f9189d9d6ad1578c1bfddd17d45dc132e4b9b6/torch/_dynamo/output_graph.py#L754-L755  However, the recompile function has already been called once during construction, so this call should be redundant. ``` call stack:   recompile, graph_module.py:644   graph, graph_module.py:411   __setattr__, module.py:1674   __init__, graph_module.py:370   compile_and_call_fx_graph, output_graph.py:754   ... ```  So maybe it can be deleted.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/100084 Approved by: https://github.com/ezyang",1,Remove Dead Code,,
3e00f79a1e041c72ab188b84efd46406640b6d3f,2019-03-12T19:01:49Z,https://github.com/pytorch/pytorch/commit/3e00f79a1e041c72ab188b84efd46406640b6d3f,remove warning for upsample code (#17921)Summary:IIRC we decided to remove warning in code in #11568. This got reverted accidentally in #14123.Pull Request resolved: https://github.com/pytorch/pytorch/pull/17921Differential Revision: D14422811Pulled By: ailzhangfbshipit-source-id: 7067264bd1d3e3b7861d29e18ade2969ed705ca1,1,Remove Dead Code,,
3f04ca9a915b3991aef6e324911c1fe6ed1d6c26,2018-10-06T00:10:48Z,https://github.com/pytorch/pytorch/commit/3f04ca9a915b3991aef6e324911c1fe6ed1d6c26,"Remove duplicate math transpilation function (ROCm 233) (#12387)Summary:* Remove duplicate math transpilation function* Modify regex to expand matches to more __device__ functions* Try a different tack. Apply math transpilations only to .cu and .cuh files* Undo change that's not required anymore since we're not using regex to detect device functionsThis should address ""overtranspilation"" as observed in another PR.bddppq ezyangPull Request resolved: https://github.com/pytorch/pytorch/pull/12387Differential Revision: D10226798Pulled By: bddppqfbshipit-source-id: fa4aac8cd38d8f7ef641fad5129ed4714c0fada5",1,Remove Dead Code,,
422c65ca35a5ba1d00e5384876e0dd53d438b397,2017-03-23T21:50:28Z,https://github.com/pytorch/pytorch/commit/422c65ca35a5ba1d00e5384876e0dd53d438b397,"Removing unnecessary Copy after fixing gradients for external parametersSummary: Apart from copying gradient blobs for inputs with initial_cell_input, we needed to perform a similar operation for external parameters used by the step netReviewed By: salexspbDifferential Revision: D4752259fbshipit-source-id: 13ee48cf583ed86221a4cc1cc9f57f5c3a7d2450",1,Remove Dead Code,,
42acae5406a024a7eca67bb119bab09222fd2fe6,2019-03-13T20:28:08Z,https://github.com/pytorch/pytorch/commit/42acae5406a024a7eca67bb119bab09222fd2fe6,Remove unused BoolOption.Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/17979Reviewed By: zou3519Differential Revision: D14438876Pulled By: gchananfbshipit-source-id: a6aeab0261ce6926ed82a81edee4564a8dd341ed,1,Remove Dead Code,,
435228508eb2ad47963b4c53d87ae43a66d7056b,2018-10-26T16:13:00Z,https://github.com/pytorch/pytorch/commit/435228508eb2ad47963b4c53d87ae43a66d7056b,Remove test_distributed_trap.py (#13151)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/13151No longer needed.Reviewed By: ezyangDifferential Revision: D10862319fbshipit-source-id: 01405d7cf2553f59ff7d3dce33755a5fdd8a8f05,1,Remove Dead Code,,
43928effeeb368063948e2ce227792ae77cfbfa4,2020-03-28T01:35:56Z,https://github.com/pytorch/pytorch/commit/43928effeeb368063948e2ce227792ae77cfbfa4,[jit] Remove _assert_int_or_pair op (#34509)Summary:This one doesn't actually do anything so we don't need an op for it.It is used inside `torch.nn.functional.unfold` which is already testedPull Request resolved: https://github.com/pytorch/pytorch/pull/34509Pulled By: driazatiDifferential Revision: D20676445fbshipit-source-id: b72d1308bdec593367ec4e14bf9a901d0b62e1cc,1,Remove Dead Code,,
4447dfa6730da2434b2b7f4cdc608acce0feefcf,2023-05-09T00:34:24Z,https://github.com/pytorch/pytorch/commit/4447dfa6730da2434b2b7f4cdc608acce0feefcf,"Remove MacOS workflow step to disable XProtect (#100692)  I added this few weeks back trying to fix the flaky dependencies missing on MacOS in https://github.com/pytorch/pytorch/pull/99506.  But I think this step is not really needed.  More importantly, it starts to hang on MacOS 13, for example https://github.com/pytorch/pytorch/actions/runs/4889081518/jobs/8727397905.  The reason is unclear, but this should be removed nonetheless.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/100692 Approved by: https://github.com/ZainRizvi",1,Remove Dead Code,,
45943bd61183a1e3c67d1b1e765e5cf02c9ad6c0,2019-08-28T14:38:55Z,https://github.com/pytorch/pytorch/commit/45943bd61183a1e3c67d1b1e765e5cf02c9ad6c0,Remove some unused plugins.Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/25201Test Plan: Imported from OSSDifferential Revision: D17060444Pulled By: gchananfbshipit-source-id: 94722533fecc6d4eb11940eaf4f71aeea41502fb,1,Remove Dead Code,,
46a81c8db786ac03abc16bbecc8401dcbf451f10,2023-01-17T16:54:35Z,https://github.com/pytorch/pytorch/commit/46a81c8db786ac03abc16bbecc8401dcbf451f10,"Deprecate .mT,.T,.mH,.H on 0D tensors (#92143)  As discussed with @ngimel, this is not only not documented, but also an unnecessary edge case. See https://github.com/pytorch/pytorch/pull/90463#discussion_r1064807197 Pull Request resolved: https://github.com/pytorch/pytorch/pull/92143 Approved by: https://github.com/ngimel",1,Remove Dead Code,,
47869b1b12403720ac9b26281ff9cf2723f4f781,2020-05-26T22:50:47Z,https://github.com/pytorch/pytorch/commit/47869b1b12403720ac9b26281ff9cf2723f4f781,Windows build updates (#39035)Summary:Small follow-up updates https://github.com/pytorch/pytorch/pull/38971- Remove extra whitespace- Delete unused script files- Modify `vs_install.ps1` to use correct workspace pathPull Request resolved: https://github.com/pytorch/pytorch/pull/39035Differential Revision: D21731129Pulled By: malfetfbshipit-source-id: e04253e82f8753423b4634d1928f2d0fcf20ebbb,1,Remove Dead Code,,
4805441b4a582b140a408f864403ab45680c8131,2023-03-18T06:01:37Z,https://github.com/pytorch/pytorch/commit/4805441b4a582b140a408f864403ab45680c8131,[dtensor] remove unused tests and fix ci (#97064)  fix ci Pull Request resolved: https://github.com/pytorch/pytorch/pull/97064 Approved by: https://github.com/huydhn,1,Remove Dead Code,,
4934dde3109f621b779143b8d45120cfe4d0326f,2023-04-04T17:07:58Z,https://github.com/pytorch/pytorch/commit/4934dde3109f621b779143b8d45120cfe4d0326f,"Cleanup redundant CI jobs (#98044)  This cleanup some redundant CI jobs that I found:  * @malfet @ZainRizvi  Do we need debug build in periodic for both 11.8 and 11.7?   This is rarely needed AFAIK.  I try to remove 11.8 here while keep 11.7 to be consistent with the rest of the CI.  Or may be it should be the other way around to keep 11.8 * Remove libtorch 11.7 and 11.8 builds in periodic as it has already been done in [trunk](https://github.com/pytorch/pytorch/blob/master/.github/workflows/trunk.yml#L86-L97) * Cleanup TSAN (I added this a while back, but there is no drive to go into that further, so let's just kill it) - If you want to keep it, please raise your hand.  <!-- copilot:summary --> ### <samp>🤖 Generated by Copilot at 4b3ec53</samp>  This pull request simplifies and consolidates the scripts and workflows for the thread sanitizer (TSAN) build and test configuration. It removes redundant and outdated logic, files, and workflows that were previously used to handle the TSAN build differently from the regular build. It enables all the tests for the TSAN build, which has been fixed by another pull request. Pull Request resolved: https://github.com/pytorch/pytorch/pull/98044 Approved by: https://github.com/malfet, https://github.com/ZainRizvi",1,Remove Dead Code,,
4c56ce09587cd078a441cbf23393d47dcc3b4f87,2017-12-20T03:40:28Z,https://github.com/pytorch/pytorch/commit/4c56ce09587cd078a441cbf23393d47dcc3b4f87,Remove unused thnn/loss.py (#4267),1,Remove Dead Code,,
4d2f6f1bbeeb15b57d62365a6b3aa5e36a4d1f9a,2019-03-12T18:25:37Z,https://github.com/pytorch/pytorch/commit/4d2f6f1bbeeb15b57d62365a6b3aa5e36a4d1f9a,Remove remaining test jit expects redux (#17924)Summary:Trying to reland https://github.com/pytorch/pytorch/pull/17886 since it broke a build and I reverted itPull Request resolved: https://github.com/pytorch/pytorch/pull/17924Differential Revision: D14423842Pulled By: eellisonfbshipit-source-id: f219e786bd07f7da3b7f9e866981199f5ccf6318,1,Remove Dead Code,,
4e71be449e9c15d13a26bee8aa6adc324b8c87f5,2019-10-17T16:03:38Z,https://github.com/pytorch/pytorch/commit/4e71be449e9c15d13a26bee8aa6adc324b8c87f5,Remove tools/setup_helpers/nvtoolext.py (do not seem to be used) (#28125)Summary:`git grep nvtoolext` shows nothing (meaning that it is never imported).Pull Request resolved: https://github.com/pytorch/pytorch/pull/28125Differential Revision: D17979164Pulled By: ezyangfbshipit-source-id: 7cfe770c9f7140c8ad58676f912037e6226647d3,1,Remove Dead Code,,
4ed9de8680864a6a77b0861d1a74ba4faaeaa041,2019-01-15T01:55:13Z,https://github.com/pytorch/pytorch/commit/4ed9de8680864a6a77b0861d1a74ba4faaeaa041,Remove code duplication (#15880)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/15880The layer_norm reference was implemented twice. Removing one of them.Reviewed By: dzhulgakovDifferential Revision: D13611232fbshipit-source-id: cee96c78d3255c3a4e34300693bf9260cf096615,1,Remove Dead Code,,
4ef9daf7b2cbbf8b1408ce7ac36a286756d8834c,2020-01-06T22:36:45Z,https://github.com/pytorch/pytorch/commit/4ef9daf7b2cbbf8b1408ce7ac36a286756d8834c,Remove dead CAFFE2_LIBS variable (#31155)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/31155Signed-off-by: Edward Z. Yang <ezyang@fb.com>Test Plan: Imported from OSSDifferential Revision: D19262584Pulled By: ezyangfbshipit-source-id: 147ac5a9c36e813ea9a2f68b498880942d661be5,1,Remove Dead Code,,
4f62e7cb10ef835afb49049b317c16e8746c109e,2023-04-21T23:11:37Z,https://github.com/pytorch/pytorch/commit/4f62e7cb10ef835afb49049b317c16e8746c109e,[FSDP][BE] Remove unused code (#99731)  Remove the unused code. https://github.com/pytorch/pytorch/pull/99675 is duplicated and we should land this PR.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/99731 Approved by: https://github.com/wz337,1,Remove Dead Code,,
50c29fef3ef88b4f6af17148310e1f35f44858d9,2021-09-18T00:31:15Z,https://github.com/pytorch/pytorch/commit/50c29fef3ef88b4f6af17148310e1f35f44858d9,remove utils.cpp (#65184)  Summary: Dead code  Pull Request resolved: https://github.com/pytorch/pytorch/pull/65184  Reviewed By: mruberry  Differential Revision: D31031777  Pulled By: ngimel  fbshipit-source-id: 13633888229a7af8cfd8ea7e55ea2880b2e47273,1,Remove Dead Code,,
51267095d5360f835baf517a2c7980a09d2304d3,2018-02-09T20:11:53Z,https://github.com/pytorch/pytorch/commit/51267095d5360f835baf517a2c7980a09d2304d3,Remove enqueue_splits() from ReaderBuilderSummary: The interface is not used anywhere AFAICT; cleaning up to make it less confusing.Reviewed By: kuttasDifferential Revision: D6867040fbshipit-source-id: 3e8a77df76ef09c6864c308561825777b326f76c,1,Remove Dead Code,,
5180caeeb49f8bdf1ec58e37a40e10691d0f4c92,2020-12-05T12:11:00Z,https://github.com/pytorch/pytorch/commit/5180caeeb49f8bdf1ec58e37a40e10691d0f4c92,"Remove deprecated spectral ops from torch namespace (#48594)Summary:Ref https://github.com/pytorch/pytorch/issues/42175This removes the 4 deprecated spectral functions: `torch.{fft,rfft,ifft,irfft}`. `torch.fft` is also now imported by by default.The actual `at::native` functions are still used in `torch.stft` so can't be full removed yet. But will once https://github.com/pytorch/pytorch/issues/47601 has been merged.Pull Request resolved: https://github.com/pytorch/pytorch/pull/48594Reviewed By: heitorschueroffDifferential Revision: D25298929Pulled By: mruberryfbshipit-source-id: e36737fe8192fcd16f7e6310f8b49de478e63bf0",1,Remove Dead Code,,
52434567286bd79c2407e92344aef9b04a25cfa1,2020-11-18T20:17:37Z,https://github.com/pytorch/pytorch/commit/52434567286bd79c2407e92344aef9b04a25cfa1,[pytorch][codegen] remove dead code in gen_variable_type.py (#47975)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/47975Test Plan: Imported from OSSReviewed By: ezyangDifferential Revision: D24976274Pulled By: ljk53fbshipit-source-id: 8542471ee30f26592aad949fc17eef87a47df024,1,Remove Dead Code,,
5316cad5c2b10d5c3ef36b0314842593848857d2,2018-05-23T05:32:47Z,https://github.com/pytorch/pytorch/commit/5316cad5c2b10d5c3ef36b0314842593848857d2,[Easy] Remove unused code (#7782),1,Remove Dead Code,,
5407108533525b78c3d23a3af905f3b5ab12137e,2021-07-15T16:48:03Z,https://github.com/pytorch/pytorch/commit/5407108533525b78c3d23a3af905f3b5ab12137e,CopyBackward: Remove redundant src_device and unnecessary copy=True (#60025)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/60025  `to` already copies unconditionally if `src.device() != options.device()` so specifying the copy argument is unnecessary.  `src.device()` is also completely equivalent to `src.options().device()` so storing both is redundant.  Test Plan: Imported from OSS  Reviewed By: zou3519  Differential Revision: D29698627  Pulled By: albanD  fbshipit-source-id: eb091d39b71db688e6bcbb33a227c01b94b432bb,1,Remove Dead Code,,
5952ca8d9f22e7a77ab8e24f01cdcbf8d382a9f7,2019-05-23T01:27:24Z,https://github.com/pytorch/pytorch/commit/5952ca8d9f22e7a77ab8e24f01cdcbf8d382a9f7,"Remove duplicated _optimize_trace and use core (#20394)Summary:The duplicated code of `_optimize_trace` in _pytorch_graph.py is used to bypass some optimization step which causes missing scope.It seems that most of the problematic steps have been fixed recently. Standard models implemented in torchvision are visually inspected before the commit. However, the `+=` in https://github.com/pytorch/vision/blob/50d54a82d1479ffb6dd7469ed05fccdf290a1d84/torchvision/models/resnet.py#L63 will let https://github.com/pytorch/pytorch/blob/f4d9bfaa4dd983288518a310bb900756ee3c6046/torch/onnx/utils.py#L159 produce a bad result. It can be fixed by replacing it with `out += identity`. This also implies that `+=` has non-intuitive behavior.cc orionr ezyangPull Request resolved: https://github.com/pytorch/pytorch/pull/20394Reviewed By: NarineKDifferential Revision: D15452204Pulled By: orionrfbshipit-source-id: eaa4c13f16551c78dc6419f1e22eb2c560af4cc5",1,Remove Dead Code,,
5b1a1a17ed27fe3a13608bcf0c699ff676ab697b,2019-11-08T21:32:58Z,https://github.com/pytorch/pytorch/commit/5b1a1a17ed27fe3a13608bcf0c699ff676ab697b,remove FunctionType as an allowed constant (#29405)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/29405We never actually used this (function attributes are a separate pathwayin ConcreteModuleType).Test Plan: Imported from OSSDifferential Revision: D18378392Pulled By: suofbshipit-source-id: b06c4b6d70f0b2534be78a215125cffd22ab44f0,1,Remove Dead Code,,
5bd29027965fd4c99290fe7510a66f989b0bcb64,2020-09-05T08:38:43Z,https://github.com/pytorch/pytorch/commit/5bd29027965fd4c99290fe7510a66f989b0bcb64,[JIT] Remove references to no longer generated _tanh_backward and _sigmoid_backward (#44138)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/44138If you look at the sigmoid and tanh backward they are composed of other ops: https://github.com/pytorch/pytorch/blob/master/torch/csrc/jit/runtime/symbolic_script.cpp#L786https://github.com/pytorch/pytorch/blob/master/torch/csrc/jit/runtime/symbolic_script.cpp#L164So tanh_backward and sigmoid_backward are no longer generated / legacy ops.Test Plan: Imported from OSSReviewed By: ZolotukhinMDifferential Revision: D23543603Pulled By: eellisonfbshipit-source-id: ce8353e53043cf969b536aac47c9576d66d4ce02,1,Remove Dead Code,,
5d33596c5f67a28e91fb106a71f51f764fccbf93,2023-03-27T21:19:29Z,https://github.com/pytorch/pytorch/commit/5d33596c5f67a28e91fb106a71f51f764fccbf93,"remove dead proto_convert library (#97598)  This has no code, only a collection of headers. Just make sure the only thing that includes it still builds.  Differential Revision: [D44395700](https://our.internmc.facebook.com/intern/diff/D44395700/)  **NOTE FOR REVIEWERS**: This PR has internal Meta-specific changes or comments, please review them on [Phabricator](https://our.internmc.facebook.com/intern/diff/D44395700/)! Pull Request resolved: https://github.com/pytorch/pytorch/pull/97598 Approved by: https://github.com/PaliC",1,Remove Dead Code,,
5ed7c701a3dfa0135c621a47361e03eceb02b37f,2023-02-14T00:08:09Z,https://github.com/pytorch/pytorch/commit/5ed7c701a3dfa0135c621a47361e03eceb02b37f,"[ONNX] Remove the deprecated monkey patches to torch.Graph (#94747)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/94747 Approved by: https://github.com/BowenBao, https://github.com/Skylion007",1,Remove Dead Code,,
5ffd7dbbb4ac10096f802939d359ead89b99927d,2019-03-08T17:39:03Z,https://github.com/pytorch/pytorch/commit/5ffd7dbbb4ac10096f802939d359ead89b99927d,Remove ProcessorSpecificPlugin. (#17789)Summary:It doesn't seem to be used.Pull Request resolved: https://github.com/pytorch/pytorch/pull/17789Reviewed By: ezyangDifferential Revision: D14382423Pulled By: gchananfbshipit-source-id: 0ac3236c48979a1b2bcd615e307e55f10fd8eb77,1,Remove Dead Code,,
603a32c96458af870fd1653cdf57453bc7d9905d,2023-03-23T03:34:12Z,https://github.com/pytorch/pytorch/commit/603a32c96458af870fd1653cdf57453bc7d9905d,"cleanup caffe2 cc_proto_library (#97325)  cleanup caffe2 cc_proto_library  Summary: This doesn't need to be public, nor does it need a long name. Since this is the most private library, we move it to the bottom of the file.  Test Plan: Should be a no-op, verify in CI.  Reviewers: sahanp  Subscribers:  Tasks:  Tags:  --- Stack created with [Sapling](https://sapling-scm.com). Best reviewed with [ReviewStack](https://reviewstack.dev/pytorch/pytorch/pull/97325). * #97337 * #97336 * #97335 * #97334 * __->__ #97325 Pull Request resolved: https://github.com/pytorch/pytorch/pull/97325 Approved by: https://github.com/malfet, https://github.com/PaliC",1,Remove Dead Code,,
604a27361f6f8e8df1e44bfed224f822b399d6e5,2019-12-03T22:40:31Z,https://github.com/pytorch/pytorch/commit/604a27361f6f8e8df1e44bfed224f822b399d6e5,remove tuple_parser (#30659)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/30659I could only find one usage of TupleParser and it doesn't seem worth maintaining just for that one usage.Test Plan: Imported from OSSDifferential Revision: D18795979Pulled By: nairbvfbshipit-source-id: 6e50d65fc8fade0944f36ab20d00f1539a3d4cb8,1,Remove Dead Code,,
61bb0d2954a7d89a4b05becf01f806858b02d741,2017-10-12T05:20:48Z,https://github.com/pytorch/pytorch/commit/61bb0d2954a7d89a4b05becf01f806858b02d741,Remove unused parameter 'input' from Tanh,1,Remove Dead Code,,
635aebdfab20d9ace8ecfaf347102f0a49fa3553,2020-10-14T20:12:44Z,https://github.com/pytorch/pytorch/commit/635aebdfab20d9ace8ecfaf347102f0a49fa3553,[quant] Refactoring the mappings files (#44847)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/44847Test Plan: Imported from OSSReviewed By: jerryzh168Differential Revision: D23747007Pulled By: z-a-ffbshipit-source-id: 7d8fcc84a77454cc1479e5158f5a62eda5824a87,1,Remove Dead Code,,
63d54874e7f60a2ff768131896cd44cb562f4993,2021-04-28T22:52:21Z,https://github.com/pytorch/pytorch/commit/63d54874e7f60a2ff768131896cd44cb562f4993,[torch/deploy] smol cleanups to generate_packagesSummary: Remove some unnecessary argsTest Plan: sandcastleReviewed By: wconstabDifferential Revision: D28052626fbshipit-source-id: f1b4d0555b4ab37dc9a245fbc1fa455f69a4db20,1,Remove Dead Code,,
63f2f9fb0d0b7560a18117987b89c286b8f6b994,2023-05-05T05:45:48Z,https://github.com/pytorch/pytorch/commit/63f2f9fb0d0b7560a18117987b89c286b8f6b994,[BE] Remove unused CircleCI checks (#100630)  Fixes #ISSUE_NUMBER  Pull Request resolved: https://github.com/pytorch/pytorch/pull/100630 Approved by: https://github.com/atalman,1,Remove Dead Code,,
65e762acc888277a6aee1e7c490299efaa347550,2022-12-13T21:05:04Z,https://github.com/pytorch/pytorch/commit/65e762acc888277a6aee1e7c490299efaa347550,"[FSDP][optim_state_dict][5/N] Remove optim_inputs for sharded state_dict. (#89981)  The argument, `optim_inputs`, is being deprecated. Sharded optimizer state_dict APIs are not be used. It is safe to remove them.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/89981 Approved by: https://github.com/awgu",1,Remove Dead Code,,
66556f48e3f5c6f6d6f81ae61e37460bf4906c52,2019-03-13T03:05:36Z,https://github.com/pytorch/pytorch/commit/66556f48e3f5c6f6d6f81ae61e37460bf4906c52,Remove sinkMaxPool transformation (#17694)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/17694Remove sinkMaxPool transformation as it's unusedDifferential Revision: D14328624fbshipit-source-id: bd245403b756157120faa61a0f9253c15120e7a8,1,Remove Dead Code,,
66ac6698f67ad37c291eb94ca16bd8160be24c92,2019-09-06T13:52:45Z,https://github.com/pytorch/pytorch/commit/66ac6698f67ad37c291eb94ca16bd8160be24c92,remove tools/setup_helpers/cudnn.py (#25482)Summary:FindCUDNN.cmake and cuda.cmake have done the detection. This commit deletes `tools/setup_helpers/cudnn.py` as it is no longer needed.Pull Request resolved: https://github.com/pytorch/pytorch/pull/25482Differential Revision: D17226408Pulled By: ezyangfbshipit-source-id: abd9cd0244cabea1f5d9f93f828d632d77c8dd5e,1,Remove Dead Code,,
6721e67c100e02d62552e924e8ade32eee45f1bc,2019-07-02T06:18:01Z,https://github.com/pytorch/pytorch/commit/6721e67c100e02d62552e924e8ade32eee45f1bc,Remove hacky stub for quantized ops (#22388)Summary:Effectively reverts https://github.com/pytorch/pytorch/pull/18267 - this was a temporary measure and is not used any more.Pull Request resolved: https://github.com/pytorch/pytorch/pull/22388Differential Revision: D16070725Pulled By: dzhulgakovfbshipit-source-id: ee5db11a608f248b0da981169d4cc90470fd482f,1,Remove Dead Code,,
6769b850b2696c2dd7dcea069907f20f54aeecf9,2020-07-20T17:11:45Z,https://github.com/pytorch/pytorch/commit/6769b850b2696c2dd7dcea069907f20f54aeecf9,"Remove needless test duplication (#41583)Summary:The test loops over `upper` but does not use it effectively running the same test twice which increases test times for no gain.Pull Request resolved: https://github.com/pytorch/pytorch/pull/41583Reviewed By: soumith, seemethere, izdebyDifferential Revision: D22598475Pulled By: zou3519fbshipit-source-id: d100f20143293a116ff3ba08b0f4eaf0cc5a8099",1,Remove Dead Code,,
6a883d1bc0dd39bcd248ff9d3423cf1c379e1893,2017-09-08T01:41:31Z,https://github.com/pytorch/pytorch/commit/6a883d1bc0dd39bcd248ff9d3423cf1c379e1893,"Remove dot_product layerSummary: This dot_product layer was added before functional layer was added. Now we have functional layer, this dot_product layer is no longer needed. This diff removes dot_product layer.Reviewed By: kittipatvDifferential Revision: D5783303fbshipit-source-id: 5d13f729918148ee57836fb47c48e6f24773654b",1,Remove Dead Code,,
6bb20822f53176ca4284f640b552626240040ced,2023-04-16T00:07:27Z,https://github.com/pytorch/pytorch/commit/6bb20822f53176ca4284f640b552626240040ced,[SPMD][BE] Remove deprecated aten.sym_numel branch (#99232)  Differential Revision: [](https://our.internmc.facebook.com/intern/diff/)  Differential Revision: [](https://our.internmc.facebook.com/intern/diff/)  Differential Revision: [](https://our.internmc.facebook.com/intern/diff/)  Differential Revision: [D45028732](https://our.internmc.facebook.com/intern/diff/D45028732) Pull Request resolved: https://github.com/pytorch/pytorch/pull/99232 Approved by: https://github.com/yifuwang,1,Remove Dead Code,,
6bdd5ecaf54de34d9795216d14b89f42c44234b1,2017-03-10T20:53:38Z,https://github.com/pytorch/pytorch/commit/6bdd5ecaf54de34d9795216d14b89f42c44234b1,Remove some unnecessary AutoGPU calls,1,Remove Dead Code,,
6dd71947ea39b321dbc7c357122c2d685e973e7d,2018-10-15T09:28:32Z,https://github.com/pytorch/pytorch/commit/6dd71947ea39b321dbc7c357122c2d685e973e7d,"remove unused Iterable, also avoid Python 3.7 deprecation warningSummary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/12639Differential Revision: D10377094Pulled By: soumithfbshipit-source-id: d904c4c1bbac900e44ea0b3b5635697159aec717",1,Remove Dead Code,,
6def5b69e36ecd85f79ee3404cc8be0208b9ac9e,2019-03-14T15:00:51Z,https://github.com/pytorch/pytorch/commit/6def5b69e36ecd85f79ee3404cc8be0208b9ac9e,Remove unused KwargsPlugin.Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/17980Reviewed By: ezyangDifferential Revision: D14438877Pulled By: gchananfbshipit-source-id: f93764b00999effb5c8f852f8eda3a6da32dc767,1,Remove Dead Code,,
6e7e595c1df18bbe25328f6a034114f86c2dfcce,2020-01-28T19:53:19Z,https://github.com/pytorch/pytorch/commit/6e7e595c1df18bbe25328f6a034114f86c2dfcce,"[rpc][easy] remove redundant test in rpc_test.py (#32588)Summary:Both `test_wait_all_workers` and `test_wait_all_workers_and_shutdown` test the same pattern of initialize RPC, call `_wait_all_workers`, and `rpc.shutdown(graceful=False)`.`test_wait_all_workers` seems to be more thorough since it tests one worker driving and the others waiting on it as well.We shouldn't have duplicate test so removing this `test_wait_all_workers_and_shutdown`.Pull Request resolved: https://github.com/pytorch/pytorch/pull/32588Differential Revision: D19566294Pulled By: rohan-varmafbshipit-source-id: b69519d169b3964649d47ad75532bda5de538241",1,Remove Dead Code,,
737efa78ba3902941ef61ad01bda231f54c1a2d9,2018-12-03T15:30:03Z,https://github.com/pytorch/pytorch/commit/737efa78ba3902941ef61ad01bda231f54c1a2d9,Remove 'type_method_inline_definitions' which isn't used.Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/14648Differential Revision: D13284176Pulled By: gchananfbshipit-source-id: e6b8f9410fab57164259f97de2fd46f6bdf88d5a,1,Remove Dead Code,,
73c5921134ed3e3cb9dae4928da103f0d98843f9,2019-03-14T16:21:02Z,https://github.com/pytorch/pytorch/commit/73c5921134ed3e3cb9dae4928da103f0d98843f9,"Remove ArgcountSortPlugin, which doesn't seem to be used.Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/17977Reviewed By: ezyangDifferential Revision: D14438842Pulled By: gchananfbshipit-source-id: 9b1746880fd7e3bd2b76a2559face34940ce7570",1,Remove Dead Code,,
75dfa5a45925a2cea27064d3b8461e83c5d096a9,2020-08-14T18:33:59Z,https://github.com/pytorch/pytorch/commit/75dfa5a45925a2cea27064d3b8461e83c5d096a9,Remove `itruediv` because it's already defined in torch/tensor.py (#42962)Summary:Fixes https://github.com/pytorch/pytorch/issues/42955Pull Request resolved: https://github.com/pytorch/pytorch/pull/42962Reviewed By: mruberryDifferential Revision: D23111523Pulled By: malfetfbshipit-source-id: ecab7a4aae1fe556753b8d6528cae1ae201beff3,1,Remove Dead Code,,
76da0b34c2bc5b77b603072839cf4ff71cc70ca7,2018-08-16T07:20:49Z,https://github.com/pytorch/pytorch/commit/76da0b34c2bc5b77b603072839cf4ff71cc70ca7,Remove an unused variable found by linterSummary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/10578Differential Revision: D9357880Pulled By: bddppqfbshipit-source-id: 6b56c2dbd02258124b5a4656cdf44d14a59e1b71,1,Remove Dead Code,,
7749eec8df75f1b0e31031db2745a895cec82e3d,2023-04-22T06:49:28Z,https://github.com/pytorch/pytorch/commit/7749eec8df75f1b0e31031db2745a895cec82e3d,"Remove deprecated declaration suppression (#99749)  As https://github.com/pytorch/pytorch/pull/55889 landed a while back  Pull Request resolved: https://github.com/pytorch/pytorch/pull/99749 Approved by: https://github.com/huydhn, https://github.com/kit1980",1,Remove Dead Code,,
79a343bbd4f8546430fead6c4b4f2aebd7fb4422,2017-06-14T18:23:42Z,https://github.com/pytorch/pytorch/commit/79a343bbd4f8546430fead6c4b4f2aebd7fb4422,Remove unnecesssary squeezing in Expand backwards.Also add size checks to test_autograd to try to catch such issues.,1,Remove Dead Code,,
7a90bae416aba899fa1d3a5239fced428cf9f2e9,2019-03-25T22:48:11Z,https://github.com/pytorch/pytorch/commit/7a90bae416aba899fa1d3a5239fced428cf9f2e9,Remove unused th_scalar_type (#18390)Summary:th_scalar_type seems to be unused anywhere so can be removed.Pull Request resolved: https://github.com/pytorch/pytorch/pull/18390Reviewed By: ezyangDifferential Revision: D14591374Pulled By: izdebyfbshipit-source-id: 2113aa81229cdfdfb8dc5c951ea6dea3725b8582,1,Remove Dead Code,,
7bc154f8eab38b3a290639e2351fdefc3020def0,2017-10-11T21:52:50Z,https://github.com/pytorch/pytorch/commit/7bc154f8eab38b3a290639e2351fdefc3020def0,Remove unused argument 'input' to Sigmoid_updateGradInput (#3079),1,Remove Dead Code,,
7cda964e20b76906b317f3be88185f0e0d9f928e,2020-03-03T22:42:06Z,https://github.com/pytorch/pytorch/commit/7cda964e20b76906b317f3be88185f0e0d9f928e,Remove deprecated codepath for old-style autograd.Function (#30696) (#33956)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/33956Test Plan: Imported from OSSDifferential Revision: D20167359Pulled By: glaringleefbshipit-source-id: 9b323bd29eca97bce0475225ad2b3b2ded29005d,1,Remove Dead Code,,
7ea3aab45d192cdfbfc4cc1074073aead6d3ce63,2023-03-01T01:02:04Z,https://github.com/pytorch/pytorch/commit/7ea3aab45d192cdfbfc4cc1074073aead6d3ce63,Remove dead ZeroGuard (#95701)  Signed-off-by: Edward Z. Yang <ezyang@meta.com>  Pull Request resolved: https://github.com/pytorch/pytorch/pull/95701 Approved by: https://github.com/Skylion007,1,Remove Dead Code,,
82592f7e53d1507509bdcb21752c9f02052b1974,2023-03-28T00:55:17Z,https://github.com/pytorch/pytorch/commit/82592f7e53d1507509bdcb21752c9f02052b1974,"remove dead torch_pb.h library (#97599)  This is only used in one place, ensure it still builds.  Differential Revision: [D44395699](https://our.internmc.facebook.com/intern/diff/D44395699/)  **NOTE FOR REVIEWERS**: This PR has internal Meta-specific changes or comments, please review them on [Phabricator](https://our.internmc.facebook.com/intern/diff/D44395699/)! Pull Request resolved: https://github.com/pytorch/pytorch/pull/97599 Approved by: https://github.com/PaliC",1,Remove Dead Code,,
833b8cbc7a19556086ee128d7ddcfcd495c1fe7f,2017-02-02T16:00:30Z,https://github.com/pytorch/pytorch/commit/833b8cbc7a19556086ee128d7ddcfcd495c1fe7f,Remove unused code from module,1,Remove Dead Code,,
837f933cac6c55366752fe14a793d0010eef0d89,2017-10-25T18:19:11Z,https://github.com/pytorch/pytorch/commit/837f933cac6c55366752fe14a793d0010eef0d89,remove 'path' from key_averages headerpath appears to be unused,1,Remove Dead Code,,
849794cd2cbf21667c1b4fb9e4127097556f76cf,2016-12-30T23:37:44Z,https://github.com/pytorch/pytorch/commit/849794cd2cbf21667c1b4fb9e4127097556f76cf,Remove deprecated and unimplemented functions (#383),1,Remove Dead Code,,
84ee795b25a6bc1d3105922cd77046c7b92a93d6,2017-04-11T04:17:12Z,https://github.com/pytorch/pytorch/commit/84ee795b25a6bc1d3105922cd77046c7b92a93d6,remove net_predictor_extract.pySummary: Having directory utils broke open source build :(. Removing the contents as this utility is not really needed.Differential Revision: D4866228fbshipit-source-id: 1eae4580ebac5b60e52e2e8553e0ffd919152228,1,Remove Dead Code,,
85d3fccee740bfa3493fab3f0bf7cea039e2c0bc,2018-11-22T00:54:36Z,https://github.com/pytorch/pytorch/commit/85d3fccee740bfa3493fab3f0bf7cea039e2c0bc,Removed redundant allreduce options in DDP (#14208)Summary:This somehow is not cleaned up after the C++ migration. Unused and can be removed.Pull Request resolved: https://github.com/pytorch/pytorch/pull/14208Differential Revision: D13132492Pulled By: teng-lifbshipit-source-id: 0f05b6368174664ebb2560c037347c8eb45f7c38,1,Remove Dead Code,,
87508f401cabbc3f4d0aa64b604415e62131ed62,2019-08-09T15:47:10Z,https://github.com/pytorch/pytorch/commit/87508f401cabbc3f4d0aa64b604415e62131ed62,Delete unnecessary file split_types.pySummary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/23754Differential Revision: D16732834Pulled By: ezyangfbshipit-source-id: 087c573ecde8cd05dd7a28f47939a257e1cc25f3,1,Remove Dead Code,,
8766daeec97a3945e115a6422b4356bd20ad19e9,2018-07-16T00:37:52Z,https://github.com/pytorch/pytorch/commit/8766daeec97a3945e115a6422b4356bd20ad19e9,Refactor `_log_sum_exp` (#9173)Summary:This PR removes `distributions.utils._log_sum_exp` in favor of `torch.logsumexp`. Also fixes some warnings with `reduce` arg. in `binary_cross_entropy_with_logits`Pull Request resolved: https://github.com/pytorch/pytorch/pull/9173Reviewed By: SsnLDifferential Revision: D8764174Pulled By: ezyangfbshipit-source-id: b9c4136dbf0182e8ae77082e6448d23a430d5cb6,1,Remove Dead Code,,
87be8c1d7c84a41bf5da3c620cec2e5fc1b528b4,2021-03-01T16:51:50Z,https://github.com/pytorch/pytorch/commit/87be8c1d7c84a41bf5da3c620cec2e5fc1b528b4,"ns for fx: clean up duplicate code in get_matching_activations_a_shadows_b (#52927)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/52927Refactor to use an existing util instead of duplicating code, no logicchange.Test Plan:CIImported from OSSReviewed By: raghuramank100Differential Revision: D26693474fbshipit-source-id: 06b7047eb9a762557b7f679347e424c0dd009aad",1,Remove Dead Code,,
8a026d4f74b71944ac2860c315996165a40f5626,2019-09-10T11:31:31Z,https://github.com/pytorch/pytorch/commit/8a026d4f74b71944ac2860c315996165a40f5626,"Remove tools/setup_helpers/dist_check.py (#25879)Summary:What dist_check.py does is largely merely determining whether we shoulduse set ""USE_IBVERBS"" to ON or OFF when the user sets ""USE_GLOO_IBVERBS""to ON. But this is unnecessary, because this complicated determinationwill always be overrided by gloo:https://github.com/facebookincubator/gloo/blob/2101e02ceabd9f1b0bb354f6ea705cefe83558b2/cmake/Dependencies.cmake#L19-L28Since dist_check.py becomes irrelevant, this commit also simplifies thesetting of `USE_DISTRIBUTED` (by removing its explicit setting in Python scripts), and deprecate `USE_GLOO_IBVERBS` in favorof `USE_IBVERBS`.Pull Request resolved: https://github.com/pytorch/pytorch/pull/25879Differential Revision: D17282395Pulled By: pieternfbshipit-source-id: a10735f50728d89c3d81fd57bcd26764e7f84dd1",1,Remove Dead Code,,
8c095102948c9601792a884dad56da5085c51bee,2021-09-09T02:16:13Z,https://github.com/pytorch/pytorch/commit/8c095102948c9601792a884dad56da5085c51bee,[DDP] Remove self.modules_params (#64473)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/64473  Unused after SPMD deprecated. ghstack-source-id: 137526305  Test Plan: CI  Reviewed By: zhaojuanmao  Differential Revision: D30745961  fbshipit-source-id: 32d102502570291e01579e5b47a6d74dc71013bb,1,Remove Dead Code,,
8c13dde458c3082d08fe646307ad5a51e2b16cf1,2021-03-29T21:12:25Z,https://github.com/pytorch/pytorch/commit/8c13dde458c3082d08fe646307ad5a51e2b16cf1,[DDP] Remove redundant pass statement (#54219)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/54219There is no need for this ``pass``.ghstack-source-id: 125124311Test Plan: CIReviewed By: zhaojuanmaoDifferential Revision: D27105234fbshipit-source-id: 95496fa785fdc66a6c3c8ceaa14af565588325df,1,Remove Dead Code,,
8d56b0a5b57cf3e82402556ceb5c7080c0f9d5b6,2023-05-06T12:48:44Z,https://github.com/pytorch/pytorch/commit/8d56b0a5b57cf3e82402556ceb5c7080c0f9d5b6,remove unused tuple_cat utility (#100731)  remove unused tuple_cat utility  Test Plan: Verified unused with `git grep`.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/100731 Approved by: https://github.com/ezyang,1,Remove Dead Code,,
8da2d75ec86de66f6f9d77a6527b918a87c8c07f,2017-04-05T21:05:12Z,https://github.com/pytorch/pytorch/commit/8da2d75ec86de66f6f9d77a6527b918a87c8c07f,"Caffe2/Recurrent] recurrent.py API to cuDNN LSTMSummary:Quite large diff to make cuDNN LSTM and our LSTM produce same results and provide python API for the cuDNN LSTM.* Added operators RecurrentParamGet and RecurrentParamSet to access weights and biases for the different gates, input/recurrent.* Removed RecurrentInit as not needed* recurrent.cudnn_LSTM() returns a special net and mapping that can be used to retrieve the parameters from the LSTM* recurrent.cudnn_LSTM() can be passed blobs that have the parameters for the individual gate weights and biases* recurrnet.InitFromLSTMParams() can be used to initialize our own LSTM from CUDNN params.  This way we can test if cuDNN and our own produce the same result.recurrent_test.py tests for the equivalencyReviewed By: salexspbDifferential Revision: D4654988fbshipit-source-id: 6c1547d873cadcf33e03b0e0110248f0a7ab8cb0",1,Remove Dead Code,,
906c50eb69daf763e48573c8201cfdbd6a60654e,2020-05-12T19:39:19Z,https://github.com/pytorch/pytorch/commit/906c50eb69daf763e48573c8201cfdbd6a60654e,"Remove dead code in ddp.{h, cpp} (#37990)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/37990The code in `ddp.{h, cpp}` and the corresponding pybind implementations are no longer used. The pybinded calls were all private APIs and only ran in unittests, so we should remove these unused APIs.https://github.com/pytorch/pytorch/pull/20234 from a year ago also mentioned that we should delete `_dist_broadcast_coalesced`Verified that all tests pass with cuda by running `test_c10d` on a gpu-enabled machine.ghstack-source-id: 103885383Test Plan: CIDifferential Revision: D21443879fbshipit-source-id: 764d8681ca629056bfe2c260ffab47fa5bdf07ff",1,Remove Dead Code,,
919e09f26a9b7aecd37fd332d4bde8c4108b3cfb,2022-12-06T21:28:40Z,https://github.com/pytorch/pytorch/commit/919e09f26a9b7aecd37fd332d4bde8c4108b3cfb,[FSDP][BE] Clean up dead code from `clip_grad_norm_()` testing (#90250)  `FSDP.clip_grad_norm_()` is tested separately in `test_fsdp_clip_grad_norm.py`. This PR removes the dead non-run code from `common_fsdp.py` and `test_fsdp_core.py` related to `clip_grad_norm_()`. Pull Request resolved: https://github.com/pytorch/pytorch/pull/90250 Approved by: https://github.com/rohan-varma,1,Remove Dead Code,,
9302f860aeba45bf853bccc7e5eacb570655f6ba,2017-01-18T18:34:40Z,https://github.com/pytorch/pytorch/commit/9302f860aeba45bf853bccc7e5eacb570655f6ba,Remove unused file TensorDocstrings.cpp (#481)Tensor docstrings are created in _tensor_docs.py,1,Remove Dead Code,,
94a3d4b083c945050a93fefcdd20d7d336185f2d,2020-12-14T04:27:06Z,https://github.com/pytorch/pytorch/commit/94a3d4b083c945050a93fefcdd20d7d336185f2d,Remove unused operator at::_fft_with_size (#48905)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/48905Test Plan: Imported from OSSReviewed By: ngimelDifferential Revision: D25480385Pulled By: mruberryfbshipit-source-id: 192d04a1b7e33b4e408cda8a82679c3ae3490a7d,1,Remove Dead Code,,
95650b152a4b06b5c72b5d33c787695d779fe13e,2019-10-22T14:45:03Z,https://github.com/pytorch/pytorch/commit/95650b152a4b06b5c72b5d33c787695d779fe13e,remove deprecated torch.Tensor in test_distributed.pySummary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/28316Test Plan: Imported from OSSDifferential Revision: D18019147Pulled By: mrshenlifbshipit-source-id: eb0fb08031d810ea85fb6ea54b1b25791178131b,1,Remove Dead Code,,
958d6272883f5b053545e8bdbff8af5bb0259dcc,2019-09-17T17:28:01Z,https://github.com/pytorch/pytorch/commit/958d6272883f5b053545e8bdbff8af5bb0259dcc,Remove dead function (#26259)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/26259This wasn't called from anywhere (confirmed by grep)ghstack-source-id: 90222268Test Plan: waitforsandcastleDifferential Revision: D17391417fbshipit-source-id: 77c395f2f7104995f6af6e3e20d3f615223085b3,1,Remove Dead Code,,
95dc2b6e9b419ddbd88cd974ad3e999773eb9f8f,2021-04-30T14:30:33Z,https://github.com/pytorch/pytorch/commit/95dc2b6e9b419ddbd88cd974ad3e999773eb9f8f,Remove unused forward AD flag (#57058)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/57058Test Plan: Imported from OSSReviewed By: soulitzerDifferential Revision: D28071504Pulled By: albanDfbshipit-source-id: df694ac6b9fbb4aed269d61cd9522f8602fdae0c,1,Remove Dead Code,,
99349defc128220df0876fc35453f200f0935593,2020-02-12T22:45:44Z,https://github.com/pytorch/pytorch/commit/99349defc128220df0876fc35453f200f0935593,"remove unnecessary Node* ops (#32760)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/32760Minor changes to the way ops are implemented to remove incidental use of Node*in the operator implementation.Current state for operators that previously took Node:```TBD:USES NODE: prim::DifferentiableGraph(...) -> (...)USES NODE: prim::profile(...) -> (...)USES NODE: prim::FusionGroup(...) -> (...)USES NODE: prim::PythonOp(...) -> (...)USES NODE: prim::ImplicitTensorToNum(Tensor a) -> Scalar # next PRShould be made interpreter primitives:USES NODE: prim::TupleUnpack(...) -> (...)USES NODE: prim::TupleSlice(...) -> (...)USES NODE: prim::TupleConstruct(...) -> (...)USES NODE: prim::ListUnpack(...) -> (...)USES NODE: prim::ListConstruct(...) -> (...)USES NODE: prim::DictConstruct(...) -> (...)USES NODE: prim::Constant() -> (...)USES NODE: prim::isinstance(...) -> (...)USES NODE: prim::CreateObject(...) -> (...)USES NODE: prim::fork(...) -> (...)USES NODE: aten::warn(str message, *, int stacklevel=2) -> () # need stack level information, so ideally in interpreter so it can look at the stackShould be made into vararg operators, i.e. the operators last argument should be an IValuethat contains the number of arguments.USES NODE: prim::FusedConcat(...) -> (...)USES NODE: prim::MMTreeReduce(...) -> (...)USES NODE: prim::MMBatchSide(...) -> (...)USES NODE: prim::ConstantChunk(...) -> (...)USES NODE: prim::AutogradAnyNonZero(...) -> boolUSES NODE: prim::BroadcastSizes(...) -> (...)USES NODE: prim::ChunkSizes(...) -> (...)USES NODE: aten::format(str self, ...) -> strUSES NODE: prim::Print(...) -> (...)fixed:USES NODE: aten::extend(Tensor[](a!) self, Tensor [] other) -> ()USES NODE: aten::copy(Tensor[](a) self) -> Tensor[]USES NODE: aten::extend(int[](a!) self, int [] other) -> ()USES NODE: aten::copy(int[](a) self) -> int[]USES NODE: aten::extend(float[](a!) self, float [] other) -> ()USES NODE: aten::copy(float[](a) self) -> float[]USES NODE: aten::extend(bool[](a!) self, bool [] other) -> ()USES NODE: aten::copy(bool[](a) self) -> bool[]USES NODE: aten::extend(t[](a!) self, t [] other) -> ()USES NODE: aten::copy(t[](a) self) -> t[]USES NODE: aten::keys(Dict(str, t) self) -> str[](*)USES NODE: aten::values(Dict(str, t) self) -> t[](*)USES NODE: aten::dict((str, tVal)[] inputs) -> Dict(str, tVal)USES NODE: aten::keys(Dict(int, t) self) -> int[](*)USES NODE: aten::values(Dict(int, t) self) -> t[](*)USES NODE: aten::dict((int, tVal)[] inputs) -> Dict(int, tVal)USES NODE: aten::keys(Dict(float, t) self) -> float[](*)USES NODE: aten::values(Dict(float, t) self) -> t[](*)USES NODE: aten::dict((float, tVal)[] inputs) -> Dict(float, tVal)USES NODE: aten::keys(Dict(Tensor, t) self) -> Tensor[](*)USES NODE: aten::values(Dict(Tensor, t) self) -> t[](*)USES NODE: aten::dict((Tensor, tVal)[] inputs) -> Dict(Tensor, tVal)USES NODE: aten::test_vartype2(t a, t[] b) -> (t[])USES NODE: aten::_ncf_unsqueeze(Tensor self, int ndim) -> TensorUSES NODE: aten::_ncf_view(Tensor self, int[] input_shape, int normalized_ndim) -> TensorUSES NODE: prim::is_none(int? a) -> boolUSES NODE: aten::__interpolate(Tensor input, int? size = None, float[]? scale_factor = None, str mode = 'nearest', bool? align_corners = None, bool? recompute_scale_factor = None) -> TensorUSES NODE: aten::__interpolate(Tensor input, int[]? size = None, float[]? scale_factor = None, str mode = 'nearest', bool? align_corners = None, bool? recompute_scale_factor = None) -> TensorUSES NODE: aten::__interpolate(Tensor input, int? size = None, float? scale_factor = None, str mode = 'nearest', bool? align_corners = None, bool? recompute_scale_factor = None) -> TensorUSES NODE: aten::__interpolate(Tensor input, int[]? size = None, float? scale_factor = None, str mode = 'nearest', bool? align_corners = None, bool? recompute_scale_factor = None) -> TensorUSES NODE: aten::sorted(t[](a) self) -> (t[])USES NODE: aten::sort(t[](a!) self, bool reverse=False) -> ()USES NODE: aten::test_vartype(t[] a, t b) -> (t)USES NODE: prim::unchecked_unwrap_optional(t(a)? optional) -> t(a)USES NODE: prim::unchecked_cast(...) -> (...)USES NODE: aten::dict() -> Dict(str, Tensor)USES NODE: prim::Load(...) -> (...)USES NODE: prim::Store(...) -> (...)USES NODE: prim::Drop(...) -> (...)USES NODE: aten::tensor(t[] data, *, ScalarType? dtype=None, Device? device=None, bool requires_grad=False) -> TensorUSES NODE: aten::as_tensor(t[] data, *, ScalarType? dtype=None, Device? device=None) -> Tensor```Test Plan: Imported from OSSDifferential Revision: D19615387Pulled By: zdevitofbshipit-source-id: 95298c3c4249b9f812c332d13f0fb79daeecb662",1,Remove Dead Code,,
996f444c007a89f7364ed03b7c24755f7ec43eb0,2020-11-04T07:42:24Z,https://github.com/pytorch/pytorch/commit/996f444c007a89f7364ed03b7c24755f7ec43eb0,"[pt][static_runtime] Memory model (#46896)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/46896The idea of the memory model is quite similar to that of BlackBoxPredictor, however, it's more complicated in pt due to 1) tensor views that share storage with storage refcount bumps but with different TensorImpls, 2) tensors sharing the same TensorImpl and the same storage, but with no refcount bump of the StorageImpl, 3) data types such as TensorList and Tuples that have Tensors in them, 4) need to support non-out/out variant mix while we move the aten ops to out variants.As a result, I have to make the following adjustments:1) remove tensors in output Tuples from internal blob list;2) for memory allocation/deallocation, get candidate Tensors from the outputs of ops with out variant, extract StorageImpls from the Tensors, dedup, and remove output tensor StorageImpls, and get the final list of blobs for memory planning;3) during the clean_up_memory pass, clean up memory held by the StorageImpls as well as Tensors/Lists/Tuples in IValues that don't participate in memory planning to reduce overall memory usageRisk:PyTorch team is planning to deprecate the current resize_outout api, which we do rely on. This is a pretty big risk.https://www.internalfb.com/intern/diffusion/FBS/browsefile/master/fbcode/caffe2/aten/src/ATen/native/Resize.cpp?commit=6457b329847607553d34e788a3a7092f41f38895&lines=9-23Test Plan:```buck test //caffe2/test:static_runtimebuck test //caffe2/benchmarks/static_runtime:static_runtime_cpptestbuck test //caffe2/caffe2/fb/predictor:pytorch_predictor_test```Benchmarks:```MKL_NUM_THREADS=1 OMP_NUM_THREADS=1 numactl -m 0 -C 13 \buck-out/opt/gen/caffe2/caffe2/fb/predictor/ptvsc2_predictor_bench \--scripted_model=/home/hlu/ads/adindexer/adindexer_ctr_mobilefeed/pt/merge/traced_precomputation.pt \--pt_inputs=/home/hlu/ads/adindexer/adindexer_ctr_mobilefeed/pt/merge/container_precomputation_bs1.pt \--iters=1000 --warmup_iters=10000 --num_threads=1 --pt_enable_static_runtime=true \--pt_cleanup_activations=true --pt_enable_out_variant=false```|pt_cleanup_activations	|pt_enable_out_variant	|old ms/iter	|new ms/iter	||---	|---	|---	|---	||0	|0	|0.31873	|0.30228	||0	|1	|0.30018	|0.29184	||1	|0	|0.35246	|0.31895	||1	|1	|0.35742	|0.30417	|Reviewed By: bwasti, razielDifferential Revision: D24471854fbshipit-source-id: 4ac37dca7d2a0c362120a7f02fd3995460c9a55c",1,Remove Dead Code,,
9cd0ae5e2da18f86030a120efb25bdb2ca505fca,2018-09-20T18:36:41Z,https://github.com/pytorch/pytorch/commit/9cd0ae5e2da18f86030a120efb25bdb2ca505fca,Remove deprecated factory functions from Type.Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/11583Reviewed By: SsnLDifferential Revision: D9792800fbshipit-source-id: 9af46d577911ff38647790169df66aa5d0379dd9,1,Remove Dead Code,,
9d62f771eba141551bb4e49af8ac131ac78fba6c,2023-04-14T03:19:43Z,https://github.com/pytorch/pytorch/commit/9d62f771eba141551bb4e49af8ac131ac78fba6c,"[ONNX] Remove duplicated code from previous rebase (#99072)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/99072 Approved by: https://github.com/titaiwangms, https://github.com/justinchuby",1,Remove Dead Code,,
a02681f804f3e195c9045b4a65979a3a9ef0ec65,2019-11-05T16:47:07Z,https://github.com/pytorch/pytorch/commit/a02681f804f3e195c9045b4a65979a3a9ef0ec65,Cleaned up func removed unused variable (#29179)Summary:I don't see `_frames_up` being used anywhere. Just to clean up the code thought it should be removed.Pull Request resolved: https://github.com/pytorch/pytorch/pull/29179Differential Revision: D18319876Pulled By: suofbshipit-source-id: 5e612ff94ccc88fc85288ffc26213e1d11580c36,1,Remove Dead Code,,
a0752b68e73545707dab02e5e0c0fe1ff08d49ad,2023-05-09T05:30:52Z,https://github.com/pytorch/pytorch/commit/a0752b68e73545707dab02e5e0c0fe1ff08d49ad,"[BE] Remove empty pre and post proc functions (#100780)  These functions are noops, so just use the collective() override.  Differential Revision: [D45632429](https://our.internmc.facebook.com/intern/diff/D45632429/) Pull Request resolved: https://github.com/pytorch/pytorch/pull/100780 Approved by: https://github.com/Skylion007, https://github.com/fegin",1,Remove Dead Code,,
a104dac193ceeb289bd657b1b9151fb6928e989e,2017-08-16T20:43:56Z,https://github.com/pytorch/pytorch/commit/a104dac193ceeb289bd657b1b9151fb6928e989e,remove unsed code and bring back single benchmark modeSummary: the old gpu single benchmark mode is lost in recent changes. We still need this mode to benchmark some operators. I also removed some unused ancient codeReviewed By: azzoliniDifferential Revision: D5628501fbshipit-source-id: c5d2c6c99af18c41bead5d86c46a42f05821e2ff,1,Remove Dead Code,,
a117d968f6ec20eb6b0b3d856e1adc6887a1d582,2020-09-25T16:50:26Z,https://github.com/pytorch/pytorch/commit/a117d968f6ec20eb6b0b3d856e1adc6887a1d582,"[quant][graph] Remove redundant aten::wait calls in the graph (#45257)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/45257Currently we inline fork-wait calls when we insert observers for quantizationIn the case where fork and wait are in different subgraphs, inlining the fork-wait callsonly gets rid of the fork. This leaves the aten::wait call in the graph with a torch.Tensor as input,which is currently not supported.To avoid this we check to make sure input to all wait calls in the graph is of type Future[tensor]in the cleanup phaseTest Plan:python test/test_quantization.py TestQuantizeJitPasses.test_quantize_fork_waitImported from OSSReviewed By: qizzzhDifferential Revision: D23895412fbshipit-source-id: 3c58c6be7d7e7904eb6684085832ac21f827a399",1,Remove Dead Code,,
a18048d982fffdd0417f98a47fcf8847c3996f1f,2023-06-13T00:27:28Z,https://github.com/pytorch/pytorch/commit/a18048d982fffdd0417f98a47fcf8847c3996f1f,"Remove redundant fallback for view_as_complex (#103261)  This enables lowering to work for it  Differential Revision: [D46585029](https://our.internmc.facebook.com/intern/diff/D46585029) Pull Request resolved: https://github.com/pytorch/pytorch/pull/103261 Approved by: https://github.com/desertfire, https://github.com/eellison",1,Remove Dead Code,,
a1ef0be30c163b43707c6cfb60cf4097fd55106d,2023-03-21T23:15:27Z,https://github.com/pytorch/pytorch/commit/a1ef0be30c163b43707c6cfb60cf4097fd55106d,[BE] Remove spurious semicolon in XPUHooksInterface.h (#97296)  Semicolon in `void foo() {};` is redundant.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/97296 Approved by: https://github.com/kit1980,1,Remove Dead Code,,
a3989b2802a5b32d8793557ddb5aba36298ef2be,2023-05-05T02:02:57Z,https://github.com/pytorch/pytorch/commit/a3989b2802a5b32d8793557ddb5aba36298ef2be,remove unused concat_iseq (#100648)  remove unused concat_iseq  Test Plan: Verified with `git grep`.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/100648 Approved by: https://github.com/Skylion007,1,Remove Dead Code,,
a3ca66c69e625cd76e3773690c1920498d003882,2023-02-07T15:56:05Z,https://github.com/pytorch/pytorch/commit/a3ca66c69e625cd76e3773690c1920498d003882,[MPS] Remove the unused code for view lists in OperationUtils.h (#94265)  Clean up redundant code that was added before and not needed anymore.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/94265 Approved by: https://github.com/kulinseth,1,Remove Dead Code,,
a7217e6626c4ca4b74d2217d7d642ed727f2a0b1,2017-04-06T04:04:39Z,https://github.com/pytorch/pytorch/commit/a7217e6626c4ca4b74d2217d7d642ed727f2a0b1,Remove unused optimizersSummary: As desc.Reviewed By: xianjiecDifferential Revision: D4840482fbshipit-source-id: bf820154475508ce581d16a45bcd93d026b60f30,1,Remove Dead Code,,
a88bfc60c75d22a047f03787aaa43130c6a8d6d9,2023-02-26T03:03:37Z,https://github.com/pytorch/pytorch/commit/a88bfc60c75d22a047f03787aaa43130c6a8d6d9,"[2/N][ST deprecate][BE] Remove Replicate Tensor convert from DDP and PTD (#95450)  No use is found for this ST/Replicated Tensor based DDP. As part of ShardedTensor migration, let's remove this logic. Trying to undo everything in https://github.com/pytorch/pytorch/pull/75753. Pull Request resolved: https://github.com/pytorch/pytorch/pull/95450 Approved by: https://github.com/wanchaol",1,Remove Dead Code,,
a9c14a530696213fda21d94ee200ccb89310bcd5,2016-10-28T22:28:22Z,https://github.com/pytorch/pytorch/commit/a9c14a530696213fda21d94ee200ccb89310bcd5,Remove unused code,1,Remove Dead Code,,
b2f3ff618348ad6ca070c591ca42ba24b0f6f318,2023-01-25T22:40:56Z,https://github.com/pytorch/pytorch/commit/b2f3ff618348ad6ca070c591ca42ba24b0f6f318,[Py3.11] Remove skip logic  from vmap and forward_ad (#91825)  Depends on https://github.com/pytorch/pytorch/pull/91805  Fixes https://github.com/pytorch/pytorch/issues/85506 Pull Request resolved: https://github.com/pytorch/pytorch/pull/91825 Approved by: https://github.com/albanD,1,Remove Dead Code,,
b5d8fef9a520bfbaef23591322de59b8bb24451c,2023-01-16T01:17:45Z,https://github.com/pytorch/pytorch/commit/b5d8fef9a520bfbaef23591322de59b8bb24451c,[DTensor] remove redundant device mesh test code (#92069)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/92069 Approved by: https://github.com/wanchaol,1,Remove Dead Code,,
b6e80a1ec407e866ba154c00b942338d1ef5228a,2018-03-27T02:23:45Z,https://github.com/pytorch/pytorch/commit/b6e80a1ec407e866ba154c00b942338d1ef5228a,Caffe2-onnx exporter (#2248)* caffe2-onnx frontend* Remove Python part of the conversion code* nit* convert more ops* Address commmetns,1,Remove Dead Code,,
b99a299c6002354acef5c43eba5cd25b41e773c7,2021-08-20T01:53:49Z,https://github.com/pytorch/pytorch/commit/b99a299c6002354acef5c43eba5cd25b41e773c7,"[PyTorch] Remove unused dump() methods in vec headers (#63533)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/63533  These methods don't seem to be used, and they use std::cout, which incurs a small code size overhead on platforms using libstdc++ due to std::__ioinit (see #61500). Seems like we can just delete them? ghstack-source-id: 136163409  Test Plan: CI  Reviwers: #sentinel, dhruvbird  Reviewed By: dskhudia  Differential Revision: D30412269  fbshipit-source-id: 380b9aa2f9aabc4107188b6b209d2afc1769c0ee",1,Remove Dead Code,,
b9f1555b6a3e516f270100afda72bf325a903984,2016-11-23T00:50:56Z,https://github.com/pytorch/pytorch/commit/b9f1555b6a3e516f270100afda72bf325a903984,remove unused function from resnet50_trainerSummary: Just noticed that I had duplicate code in the example imagenet trainer. Removed the function.Differential Revision: D4223070fbshipit-source-id: 443a9401bf7e425f7a3a13a44c9d0f7e21e72303,1,Remove Dead Code,,
bb8278731e65ae524119c7beccdc3c68faf48a9c,2023-06-09T00:56:13Z,https://github.com/pytorch/pytorch/commit/bb8278731e65ae524119c7beccdc3c68faf48a9c,[FSDP][Easy] Remove redundant var def in test (#103270)  This is an easy follow-up from the previous PR to avoid re-running CI. Pull Request resolved: https://github.com/pytorch/pytorch/pull/103270 Approved by: https://github.com/rohan-varma,1,Remove Dead Code,,
bc3151dee0b73e10c64788fce2d822e96aeffb4a,2020-09-25T05:10:52Z,https://github.com/pytorch/pytorch/commit/bc3151dee0b73e10c64788fce2d822e96aeffb4a,[quant] Remove unused qconfig argument in qat linear module (#45307)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/45307fixes: https://github.com/pytorch/pytorch/issues/35634Test Plan: Imported from OSSReviewed By: vkuzoDifferential Revision: D23917339fbshipit-source-id: 65f8844b98198bbf93547b3d71408c2a54605218,1,Remove Dead Code,,
bf20e4e9b0e5a7377d190f36d7612b9169f0d66d,2017-04-22T21:35:59Z,https://github.com/pytorch/pytorch/commit/bf20e4e9b0e5a7377d190f36d7612b9169f0d66d,Remove MiLSTM from recurrent.py left over after refactoringSummary: its not usedReviewed By: urikzDifferential Revision: D4936008fbshipit-source-id: cc044bbdac0d17503ce9376b98e4bf79a4dc959c,1,Remove Dead Code,,
c03cae49fc70408a93f4de15a11a5a73997e9565,2021-06-03T00:20:22Z,https://github.com/pytorch/pytorch/commit/c03cae49fc70408a93f4de15a11a5a73997e9565,[DDP] Remove unused initialize_buckets (#59066)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/59066  Per title ghstack-source-id: 130338812  Test Plan: ci  Reviewed By: SciPioneer  Differential Revision: D28734666  fbshipit-source-id: 89ca7f8e625c4068ba0ed9800be2619e469ae515,1,Remove Dead Code,,
c0d33f66c95abd29b10bf4574d8d9ebb35c5079d,2023-05-10T15:45:36Z,https://github.com/pytorch/pytorch/commit/c0d33f66c95abd29b10bf4574d8d9ebb35c5079d,[pt2] remove unused `meta_linalg_eigh` (#100965)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/100965 Approved by: https://github.com/ezyang,1,Remove Dead Code,,
c2adedf6fe90153dcca640c09ae4cbfde1b46cd9,2021-04-01T00:46:37Z,https://github.com/pytorch/pytorch/commit/c2adedf6fe90153dcca640c09ae4cbfde1b46cd9,[quant][graphmode][refactor] Remove reduandent code (#54073)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/54073Test Plan: Imported from OSSReviewed By: vkuzoDifferential Revision: D27086067fbshipit-source-id: b1995138de56f1352c5df03378ebc2832bf35ef7,1,Remove Dead Code,,
c2be9f148732c2d1e4c6b54a9a46c46285c0504e,2019-01-24T23:41:50Z,https://github.com/pytorch/pytorch/commit/c2be9f148732c2d1e4c6b54a9a46c46285c0504e,Remove unneeded manual unwrap optionals (#16245)Summary:Remove calls to torch.jit._unwrap_optional that are no longer needed.The remaining instances would require control flow logic for exceptions.Pull Request resolved: https://github.com/pytorch/pytorch/pull/16245Differential Revision: D13804292Pulled By: eellisonfbshipit-source-id: 08c5cbe4b956519be2333de5cf4e202488aff626,1,Remove Dead Code,,
c38a5cba0d4b310b0e24fbf6fe0fa14fe2b23d3a,2020-07-06T19:30:10Z,https://github.com/pytorch/pytorch/commit/c38a5cba0d4b310b0e24fbf6fe0fa14fe2b23d3a,Remove duplicate assignment in collate.py (#40655)Summary:Duplicated assignmentPull Request resolved: https://github.com/pytorch/pytorch/pull/40655Reviewed By: ezyangDifferential Revision: D22308827Pulled By: colesburyfbshipit-source-id: 48361da8994b3ca00ef29e9afd3ec2672266f00a,1,Remove Dead Code,,
c5b50a3440f6bf2c503a3f06e8e5b4b4f66f60ad,2019-03-13T22:07:49Z,https://github.com/pytorch/pytorch/commit/c5b50a3440f6bf2c503a3f06e8e5b4b4f66f60ad,"Remove AssertNDim, which doesn't seem to be used.Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/17978Reviewed By: colesburyDifferential Revision: D14438845Pulled By: gchananfbshipit-source-id: 106650c37fb1885201eaef27cb6d86b49ef27976",1,Remove Dead Code,,
c7448aa13c94ab47429484f4d02356c1a2f789ed,2019-03-16T01:02:53Z,https://github.com/pytorch/pytorch/commit/c7448aa13c94ab47429484f4d02356c1a2f789ed,remove unused parameters in optimizer tests (#18084)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/18084data_strategy parameter was not used in some of unit tests for optimizersReviewed By: hyuenDifferential Revision: D14487830fbshipit-source-id: d757cd06aa2965f4c0570a4a18ba090b98820ef4,1,Remove Dead Code,,
c9eb312ce9ddc7d8bb433f74814df549cc282c5e,2021-09-11T18:22:55Z,https://github.com/pytorch/pytorch/commit/c9eb312ce9ddc7d8bb433f74814df549cc282c5e,[iOS][OSS][BE] Remove unused files (#64849)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/64849  ghstack-source-id: 137827893  Test Plan: CircleCI  Reviewed By: hanton  Differential Revision: D30877962  fbshipit-source-id: a76f7fe888b990ba6cad650f72be7f4a1e58a2f1,1,Remove Dead Code,,
d306d0c2b1eac60226138c903656ca4bb0f8b9e6,2020-10-01T05:16:11Z,https://github.com/pytorch/pytorch/commit/d306d0c2b1eac60226138c903656ca4bb0f8b9e6,remove redundant PE(profiling executor) jobs in CI (#45397)Summary:This PR removes redundant profiling jobs since after the switch PE (https://github.com/pytorch/pytorch/pull/45396)  will be now running by default.Pull Request resolved: https://github.com/pytorch/pytorch/pull/45397Reviewed By: zhangguanheng66Differential Revision: D23966890Pulled By: Krovatkinfbshipit-source-id: ef184ca5fcf079580fa139b6653f8d9a6124050e,1,Remove Dead Code,,
d72db37c4a6513c0f67f6f69870c9c45bf4880e6,2023-01-31T16:45:32Z,https://github.com/pytorch/pytorch/commit/d72db37c4a6513c0f67f6f69870c9c45bf4880e6,"Remove a redundant check from code. (#93025)  In file: combinatorics.py, the comparison of Collection length creates a logical short circuit.     if isinstance(self.sampler, Sized) and len(self.sampler) >= 0:  Here, the right side of the comparison will always return true.  I suggested that the Collection length check should be removed since this is redundant.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/93025 Approved by: https://github.com/albanD",1,Remove Dead Code,,
d850c33bfe3f1d1f0040738718cacb04ee449bdc,2023-03-22T14:40:31Z,https://github.com/pytorch/pytorch/commit/d850c33bfe3f1d1f0040738718cacb04ee449bdc,"remove dead proto_convert library (#97322)  remove dead proto_convert library  Summary: This has no code, only a collection of headers. Just make sure the only thing that includes it still builds.  Test Plan: Rely on CI.  Reviewers: sahanp  Subscribers:  Tasks:  Tags:  --- Stack created with [Sapling](https://sapling-scm.com). Best reviewed with [ReviewStack](https://reviewstack.dev/pytorch/pytorch/pull/97322). * #97337 * #97336 * #97335 * #97334 * #97325 * #97324 * #97323 * __->__ #97322 Pull Request resolved: https://github.com/pytorch/pytorch/pull/97322 Approved by: https://github.com/malfet",1,Remove Dead Code,,
d86387654557c24941f9fecb53128b87841f3f37,2023-04-14T14:35:55Z,https://github.com/pytorch/pytorch/commit/d86387654557c24941f9fecb53128b87841f3f37,[SPMD] Remove the unused code (#99075)  Remove the unused code  Differential Revision: [D44973692](https://our.internmc.facebook.com/intern/diff/D44973692/) Pull Request resolved: https://github.com/pytorch/pytorch/pull/99075 Approved by: https://github.com/lessw2020,1,Remove Dead Code,,
da51fd31a58b36c727bbeb1528d5fefdc64d8f14,2021-05-03T03:10:58Z,https://github.com/pytorch/pytorch/commit/da51fd31a58b36c727bbeb1528d5fefdc64d8f14,"fx quant: remove `find_quants` from convert (#57402)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/57402This is a cleanup, the value is not used by anything. It wasprobably left behind after previous refactors.Test Plan:```python test/test_quantization.py TestQuantizeFxpython test/test_quantization.py TestQuantizeFxOps```Imported from OSSReviewed By: jerryzh168Differential Revision: D28133622fbshipit-source-id: 44a3f955d4af8d6dd15b4fb3038188568e4ee549",1,Remove Dead Code,,
dab1e596525e7a1f767e4b207c13836fd009309e,2021-06-16T23:44:16Z,https://github.com/pytorch/pytorch/commit/dab1e596525e7a1f767e4b207c13836fd009309e,Remove dead code in SavedVariable (#59838)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/59838  Test Plan: Imported from OSS  Reviewed By: soulitzer  Differential Revision: D29069214  fbshipit-source-id: 5debf93a6c3d1c3d585efbe54438e8df92646d62,1,Remove Dead Code,,
dc1c0f78e23504b2b5aa8b0a0e1a18459158cc3e,2023-01-18T20:57:52Z,https://github.com/pytorch/pytorch/commit/dc1c0f78e23504b2b5aa8b0a0e1a18459158cc3e,Remove dead TORCHDYNAMO_DYNAMIC_SHAPES print (#92547)  Signed-off-by: Edward Z. Yang <ezyang@meta.com>  Pull Request resolved: https://github.com/pytorch/pytorch/pull/92547 Approved by: https://github.com/albanD,1,Remove Dead Code,,
def01eafc5c1e8f1f4f04b161986ca821f062624,2023-06-15T20:43:57Z,https://github.com/pytorch/pytorch/commit/def01eafc5c1e8f1f4f04b161986ca821f062624,"[BE] Remove unused `dim_plane` from `reflection_pad2d_backward_out_template` (#103680)  Probably introduced by https://github.com/pytorch/pytorch/pull/102254  This fixes `variable 'dim_plane' set but not used ` on my clang-14.0.3 compiler complained about it: ``` /Users/nshulga/git/pytorch/pytorch/aten/src/ATen/native/ReflectionPad.cpp:272:7: error: variable 'dim_plane' set but not used [-Werror,-Wunused-but-set-variable]   int dim_plane = 0;       ^ 1 error generated. ```  <!-- copilot:poem --> ### <samp>🤖 Generated by Copilot at e254b4b</samp>  > _`dim_plane` is gone_ > _Simpler code, no more warning_ > _Autumn leaves fall fast_  Pull Request resolved: https://github.com/pytorch/pytorch/pull/103680 Approved by: https://github.com/kit1980, https://github.com/Skylion007",1,Remove Dead Code,,
def8aa5499065ae554d2c4d692f272f868c9b42b,2021-01-06T03:36:56Z,https://github.com/pytorch/pytorch/commit/def8aa5499065ae554d2c4d692f272f868c9b42b,"Remove cpu half and dead code from multinomial (#50063)Summary:Based on ngimel's (Thank you!) feedback, cpu half was only accidental, so I'm removing it.This lets us ditch the old codepath for without replacement in favour of the new, better one.Pull Request resolved: https://github.com/pytorch/pytorch/pull/50063Reviewed By: mruberryDifferential Revision: D25772449Pulled By: ngimelfbshipit-source-id: 608729c32237de4ee6d1acf7e316a6e878dac7f0",1,Remove Dead Code,,
e1ee3bfc0e50e093d95c5f0b69aa641e007a2991,2020-11-12T15:55:33Z,https://github.com/pytorch/pytorch/commit/e1ee3bfc0e50e093d95c5f0b69aa641e007a2991,"Port bmm and baddbmm from TH to ATen (#42553)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/42553Ports `torch.bmm` and `torch.baddbmm` from TH to ATen, as well as adds support for complex dtypes. Also removes dead TH code for Level 2 functions.Closes #24539Test Plan: Imported from OSSReviewed By: ansleyDifferential Revision: D24893511Pulled By: anjali411fbshipit-source-id: 0eba3f2aec99c48b3018a5264ee7789279cfab58",1,Remove Dead Code,,
e3e7b76310612f2d372e8340c12c758565e24e8a,2017-01-31T21:34:33Z,https://github.com/pytorch/pytorch/commit/e3e7b76310612f2d372e8340c12c758565e24e8a,Rename all normal and log_normal args to std,1,Remove Dead Code,,
e47af44eb81b9cd0c3583de91b0a2d4f56a5cf8d,2022-12-03T17:55:27Z,https://github.com/pytorch/pytorch/commit/e47af44eb81b9cd0c3583de91b0a2d4f56a5cf8d,[FSDP][Easy] Remove unused methods (#89229)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/89229 Approved by: https://github.com/mrshenli,1,Remove Dead Code,,
e48db02e10d4632bc650e4a83157d2f5bfc4f2dc,2017-04-07T00:38:45Z,https://github.com/pytorch/pytorch/commit/e48db02e10d4632bc650e4a83157d2f5bfc4f2dc,remove unused python-level BatchNorm.py,1,Remove Dead Code,,
e51e651255c80de90788fe8bde6d05bb6858f8b3,2016-12-22T22:54:42Z,https://github.com/pytorch/pytorch/commit/e51e651255c80de90788fe8bde6d05bb6858f8b3,Remove redundant and failing test of FeedBlob assertsSummary: Recently a PR landed that removed asserts of trying to feed float64 to FeedBlob for GPUs and changed to a warning. Thus the test testing assertions were given started to fail. Removing it.Reviewed By: YangqingDifferential Revision: D4363780fbshipit-source-id: d9e222c309302243138d4ff3c223c711a4d2052d,1,Remove Dead Code,,
e53a0e391b092733aa143e00d40ce95962182900,2022-12-03T03:03:13Z,https://github.com/pytorch/pytorch/commit/e53a0e391b092733aa143e00d40ce95962182900,[Easy] Remove unused parametrization (#90079)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/90079 Approved by: https://github.com/awgu,1,Remove Dead Code,,
e53b28867987cecc0ff7e2466d7f6c66ad3b55d8,2023-05-05T16:15:56Z,https://github.com/pytorch/pytorch/commit/e53b28867987cecc0ff7e2466d7f6c66ad3b55d8,remove unused filter_map utility (#100647)  remove unused filter_map utility  Test Plan: Verified unused with `git grep`.  --- Stack created with [Sapling](https://sapling-scm.com). Best reviewed with [ReviewStack](https://reviewstack.dev/pytorch/pytorch/pull/100647). * #100649 * __->__ #100647 Pull Request resolved: https://github.com/pytorch/pytorch/pull/100647 Approved by: https://github.com/ezyang,1,Remove Dead Code,,
e613a419ed2e8711a38ee22fc6580096907e397b,2023-04-14T03:11:25Z,https://github.com/pytorch/pytorch/commit/e613a419ed2e8711a38ee22fc6580096907e397b,"Remove dead wrap_sym (#99049)  I'm pretty sure this isn't used by anything  Signed-off-by: Edward Z. Yang <ezyang@meta.com>  Pull Request resolved: https://github.com/pytorch/pytorch/pull/99049 Approved by: https://github.com/Skylion007, https://github.com/voznesenskym",1,Remove Dead Code,,
e958ceb5d7b610c81fce0ebc774af7a288d377c8,2019-04-13T15:28:13Z,https://github.com/pytorch/pytorch/commit/e958ceb5d7b610c81fce0ebc774af7a288d377c8,Remove GraphExecutor's python bindings (#19141)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/19141ghimport-source-id: 796a41f5514d29959af052fcf5391a2834850a80Reviewed By: jamesr66aDifferential Revision: D14888702Pulled By: zdevitofbshipit-source-id: c280145f08e7bc210434d1c99396a3257b626cf9,1,Remove Dead Code,,
ebf36ad3da70c32370d3719ec7e792b95e7128d1,2020-11-02T22:58:55Z,https://github.com/pytorch/pytorch/commit/ebf36ad3da70c32370d3719ec7e792b95e7128d1,"Remove travis-python references as well as some unnecessary dependencies (#47209)Summary:This PR attempts to remove unneeded installations of `pip` among other packages in `install_base.sh` since these very same packages are already installed elsewhere (for example in `install_conda.sh`).In the process, I found some old `TRAVIS_PYTHON_VERSION` references that are no longer needed, so I removed all references that need `install_travis_python.sh`Pull Request resolved: https://github.com/pytorch/pytorch/pull/47209Reviewed By: mruberryDifferential Revision: D24690079Pulled By: janeyx99fbshipit-source-id: f8fef4cda9832c868595d4745d811fc7d42df34d",1,Remove Dead Code,,
f2b3f0ab5c4e94b6b40c01f82eb9a47e3019660b,2017-02-09T08:58:40Z,https://github.com/pytorch/pytorch/commit/f2b3f0ab5c4e94b6b40c01f82eb9a47e3019660b,remove decode()Summary: This should not be needed any more since we use pybind. It will help python3 migration.Reviewed By: salexspbDifferential Revision: D4535490fbshipit-source-id: a47615f73b5c35b940d21bb2d5d55060fa0850be,1,Remove Dead Code,,
f5b4e369f6fd37dcccc39d32ac020d724e6ed0a6,2021-09-27T20:51:49Z,https://github.com/pytorch/pytorch/commit/f5b4e369f6fd37dcccc39d32ac020d724e6ed0a6,Sparse SoftMax: Remove unused variables (#65539)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/65539  This function doesn't directly use thrust so these are simply unused variables.  Test Plan: Imported from OSS  Reviewed By: gchanan  Differential Revision: D31193191  Pulled By: malfet  fbshipit-source-id: 231b6a197c9f1bd5a61e46cb858e8eedc85b2818,1,Remove Dead Code,,
f6adbf4d97b1150d7d153f23f50253683445d450,2023-02-13T16:33:40Z,https://github.com/pytorch/pytorch/commit/f6adbf4d97b1150d7d153f23f50253683445d450,ao migration: delete unused test class (#94420)  Summary:  This test case is dead code.  A newer version of this code exists in `test/quantization/ao_migration/test_quantization.py`. I think this class must have been mistakenly left during a refactor. Deleting it.  Test plan: CI Pull Request resolved: https://github.com/pytorch/pytorch/pull/94420 Approved by: https://github.com/jerryzh168,1,Remove Dead Code,,
f76d0e1b82e4103abb3b411aacf597a3d0163e91,2023-05-05T22:25:43Z,https://github.com/pytorch/pytorch/commit/f76d0e1b82e4103abb3b411aacf597a3d0163e91,remove unused extract_arg_by_filtered_index utility (#100649)  remove unused extract_arg_by_filtered_index utility  Test Plan: Verified unused with `git grep`.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/100649 Approved by: https://github.com/ezyang,1,Remove Dead Code,,
fa7f17799a8417b3e450ddf99cb53bf01e82cae5,2023-02-26T06:18:31Z,https://github.com/pytorch/pytorch/commit/fa7f17799a8417b3e450ddf99cb53bf01e82cae5,[3/N][BE][ST Deprecate] Remove Replicated Tensor (#95453)  Please use distributed tensor instead. We are deprecating ShardedTensor.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/95453 Approved by: https://github.com/wanchaol,1,Remove Dead Code,,
fd67f6b463b7ceec5a4aab9c6c550765fa375af8,2019-03-12T00:23:27Z,https://github.com/pytorch/pytorch/commit/fd67f6b463b7ceec5a4aab9c6c550765fa375af8,Remove remaining IR Expect files (#17886)Summary:Last batch of IR expect files removed. Includes some removal of expect files that are no longer used.Pull Request resolved: https://github.com/pytorch/pytorch/pull/17886Differential Revision: D14414435Pulled By: eellisonfbshipit-source-id: 0bfd7ce66ac2f72a57f15f45ebd60b95e80b6c16,1,Remove Dead Code,,
ff9a809ccd5bd61f18dfaa04d41b681e600b3a02,2020-05-08T18:00:31Z,https://github.com/pytorch/pytorch/commit/ff9a809ccd5bd61f18dfaa04d41b681e600b3a02,[quant][graphmode][refactor] Remove unused code in quantization.cpp (#37974)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/37974Differential Revision: D21468498Pulled By: jerryzh168fbshipit-source-id: 96f34db9f98474ec8e5d33e9b7c406b1637f5de8,1,Remove Dead Code,,
ff9d1aeab5d943cfb549cd3257ab7129a624b1e9,2017-12-28T23:34:53Z,https://github.com/pytorch/pytorch/commit/ff9d1aeab5d943cfb549cd3257ab7129a624b1e9,removes duplicate variable reference crash from pad_sequences (#4383),1,Remove Dead Code,,
a7afba7308bc48c602cea48a0ec7df61749239f9,2018-07-24T17:14:08Z,https://github.com/pytorch/pytorch/commit/a7afba7308bc48c602cea48a0ec7df61749239f9,"Remove duplicated functions (#9601)Summary:found by linter, duplication was likely introduced in previous code syncPull Request resolved: https://github.com/pytorch/pytorch/pull/9601Differential Revision: D8922379Pulled By: bddppqfbshipit-source-id: 1f61bd7f539d823e62920615674a532ec0149623",1,Remove Dead Code,,
aa842fe1013207477f4444e1d8d86527fb51f2d1,2018-11-30T17:31:07Z,https://github.com/pytorch/pytorch/commit/aa842fe1013207477f4444e1d8d86527fb51f2d1,clean up linkage options (#14609)Summary: minor code cleanupDifferential Revision: D13277803Pulled By: soumithfbshipit-source-id: 5ef925fe95037cab540b329054d7070c1ea7031e,1,Remove Dead Code,,
ab035d01e386363eb87a97b39825b932a662a6fb,2019-02-06T05:09:06Z,https://github.com/pytorch/pytorch/commit/ab035d01e386363eb87a97b39825b932a662a6fb,Remove unnecessary typing import. (#16777)Summary:Signed-off-by: Edward Z. Yang <ezyang@fb.com>Pull Request resolved: https://github.com/pytorch/pytorch/pull/16777Differential Revision: D13969679Pulled By: ezyangfbshipit-source-id: d4728797a5927ae32628621c654eadb93c0e7682,1,Remove Dead Code,,
b02c932fb67717cb26d6258908541b670faa4e72,2020-06-23T00:43:46Z,https://github.com/pytorch/pytorch/commit/b02c932fb67717cb26d6258908541b670faa4e72,"qat eager: remove unneeded modules (#40396)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/40396Removes activation and normalization modules from eager mode QAT.These were incorrectly added, but we don't actually need them.Test Plan:```python test/test_quantization.py TestQuantizationAwareTraining```Imported from OSSDifferential Revision: D22169768fbshipit-source-id: b5bd753dafe92e90e226fb773eb18c6aae179703",1,Remove Dead Code,,
b10a3e916f47a01a9ee5a6455a9412f822204086,2019-08-15T20:37:06Z,https://github.com/pytorch/pytorch/commit/b10a3e916f47a01a9ee5a6455a9412f822204086,Remove redundant assignment (#24408)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/24408As Title says.ghstack-source-id: 88388745Differential Revision: D16830709fbshipit-source-id: 87eafcd3236abcec94cf87009fc705ad26d87eca,1,Remove Dead Code,,
b335f3910fe1a36c3fb84452db5b0907c79e0650,2019-07-29T15:04:33Z,https://github.com/pytorch/pytorch/commit/b335f3910fe1a36c3fb84452db5b0907c79e0650,"Remove redundant MSVC_Z7_OVERRIDE processing and combine ""/EHa"" flag setup (#23455)Summary:- MSVC_Z7_OVERRIDE has already handled in CMakeLists.txt. No need to process it for once more in the Python scripts.- Option MSVC_Z7_OVERRIDE should be visible to the user only if MSVC is used.- Move the setting of ""/EHa"" flag to CMakeLists.txt, where other MSVC-specific flags are processed. This also further prepares the removal of redundant cflags setup in Python build scripts.Pull Request resolved: https://github.com/pytorch/pytorch/pull/23455Differential Revision: D16542274Pulled By: ezyangfbshipit-source-id: 4d3b8b07161478bbba8a21feb6ea24c9024e21ac",1,Remove Dead Code,,
cb689a5d68a9c4c203f0d3dffbb1ef2cb7d2a506,2020-03-10T16:04:58Z,https://github.com/pytorch/pytorch/commit/cb689a5d68a9c4c203f0d3dffbb1ef2cb7d2a506,remove duplicated process group gloo timeout (#31342)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/31342Test Plan: unit testDifferential Revision: D19131704fbshipit-source-id: 4e91d5933635ee2c7c301caf89a5a7009c5cb7c8,1,Remove Dead Code,,
ce1a9653a86dfac7d61c751d9aba1afcd098e385,2019-06-25T14:15:07Z,https://github.com/pytorch/pytorch/commit/ce1a9653a86dfac7d61c751d9aba1afcd098e385,Remove more build options not needed to be explicitly set in Python build scripts. (#22153)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/22153ghimport-source-id: 129d90626a8e64079477a744fbbaba58e139a852Test Plan: Imported from OSSDifferential Revision: D15985375Pulled By: ezyangfbshipit-source-id: 925bb1c886633b002beb1da0754bb055aa971e21,1,Remove Dead Code,,
d613bd0522d51602ccf8cb29d00eb26cf3af923d,2020-02-13T17:12:21Z,https://github.com/pytorch/pytorch/commit/d613bd0522d51602ccf8cb29d00eb26cf3af923d,"[rpc][easy] move unnecessary python call directly to pybind (#33174)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/33174Closes https://github.com/pytorch/pytorch/issues/32780. It looks likethis is the only callsite where we do `_get_current_rpc_agent().foo()`, and wecan do this directly in the pybind layer to save some overhead.ghstack-source-id: 98200664Test Plan: All UTs should pass.Differential Revision: D19828786fbshipit-source-id: 5c34a96b5a970e57e6a1fdf7f6e54c1f6b88f3d8",1,Remove Dead Code,,
d6ce6570f96e8edbf450728a5bfa080f181bcba0,2020-04-24T22:08:39Z,https://github.com/pytorch/pytorch/commit/d6ce6570f96e8edbf450728a5bfa080f181bcba0,"Remove unused imports in aten/src/ATen/function_wrapper.py (#37245)Summary:typing is available since Python 3.5, no need to try-import.Pull Request resolved: https://github.com/pytorch/pytorch/pull/37245Differential Revision: D21236650Pulled By: albanDfbshipit-source-id: daf150103835d0c6cd3c39300044e548bb6d311d",1,Remove Dead Code,,
e0a5b443d6154c9ea1294d3da2343e69d0a8b4c1,2020-04-29T00:12:37Z,https://github.com/pytorch/pytorch/commit/e0a5b443d6154c9ea1294d3da2343e69d0a8b4c1,[pytorch] remove unused flags from code analyzer & move format support to python (#37393)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/37393Simplify the code analyzer by removing some unused flags and moving thedifferent format printer logic to python script. It's easier to add otherpost processing logic to adapt to different BUCK build configs.Test Plan: Imported from OSSDifferential Revision: D21280836Pulled By: ljk53fbshipit-source-id: 0d66d5891d850f012c4ab4f39eabbd9aecc1caa9,1,Remove Dead Code,,
e41eb4332783ce32d26fdf3418688a583a5cc478,2018-07-27T03:48:55Z,https://github.com/pytorch/pytorch/commit/e41eb4332783ce32d26fdf3418688a583a5cc478,"Remove deprecated masked_copy (#9819)Summary:No tests are affected by this removal.Closes https://github.com/pytorch/pytorch/issues/1885 and closes #9817While I was at it, I also fixed #9876 .Pull Request resolved: https://github.com/pytorch/pytorch/pull/9819Differential Revision: D9018126Pulled By: SsnLfbshipit-source-id: a9142bf4e2403bef05779a097f61fa8b7db04b71",1,Remove Dead Code,,
e979b7c940d034495ebff3b8ceb77a443330beef,2018-01-24T04:43:28Z,https://github.com/pytorch/pytorch/commit/e979b7c940d034495ebff3b8ceb77a443330beef,Removed redundant import re (#4826),1,Remove Dead Code,,
eb7843ed01512f01017b3024991ea8486c857b70,2020-06-10T19:41:05Z,https://github.com/pytorch/pytorch/commit/eb7843ed01512f01017b3024991ea8486c857b70,[quantization] Remove duplicated piece of code in test (just a nit). (#39770)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/39770Remove duplicated piece of code in test (just a nit).Test Plan: buck test test:quantizationReviewed By: supriyarDifferential Revision: D21967877fbshipit-source-id: 48a2d60e108fb9ddfa98e30888cf45744905277d,1,Remove Dead Code,,
f09054f8d09cca58e3ef63568b18977e66ca56a6,2018-09-15T00:45:51Z,https://github.com/pytorch/pytorch/commit/f09054f8d09cca58e3ef63568b18977e66ca56a6,"Remove deprecate warning for Upsampling (#11568)Summary:Fixes #11452 .Based on the discussion with SsnL  and soumith , we want to bring back Upsample as a module instead of introducing a new nn.interpolate module for now. If anyone want to do downsample, they should use `nn.functional.interpolate ` instead.Pull Request resolved: https://github.com/pytorch/pytorch/pull/11568Differential Revision: D9804359Pulled By: ailzhangfbshipit-source-id: 2b232d55fc83c2b581bf336f1ee8d1cf1c1159ca",1,Remove Dead Code,,
36c50736017aeb114f9586b1e1b56779dee03749,2023-07-27T17:43:45Z,https://github.com/scikit-learn/scikit-learn/commit/36c50736017aeb114f9586b1e1b56779dee03749,MNT (SLEP6) remove other_params from provess_routing (#26909)  Co-authored-by: Thomas J. Fan <thomasjpfan@gmail.com>,1,Remove Dead Code,Rename Variable,
4e679023eb63fff9aa611ed7189fad7581b742a0,2023-07-17T10:26:41Z,https://github.com/scikit-learn/scikit-learn/commit/4e679023eb63fff9aa611ed7189fad7581b742a0,CLN clean up some repeated code related to SLEP006 (#26836)  Co-authored-by: Omar Salman <omar.salman@arbisoft.com>,1,Remove Dead Code,,
dfd299b19e1e4a167023cac76c8e1c57c01341a9,2023-07-12T16:34:01Z,https://github.com/scikit-learn/scikit-learn/commit/dfd299b19e1e4a167023cac76c8e1c57c01341a9,MAINT Remove soon-to-be deprecated scipy.sparse functions (#26751),1,Remove Dead Code,,
7437d9522a39588b8ac73fdf006d47dbafc94c3d,2023-07-10T15:01:32Z,https://github.com/scikit-learn/scikit-learn/commit/7437d9522a39588b8ac73fdf006d47dbafc94c3d,MNT clean up old scipy sparse.linalg.cg fallback code (#26813),1,Remove Dead Code,,
168b4e714d48406686220e28226842930329fcf6,2023-06-09T04:02:23Z,https://github.com/scikit-learn/scikit-learn/commit/168b4e714d48406686220e28226842930329fcf6,MAINT Clean up leftovers from previous deprecations clean up PRs (#26545)  Co-authored-by: Olivier Grisel <olivier.grisel@ensta.org>,1,Remove Dead Code,,
9be4d8d897ad38b64e9cb0368f37ea545ed9b5a2,2023-06-01T14:57:13Z,https://github.com/scikit-learn/scikit-learn/commit/9be4d8d897ad38b64e9cb0368f37ea545ed9b5a2,MAINT Remove outdated fixes (#26442),1,Remove Dead Code,,
1415a2890b0451d80feef2d81e921a15d2b9d680,2023-05-30T07:26:11Z,https://github.com/scikit-learn/scikit-learn/commit/1415a2890b0451d80feef2d81e921a15d2b9d680,ENH Remove unnecessary OOB computation when n_more_estimators == 0 (#26318)  Co-authored-by: Guillaume Lemaitre <g.lemaitre58@gmail.com>,1,Remove Dead Code,,
ae35ce83679ccef74932fbfe554d1e1ea63ff6fa,2023-05-02T19:37:13Z,https://github.com/scikit-learn/scikit-learn/commit/ae35ce83679ccef74932fbfe554d1e1ea63ff6fa,MNT remove unused args in _predict_regression_tree_inplace_fast_dense (#26314),1,Remove Dead Code,,
9e47147a174e5bc31718f55855b8afd82e89ab90,2023-03-29T14:30:45Z,https://github.com/scikit-learn/scikit-learn/commit/9e47147a174e5bc31718f55855b8afd82e89ab90,MAINT remove unecessary check covered by parameter validation framework (#26014),1,Remove Dead Code,,
9679dcf015047b33b6189f79a0a7c5baac129913,2023-03-23T14:13:48Z,https://github.com/scikit-learn/scikit-learn/commit/9679dcf015047b33b6189f79a0a7c5baac129913,MAINT remove deprecated call to resources.content (#25951),1,Remove Dead Code,,
ef5c0879e1367397f671791cdfad46eef8892826,2023-02-28T17:31:31Z,https://github.com/scikit-learn/scikit-learn/commit/ef5c0879e1367397f671791cdfad46eef8892826,MAINT Remove redundant sparse square euclidian distances function (#25731),1,Remove Dead Code,,
5ba1fee683243bb60cc068f4f0942b98186799a3,2023-02-27T19:32:35Z,https://github.com/scikit-learn/scikit-learn/commit/5ba1fee683243bb60cc068f4f0942b98186799a3,MAINT Remove -Wcpp warnings when compiling arrayfuncs (#25415)  Co-authored-by: Thomas J. Fan <thomasjpfan@gmail.com>,1,Remove Dead Code,,
28f8c873917d2ee0d92bb43172a30713d01516b3,2023-02-11T16:35:01Z,https://github.com/scikit-learn/scikit-learn/commit/28f8c873917d2ee0d92bb43172a30713d01516b3,MAINT Removes ReadOnlyWrapper (#25586),1,Remove Dead Code,,
f9a1cf072da9d7375d6c2163f68a6038b13b310f,2023-02-09T18:52:44Z,https://github.com/scikit-learn/scikit-learn/commit/f9a1cf072da9d7375d6c2163f68a6038b13b310f,MAINT Remove ReadonlyArrayWrapper from _loss module (#25555)  * MAINT Remove ReadonlyArrayWrapper from _loss module  * CLN Remove comments about Cython 3.0,1,Remove Dead Code,,
fdbe4413b78e39699d165b35a2d7a40e5ff67890,2023-01-11T16:20:19Z,https://github.com/scikit-learn/scikit-learn/commit/fdbe4413b78e39699d165b35a2d7a40e5ff67890,CI Remove unused env var (#25359),1,Remove Dead Code,,
ba1d23d13e402367c6401e07256867fdd5a4a0bf,2023-01-05T17:31:47Z,https://github.com/scikit-learn/scikit-learn/commit/ba1d23d13e402367c6401e07256867fdd5a4a0bf,TST Remove ConvergenceWarnings in test_logistic (#25062)  Co-authored-by: Julien Jerphanion <git@jjerphan.xyz>,1,Remove Dead Code,,
96a0bc861ad2ba3c63db0326b42b41ddabeb2aff,2022-12-31T15:59:24Z,https://github.com/scikit-learn/scikit-learn/commit/96a0bc861ad2ba3c63db0326b42b41ddabeb2aff,ENH remove redundant expr in min_max_dist (#25262),1,Remove Dead Code,,
6227ee1de70fa85ba0e99fca655f634677dc41c1,2022-12-28T14:10:40Z,https://github.com/scikit-learn/scikit-learn/commit/6227ee1de70fa85ba0e99fca655f634677dc41c1,MNT Remove unneeded computation (#25194),1,Remove Dead Code,,
4dde64d61e6e172da466cc7b7eaa21b832b96fbb,2022-12-02T13:51:28Z,https://github.com/scikit-learn/scikit-learn/commit/4dde64d61e6e172da466cc7b7eaa21b832b96fbb,"MAINT Remove warnings in vendored `lib{linear,svm}` C++ code (#24998)",1,Remove Dead Code,,
7c2a58d51f4528827e9bfe9c43d06c5c1716bfb8,2022-10-20T14:20:45Z,https://github.com/scikit-learn/scikit-learn/commit/7c2a58d51f4528827e9bfe9c43d06c5c1716bfb8,CI Remove remaining windows 32 references (#24657)  Co-authored-by: Julien Jerphanion <git@jjerphan.xyz> Co-authored-by: Olivier Grisel <olivier.grisel@ensta.org>,1,Remove Dead Code,,
8648cf9218945b8cb1d078ced0edc7bfde0aa5f2,2022-10-13T12:54:53Z,https://github.com/scikit-learn/scikit-learn/commit/8648cf9218945b8cb1d078ced0edc7bfde0aa5f2,MAINT clean deprecation for 1.2: leftovers (#24647),1,Remove Dead Code,,
c22be1defcf3e59ebd79ed3e479ada8ea558f601,2022-10-07T09:07:24Z,https://github.com/scikit-learn/scikit-learn/commit/c22be1defcf3e59ebd79ed3e479ada8ea558f601,CLN Remove unnecessary operation in mutual_info (#24569),1,Remove Dead Code,,
aca8f20db461ca0dd70b02b6a1f41b957b2b12ee,2022-10-06T15:11:46Z,https://github.com/scikit-learn/scikit-learn/commit/aca8f20db461ca0dd70b02b6a1f41b957b2b12ee,CLN Remove unneeded variable definition in DictVectorizer.fit (#24590),1,Remove Dead Code,,
6a1a4d63db0c69104dddac3170e777e42e9517f4,2022-10-06T11:10:57Z,https://github.com/scikit-learn/scikit-learn/commit/6a1a4d63db0c69104dddac3170e777e42e9517f4,CI remove LGTM (#24592),1,Remove Dead Code,,
df626e43ac3c99da2aeb005709d77395bd717e6a,2022-09-30T18:34:07Z,https://github.com/scikit-learn/scikit-learn/commit/df626e43ac3c99da2aeb005709d77395bd717e6a,MAINT remove redundant items from iterable (#24554),1,Remove Dead Code,,
ad91259f20529306efe445f5a1da4dccc8c81b5a,2022-09-15T15:36:50Z,https://github.com/scikit-learn/scikit-learn/commit/ad91259f20529306efe445f5a1da4dccc8c81b5a,ENH Remove validation from `__init__` for `SGDOneClassSVM` (#24433)    Co-authored-by: iofall <50991099+iofall@users.noreply.github.com> Co-authored-by: arisayosh <15692997+arisayosh@users.noreply.github.com>,1,Remove Dead Code,,
b4f51fd1569a0b90d56061f678f2f4fa7b04bf5e,2022-09-08T15:15:06Z,https://github.com/scikit-learn/scikit-learn/commit/b4f51fd1569a0b90d56061f678f2f4fa7b04bf5e,MAINT Clean deprecation for 1.2: n_features_ replaced by n_featues_in_ (#24388),1,Remove Dead Code,,
1a6f9b6414e5aefadfa2f923f939d370db917ae0,2022-09-07T12:50:31Z,https://github.com/scikit-learn/scikit-learn/commit/1a6f9b6414e5aefadfa2f923f939d370db917ae0, TST Remove remaining tests now covered by common param validation test (#24383),1,Remove Dead Code,,
60f16feaadaca28f9a1cc68d2f406201860d27e8,2022-09-05T20:15:30Z,https://github.com/scikit-learn/scikit-learn/commit/60f16feaadaca28f9a1cc68d2f406201860d27e8,MAINT Remove `x_squared_norms` arg from `k_means_lloyd` signature (#24264)  Co-authored-by: Thomas J. Fan <thomasjpfan@gmail.com>,1,Remove Dead Code,,
2f65ac764be40e2420817cbeca3301c8d664baa3,2022-09-05T08:39:20Z,https://github.com/scikit-learn/scikit-learn/commit/2f65ac764be40e2420817cbeca3301c8d664baa3,MAINT clean-up unused variables and imports in cython files (#24347),1,Remove Dead Code,,
411416149fa2fa5e95f6fe7a874e5455fea7f582,2022-09-01T16:38:40Z,https://github.com/scikit-learn/scikit-learn/commit/411416149fa2fa5e95f6fe7a874e5455fea7f582,MAINT Param validation: remove n_estimators checks from validate_estimator (#24224)  Co-authored-by: Meekail Zain <34613774+Micky774@users.noreply.github.com> Co-authored-by: jeremie du boisberranger <jeremiedbb@yahoo.fr>,1,Remove Dead Code,,
47f3c37c1c820f59e16fe1bb6f6ac1bfd3560c56,2022-06-16T10:40:35Z,https://github.com/scikit-learn/scikit-learn/commit/47f3c37c1c820f59e16fe1bb6f6ac1bfd3560c56,MNT Removed object dtype validation in `check_array` for scipy nightly (#23641)    Co-authored-by: Olivier Grisel <olivier.grisel@ensta.org> Co-authored-by: Loïc Estève <loic.esteve@ymail.com>,1,Remove Dead Code,,
4b9d5904752b4781e92988c4fdb09cb87b7a0e36,2022-06-16T06:41:19Z,https://github.com/scikit-learn/scikit-learn/commit/4b9d5904752b4781e92988c4fdb09cb87b7a0e36,MAINT remove deprecated sym_pos argument in scipy.linalg.solve (#23617),1,Remove Dead Code,,
38d23c4de5acee458bf1dc6aaeb6d86a86b7ace1,2022-05-25T20:40:34Z,https://github.com/scikit-learn/scikit-learn/commit/38d23c4de5acee458bf1dc6aaeb6d86a86b7ace1,MNT Removed `_safe_accumulator_op` for first-pass algorithm in `_assert_all_finite` (#23446)  Co-authored-by: Olivier Grisel <olivier.grisel@ensta.org>,1,Remove Dead Code,,
a7bbba1fbae4e2de2ab941eacb6bda046deca120,2022-05-13T16:37:51Z,https://github.com/scikit-learn/scikit-learn/commit/a7bbba1fbae4e2de2ab941eacb6bda046deca120,MNT Removes unneeded np imports in cython files (#23364),1,Remove Dead Code,,
35d5b97ff000027bc4ea25197ee5b3f94373c471,2022-05-12T09:28:53Z,https://github.com/scikit-learn/scikit-learn/commit/35d5b97ff000027bc4ea25197ee5b3f94373c471,MNT Removes pytest.warns(None) in test_validation (#23282),1,Remove Dead Code,,
85e7a32ec9c2c84e49b19a4efaf7ba639436ecbb,2022-04-29T09:03:48Z,https://github.com/scikit-learn/scikit-learn/commit/85e7a32ec9c2c84e49b19a4efaf7ba639436ecbb,remove redundant lambda function (#23232),1,Remove Dead Code,,
f5044bdc7967011c39d16660192b1f265a960c4c,2022-04-23T19:20:19Z,https://github.com/scikit-learn/scikit-learn/commit/f5044bdc7967011c39d16660192b1f265a960c4c,CLN Remove unnecessary code from DecisionBoundaryDisplay (#23192),1,Remove Dead Code,,
cf017ac03cf08233f1f64ce242bd2b27d6f583c7,2022-04-12T17:36:15Z,https://github.com/scikit-learn/scikit-learn/commit/cf017ac03cf08233f1f64ce242bd2b27d6f583c7,CI Removes manylinux2010 since SciPy does not support it in 1.8 (#23121),1,Remove Dead Code,,
8cf07020a9c96eaf7684e6f26fb3daecfca93713,2022-04-06T17:32:35Z,https://github.com/scikit-learn/scikit-learn/commit/8cf07020a9c96eaf7684e6f26fb3daecfca93713,TST Remove deprecation warnings pytest in test_pipeline.py (#23037)  Co-authored-by: Marie <marie.sacksick@cybelangel.com>,1,Remove Dead Code,,
a5c90f8abde028635d0a109596cc53a7d586bedf,2022-03-18T13:52:32Z,https://github.com/scikit-learn/scikit-learn/commit/a5c90f8abde028635d0a109596cc53a7d586bedf,MNT Removes externals._pilutil and uses Pillow directly (#22743),1,Remove Dead Code,,
3d326aad0a5dbb1daaec01a2e2053c028a1c4b82,2022-03-03T09:31:50Z,https://github.com/scikit-learn/scikit-learn/commit/3d326aad0a5dbb1daaec01a2e2053c028a1c4b82,MAINT Remove deprecated exceptions for 1.1 (#22659),1,Remove Dead Code,,
d135a0f8db4edb52594203d982fa046db7bf4c1b,2022-03-03T09:31:02Z,https://github.com/scikit-learn/scikit-learn/commit/d135a0f8db4edb52594203d982fa046db7bf4c1b,MNT additional cleaning in test for 1.1 (#22661),1,Remove Dead Code,,
33e4843e8839b87defcebe966063c5d04736854e,2022-03-02T13:01:51Z,https://github.com/scikit-learn/scikit-learn/commit/33e4843e8839b87defcebe966063c5d04736854e,MNT remaining clean up for 1.1 (#22643),1,Remove Dead Code,,
da682de395002c4b22dcacbae25dcf5d4b0b258e,2022-02-24T15:47:03Z,https://github.com/scikit-learn/scikit-learn/commit/da682de395002c4b22dcacbae25dcf5d4b0b258e,"MNT Removes duplicates in neighbors.VALID_METRICS[""brute""](#22602)  Co-authored-by: akiyuki ishikawa <aki.y.ishikwa@gmail.com> Co-authored-by: Jérémie du Boisberranger <34657725+jeremiedbb@users.noreply.github.com>",1,Remove Dead Code,,
9abeb861ecbf348447cf711cea1735c3f5bca8a7,2022-02-19T11:16:03Z,https://github.com/scikit-learn/scikit-learn/commit/9abeb861ecbf348447cf711cea1735c3f5bca8a7,MNT Remove unused private attribute _residues from LinearRegression (#22334),1,Remove Dead Code,,
229bd226ab0d18c0ea84c598cd87d86f599eaac8,2022-02-09T15:58:01Z,https://github.com/scikit-learn/scikit-learn/commit/229bd226ab0d18c0ea84c598cd87d86f599eaac8,MNT remove _pairwise attribute (#21594),1,Remove Dead Code,,
02087e13084e95e17c26cd35b6152e0c833e6052,2022-02-08T19:44:05Z,https://github.com/scikit-learn/scikit-learn/commit/02087e13084e95e17c26cd35b6152e0c833e6052,MNT remove deprecated attributes in PLS (#21585),1,Remove Dead Code,,
392151b63491d60daabc4a8fa9b43a71b8df811d,2022-01-29T10:08:03Z,https://github.com/scikit-learn/scikit-learn/commit/392151b63491d60daabc4a8fa9b43a71b8df811d,MNT remove coef_ and intercept_ from OneVsRestClassifier (#21581),1,Remove Dead Code,,
1ba0f54c7c3df5c34d73cef1f77a885c0629f7cb,2022-01-29T10:07:27Z,https://github.com/scikit-learn/scikit-learn/commit/1ba0f54c7c3df5c34d73cef1f77a885c0629f7cb,MNT remove deprecated attributes in KMeans (#21583),1,Remove Dead Code,,
c3dd4051dda40b28877877a2405806c77502c18d,2022-01-28T20:37:46Z,https://github.com/scikit-learn/scikit-learn/commit/c3dd4051dda40b28877877a2405806c77502c18d,MNT remove coef_ and intercept_ form discrete NaiveBayes (#21582),1,Remove Dead Code,,
31aa26b73e74d70adaa29f6eeb6bbe2ffc3b6325,2022-01-28T20:00:44Z,https://github.com/scikit-learn/scikit-learn/commit/31aa26b73e74d70adaa29f6eeb6bbe2ffc3b6325,MNT remove mae criterion is GBDT (#21588),1,Remove Dead Code,,
8fbb20eabf5809631c46baec74f60a9ee1a52495,2022-01-28T19:35:49Z,https://github.com/scikit-learn/scikit-learn/commit/8fbb20eabf5809631c46baec74f60a9ee1a52495,MNT remove deprecated attribute from GraphicalLassoCV (#21584),1,Remove Dead Code,,
f8f77b4acca401904f6e7332bea55067f9d1e797,2021-11-24T18:18:47Z,https://github.com/scikit-learn/scikit-learn/commit/f8f77b4acca401904f6e7332bea55067f9d1e797,MNT remove deprecated components_ in SparseCoder (#21586),1,Remove Dead Code,,
2330c4c4652074609b614c193ac90d131a68dac5,2021-11-24T10:11:10Z,https://github.com/scikit-learn/scikit-learn/commit/2330c4c4652074609b614c193ac90d131a68dac5,MNT remove deprecated kind='legacy' in partial_dependence (#21589)  Co-authored-by: Julien Jerphanion <git@jjerphan.xyz>,1,Remove Dead Code,,
cd9c63916174fdc937148b8ecadeaf9dbe55ebb1,2021-11-15T14:35:29Z,https://github.com/scikit-learn/scikit-learn/commit/cd9c63916174fdc937148b8ecadeaf9dbe55ebb1,MNT remove deprecated calibrators_ from _CalibratedClassifier (#21580),1,Remove Dead Code,,
cc81c4f2ba3b404251fc65618746432420b17e0a,2021-11-08T07:08:43Z,https://github.com/scikit-learn/scikit-learn/commit/cc81c4f2ba3b404251fc65618746432420b17e0a,MNT remove X_idx_sorted parameter in decision trees (#21593),1,Remove Dead Code,,
d128e794698b0214af46fad721fd0e3262ab2579,2021-11-03T17:16:09Z,https://github.com/scikit-learn/scikit-learn/commit/d128e794698b0214af46fad721fd0e3262ab2579,MNT remove unecessary isintance Pipeline (#21540),1,Remove Dead Code,,
d4129527d3e86e34e898885ee8640e2c65900f47,2021-10-27T20:09:11Z,https://github.com/scikit-learn/scikit-learn/commit/d4129527d3e86e34e898885ee8640e2c65900f47,TST Simplify the test and remove empty DOCSTRING_IGNORE_LIST (#21468),1,Remove Dead Code,,
6c068e2c75b551c72d3f551e68d7c5a76b6fd7a1,2021-09-20T21:04:37Z,https://github.com/scikit-learn/scikit-learn/commit/6c068e2c75b551c72d3f551e68d7c5a76b6fd7a1,MNT Remove obsolete code (Python >= 3.7) (#21092),1,Remove Dead Code,,
5f6abe6f7d64fb5e1fa7dccc0aaf4ec2e217cdc4,2021-09-15T15:53:42Z,https://github.com/scikit-learn/scikit-learn/commit/5f6abe6f7d64fb5e1fa7dccc0aaf4ec2e217cdc4,MAINT remove duplicate category (#21056),1,Remove Dead Code,,
f500326a9a7cab37fc2a30f2754bbc4c2e42d0e4,2021-09-02T01:13:04Z,https://github.com/scikit-learn/scikit-learn/commit/f500326a9a7cab37fc2a30f2754bbc4c2e42d0e4,CLN Removes unneeded test,1,Remove Dead Code,,
4cc9fece8b00debc7f6e629747b9360f4b1196a4,2021-09-02T01:04:55Z,https://github.com/scikit-learn/scikit-learn/commit/4cc9fece8b00debc7f6e629747b9360f4b1196a4,CLN Removes unneeded return,1,Remove Dead Code,,
6f7ae911f18fda59669309582706f1aa1f36374d,2021-07-30T09:35:03Z,https://github.com/scikit-learn/scikit-learn/commit/6f7ae911f18fda59669309582706f1aa1f36374d,"API Deprecates mean_score, std_score, split(k)_score in GraphicalLassoCV (#20583)",1,Remove Dead Code,,
1013f930efccef2c69cdefdce5ab119440ad3cfc,2021-07-13T08:45:38Z,https://github.com/scikit-learn/scikit-learn/commit/1013f930efccef2c69cdefdce5ab119440ad3cfc,MAINT Removes UserWarning when calling all_estimators (#20500),1,Remove Dead Code,,
d223747863cbc62f2afd130c9268f6cc0fc8ebeb,2021-07-13T07:22:15Z,https://github.com/scikit-learn/scikit-learn/commit/d223747863cbc62f2afd130c9268f6cc0fc8ebeb,MAINT Removes assert_warns in test_estimator_checks (#20518),1,Remove Dead Code,,
daae053f7e9afc1dac24ce9ecce87f1356b96b03,2021-06-28T18:12:08Z,https://github.com/scikit-learn/scikit-learn/commit/daae053f7e9afc1dac24ce9ecce87f1356b96b03,TST Remove the use of assert_warns and assert_warns_message from the tests  (#20417)  Co-authored-by: Sofía Denner <sofia.denner@mercadolibre.com>,1,Remove Dead Code,,
6835cb339906beb15169ecee5c8cacdd1e58be4c,2021-06-27T13:42:15Z,https://github.com/scikit-learn/scikit-learn/commit/6835cb339906beb15169ecee5c8cacdd1e58be4c,TST Remove `assert_warns_message` from `test_base` and `test_dummy` (#20388),1,Remove Dead Code,,
bd966fb7e43691918669db4533488d7596c1cd69,2021-06-22T15:41:32Z,https://github.com/scikit-learn/scikit-learn/commit/bd966fb7e43691918669db4533488d7596c1cd69,TST Remove test for sparse matrices and minkowski (#20325),1,Remove Dead Code,,
617ff6ef72f28b7964f2b7fbedaeff7b24d8c2f9,2021-06-19T08:24:10Z,https://github.com/scikit-learn/scikit-learn/commit/617ff6ef72f28b7964f2b7fbedaeff7b24d8c2f9,MAINT Remove unused variables indicated by lgtm.com (#20303),1,Remove Dead Code,,
0ad2b5b0a9fdc010ff92dd536b102e865ac3c512,2021-06-18T18:17:32Z,https://github.com/scikit-learn/scikit-learn/commit/0ad2b5b0a9fdc010ff92dd536b102e865ac3c512,Remove unused variables in TfidfTransformer's transform method (#20302),1,Remove Dead Code,,
f6971817061545b0ddb39981c0b2c98fee548e0e,2021-06-15T18:42:21Z,https://github.com/scikit-learn/scikit-learn/commit/f6971817061545b0ddb39981c0b2c98fee548e0e,MNT Remove unused line in example (#20273),1,Remove Dead Code,,
9406b3d2a4715fc71005194d30e0256c897453a0,2021-05-28T11:53:10Z,https://github.com/scikit-learn/scikit-learn/commit/9406b3d2a4715fc71005194d30e0256c897453a0,TST Removed assert_warns_message from feature_selection/tests (#20158),1,Remove Dead Code,,
ca6caa28ab92cbf75a3cc2a411d2a225abd9a4ce,2021-05-18T19:09:11Z,https://github.com/scikit-learn/scikit-learn/commit/ca6caa28ab92cbf75a3cc2a411d2a225abd9a4ce,TST Removed the estimators from the IGNORED list in test_fit_docstring_attributes (#20103),1,Remove Dead Code,,
9694d5a4b517420f9a2953c67b8c06100b256efd,2021-04-27T10:37:56Z,https://github.com/scikit-learn/scikit-learn/commit/9694d5a4b517420f9a2953c67b8c06100b256efd,Remove the unused import of csc_matrix (#19989),1,Remove Dead Code,,
09684342745cfc3509432885396e7be776e64cee,2021-04-23T11:02:14Z,https://github.com/scikit-learn/scikit-learn/commit/09684342745cfc3509432885396e7be776e64cee,MAINT Remove tests for metric configuration ignoring pos_label (#19961),1,Remove Dead Code,,
3e45aeef901871b84ce59709e62f3d2245463cd8,2021-03-20T14:07:09Z,https://github.com/scikit-learn/scikit-learn/commit/3e45aeef901871b84ce59709e62f3d2245463cd8,TST Remove assert warn from preprocessing tests (#19691),1,Remove Dead Code,,
071ddc75e92917d372f84e20a7fca15c1b7c6ca0,2021-03-19T15:26:15Z,https://github.com/scikit-learn/scikit-learn/commit/071ddc75e92917d372f84e20a7fca15c1b7c6ca0,Removed assert_warns_message from gaussian_process/tests (#19697),1,Remove Dead Code,,
e3e4a778d3a39e17a21db596d89b3357277cc3dc,2021-03-14T11:36:49Z,https://github.com/scikit-learn/scikit-learn/commit/e3e4a778d3a39e17a21db596d89b3357277cc3dc,MNT Remove absolute imports (#19668),1,Remove Dead Code,,
8965abb264aaf70d11d9f56d2947bcc0b5ddaf75,2021-01-26T13:42:44Z,https://github.com/scikit-learn/scikit-learn/commit/8965abb264aaf70d11d9f56d2947bcc0b5ddaf75,CLN Removes duplicated or unneeded code in ColumnTransformer (#19261),1,Remove Dead Code,,
339fe04e32199617800afc19d44bfa323cdcd292,2020-09-28T15:01:18Z,https://github.com/scikit-learn/scikit-learn/commit/339fe04e32199617800afc19d44bfa323cdcd292,CLN Removes unneeded attribute in FastICA (#18445),1,Remove Dead Code,,
22f232efc608e3d90b833c72c9fd3da1b4eacd97,2020-08-21T08:32:30Z,https://github.com/scikit-learn/scikit-learn/commit/22f232efc608e3d90b833c72c9fd3da1b4eacd97,MNT remove duplicated call to children_impurity() in tree code (#18203)  Co-authored-by: Juan Carlos Alfaro Jiménez <JuanCarlos.Alfaro@uclm.es>,1,Remove Dead Code,,
4f496868c6aa7f50db99229847285efbe50040c2,2020-08-03T12:09:00Z,https://github.com/scikit-learn/scikit-learn/commit/4f496868c6aa7f50db99229847285efbe50040c2,"TST More cleaning / refactoring in KMeans tests part 2 (#17973)  * remove test_minibatch_set_init_size already included in test_minibatch_init_size  * remove test_minibatch_tol test nothing  * improve and parametrize test_predict_dense_sparse  * remove test_full_vs_elkan already in test_predict and test_elkan_results  * simplify test_n_init  * fix test_centers_not_mutated  * cleaner test_kmeans_init_fitted_centers  * simpler test_kmeans_iter_attribute  * parametrize test_kmeans_empty_cluster_relocated dense sparse  * cln test_warning_elkan_1_cluster  * single double quote uniformisation  * add comment for test_euclidean_distance  * parametrize test_sample_weight_unchanged  * join test_predict, test_fit_predict and test_predict_equal_labels  * remove test_sparse_mb_k_means_callable_init & test_mini_batch_k_means_random_init_partial_fit already included it test_all_init  * Estimator -> algorithm",1,Remove Dead Code,Rename Method,
f642ff79fd2d8bf3c41e54a03ee9aeec502732da,2020-07-27T13:08:01Z,https://github.com/scikit-learn/scikit-learn/commit/f642ff79fd2d8bf3c41e54a03ee9aeec502732da,MNT Remove redundant typing import (#18004),1,Remove Dead Code,,
cd3dfa02a1c50813c62b60244fa2e5ba22a2d1ae,2020-07-20T23:19:40Z,https://github.com/scikit-learn/scikit-learn/commit/cd3dfa02a1c50813c62b60244fa2e5ba22a2d1ae,MNT Remove unnecessary try and except for numpy 1.3 (#17957),1,Remove Dead Code,,
d849033fa5ed6ee36b310ca891bfc68ba27d7dc3,2020-07-11T17:29:07Z,https://github.com/scikit-learn/scikit-learn/commit/d849033fa5ed6ee36b310ca891bfc68ba27d7dc3,MNT removed repeated definition of ranked_exposure (#17895),1,Remove Dead Code,,
19b2daaae7604579edbabe4939a18b0c2aade044,2020-07-11T16:37:08Z,https://github.com/scikit-learn/scikit-learn/commit/19b2daaae7604579edbabe4939a18b0c2aade044,removed os import (#17893),1,Remove Dead Code,,
8e6cc67381dd33b509c821cef6aea059746f3305,2020-07-08T09:21:52Z,https://github.com/scikit-learn/scikit-learn/commit/8e6cc67381dd33b509c821cef6aea059746f3305,TST clean up and parametrization in KMeans tests (#17850),1,Remove Dead Code,Rename Method,
2b503bdc08615ab64e91576d91794e126850abbb,2020-06-29T19:22:21Z,https://github.com/scikit-learn/scikit-learn/commit/2b503bdc08615ab64e91576d91794e126850abbb,CLN Remove self-assignments from tests (#17776),1,Remove Dead Code,,
cf4fa5c771789ed569b1b40787d9118f4be79737,2020-06-27T11:39:28Z,https://github.com/scikit-learn/scikit-learn/commit/cf4fa5c771789ed569b1b40787d9118f4be79737,MNT Remove unused variable `batch_size` in MLP `_fit` (#17754),1,Remove Dead Code,,
7494da6f520b70db490fbe0d602b05ed4078bcbc,2020-05-25T15:34:17Z,https://github.com/scikit-learn/scikit-learn/commit/7494da6f520b70db490fbe0d602b05ed4078bcbc,MNT removed deprecated files generation (#17132),1,Remove Dead Code,,
1931e142edf2adb324b641a76d7ae5615fd9435c,2020-05-20T20:03:54Z,https://github.com/scikit-learn/scikit-learn/commit/1931e142edf2adb324b641a76d7ae5615fd9435c,Remove deprecated utils (#17133),1,Remove Dead Code,,
4f5384b249c488ada8dd012bdc029600ac912917,2020-05-10T21:11:39Z,https://github.com/scikit-learn/scikit-learn/commit/4f5384b249c488ada8dd012bdc029600ac912917,MNT Remove class support check estimator and parametrize_with_checks (#17134),1,Remove Dead Code,,
89fcef7ad2b5d8b2fec39cacfe3b10c5db613f43,2020-05-07T15:05:06Z,https://github.com/scikit-learn/scikit-learn/commit/89fcef7ad2b5d8b2fec39cacfe3b10c5db613f43,MNT Removed duplicate method calls in pickle estimator test (#17152),1,Remove Dead Code,,
37776a0506668e3d635b9c94f0421a5e746cd72e,2020-04-01T17:42:03Z,https://github.com/scikit-learn/scikit-learn/commit/37776a0506668e3d635b9c94f0421a5e746cd72e,CLN Removes unneeded code in histgradientboosting (#16820),1,Remove Dead Code,,
75d3f29e724c9a2db7bcb5afb2d7e8c08ddbd80b,2020-03-20T12:57:18Z,https://github.com/scikit-learn/scikit-learn/commit/75d3f29e724c9a2db7bcb5afb2d7e8c08ddbd80b,MAINT Remove outdated numpy and scipy backports (#16725)  * Remove unecessary numpy & scipy backports  * More fixes  * Remove unused imports,1,Remove Dead Code,,
1cbe59ee06c08ed87fbaf2fba43785e001d3fe69,2020-03-12T11:56:35Z,https://github.com/scikit-learn/scikit-learn/commit/1cbe59ee06c08ed87fbaf2fba43785e001d3fe69,CI Check for unused imports when linting (#16678)  * Check for missing imports in linting  * Exclude externals  * Remove unused imports,1,Remove Dead Code,,
0e4996d28a01fba26bc7c4b3c894bfec6f427eeb,2020-03-12T10:58:53Z,https://github.com/scikit-learn/scikit-learn/commit/0e4996d28a01fba26bc7c4b3c894bfec6f427eeb,MNT Removes unused private attributes (#16675),1,Remove Dead Code,,
438bb3a438a42e23e3111c58575cf16841bb694d,2020-03-10T23:01:51Z,https://github.com/scikit-learn/scikit-learn/commit/438bb3a438a42e23e3111c58575cf16841bb694d,MNT Remove unused imports (#16665),1,Remove Dead Code,,
5c36df6098d4a6325b621030163897d19853e698,2020-01-24T13:45:47Z,https://github.com/scikit-learn/scikit-learn/commit/5c36df6098d4a6325b621030163897d19853e698,MNT remove check for deprecated behavior in test.py (#16109),1,Remove Dead Code,,
4953ec36a41694d38f8d92fd48c7049cdd82e0ed,2020-01-13T12:43:50Z,https://github.com/scikit-learn/scikit-learn/commit/4953ec36a41694d38f8d92fd48c7049cdd82e0ed,MNT remove more deprecations for 0.23 (#15860)  * removed warn_on_dtype  * removed parameters to check_is_fitted  * all_estimators parameters  * deprecated n_components attribute in AgglomerativeClustering  * change default of base.score for multioutput  * removed lots of useless decorators?  * changed default of copy in quantil_transform  * removed six.py  * nmf default value of init param  * raise error instead of warning in LinearDiscriminantAnalysis  * removed label param in hamming_loss  * updated method parameter of power_transform  * pep8  * changed default value of min_impurity_split  * removed assert_false and assert_true  * added and fixed versionchanged directives  * reset min_impurity_split default to None  * fixed LDA issue  * fixed some test  * more docstrings updates  * set min_impurity_decrease for test to pass  * upate docstring example  * fixed doctest  * removed multiouput.score since it's now consistent with the default  * deprecate least_angle parameter combination  * remove support for l1 or l2 loss in svm  * removed linear_assignment.py  * add test,1,Remove Dead Code,,
a4ec379e81843a24ba8e1fd355b18950570cdbfa,2020-01-09T22:34:10Z,https://github.com/scikit-learn/scikit-learn/commit/a4ec379e81843a24ba8e1fd355b18950570cdbfa,MNT remove unused variables in elkan algorithm (#16082),1,Remove Dead Code,,
70d8b70d7a3fbd2ead8c27ed9190024ff10372ca,2019-12-31T14:19:15Z,https://github.com/scikit-learn/scikit-learn/commit/70d8b70d7a3fbd2ead8c27ed9190024ff10372ca,Remove abstractmethod that silently brake downstream packages (#15996),1,Remove Dead Code,,
42e17b34876101bec79786b42206d4f2e946c278,2019-12-13T20:05:51Z,https://github.com/scikit-learn/scikit-learn/commit/42e17b34876101bec79786b42206d4f2e946c278,MNT Removed deprecated attributes and parameters -- ctnd (#15804),1,Remove Dead Code,,
4256542b10bcc6bd10ddf31dfb356ecc084f2e7d,2019-12-09T14:17:06Z,https://github.com/scikit-learn/scikit-learn/commit/4256542b10bcc6bd10ddf31dfb356ecc084f2e7d,MNT Removed deprecated attributes and parameters (#15803),1,Remove Dead Code,,
ad80d3159a3621367e074f1b781c704193e5c27a,2019-12-06T12:59:46Z,https://github.com/scikit-learn/scikit-learn/commit/ad80d3159a3621367e074f1b781c704193e5c27a,DEP Remove deprecated joblib tools in utils (#15792),1,Remove Dead Code,,
70ae89ecb2bccb8b7d6426770fcfe4b9bb40376f,2019-12-05T15:49:00Z,https://github.com/scikit-learn/scikit-learn/commit/70ae89ecb2bccb8b7d6426770fcfe4b9bb40376f,MNT Removed deprecated metrics (#15794),1,Remove Dead Code,,
5573abbb998b03105a541be1ac2095f2c2abc026,2019-12-04T17:24:10Z,https://github.com/scikit-learn/scikit-learn/commit/5573abbb998b03105a541be1ac2095f2c2abc026,MNT Removed deprecated logistic_regression_path (#15791),1,Remove Dead Code,,
4cdbde308552b8700da30ed1c1c4f5085a24abde,2019-12-04T17:22:56Z,https://github.com/scikit-learn/scikit-learn/commit/4cdbde308552b8700da30ed1c1c4f5085a24abde,MNT remove deprecated ensemble.partial_dependence (#15789),1,Remove Dead Code,,
3a3178ec31e84a97a60a9bf109ed39527e962392,2019-12-04T17:21:56Z,https://github.com/scikit-learn/scikit-learn/commit/3a3178ec31e84a97a60a9bf109ed39527e962392,MNT remove deprecated loss functions in gb.py (#15790),1,Remove Dead Code,,
9f5b97119b08789740876e384d04b4a2e314bc8b,2019-11-25T07:34:54Z,https://github.com/scikit-learn/scikit-learn/commit/9f5b97119b08789740876e384d04b4a2e314bc8b,CLN Removes ccp_alpha from RandomTreesEmbedding (#15708),1,Remove Dead Code,,
1c546cd9b1c229cba6f076f7532fadc27066f63e,2019-11-20T21:03:25Z,https://github.com/scikit-learn/scikit-learn/commit/1c546cd9b1c229cba6f076f7532fadc27066f63e,CLN Move gradient and hessian closer to for loop in hist GBDT (#15686),1,Remove Dead Code,,
a22813bd16d6cbbd4411e487edee2d5bc23dd22b,2019-10-22T03:13:06Z,https://github.com/scikit-learn/scikit-learn/commit/a22813bd16d6cbbd4411e487edee2d5bc23dd22b,MNT Remove redundant import in logistic.py (#15327),1,Remove Dead Code,,
c457c6aaf5fc59ab832b59204b6bc5aa109a6117,2019-10-21T13:14:55Z,https://github.com/scikit-learn/scikit-learn/commit/c457c6aaf5fc59ab832b59204b6bc5aa109a6117,MNT Remove six imports (#15251),1,Remove Dead Code,,
bbc23691cb9c5a7f2174d58c934f233b90f51ab2,2019-10-20T12:00:29Z,https://github.com/scikit-learn/scikit-learn/commit/bbc23691cb9c5a7f2174d58c934f233b90f51ab2,MNT remove utils._unittest_backport which was needed for Python<3.5 (#15252),1,Remove Dead Code,,
e489aab0d60ee48400e98f77abd92116620d9681,2019-10-18T16:55:25Z,https://github.com/scikit-learn/scikit-learn/commit/e489aab0d60ee48400e98f77abd92116620d9681,MNT Remove warning in logistic regression cv scoring (#15184),1,Remove Dead Code,,
e50ea510d5abffe2bb1b5482fc437029c742ec62,2019-10-16T21:10:16Z,https://github.com/scikit-learn/scikit-learn/commit/e50ea510d5abffe2bb1b5482fc437029c742ec62,TST Removes deprecated imports from cluster tests (#15278),1,Remove Dead Code,,
d0d8f204675fd2718d373f8cde5ae12707521061,2019-10-15T04:29:05Z,https://github.com/scikit-learn/scikit-learn/commit/d0d8f204675fd2718d373f8cde5ae12707521061,TST Remove redundant py2 test in test_forest (#15235),1,Remove Dead Code,,
847b3468c7c60c7d89c21f5e854b6c492f7261d5,2019-10-14T11:45:10Z,https://github.com/scikit-learn/scikit-learn/commit/847b3468c7c60c7d89c21f5e854b6c492f7261d5,MNT Remove utils.fixes.parallel_helper (#15232),1,Remove Dead Code,,
6d53d067d0efec4e1868cbb266fca8c294b7324f,2019-10-12T15:44:11Z,https://github.com/scikit-learn/scikit-learn/commit/6d53d067d0efec4e1868cbb266fca8c294b7324f,TST Remove test functions defined twice (#15220),1,Remove Dead Code,,
bd10e75ff39663ceea66b47a6565a2cd4673770f,2019-09-23T19:01:24Z,https://github.com/scikit-learn/scikit-learn/commit/bd10e75ff39663ceea66b47a6565a2cd4673770f,CLN remove extraneous statement in ransac.py (#15067),1,Remove Dead Code,,
64ed8436095235ef3d1be67d6772104f08c76b2e,2019-08-29T11:52:45Z,https://github.com/scikit-learn/scikit-learn/commit/64ed8436095235ef3d1be67d6772104f08c76b2e,MAINT: Remove redundant code in MLP (#14815),1,Remove Dead Code,,
628f34fa7281b4e4da356d47f657a5ce561c7128,2019-08-26T17:21:49Z,https://github.com/scikit-learn/scikit-learn/commit/628f34fa7281b4e4da356d47f657a5ce561c7128,Removed useless declaration in plot_nca_illustration (#14794),1,Remove Dead Code,,
864d32ac44474e212ee4a71ac842704a900f0aa2,2019-08-15T03:52:27Z,https://github.com/scikit-learn/scikit-learn/commit/864d32ac44474e212ee4a71ac842704a900f0aa2,MNT Removed redundant checks when calling scorer/get_scorer (#14658),1,Remove Dead Code,,
b162acaa139c19e3e5c53579b163517f4bc95cff,2019-07-30T14:39:16Z,https://github.com/scikit-learn/scikit-learn/commit/b162acaa139c19e3e5c53579b163517f4bc95cff,MAINT Slight common tests cleanup (#14511),1,Remove Dead Code,,
7d9ea3e0236da77079b7aeff6037a167a4947e27,2019-07-29T20:47:40Z,https://github.com/scikit-learn/scikit-learn/commit/7d9ea3e0236da77079b7aeff6037a167a4947e27,CLN: remove collinearity warning from LDA (#14486),1,Remove Dead Code,,
01a140a0bf71b71ef8188103077de44c55b74f17,2019-07-18T10:55:56Z,https://github.com/scikit-learn/scikit-learn/commit/01a140a0bf71b71ef8188103077de44c55b74f17,MAINT Remove BLAS infos from show_versions and build log (#14205),1,Remove Dead Code,,
f37277ad678c40710116d406e98624fe0472dd9b,2019-07-14T02:59:36Z,https://github.com/scikit-learn/scikit-learn/commit/f37277ad678c40710116d406e98624fe0472dd9b,MNT Clean up plot_tree (remove matplotlib < 1.5) (#14321),1,Remove Dead Code,,
1015caf54df347c00152c67adaf1851c5771f0a0,2019-06-18T14:37:14Z,https://github.com/scikit-learn/scikit-learn/commit/1015caf54df347c00152c67adaf1851c5771f0a0,MAINT Remove imports from sklearn.utils._joblib (#13676)  * Remove sklearn.utils._joblib imports  * Lint  * More fixes,1,Remove Dead Code,,
0eedf99eee0b8b86f537a38d870b408cb93351dd,2019-06-17T12:10:05Z,https://github.com/scikit-learn/scikit-learn/commit/0eedf99eee0b8b86f537a38d870b408cb93351dd,MAINT Don't use clean_warnings_registry in tests (#14085),1,Remove Dead Code,,
e669a89aa470f3a9e24f344c122f983d26904bb6,2019-06-12T18:19:45Z,https://github.com/scikit-learn/scikit-learn/commit/e669a89aa470f3a9e24f344c122f983d26904bb6,CLN Removed some unused imports (#14074),1,Remove Dead Code,,
ccd3331f7eb3468ac96222dc5350e58c58ccba20,2019-06-04T13:15:19Z,https://github.com/scikit-learn/scikit-learn/commit/ccd3331f7eb3468ac96222dc5350e58c58ccba20,MNT remove unused imports (#14021),1,Remove Dead Code,,
f283ed6b4085b0751db43dfa5fc6ad76103b4d12,2019-05-28T17:23:06Z,https://github.com/scikit-learn/scikit-learn/commit/f283ed6b4085b0751db43dfa5fc6ad76103b4d12,CLN Removed max_bins from splitter in GBDT (#13927),1,Remove Dead Code,,
af4247b152350b4fd0ac8bb9395833bd84e827d2,2019-05-21T08:37:09Z,https://github.com/scikit-learn/scikit-learn/commit/af4247b152350b4fd0ac8bb9395833bd84e827d2,DEP remove utilities related to mldata (#13798),1,Remove Dead Code,,
83656484a8f6be9a920b736dccad214d5afc177e,2019-05-10T10:06:25Z,https://github.com/scikit-learn/scikit-learn/commit/83656484a8f6be9a920b736dccad214d5afc177e,MNT Remove raises and with_setup requiring nose (#13842),1,Remove Dead Code,,
7fdac52c19d63dad5f790ed2befa1669b2c1403e,2019-05-09T12:54:30Z,https://github.com/scikit-learn/scikit-learn/commit/7fdac52c19d63dad5f790ed2befa1669b2c1403e,MNT Remove backward compatibility of param order in make_column_transformer (#13831),1,Remove Dead Code,,
9631a67388014c851091007d324420d1138b5892,2019-05-09T00:31:53Z,https://github.com/scikit-learn/scikit-learn/commit/9631a67388014c851091007d324420d1138b5892,DEP remove scale_face function from lfw (#13830),1,Remove Dead Code,,
53624e8c26a541bd8e976771679e9c0c838ad5d5,2019-05-09T00:27:24Z,https://github.com/scikit-learn/scikit-learn/commit/53624e8c26a541bd8e976771679e9c0c838ad5d5,DEP remove public function download_20newsgroups (#13829),1,Remove Dead Code,,
43f85020c5d9ca0010ff7459e5b4bc4550e33b79,2019-05-08T23:58:39Z,https://github.com/scikit-learn/scikit-learn/commit/43f85020c5d9ca0010ff7459e5b4bc4550e33b79,DEP remove correlation and regression models from GaussianProcess (#13819),1,Remove Dead Code,,
6525a39dd67484485eab1bfb369fd115d5548a90,2019-05-08T14:24:32Z,https://github.com/scikit-learn/scikit-learn/commit/6525a39dd67484485eab1bfb369fd115d5548a90,MNT Remove Imputer in preprocessing (#13796),1,Remove Dead Code,,
d0a94fea742e8d9cafbccf8f814fcfcea4a8b10c,2019-05-07T14:22:06Z,https://github.com/scikit-learn/scikit-learn/commit/d0a94fea742e8d9cafbccf8f814fcfcea4a8b10c,DEP remove graph lasso (#13795),1,Remove Dead Code,,
905dedc63592b019542011956bb10b9e43c7c8bd,2019-05-07T11:33:00Z,https://github.com/scikit-learn/scikit-learn/commit/905dedc63592b019542011956bb10b9e43c7c8bd,DEP remove random_state from OneClassSVM (#13802),1,Remove Dead Code,,
b8ef9a919b4c739afcfdc4782e77e7a7cbee2f65,2019-04-26T14:59:24Z,https://github.com/scikit-learn/scikit-learn/commit/b8ef9a919b4c739afcfdc4782e77e7a7cbee2f65,MAINT removed close_figure helper (#13730),1,Remove Dead Code,,
6a3fc959b684e2f4b2fab28b27d5fa4018acb6a3,2019-04-26T08:05:27Z,https://github.com/scikit-learn/scikit-learn/commit/6a3fc959b684e2f4b2fab28b27d5fa4018acb6a3,TST Remove np.seterr calls in test files (#13712),1,Remove Dead Code,,
df767ebc84c311d9ca1681cc7dabe9c3875f722f,2019-04-22T12:12:05Z,https://github.com/scikit-learn/scikit-learn/commit/df767ebc84c311d9ca1681cc7dabe9c3875f722f,MNT Minor clean up in OneVsOneClassifier (#13677),1,Remove Dead Code,,
afd432137fd840adc182f0bad87f405cb80efac7,2019-03-02T08:45:49Z,https://github.com/scikit-learn/scikit-learn/commit/afd432137fd840adc182f0bad87f405cb80efac7,CLN: remove duplicate validation of X in Encoders transform (#13347),1,Remove Dead Code,,
8a4cb4871d07c0ddd966fce0959d8118a8f62c59,2019-02-28T09:49:50Z,https://github.com/scikit-learn/scikit-learn/commit/8a4cb4871d07c0ddd966fce0959d8118a8f62c59,Remove unused scorers (#13318),1,Remove Dead Code,,
f02ef9f52f81c2d212f428092ad7c3f2f3fbd0f5,2019-02-27T10:14:29Z,https://github.com/scikit-learn/scikit-learn/commit/f02ef9f52f81c2d212f428092ad7c3f2f3fbd0f5,LogisticRegression convert to float64 (for SAG solver) (#13243)  * Remove unused code  * Squash all the PR 9040 commits  initial PR commit  seq_dataset.pyx generated from template  seq_dataset.pyx generated from template #2  rename variables  fused types consistency test for seq_dataset  a  sklearn/utils/tests/test_seq_dataset.py  new if statement  add doc  sklearn/utils/seq_dataset.pyx.tp  minor changes  minor changes  typo fix  check numeric accuracy only up 5th decimal  Address oliver's request for changing test name  add test for make_dataset and rename a variable in test_seq_dataset  * FIX tests  * TST more numerically stable test_sgd.test_tol_parameter  * Added benchmarks to compare SAGA 32b and 64b  * Fixing gael's comments  * fix  * solve some issues  * PEP8  * Address lesteve comments  * fix merging  * avoid using assert_equal  * use all_close  * use explicit ArrayDataset64 and CSRDataset64  * fix: remove unused import  * Use parametrized to cover ArrayDaset-CSRDataset-32-64 matrix  * for consistency use 32 first then 64 + add 64 suffix to variables  * it would be cool if this worked !!!  * more verbose version  * revert SGD changes as much as possible.  * Add solvers back to bench_saga  * make 64 explicit in the naming  * remove checking native python type + add comparison between 32 64  * Add whatsnew with everyone with commits  * simplify a bit the testing  * simplify the parametrize  * update whatsnew  * fix pep8,1,Remove Dead Code,,
b65afbf2fd1396ce5ccdc296a129137bd5f33306,2019-02-27T07:41:34Z,https://github.com/scikit-learn/scikit-learn/commit/b65afbf2fd1396ce5ccdc296a129137bd5f33306,TST remove _UnstableOn32BitMixin from kpca class (#13284),1,Remove Dead Code,,
9c6de2f1fa3034618352b8d74962d6f7173aa252,2019-02-22T00:56:55Z,https://github.com/scikit-learn/scikit-learn/commit/9c6de2f1fa3034618352b8d74962d6f7173aa252,MNT Remove unused import in text.py (#13217),1,Remove Dead Code,,
943239592e7c65254eec8956eb38fe04fe116723,2019-02-20T01:36:22Z,https://github.com/scikit-learn/scikit-learn/commit/943239592e7c65254eec8956eb38fe04fe116723,EXA Remove unused variables (#13197),1,Remove Dead Code,,
be5d3eab97c68f6d2a9d41725266375648acddc7,2019-02-13T01:24:15Z,https://github.com/scikit-learn/scikit-learn/commit/be5d3eab97c68f6d2a9d41725266375648acddc7,MNT Remove base._first_and_last_element (#13137),1,Remove Dead Code,,
16100944b9f5a4d611a48eb372a39144b790d6a0,2019-02-04T10:32:23Z,https://github.com/scikit-learn/scikit-learn/commit/16100944b9f5a4d611a48eb372a39144b790d6a0,MNT Remove utils.fixes.euler_gamma (#13082),1,Remove Dead Code,,
a73260db9c0b63d582ef4a7f3c696b68058c1c43,2019-02-04T07:18:17Z,https://github.com/scikit-learn/scikit-learn/commit/a73260db9c0b63d582ef4a7f3c696b68058c1c43,MNT Remove utils.validation._shape_repr (#13083)  Following dropping python 2.X support,1,Remove Dead Code,,
62d205980446a1abc1065f4332fd74eee57fcf73,2019-02-02T14:05:06Z,https://github.com/scikit-learn/scikit-learn/commit/62d205980446a1abc1065f4332fd74eee57fcf73,MNT remove __future__ imports (#12791),1,Remove Dead Code,,
575064b8e17c7243ff958e762b042d484283cd55,2019-02-02T14:01:13Z,https://github.com/scikit-learn/scikit-learn/commit/575064b8e17c7243ff958e762b042d484283cd55,MNT More clean up after we remove python < 3.5 (#13078),1,Remove Dead Code,,
a7b8b9e9e16d4e15fabda5ae615086c2e1c47d8a,2019-01-13T15:41:28Z,https://github.com/scikit-learn/scikit-learn/commit/a7b8b9e9e16d4e15fabda5ae615086c2e1c47d8a,MAINT Removes total_seconds completely in benchmarks (#12969),1,Remove Dead Code,,
701144559f0448e7b140fead0384b9cba99af096,2019-01-08T01:43:49Z,https://github.com/scikit-learn/scikit-learn/commit/701144559f0448e7b140fead0384b9cba99af096,"MAINT Remove unused utils.fixes (#12928)  This continues the work done in https://github.com/scikit-learn/scikit-learn/pull/12639 on dropping the python 2 support by,  - ~~removing unnecessary `from __future__` imports~~  - removing unused `sklearn.utils.fixes` assuming we can agree in https://github.com/scikit-learn/scikit-learn/issues/12927 that `sklearn.utils.fixes` are private as was stated e.g. in https://github.com/scikit-learn/scikit-learn/issues/6616#issuecomment-245109979",1,Remove Dead Code,,
de38dfc719b3b5a754df36c1585aa4cf810f4e3b,2018-12-21T20:44:40Z,https://github.com/scikit-learn/scikit-learn/commit/de38dfc719b3b5a754df36c1585aa4cf810f4e3b,MAINT Remove minor duplication in metrics.__init__ (#12851),1,Remove Dead Code,,
e6e8345248c09214ad1946c8549204dbbcbaf8a6,2018-11-24T15:34:56Z,https://github.com/scikit-learn/scikit-learn/commit/e6e8345248c09214ad1946c8549204dbbcbaf8a6,EXA remove unused variables. (#12647)  The data comes from static CSVs that cover 2003-01-01 to 2007-12-31.,1,Remove Dead Code,,
43e3a0208547605a5dae709283ca15327d48b48a,2018-11-11T03:08:37Z,https://github.com/scikit-learn/scikit-learn/commit/43e3a0208547605a5dae709283ca15327d48b48a,MNT Remove unused assert_true imports (#12560),1,Remove Dead Code,,
3a3a78a485571b45b3686f4fae1b132387a1ee1b,2018-10-22T12:43:04Z,https://github.com/scikit-learn/scikit-learn/commit/3a3a78a485571b45b3686f4fae1b132387a1ee1b,MNT Remove unused variables (#12230),1,Remove Dead Code,,
5af272ac61214162aaaa33fa0d4d10fa5a4fc744,2018-10-22T01:48:40Z,https://github.com/scikit-learn/scikit-learn/commit/5af272ac61214162aaaa33fa0d4d10fa5a4fc744,MNT Remove unused variables (#12230),1,Remove Dead Code,,
e0e738760625129be71839fac2dad9325fb90225,2018-10-04T01:08:17Z,https://github.com/scikit-learn/scikit-learn/commit/e0e738760625129be71839fac2dad9325fb90225,Remove unused private functions (#12253),1,Remove Dead Code,,
dfd009d61ebc2b323543035474bb16e5b0e7e316,2018-10-02T16:13:48Z,https://github.com/scikit-learn/scikit-learn/commit/dfd009d61ebc2b323543035474bb16e5b0e7e316,Remove test_import_sklearn_no_warnings (#12244),1,Remove Dead Code,,
9d58ca5ad4700a1a06659196d8d0d925d71ab179,2018-09-30T00:11:25Z,https://github.com/scikit-learn/scikit-learn/commit/9d58ca5ad4700a1a06659196d8d0d925d71ab179,MNT Remove duplicate import of warnings & unused variables (#12203),1,Remove Dead Code,,
e5333f5dfe61a69bede562c20a055359adad7e51,2018-09-08T14:46:48Z,https://github.com/scikit-learn/scikit-learn/commit/e5333f5dfe61a69bede562c20a055359adad7e51,OPTICS remove redundant recursion (#11985),1,Remove Dead Code,,
c2682309206a9e6b298a00479af8b82b80e444f4,2018-09-05T09:51:49Z,https://github.com/scikit-learn/scikit-learn/commit/c2682309206a9e6b298a00479af8b82b80e444f4,MNT Remove n_clusters_ in OPTICS (#11981),1,Remove Dead Code,,
84c4e544a0496bf382232e5c5bc7abf7eb699d70,2018-09-03T15:39:18Z,https://github.com/scikit-learn/scikit-learn/commit/84c4e544a0496bf382232e5c5bc7abf7eb699d70,COSMIT remove unnecessary _TreeNode methods (#11983),1,Remove Dead Code,,
7e8e3dec38049332f4ea038073db2f50866bf2e7,2018-09-01T08:51:25Z,https://github.com/scikit-learn/scikit-learn/commit/7e8e3dec38049332f4ea038073db2f50866bf2e7,MNT: remove pytest imported twice.  Minor reorder of the imports as well.,1,Remove Dead Code,,
9111064a345c27783898fb0b23262e4732b15368,2018-07-18T07:37:18Z,https://github.com/scikit-learn/scikit-learn/commit/9111064a345c27783898fb0b23262e4732b15368,MNT Remove redundant metrics in test_common.py (#11584),1,Remove Dead Code,,
4e87d93ce6fae938aa366742732b59a730724c73,2018-03-30T05:40:19Z,https://github.com/scikit-learn/scikit-learn/commit/4e87d93ce6fae938aa366742732b59a730724c73,Remove axis parameter from SimpleImputer (#10829),1,Remove Dead Code,,
b2d1fa6ec33222eb0eb3b5f562750282f379ca0a,2018-02-19T09:43:38Z,https://github.com/scikit-learn/scikit-learn/commit/b2d1fa6ec33222eb0eb3b5f562750282f379ca0a,COSMIT Remove redundant validation from BaseMultilayerPerceptron (#10656),1,Remove Dead Code,,
ab4a8b4a87be227dacafee7e4131fb98f189a5e4,2018-01-31T18:42:15Z,https://github.com/scikit-learn/scikit-learn/commit/ab4a8b4a87be227dacafee7e4131fb98f189a5e4,remove redundant code (#10563),1,Remove Dead Code,,
a13a7d8d20489329a78e6b12086353c8248ddc64,2017-11-17T17:37:29Z,https://github.com/scikit-learn/scikit-learn/commit/a13a7d8d20489329a78e6b12086353c8248ddc64,MAINT remove _named_check (#10160)  which was a nose-specific thing to have good names for tests using yield,1,Remove Dead Code,,
9a198bb56fd03a466d64a6f7b95549a0e7551653,2017-11-02T20:47:13Z,https://github.com/scikit-learn/scikit-learn/commit/9a198bb56fd03a466d64a6f7b95549a0e7551653,MAINT remove duplicate import in test_pca.py (#10061),1,Remove Dead Code,,
cb41c52625c7181db357cef6c0fdb30cec52cce2,2017-10-07T15:04:08Z,https://github.com/scikit-learn/scikit-learn/commit/cb41c52625c7181db357cef6c0fdb30cec52cce2,Remove unused variable alphas from the LARS example. (#9882),1,Remove Dead Code,,
4889a67942713777e0e250eda9a3e019d84d1950,2017-08-31T08:28:09Z,https://github.com/scikit-learn/scikit-learn/commit/4889a67942713777e0e250eda9a3e019d84d1950,MAINT remove unused imports,1,Remove Dead Code,,
7d13009364afd85abd964a93bcafdbe138823cfe,2017-08-27T02:44:07Z,https://github.com/scikit-learn/scikit-learn/commit/7d13009364afd85abd964a93bcafdbe138823cfe,ENH Avoid unnecessary O(n^2) calculation in affinity propagation (#9617),1,Remove Dead Code,,
2277068c8832cd6f1ffbf4a6e3b2f8dc7a146671,2017-07-24T23:03:22Z,https://github.com/scikit-learn/scikit-learn/commit/2277068c8832cd6f1ffbf4a6e3b2f8dc7a146671,"remove depreated ""plt.hold"" that defaults to ""on"". (#9444)",1,Remove Dead Code,,
dc4348680665635e91a7fc36b034ef3590a80ea2,2017-07-01T12:57:54Z,https://github.com/scikit-learn/scikit-learn/commit/dc4348680665635e91a7fc36b034ef3590a80ea2,Remove unused imports (#9235),1,Remove Dead Code,,
c2a42efe0858e8a0ee63de93cb798e07248e2d7f,2017-06-20T23:34:11Z,https://github.com/scikit-learn/scikit-learn/commit/c2a42efe0858e8a0ee63de93cb798e07248e2d7f,Remove unused import,1,Remove Dead Code,,
7ab0a96d8a5e8b1ef79094f42de81ff3069fbbdf,2017-06-14T07:21:15Z,https://github.com/scikit-learn/scikit-learn/commit/7ab0a96d8a5e8b1ef79094f42de81ff3069fbbdf,Remove obsolete reference to dbscan.random_state (#9120),1,Remove Dead Code,,
e07640ed5fa60a9523559a45eeac5166b1988b43,2017-06-13T08:25:14Z,https://github.com/scikit-learn/scikit-learn/commit/e07640ed5fa60a9523559a45eeac5166b1988b43,remove identical assert in test_iforest_sparse (#9112),1,Remove Dead Code,,
398ffed8d17e21012cff0d0ed8c0b5398204546c,2017-04-25T19:11:03Z,https://github.com/scikit-learn/scikit-learn/commit/398ffed8d17e21012cff0d0ed8c0b5398204546c,Removed DataConversionWarning in Normalize (#8712),1,Remove Dead Code,,
834608ec1dc5de20b25411f283df739fc110478b,2017-04-23T12:14:42Z,https://github.com/scikit-learn/scikit-learn/commit/834608ec1dc5de20b25411f283df739fc110478b,MAINT Remove unused condition (#8778),1,Remove Dead Code,,
7e18252a9ee04d2ae313de0c4624d9eb44b90ef4,2016-11-24T00:33:56Z,https://github.com/scikit-learn/scikit-learn/commit/7e18252a9ee04d2ae313de0c4624d9eb44b90ef4,COSMIT remove unused import (#7928),1,Remove Dead Code,,
7f076d26827d2c907d1e64a0860ccfd5be5be8f9,2016-09-24T20:58:09Z,https://github.com/scikit-learn/scikit-learn/commit/7f076d26827d2c907d1e64a0860ccfd5be5be8f9,Merge pull request #7480 from omtcyfz/minor-k-means-cleanup  Minor k_means_.py cleanup.,1,Remove Dead Code,,
4ed0a6a422c532d919595c815ae6d7403c926f12,2016-09-24T11:26:19Z,https://github.com/scikit-learn/scikit-learn/commit/4ed0a6a422c532d919595c815ae6d7403c926f12,Minor test_k_means.py cleanup.  Removed unused import.  Fixed two lines extending 79 width limit.,1,Remove Dead Code,,
8a7948aa9915ed98afd8e1c5b695ad5e9d7de31c,2016-09-22T01:16:36Z,https://github.com/scikit-learn/scikit-learn/commit/8a7948aa9915ed98afd8e1c5b695ad5e9d7de31c,MAINT remove unneeded import (#7465),1,Remove Dead Code,,
c3b21153e80c7afdbfc3462f139bf94d511f81c4,2016-09-12T14:17:59Z,https://github.com/scikit-learn/scikit-learn/commit/c3b21153e80c7afdbfc3462f139bf94d511f81c4,MNT Remove unused constants from public API(?) (#6517),1,Remove Dead Code,,
0f2a00f8903cc776a4193ed5a62f0d749c46a474,2016-09-01T08:57:21Z,https://github.com/scikit-learn/scikit-learn/commit/0f2a00f8903cc776a4193ed5a62f0d749c46a474,Remove dtype conversion warning (#7265),1,Remove Dead Code,,
d9428deb51ddb1c65bad208e13dec1eb4a59a282,2016-08-31T13:28:28Z,https://github.com/scikit-learn/scikit-learn/commit/d9428deb51ddb1c65bad208e13dec1eb4a59a282,Remove unused import,1,Remove Dead Code,,
dcb31654aaa934145917feebf6e0b4eabfd42ba9,2016-08-27T14:59:57Z,https://github.com/scikit-learn/scikit-learn/commit/dcb31654aaa934145917feebf6e0b4eabfd42ba9,"TST remove print statement in gmm test, remove verbosity in mlp test.",1,Remove Dead Code,,
4773dbbc4b8012bc0abf54b5b8e1b118233d9816,2016-08-03T18:23:50Z,https://github.com/scikit-learn/scikit-learn/commit/4773dbbc4b8012bc0abf54b5b8e1b118233d9816,Remove custom touch to backreferences files  This is now a default in sphinx-gallery v0.1.2,1,Remove Dead Code,,
e4b837cc66616ca5f1beb1f560605eaae72cf3f8,2016-07-30T00:30:23Z,https://github.com/scikit-learn/scikit-learn/commit/e4b837cc66616ca5f1beb1f560605eaae72cf3f8,Removed unused imports,1,Remove Dead Code,,
aa4f75699357c70755d6bcf7dee076a7cd723a6f,2016-07-22T07:36:28Z,https://github.com/scikit-learn/scikit-learn/commit/aa4f75699357c70755d6bcf7dee076a7cd723a6f,remove redundant NotFittedError import from voting classifier (#7060),1,Remove Dead Code,,
e669f8775bbd8b7e3d587547bd6b23fd32b306a1,2016-06-02T13:16:28Z,https://github.com/scikit-learn/scikit-learn/commit/e669f8775bbd8b7e3d587547bd6b23fd32b306a1,Modification of the GaussianMixture class. (#6824)  Remove the useless computation of the covariance matrix. Prepare the integration of the BayesianGaussianMixture class.,1,Remove Dead Code,,
e6bb6b877cc8016a89852162c8e7cdecf935e2b7,2016-04-12T20:08:45Z,https://github.com/scikit-learn/scikit-learn/commit/e6bb6b877cc8016a89852162c8e7cdecf935e2b7,Removed redundant Classification metrics entry: metrics.brier_score_loss.,1,Remove Dead Code,,
04f28574524f0a4a2ff8ec7e6613ceac139f59f1,2016-02-13T03:31:01Z,https://github.com/scikit-learn/scikit-learn/commit/04f28574524f0a4a2ff8ec7e6613ceac139f59f1,Remove redundant assignment of parameter shuffle,1,Remove Dead Code,,
706b45e03e0a4e8aae08560853eba7b6c4853b5b,2016-02-09T12:29:09Z,https://github.com/scikit-learn/scikit-learn/commit/706b45e03e0a4e8aae08560853eba7b6c4853b5b,Merge pull request #6314 from tshauck/remove-superfluous-declaration  Removes X= after raise.,1,Remove Dead Code,,
2d6f68a084f6d9ee7d5c1744fc2cb9272fa477ee,2016-02-09T06:02:36Z,https://github.com/scikit-learn/scikit-learn/commit/2d6f68a084f6d9ee7d5c1744fc2cb9272fa477ee,Removes X= after raise.,1,Remove Dead Code,,
2ff9a4b39dd3d7b604471cba85888d246af6c433,2015-12-30T14:02:57Z,https://github.com/scikit-learn/scikit-learn/commit/2ff9a4b39dd3d7b604471cba85888d246af6c433,Remove useless normalization ?fixes #6075,1,Remove Dead Code,,
5bba3d0a9773ec1d5c7f18b729c68a69ae06dff5,2015-11-13T06:39:25Z,https://github.com/scikit-learn/scikit-learn/commit/5bba3d0a9773ec1d5c7f18b729c68a69ae06dff5,Merge pull request #5806 from vighneshbirodkar/nmf_fix  Remove exit call in topic extraction example,1,Remove Dead Code,,
10445f556b1e91206a37adb19b4adefdfe72847a,2015-11-12T20:45:45Z,https://github.com/scikit-learn/scikit-learn/commit/10445f556b1e91206a37adb19b4adefdfe72847a,Removed exit() call in topic extraction example,1,Remove Dead Code,,
b06509954aed67e80885742c38386c1d259b332d,2015-11-12T16:42:27Z,https://github.com/scikit-learn/scikit-learn/commit/b06509954aed67e80885742c38386c1d259b332d,Merge pull request #5801 from hlin117/pca-plotting  Remove unused code from plotting tutorial,1,Remove Dead Code,,
c6d617014899c66df01cad2c8d42422ab374dbbb,2015-11-12T16:16:10Z,https://github.com/scikit-learn/scikit-learn/commit/c6d617014899c66df01cad2c8d42422ab374dbbb,#5766: Removed unused code from plotting tutorial,1,Remove Dead Code,,
0c366942da4263301534a425bf9611b8048acab2,2015-10-31T09:05:56Z,https://github.com/scikit-learn/scikit-learn/commit/0c366942da4263301534a425bf9611b8048acab2,Merge pull request #5645 from sieben/useless_pass  remove useless pass,1,Remove Dead Code,,
c95ee28961859731a2863379439501ea5a2770fe,2015-10-31T09:02:35Z,https://github.com/scikit-learn/scikit-learn/commit/c95ee28961859731a2863379439501ea5a2770fe,remove useless pass,1,Remove Dead Code,,
e3a95bfb35df1491215e7e3a56c6327839f24d96,2015-10-29T08:56:16Z,https://github.com/scikit-learn/scikit-learn/commit/e3a95bfb35df1491215e7e3a56c6327839f24d96,Merge pull request #5613 from jakevdp/tsne-cleanup  MAINT: remove unused code from TSNE,1,Remove Dead Code,,
28d53456b95af80b6ed1ae0773576f8625bf9205,2015-10-28T22:27:27Z,https://github.com/scikit-learn/scikit-learn/commit/28d53456b95af80b6ed1ae0773576f8625bf9205,MAINT: remove unused code from TSNE,1,Remove Dead Code,,
fffa98ad1f2636ca734a2901193685449521cc6a,2015-10-20T16:24:35Z,https://github.com/scikit-learn/scikit-learn/commit/fffa98ad1f2636ca734a2901193685449521cc6a,MAINT Remove deprecated stuff that will be removed in 0.18  MAINT Remove support for gamma == 0.0 MAINT Remove support for uppercase values for loss and penalty,1,Remove Dead Code,,
f24d94aec4715f4fdfa212a4a0467d94aff05914,2015-10-20T02:59:10Z,https://github.com/scikit-learn/scikit-learn/commit/f24d94aec4715f4fdfa212a4a0467d94aff05914,remove test for self.scale_,1,Remove Dead Code,,
ebf3f05994a86a71f54a2257a2ae7e18a423d7f5,2015-10-19T16:07:10Z,https://github.com/scikit-learn/scikit-learn/commit/ebf3f05994a86a71f54a2257a2ae7e18a423d7f5,REFACTOR Removed literal form of specifying bounds for ConstantKernel,1,Remove Dead Code,,
19fc67c86e4c867eb3425c82dc148f2d197343d0,2015-10-19T14:01:30Z,https://github.com/scikit-learn/scikit-learn/commit/19fc67c86e4c867eb3425c82dc148f2d197343d0,Merge pull request #5454 from GaelVaroquaux/test_branch  MAINT: remove unused import,1,Remove Dead Code,,
8c9c8a5eba196f553d25bc37cf8b9fad090d3cd5,2015-10-19T13:30:53Z,https://github.com/scikit-learn/scikit-learn/commit/8c9c8a5eba196f553d25bc37cf8b9fad090d3cd5,MAINT: remove unused import,1,Remove Dead Code,,
7e29af034bd306bb7c55290d9d7b53edd9465790,2015-10-19T08:44:42Z,https://github.com/scikit-learn/scikit-learn/commit/7e29af034bd306bb7c55290d9d7b53edd9465790,MAINT remove deprecated stuff that will no longer be supported in 0.18,1,Remove Dead Code,,
3d41053d67c48a997374e76cdafca247b3a0f88b,2015-10-05T15:25:06Z,https://github.com/scikit-learn/scikit-learn/commit/3d41053d67c48a997374e76cdafca247b3a0f88b,Minor doc changes and removed _set_threshold and _set_importances,1,Remove Dead Code,,
af587ec76805212f55a4301044ec5124dbae2d13,2015-08-23T13:30:53Z,https://github.com/scikit-learn/scikit-learn/commit/af587ec76805212f55a4301044ec5124dbae2d13,Removed unnecessary class checks,1,Remove Dead Code,,
7e828db722644c3ee3618887cfe96d57128da003,2015-08-11T16:57:15Z,https://github.com/scikit-learn/scikit-learn/commit/7e828db722644c3ee3618887cfe96d57128da003,MAINT remove unused import warnings,1,Remove Dead Code,,
cfd4e62e1e1f5d537eb1c6458ab3ee5b767515d1,2015-07-11T19:32:32Z,https://github.com/scikit-learn/scikit-learn/commit/cfd4e62e1e1f5d537eb1c6458ab3ee5b767515d1,"Closes #4614  Moved pickle tests for estimators from individual tests for classifiers, regressors, and transformers to tests for all estimators. This means that all estimators are now tested for pickleability.",1,Remove Dead Code,,
ac40d4ffb37c8b0042d42bc4eb5ece51ce9debe5,2015-07-03T15:10:13Z,https://github.com/scikit-learn/scikit-learn/commit/ac40d4ffb37c8b0042d42bc4eb5ece51ce9debe5,MAINT PLS Remove deprecated coefs attribute  PEP8 pls_.py,1,Remove Dead Code,,
a1c3561ddf41569ef13bfaeefb06d159739e41cc,2015-06-25T19:34:15Z,https://github.com/scikit-learn/scikit-learn/commit/a1c3561ddf41569ef13bfaeefb06d159739e41cc,remove main in test,1,Remove Dead Code,,
36bb611a8f0936acb4737721c37c0557ee1ffd24,2015-06-25T19:28:37Z,https://github.com/scikit-learn/scikit-learn/commit/36bb611a8f0936acb4737721c37c0557ee1ffd24,remove self.n_features_,1,Remove Dead Code,,
a8626b36a6d2a77487671372f52291ac10f4da2d,2015-05-28T18:54:01Z,https://github.com/scikit-learn/scikit-learn/commit/a8626b36a6d2a77487671372f52291ac10f4da2d,TST/COSMIT remove nose call boilerplate,1,Remove Dead Code,,
e822fa74fc6cb9b930e4be986980c66e90ab2a7f,2015-05-22T10:01:40Z,https://github.com/scikit-learn/scikit-learn/commit/e822fa74fc6cb9b930e4be986980c66e90ab2a7f,"STYLE removed unused import, fixed comment indent and spacing",1,Remove Dead Code,,
815270b3439382670f9b5094da24af328b5e47bf,2015-05-21T20:21:25Z,https://github.com/scikit-learn/scikit-learn/commit/815270b3439382670f9b5094da24af328b5e47bf,Remove redundant code,1,Remove Dead Code,,
3ddeb0e0e6eec5a55f14f5610493f4dec3583713,2015-05-16T02:42:45Z,https://github.com/scikit-learn/scikit-learn/commit/3ddeb0e0e6eec5a55f14f5610493f4dec3583713,remove duplicate code in _approx_bound method,1,Remove Dead Code,,
dd2fdbb18cb1ebe8acadfb3c47bf7d0564a2ad5a,2015-05-15T23:50:56Z,https://github.com/scikit-learn/scikit-learn/commit/dd2fdbb18cb1ebe8acadfb3c47bf7d0564a2ad5a,Removed superfluous testcase for robust scaler,1,Remove Dead Code,,
f7ca553d007ede31e58b0fd9e332eab8e6cfbd05,2015-05-15T21:47:10Z,https://github.com/scikit-learn/scikit-learn/commit/f7ca553d007ede31e58b0fd9e332eab8e6cfbd05,Remove warn_if_not_float,1,Remove Dead Code,,
da9a91d8f5607703c5f7f5543e84e341611fea5c,2015-05-12T20:47:59Z,https://github.com/scikit-learn/scikit-learn/commit/da9a91d8f5607703c5f7f5543e84e341611fea5c,COSMIT remove unnecessary float casting from tomography example,1,Remove Dead Code,,
8add36bdb92f318b5da4d4570a5d8f936a346257,2015-05-06T13:14:06Z,https://github.com/scikit-learn/scikit-learn/commit/8add36bdb92f318b5da4d4570a5d8f936a346257,"Better assert_raises use, API compliance, better ordering  Removed the need for printing attributes to raise exceptions in the tests  Removed unnecessary setting of attributes in the initialisation.  Moved check for warm_start and oob_score",1,Remove Dead Code,,
43a46365cc76674ab55ceef8c5e9d26d29c48001,2015-05-02T18:28:18Z,https://github.com/scikit-learn/scikit-learn/commit/43a46365cc76674ab55ceef8c5e9d26d29c48001,Removed the deprecation and added a test for a boolean flag value.,1,Remove Dead Code,,
899cc876c2a50798af6e0a9398f8fc19056c87f4,2015-05-01T16:31:44Z,https://github.com/scikit-learn/scikit-learn/commit/899cc876c2a50798af6e0a9398f8fc19056c87f4,Merge pull request #4659 from MAnyKey/sampler-samples  remove useless |samples| variable out of ParameterSampler.__iter__(),1,Remove Dead Code,,
afeb7ee2c0500f0a008d1d6ffe689862f6478e94,2015-05-01T15:06:40Z,https://github.com/scikit-learn/scikit-learn/commit/afeb7ee2c0500f0a008d1d6ffe689862f6478e94,remove useless |samples| variable out of ParameterSampler.__iter__(),1,Remove Dead Code,,
0949a2e35331c85fe24f0f3f478961ebc7e7cfc7,2015-04-16T12:13:26Z,https://github.com/scikit-learn/scikit-learn/commit/0949a2e35331c85fe24f0f3f478961ebc7e7cfc7,remove order checks for sparse matrices,1,Remove Dead Code,,
bc5acea9acd93fbbb560ce70e8da14755d315f70,2015-03-19T00:16:04Z,https://github.com/scikit-learn/scikit-learn/commit/bc5acea9acd93fbbb560ce70e8da14755d315f70,Merge pull request #4412 from ragv/maint_remove_n_iterations_2  MAINT Remove the deprecated n_iterations from StratifiedShuffleSplit,1,Remove Dead Code,,
bf5fd93f4768dd42a4bc77f6945e9b9b9c48dc7c,2015-03-18T23:43:09Z,https://github.com/scikit-learn/scikit-learn/commit/bf5fd93f4768dd42a4bc77f6945e9b9b9c48dc7c,MAINT Remove the deprecated n_iterations from StratifiedShuffleSplit,1,Remove Dead Code,,
e1af92b640e53be2707413f6f24c1bb73a34444d,2015-03-18T18:51:37Z,https://github.com/scikit-learn/scikit-learn/commit/e1af92b640e53be2707413f6f24c1bb73a34444d,remove cross_validation.Bootstrap,1,Remove Dead Code,,
6beacc3fb6cb9777f7fcb6c7a1e3e04315b98db0,2015-03-18T18:49:04Z,https://github.com/scikit-learn/scikit-learn/commit/6beacc3fb6cb9777f7fcb6c7a1e3e04315b98db0,remove deprecated stuff from 0.17,1,Remove Dead Code,,
4a57c9291e4b06e579708de6dbeffcc5ff851639,2015-03-12T17:55:11Z,https://github.com/scikit-learn/scikit-learn/commit/4a57c9291e4b06e579708de6dbeffcc5ff851639,Merge pull request #4383 from saketkc/maint  MAINT: Remove reimport,1,Remove Dead Code,,
6544a4cb513fc10783ad6869abb8c0fc788e35fa,2015-03-11T22:08:35Z,https://github.com/scikit-learn/scikit-learn/commit/6544a4cb513fc10783ad6869abb8c0fc788e35fa,MAINT: Remove reimport,1,Remove Dead Code,,
663c236cca535235bce8af5ab5c7850828e5c3f7,2015-03-03T20:38:52Z,https://github.com/scikit-learn/scikit-learn/commit/663c236cca535235bce8af5ab5c7850828e5c3f7,Removes RBF calculation by hand,1,Remove Dead Code,,
8cf714cc9d14a0050f6bb2e6f998ee50a4134975,2015-02-26T15:14:02Z,https://github.com/scikit-learn/scikit-learn/commit/8cf714cc9d14a0050f6bb2e6f998ee50a4134975,remove special case for BaggingEstimator after merge of #4137,1,Remove Dead Code,,
edc9bbb5c7fb68dde20c55033a62cc6c28897cd1,2015-01-20T20:48:35Z,https://github.com/scikit-learn/scikit-learn/commit/edc9bbb5c7fb68dde20c55033a62cc6c28897cd1,"remove duplicated test, probably caused by rebase issues.",1,Remove Dead Code,,
73f0d2bef4160f47d0b676f168fee98ef7e019ea,2015-01-18T05:52:43Z,https://github.com/scikit-learn/scikit-learn/commit/73f0d2bef4160f47d0b676f168fee98ef7e019ea,Remove unused imports.,1,Remove Dead Code,,
4fe8d93835361eed264c9cf6be94d911139fecda,2015-01-11T19:03:40Z,https://github.com/scikit-learn/scikit-learn/commit/4fe8d93835361eed264c9cf6be94d911139fecda,MAINT Remove the _check_fitted test.,1,Remove Dead Code,,
16662744acda542b45e997289d051621ac02b04d,2015-01-11T18:54:29Z,https://github.com/scikit-learn/scikit-learn/commit/16662744acda542b45e997289d051621ac02b04d,TST slight cleanup of common tests.,1,Remove Dead Code,,
4e270a5157e02a1c683c953f9016d827bd47f05a,2014-12-29T19:00:06Z,https://github.com/scikit-learn/scikit-learn/commit/4e270a5157e02a1c683c953f9016d827bd47f05a,remove deprecation tests.,1,Remove Dead Code,,
46c1c42131285cf22edb2dd1790fc849161b83de,2014-12-29T18:53:42Z,https://github.com/scikit-learn/scikit-learn/commit/46c1c42131285cf22edb2dd1790fc849161b83de,"remove deprecated ``n_bootstraps`` parameter in Bootstrap cv object, verbose in FactorAnalysis and SelectorMixin. Also adjust some deprecation strings.",1,Remove Dead Code,,
2d6f1c3d24830f6c9fa25175760431d2a73977c7,2014-12-22T15:48:29Z,https://github.com/scikit-learn/scikit-learn/commit/2d6f1c3d24830f6c9fa25175760431d2a73977c7,MAINT remove deprecated auc_score function,1,Remove Dead Code,,
7ac19aca77768d4ad21af2e708146bf0e7447d06,2014-12-18T22:48:56Z,https://github.com/scikit-learn/scikit-learn/commit/7ac19aca77768d4ad21af2e708146bf0e7447d06,remove _iff_attr_has_method function,1,Remove Dead Code,,
3a752d46108e4da3a234b836afcd276525aa0472,2014-12-18T18:42:42Z,https://github.com/scikit-learn/scikit-learn/commit/3a752d46108e4da3a234b836afcd276525aa0472,Removed redundant ran_seed from GaussianRandomProjection Initialization.,1,Remove Dead Code,,
2539e2f00afe88ea196f41a3699e89b25b6b29ae,2014-12-18T18:42:42Z,https://github.com/scikit-learn/scikit-learn/commit/2539e2f00afe88ea196f41a3699e89b25b6b29ae,Removed cached hash and replaced with numpy packbits.,1,Remove Dead Code,,
d10025bd2b83f984cec248eda4bfc2886e60bfbe,2014-12-18T18:42:30Z,https://github.com/scikit-learn/scikit-learn/commit/d10025bd2b83f984cec248eda4bfc2886e60bfbe,MAINT refactor LSH forest code  Removed _do_hash function. The functionality of _do_hash is done within the _create_tree function as a hashing function is generated for each tree and it doesn't need a separate function.  Added _convert_to_hash function. This will be used in the queries and insertions to convert the data point into the integer represented by the binary hash.  Updated _generate_masks to work with cached hashes.  Changed the insert function to accpet a batch of data points(a 2D array). Now trees and original indices are stored in lists. Tests for insert and fit functions have been updated.  Changed safe_asarray to check_arrary.,1,Remove Dead Code,,
2b5634330c72420086a4a302cb407f3e319ef4ca,2014-12-18T01:02:47Z,https://github.com/scikit-learn/scikit-learn/commit/2b5634330c72420086a4a302cb407f3e319ef4ca,Use check_array and remove shape check,1,Remove Dead Code,,
5b90e97ebf39f8ec2b0a27c6d18c6291bff20baa,2014-12-17T09:37:33Z,https://github.com/scikit-learn/scikit-learn/commit/5b90e97ebf39f8ec2b0a27c6d18c6291bff20baa,"TST remove SVR(probability=True) from AdaBoost tests  Doesn't seem to have been testing anything, because CustomSVR doesn't have predict_proba.",1,Remove Dead Code,,
4140249893c9c023894797cbb165f053a1ed8d21,2014-12-16T10:35:57Z,https://github.com/scikit-learn/scikit-learn/commit/4140249893c9c023894797cbb165f053a1ed8d21,Removed private _decision_function(),1,Remove Dead Code,,
eb6fcb2be6729aa96d05d6ada967ad9aa2def2d7,2014-12-15T13:04:07Z,https://github.com/scikit-learn/scikit-learn/commit/eb6fcb2be6729aa96d05d6ada967ad9aa2def2d7,Remove optional input validation from pairwise_metrics,1,Remove Dead Code,,
076c822da2de97853a7007f7e52afe539f2a7cab,2014-11-20T06:26:12Z,https://github.com/scikit-learn/scikit-learn/commit/076c822da2de97853a7007f7e52afe539f2a7cab,COSMIT: minor cleanup,1,Remove Dead Code,,
c1a429e46db05954f92ab74f62716579bd357cb4,2014-11-13T20:31:09Z,https://github.com/scikit-learn/scikit-learn/commit/c1a429e46db05954f92ab74f62716579bd357cb4,Remove unused distance calculation from clustering example.,1,Remove Dead Code,,
6b548f96f15ea49186ec7b6fdc7f7e2634ce0740,2014-10-24T10:58:13Z,https://github.com/scikit-learn/scikit-learn/commit/6b548f96f15ea49186ec7b6fdc7f7e2634ce0740,MAINT remove deprecated loss in gradient boosting,1,Remove Dead Code,,
d4405cbf6cb3eb0340048fe01b0e5e32b0a1b41f,2014-10-21T15:33:48Z,https://github.com/scikit-learn/scikit-learn/commit/d4405cbf6cb3eb0340048fe01b0e5e32b0a1b41f,MAINT remove deprecated oob_score_,1,Remove Dead Code,,
657c86f618de327352d0fe3a5f17f9485e77460a,2014-10-13T08:32:22Z,https://github.com/scikit-learn/scikit-learn/commit/657c86f618de327352d0fe3a5f17f9485e77460a,ENH: Removed 1d shortcut in _spatial_median again,1,Remove Dead Code,,
076bad6a7c8fb0b1727e14400c15aab42e2d9ce5,2014-10-12T13:19:33Z,https://github.com/scikit-learn/scikit-learn/commit/076bad6a7c8fb0b1727e14400c15aab42e2d9ce5,ENH: Removed median_absolute_error due to PR #3761,1,Remove Dead Code,,
b28e2b6dbf19666520e50250921e97b5b2c8171d,2014-09-06T10:00:09Z,https://github.com/scikit-learn/scikit-learn/commit/b28e2b6dbf19666520e50250921e97b5b2c8171d,ENH: Removed unnecessary generator in theil_sen,1,Remove Dead Code,,
1314697ca2978344cc2446e951a11603a6dce196,2014-09-05T23:29:16Z,https://github.com/scikit-learn/scikit-learn/commit/1314697ca2978344cc2446e951a11603a6dce196,ENH: Removed _split_indices method in TheilSen,1,Remove Dead Code,,
09d44f1664d5f20acf0a5671019909ea98b5deda,2014-09-05T22:54:30Z,https://github.com/scikit-learn/scikit-learn/commit/09d44f1664d5f20acf0a5671019909ea98b5deda,ENH: Removed shared-memory parallelism in theil_sen,1,Remove Dead Code,,
181c720267b71a86ac3b29299999b5c12946c59b,2014-09-05T22:13:24Z,https://github.com/scikit-learn/scikit-learn/commit/181c720267b71a86ac3b29299999b5c12946c59b,"TST: Cleanups in test_theil_sen  - Removed unnecessary arrays e.g. w = np.array([3.]) - Merged two functions, i.e. gen_toy_problem_1d with/without intercept - Usage of RandomState instead of np.random.seed",1,Remove Dead Code,,
c453711bc6cc5e759ab250d3bc6677e6641fd186,2014-09-04T14:13:05Z,https://github.com/scikit-learn/scikit-learn/commit/c453711bc6cc5e759ab250d3bc6677e6641fd186,"MAINT big refactor of sklearn.cluster.bicluster  * Removed dead and useless code in the utils submodule; * decoupled sklearn.base from the bicluster module (no more deep import); * rewrote tests to test the API, not the implementation; * added input validation to the get_submatrix method (but it still needs   documentation, because I've no idea what to pass for data); * got rid of the subdirectory when it turned out only one file was left.",1,Remove Dead Code,,
37ac31440fb75b6d0225ffa4b74ac8fc5f05f11c,2014-09-04T10:47:35Z,https://github.com/scikit-learn/scikit-learn/commit/37ac31440fb75b6d0225ffa4b74ac8fc5f05f11c,MAINT remove unused MST code,1,Remove Dead Code,,
e77b8ef747453c5bb16e1f2793c5373da7331253,2014-09-03T10:00:32Z,https://github.com/scikit-learn/scikit-learn/commit/e77b8ef747453c5bb16e1f2793c5373da7331253,"MAINT remove harmless, but useless, double call to csr_matrix  The input validation code will already have performed the conversion. Calling this constructor on a CSR matrix doesn't actually copy, but it's useless too.",1,Remove Dead Code,,
f37618ab526191910b9bd685c626c627bad3676e,2014-08-31T11:14:15Z,https://github.com/scikit-learn/scikit-learn/commit/f37618ab526191910b9bd685c626c627bad3676e,ENH: Remove unused copy  One copy was done above the copy removed.  Validated IRL by @ogrisel,1,Remove Dead Code,,
959a4ac698777cbb7167fef898edc476ee8befcb,2014-08-26T11:58:07Z,https://github.com/scikit-learn/scikit-learn/commit/959a4ac698777cbb7167fef898edc476ee8befcb,MAINT: Remove BaseLibLinear for LogisticRegression,1,Remove Dead Code,,
c0b92e5a4dc83133d8e463d09126901e73adc1f7,2014-08-24T13:18:25Z,https://github.com/scikit-learn/scikit-learn/commit/c0b92e5a4dc83133d8e463d09126901e73adc1f7,forgot to remove an import,1,Remove Dead Code,,
a7c912808072f10869396c611e3cebe7575ecaa6,2014-08-06T09:40:45Z,https://github.com/scikit-learn/scikit-learn/commit/a7c912808072f10869396c611e3cebe7575ecaa6,"ENH removed manual code for parallel task batching forests  Forests now use the threading backend that has such a low overhead that batching tasks together does not bring any measurable performance benefit.  This removes the boilerplate to simplify the code and make it easier to understand and maintain.  Furthermore, batching will soon be implemented in joblib. So even for models that use the multiprocessing backend, manually batching tasks will be useless at some point.",1,Remove Dead Code,,
0e314728dc3ab14c46de5cb7da2bf14302cf7f7d,2014-08-05T18:04:45Z,https://github.com/scikit-learn/scikit-learn/commit/0e314728dc3ab14c46de5cb7da2bf14302cf7f7d,Remove transposes from testing of random_choice_csc,1,Remove Dead Code,,
f59e4da4abeda4b0f38f2dd3f4f621f98e654608,2014-08-05T15:32:37Z,https://github.com/scikit-learn/scikit-learn/commit/f59e4da4abeda4b0f38f2dd3f4f621f98e654608,"Test random_choice_csc implicit, readability adjustments  Readability: remove unecessary transpose",1,Remove Dead Code,,
8c3a986500f72cc770b5a6e4d5bb5752c56688d7,2014-07-31T18:00:52Z,https://github.com/scikit-learn/scikit-learn/commit/8c3a986500f72cc770b5a6e4d5bb5752c56688d7,"Remove redundant indices, data, indptr appends in predict  Take them out of the four branches and do them once at the end of all of the conditionals",1,Remove Dead Code,,
4052878c2c7c59dea09b20c95ba8cc578904228c,2014-07-31T18:00:52Z,https://github.com/scikit-learn/scikit-learn/commit/4052878c2c7c59dea09b20c95ba8cc578904228c,Remove temporary code from test_sparse_target_data  The code was used to test a classifier with an incomplete  predict function.,1,Remove Dead Code,,
16adbd5c2441b65449c65f1a0aceb057971f6043,2014-07-28T13:45:05Z,https://github.com/scikit-learn/scikit-learn/commit/16adbd5c2441b65449c65f1a0aceb057971f6043,MAINT: Effectively remove deprecated parameters,1,Remove Dead Code,,
56057c9630dd13f3c61fbb4c7debdff6ba8e9e8c,2014-07-23T14:19:40Z,https://github.com/scikit-learn/scikit-learn/commit/56057c9630dd13f3c61fbb4c7debdff6ba8e9e8c,MAINT remove deprecated code,1,Remove Dead Code,,
228f5b043fd19c4ffcff9c05c77b46381a44325a,2014-07-22T14:57:40Z,https://github.com/scikit-learn/scikit-learn/commit/228f5b043fd19c4ffcff9c05c77b46381a44325a,Remove warning (not needed any more),1,Remove Dead Code,,
c9789c7edfc95a5b8f81e7ed9c297588490741c0,2014-07-22T14:10:16Z,https://github.com/scikit-learn/scikit-learn/commit/c9789c7edfc95a5b8f81e7ed9c297588490741c0,COSMIT clean up tests with pyflakes  test_ridge.py contained two duplicate functions.,1,Remove Dead Code,,
be93a75d293bfa0c8de57db3cd41151a98e93696,2014-07-22T13:58:55Z,https://github.com/scikit-learn/scikit-learn/commit/be93a75d293bfa0c8de57db3cd41151a98e93696,MAINT remove sklearn.test,1,Remove Dead Code,,
c484a4a8446c8809cf39e62751a6633d565d3edc,2014-07-22T13:57:18Z,https://github.com/scikit-learn/scikit-learn/commit/c484a4a8446c8809cf39e62751a6633d565d3edc,MAINT remove deprecated code from preprocessing,1,Remove Dead Code,,
259b487fb46d003a790d8426819d7faacd4ac51d,2014-07-22T13:54:54Z,https://github.com/scikit-learn/scikit-learn/commit/259b487fb46d003a790d8426819d7faacd4ac51d,MAINT remove deprecated sklearn.pls module,1,Remove Dead Code,,
2fca6ce2447eb33dc8f5a3931cba863e22a7cfb2,2014-07-22T13:52:48Z,https://github.com/scikit-learn/scikit-learn/commit/2fca6ce2447eb33dc8f5a3931cba863e22a7cfb2,MAINT remove deprecated code from trees and forests,1,Remove Dead Code,,
88b05ff90889a9854505beae793ff80e1c78aef9,2014-07-22T13:45:35Z,https://github.com/scikit-learn/scikit-learn/commit/88b05ff90889a9854505beae793ff80e1c78aef9,MAINT remove deprecated PCA code,1,Remove Dead Code,,
5517bad3fb4748f542b04d18a35d85fb7154fdbb,2014-07-20T13:51:50Z,https://github.com/scikit-learn/scikit-learn/commit/5517bad3fb4748f542b04d18a35d85fb7154fdbb,Merge pull request #3447 from amueller/input_validation_b  [WIP] remove check_arrays stuff and old input validation,1,Remove Dead Code,,
6e2a83b4e184f0e51aead75d5c82fc0284fa6233,2014-07-20T11:31:45Z,https://github.com/scikit-learn/scikit-learn/commit/6e2a83b4e184f0e51aead75d5c82fc0284fa6233,remove check_arrays stuff and old input validation,1,Remove Dead Code,,
7236ade3f03115a81c6fef79ca42ecf66fc4f17f,2014-07-17T15:32:19Z,https://github.com/scikit-learn/scikit-learn/commit/7236ade3f03115a81c6fef79ca42ecf66fc4f17f,Tidy up by removing unnecessary local variables,1,Remove Dead Code,,
ce29c70cae50d46b851effa40deb5e7e44b3976a,2014-07-17T12:38:22Z,https://github.com/scikit-learn/scikit-learn/commit/ce29c70cae50d46b851effa40deb5e7e44b3976a,Removed 'Gram' and 'Xy' parameters were still in test_omp.py,1,Remove Dead Code,,
72d9e2542eb2ac4e70debfea5b77663279bbd4a1,2014-07-14T18:47:18Z,https://github.com/scikit-learn/scikit-learn/commit/72d9e2542eb2ac4e70debfea5b77663279bbd4a1,remove redundant code,1,Remove Dead Code,,
3f5194eb063ee506807fec79bf2c7f6d3d46e223,2014-06-09T15:52:13Z,https://github.com/scikit-learn/scikit-learn/commit/3f5194eb063ee506807fec79bf2c7f6d3d46e223,MAINT removed shadowed broken test,1,Remove Dead Code,,
c7db70ac9f430baba426ed2b8fb668eaab43c3b6,2014-06-08T19:44:01Z,https://github.com/scikit-learn/scikit-learn/commit/c7db70ac9f430baba426ed2b8fb668eaab43c3b6,"removed unused variables and imports, add used imports where missing.",1,Remove Dead Code,,
a30fafaefadede3f4e86e3c2ed3253b93deeecc3,2014-06-06T04:12:42Z,https://github.com/scikit-learn/scikit-learn/commit/a30fafaefadede3f4e86e3c2ed3253b93deeecc3,TST remove dependencies for testing sphinxext,1,Remove Dead Code,,
9e7351dd2e968a9143fcf481cb0cd38830576ada,2014-06-03T00:13:48Z,https://github.com/scikit-learn/scikit-learn/commit/9e7351dd2e968a9143fcf481cb0cd38830576ada,Removed prints statements used for debugging,1,Remove Dead Code,,
bcdc26d7fdf4b88dcc6272542dbb613c2710f546,2014-06-03T00:13:48Z,https://github.com/scikit-learn/scikit-learn/commit/bcdc26d7fdf4b88dcc6272542dbb613c2710f546,"Removed densification calls on X  '.asarry()' from all predict methods, removed 'dense' parameter from check arrays call, removed contiguous cast of the input array X, detected X as list or array to find the number of examples accordinly using len() or shape[0]",1,Remove Dead Code,,
8d0fadabbc5cc0921fb2c7fdabc1659812ba03e8,2014-05-28T17:56:09Z,https://github.com/scikit-learn/scikit-learn/commit/8d0fadabbc5cc0921fb2c7fdabc1659812ba03e8,Remove generalization,1,Remove Dead Code,,
5de4c7ddc68fc194dc03de5bc1537cad082d6cf7,2014-05-28T17:56:09Z,https://github.com/scikit-learn/scikit-learn/commit/5de4c7ddc68fc194dc03de5bc1537cad082d6cf7,Remove example with digits dataset,1,Remove Dead Code,,
f2766ec044408b63b052a28d2e18241ad39d9abb,2014-05-23T12:22:29Z,https://github.com/scikit-learn/scikit-learn/commit/f2766ec044408b63b052a28d2e18241ad39d9abb,COSMIT: remove unused import,1,Remove Dead Code,,
e58405d6f662e728d510f35a7557465c205a170f,2014-05-08T18:56:21Z,https://github.com/scikit-learn/scikit-learn/commit/e58405d6f662e728d510f35a7557465c205a170f,MAINT remove redundant class hierarchy + fix api perform parameter check in fit,1,Remove Dead Code,,
9d1a850fc09773bb4df28a74559357418ad2b979,2014-05-04T10:02:29Z,https://github.com/scikit-learn/scikit-learn/commit/9d1a850fc09773bb4df28a74559357418ad2b979,pep8 remove unused variable,1,Remove Dead Code,,
efd610d801f350b2fae0444a4d2b8e14d4c2aa89,2014-04-13T18:33:00Z,https://github.com/scikit-learn/scikit-learn/commit/efd610d801f350b2fae0444a4d2b8e14d4c2aa89,ENH: remove unused variables,1,Remove Dead Code,,
2495327946cfec71c2e2b79087b22ef08aac5aad,2014-04-01T14:05:52Z,https://github.com/scikit-learn/scikit-learn/commit/2495327946cfec71c2e2b79087b22ef08aac5aad,Remove redundant yet unstable test_spectral_lobpcg_mode  The lobpcg mode is already tested in the test_spectral_clustering test.  LinAlgError was raised when executing test_spectral_lobpcg_mode on some systems depending on the version of the scipy and LAPACK libraries.,1,Remove Dead Code,,
096070d1059c780478bb704049b87c8a17826c0a,2014-03-19T22:55:56Z,https://github.com/scikit-learn/scikit-learn/commit/096070d1059c780478bb704049b87c8a17826c0a,MAINT remove deprecated functionality from SGD,1,Remove Dead Code,,
b4ca1d6f1f70f2ae7d43c0476871f4091b29304c,2014-03-06T22:18:43Z,https://github.com/scikit-learn/scikit-learn/commit/b4ca1d6f1f70f2ae7d43c0476871f4091b29304c,COSMIT Remove unnecessary assertion,1,Remove Dead Code,,
dc27992c1a60b0470cc334713addb47a97c5262c,2014-03-03T19:25:33Z,https://github.com/scikit-learn/scikit-learn/commit/dc27992c1a60b0470cc334713addb47a97c5262c,"MAINT: remove our solve_triangular  No longer needed, since we depend on scipy >= 0.9",1,Remove Dead Code,,
43da4ad830aa869a0331892fa15ed5bfde7133d7,2014-03-03T13:16:49Z,https://github.com/scikit-learn/scikit-learn/commit/43da4ad830aa869a0331892fa15ed5bfde7133d7,ENH/TST remove unnecessary sorts and complete testing for sparse median,1,Remove Dead Code,,
baae60b95df85e1e27ad5739e1a7c824a769e700,2014-03-02T22:44:10Z,https://github.com/scikit-learn/scikit-learn/commit/baae60b95df85e1e27ad5739e1a7c824a769e700,MAINT remove useless import,1,Remove Dead Code,,
998a57aab1bee2ad49acd076d973c1e3e359b8b7,2014-02-12T08:43:05Z,https://github.com/scikit-learn/scikit-learn/commit/998a57aab1bee2ad49acd076d973c1e3e359b8b7,Merge pull request #2852 from jwkvam/adaboost_test  Remove superfluous AdaBoostRegressor call.,1,Remove Dead Code,,
ed928ad9835a5897a1f043a8339df4b41ef785c1,2014-02-12T07:41:31Z,https://github.com/scikit-learn/scikit-learn/commit/ed928ad9835a5897a1f043a8339df4b41ef785c1,Remove superfluous AdaBoostRegressor call.,1,Remove Dead Code,,
75705e2b24a03d5ad20119d919818a2bc2a4938c,2014-02-07T08:25:08Z,https://github.com/scikit-learn/scikit-learn/commit/75705e2b24a03d5ad20119d919818a2bc2a4938c,MISC: remove reference to deprecated Ward,1,Remove Dead Code,,
39949ed3494e1d94d81634f9f97c817664bc79bc,2014-02-03T21:46:11Z,https://github.com/scikit-learn/scikit-learn/commit/39949ed3494e1d94d81634f9f97c817664bc79bc,Merge pull request #2818 from jnothman/flakes  COSMIT remove unused imports and variables,1,Remove Dead Code,,
dbc26ce99613db86e8d6d34c8dfedc6dd1711952,2014-02-03T08:43:56Z,https://github.com/scikit-learn/scikit-learn/commit/dbc26ce99613db86e8d6d34c8dfedc6dd1711952,COSMIT remove unused imports and variables,1,Remove Dead Code,,
5010f393a24aa380bf33bee1a7f7a107ad6da084,2014-01-16T03:43:16Z,https://github.com/scikit-learn/scikit-learn/commit/5010f393a24aa380bf33bee1a7f7a107ad6da084,Remove '_deprecate_loss_and_score_funcs',1,Remove Dead Code,,
b1dfa07ae2f310422dc73d0ee96d679be46596eb,2014-01-16T03:43:16Z,https://github.com/scikit-learn/scikit-learn/commit/b1dfa07ae2f310422dc73d0ee96d679be46596eb,Remove 'fit_grid_point' from 'BaseSearchCV',1,Remove Dead Code,,
0f591e745b1261491e41d964a745755eb2ded5d3,2014-01-16T03:43:16Z,https://github.com/scikit-learn/scikit-learn/commit/0f591e745b1261491e41d964a745755eb2ded5d3,Remove helper function '_fit',1,Remove Dead Code,,
1d7a2d4dc9f95db49e0794c2487bf82484961714,2014-01-15T08:40:17Z,https://github.com/scikit-learn/scikit-learn/commit/1d7a2d4dc9f95db49e0794c2487bf82484961714,COSMIT: remove unused import,1,Remove Dead Code,,
42ea5ecde75d25b953c4b2f3abe7137d5d525c2d,2014-01-01T17:10:16Z,https://github.com/scikit-learn/scikit-learn/commit/42ea5ecde75d25b953c4b2f3abe7137d5d525c2d,COSMIT: remove useless import,1,Remove Dead Code,,
bd58cf9772f0b623df8c9f4dd463912c566736be,2013-12-31T14:44:51Z,https://github.com/scikit-learn/scikit-learn/commit/bd58cf9772f0b623df8c9f4dd463912c566736be,Remove debug print statement,1,Remove Dead Code,,
4f57a942c806dfcb52d485c13423b2f49699e07d,2013-12-17T14:31:22Z,https://github.com/scikit-learn/scikit-learn/commit/4f57a942c806dfcb52d485c13423b2f49699e07d,MAINT remove some dead code from the LibSVM wrapper  We ship a hacked-up v300 and won't support an older version anyway.,1,Remove Dead Code,,
a64d5aa16c0de413b7d3fdebbe2465ba0b114c31,2013-12-10T15:18:52Z,https://github.com/scikit-learn/scikit-learn/commit/a64d5aa16c0de413b7d3fdebbe2465ba0b114c31,Remove deprecated zero_one and zero_one_score,1,Remove Dead Code,,
b308a5325ea4a2fc3e976836bc411760925aadae,2013-12-10T15:00:50Z,https://github.com/scikit-learn/scikit-learn/commit/b308a5325ea4a2fc3e976836bc411760925aadae,Merge pull request #2653 from jaquesgrobler/remove_ellipticenvelope_deprecation  remove EllipticEnvelop deprecation,1,Remove Dead Code,,
79c1c38f65255dfb7d76c7d5f77daec403c323f6,2013-12-10T14:14:42Z,https://github.com/scikit-learn/scikit-learn/commit/79c1c38f65255dfb7d76c7d5f77daec403c323f6,remove EllipticEnvelop deprecation,1,Remove Dead Code,,
303a465c51ff7f59881577c15d661908e16491d9,2013-12-02T10:32:42Z,https://github.com/scikit-learn/scikit-learn/commit/303a465c51ff7f59881577c15d661908e16491d9,TST remove print,1,Remove Dead Code,,
85e1db08529cb5523511ff2c214415eb8eaf4351,2013-12-02T10:32:42Z,https://github.com/scikit-learn/scikit-learn/commit/85e1db08529cb5523511ff2c214415eb8eaf4351,TST clean copy paste mistake,1,Remove Dead Code,,
0b62e572580536163a5c1573e9559d3995c65285,2013-11-29T12:55:39Z,https://github.com/scikit-learn/scikit-learn/commit/0b62e572580536163a5c1573e9559d3995c65285,remove import,1,Remove Dead Code,,
209c93a7cb4679b1aab6bf59b03633d4c20abce9,2013-11-29T10:45:52Z,https://github.com/scikit-learn/scikit-learn/commit/209c93a7cb4679b1aab6bf59b03633d4c20abce9,"remove face-recognition exercises, skeletons, etc and merge artifacts",1,Remove Dead Code,,
36d68b3612889e28ed59212d107493cb2833a9d7,2013-11-25T16:19:05Z,https://github.com/scikit-learn/scikit-learn/commit/36d68b3612889e28ed59212d107493cb2833a9d7,MAINT: unreachable code removed from BernoulliNB  The deleted code was unreachable. The previous call to check_arrays ensures that X and y have consistent first dimensions.,1,Remove Dead Code,,
ab14a08c768fb2321721ec66ee5a951dd902505f,2013-11-21T16:46:40Z,https://github.com/scikit-learn/scikit-learn/commit/ab14a08c768fb2321721ec66ee5a951dd902505f,remove check for condition that might not hold,1,Remove Dead Code,,
6bd380ece6cc61da30fa0fca24176fedfef8e8d4,2013-11-20T20:55:06Z,https://github.com/scikit-learn/scikit-learn/commit/6bd380ece6cc61da30fa0fca24176fedfef8e8d4,remove asserts,1,Remove Dead Code,,
af43c88518703cff2a90af945f5296dc0e83d0c5,2013-11-18T14:50:08Z,https://github.com/scikit-learn/scikit-learn/commit/af43c88518703cff2a90af945f5296dc0e83d0c5,"COSMIT remove useless ""if False"" in kernel approximations  Callable case handled by pairwise_kernels.",1,Remove Dead Code,,
67158600e57fac2e7ac9ac43ad54723854575401,2013-11-16T15:28:47Z,https://github.com/scikit-learn/scikit-learn/commit/67158600e57fac2e7ac9ac43ad54723854575401,TST: remove stray print statement,1,Remove Dead Code,,
0371831388925eff93ec85800f77460a574da659,2013-11-14T08:09:47Z,https://github.com/scikit-learn/scikit-learn/commit/0371831388925eff93ec85800f77460a574da659,removed CV code to tune hyperparameters (better for CI),1,Remove Dead Code,,
5944e1e98c618dae6949a20a2bb6dd713c9db155,2013-11-11T12:44:16Z,https://github.com/scikit-learn/scikit-learn/commit/5944e1e98c618dae6949a20a2bb6dd713c9db155,Remove print statement.,1,Remove Dead Code,,
23331a97d0498cd0ab9bfb447d6965034dd933d9,2013-11-04T12:34:44Z,https://github.com/scikit-learn/scikit-learn/commit/23331a97d0498cd0ab9bfb447d6965034dd933d9,Removed unnecessary attributes,1,Remove Dead Code,,
db75461e21442f7c1337fa47d199992c403cb15e,2013-10-20T13:58:03Z,https://github.com/scikit-learn/scikit-learn/commit/db75461e21442f7c1337fa47d199992c403cb15e,Remove bagged regressor,1,Remove Dead Code,,
dfc48d405eaf990ccbfa50b5b07042821ac330c1,2013-10-20T13:57:59Z,https://github.com/scikit-learn/scikit-learn/commit/dfc48d405eaf990ccbfa50b5b07042821ac330c1,Remove default perceptron base estimator for integer data type,1,Remove Dead Code,,
a12eff1a940c8a0a2b4f5a00a3fc2fcb19ba204c,2013-10-20T13:57:58Z,https://github.com/scikit-learn/scikit-learn/commit/a12eff1a940c8a0a2b4f5a00a3fc2fcb19ba204c,Remove unused variable,1,Remove Dead Code,,
34a9a1a5ca8ce2474162b4688c80117f24c5fa7c,2013-10-20T13:57:57Z,https://github.com/scikit-learn/scikit-learn/commit/34a9a1a5ca8ce2474162b4688c80117f24c5fa7c,Remove deprecated ransac implementation,1,Remove Dead Code,,
755d90cff74c9354fe349a241604523d2b80d2bb,2013-10-20T13:57:55Z,https://github.com/scikit-learn/scikit-learn/commit/755d90cff74c9354fe349a241604523d2b80d2bb,Remove unused variable,1,Remove Dead Code,,
73b1b82400024eb7352a51673c507d38694d1e26,2013-10-16T11:52:27Z,https://github.com/scikit-learn/scikit-learn/commit/73b1b82400024eb7352a51673c507d38694d1e26,Remove leftover print statement,1,Remove Dead Code,,
761dde684aa3639532c18a251ec317c384483ad0,2013-10-13T15:30:47Z,https://github.com/scikit-learn/scikit-learn/commit/761dde684aa3639532c18a251ec317c384483ad0,COSMIT remove dead code in k-means  Private functions _k_init and _kmeans_single were doing too much work.  Should improve the relative coverage.,1,Remove Dead Code,,
94642a4d60e98f337de4d78ba10ef7b71e241ee9,2013-10-09T11:34:58Z,https://github.com/scikit-learn/scikit-learn/commit/94642a4d60e98f337de4d78ba10ef7b71e241ee9,ENH: remove offset calculations,1,Remove Dead Code,,
1c0dc55cece471ae81e8a3eecbfb35eb48cbfb0f,2013-09-21T16:35:42Z,https://github.com/scikit-learn/scikit-learn/commit/1c0dc55cece471ae81e8a3eecbfb35eb48cbfb0f,ENH: remove assert,1,Remove Dead Code,,
4fcb24c8f1e214b3cd44aa3bb76f7aa11ef5f968,2013-09-16T17:17:24Z,https://github.com/scikit-learn/scikit-learn/commit/4fcb24c8f1e214b3cd44aa3bb76f7aa11ef5f968,MAINT remove dead code from LibSVM,1,Remove Dead Code,,
680234d3687c22023d99a439ee832d9d33136c9d,2013-09-16T11:07:17Z,https://github.com/scikit-learn/scikit-learn/commit/680234d3687c22023d99a439ee832d9d33136c9d,MAINT remove deprecated code from CD,1,Remove Dead Code,,
84fa0ba51ab3912cb41c57c897165a22e20d8751,2013-09-05T19:46:34Z,https://github.com/scikit-learn/scikit-learn/commit/84fa0ba51ab3912cb41c57c897165a22e20d8751,simplify FA tests after rebase,1,Remove Dead Code,,
ceffed1d6e76cbb5cabd5fdbce358cd1d9f19d43,2013-09-04T16:43:56Z,https://github.com/scikit-learn/scikit-learn/commit/ceffed1d6e76cbb5cabd5fdbce358cd1d9f19d43,MAINT remove useless deprecation in sklearn.utils  This module is off-limits to users anyway.,1,Remove Dead Code,,
b6f439370ec0077794576bb152a9fb23904947d6,2013-08-31T09:34:19Z,https://github.com/scikit-learn/scikit-learn/commit/b6f439370ec0077794576bb152a9fb23904947d6,Merge pull request #2411 from Balu-Varanasi/remove_unused_import  removed unused import from example,1,Remove Dead Code,,
b38366e33a4762221ab67786e910bad6bf6f5007,2013-08-31T07:14:58Z,https://github.com/scikit-learn/scikit-learn/commit/b38366e33a4762221ab67786e910bad6bf6f5007,removed unused import from example,1,Remove Dead Code,,
85b241c9da0dd4363d1cd1579a16216335cc80bb,2013-08-27T08:28:28Z,https://github.com/scikit-learn/scikit-learn/commit/85b241c9da0dd4363d1cd1579a16216335cc80bb,Minor code cleanup,1,Remove Dead Code,,
5a16ed78794ff858edd659f49a409bfe935fdb60,2013-08-27T08:28:28Z,https://github.com/scikit-learn/scikit-learn/commit/5a16ed78794ff858edd659f49a409bfe935fdb60,Removed euclidean_distances_argmin  This specialized case is useless since pairwise_distances_argmin has been optimized for the euclidean case.,1,Remove Dead Code,,
ec08281f75cbfb220284a179f843f8e1fa6213fc,2013-08-25T09:33:39Z,https://github.com/scikit-learn/scikit-learn/commit/ec08281f75cbfb220284a179f843f8e1fa6213fc,ENH Removed copy option and deprecation on new functions and classes,1,Remove Dead Code,,
b36dcf4f4376494b00923801a9d5a3b445b745b6,2013-08-25T09:33:07Z,https://github.com/scikit-learn/scikit-learn/commit/b36dcf4f4376494b00923801a9d5a3b445b745b6,COSMIT: remove unused import,1,Remove Dead Code,,
bf946fd475e3ff0e8e69b0de0b0a4fa8ef8a360d,2013-08-21T09:02:35Z,https://github.com/scikit-learn/scikit-learn/commit/bf946fd475e3ff0e8e69b0de0b0a4fa8ef8a360d,Removed random_seed argument to svm.SVC,1,Remove Dead Code,,
23e9e1e093c006eb2201f68ad4eff3a38e96a319,2013-08-21T08:03:15Z,https://github.com/scikit-learn/scikit-learn/commit/23e9e1e093c006eb2201f68ad4eff3a38e96a319,Remove spurious print statements in sample snippets to make the doc easier to follow,1,Remove Dead Code,,
e3596a09b445ed61d3b2648a48c8c4c513148ea4,2013-08-15T13:45:17Z,https://github.com/scikit-learn/scikit-learn/commit/e3596a09b445ed61d3b2648a48c8c4c513148ea4,Remove warning in AffinityPropagation.,1,Remove Dead Code,,
31ad968af61eb11ec3efca1b323f7c7801586365,2013-08-12T10:52:17Z,https://github.com/scikit-learn/scikit-learn/commit/31ad968af61eb11ec3efca1b323f7c7801586365,MAINT remove Counter from fixes; no longer used,1,Remove Dead Code,,
bec85af38596c2a4c38b8a53e3960a9ba375fe6f,2013-08-06T06:38:30Z,https://github.com/scikit-learn/scikit-learn/commit/bec85af38596c2a4c38b8a53e3960a9ba375fe6f,MAINT: remove sklearn.test(),1,Remove Dead Code,,
0749e5722159092ac10b08cac13ec5842c461f27,2013-07-25T17:19:25Z,https://github.com/scikit-learn/scikit-learn/commit/0749e5722159092ac10b08cac13ec5842c461f27,Remove print in Hungarian tests,1,Remove Dead Code,,
d53f470d55f12d9a88946963df9a278da3f0456d,2013-07-25T17:19:17Z,https://github.com/scikit-learn/scikit-learn/commit/d53f470d55f12d9a88946963df9a278da3f0456d,removed empty mixin,1,Remove Dead Code,,
5ebd11b2772ebad2446c4e6e711f97cc23a02adb,2013-07-25T17:19:16Z,https://github.com/scikit-learn/scikit-learn/commit/5ebd11b2772ebad2446c4e6e711f97cc23a02adb,removed unused code,1,Remove Dead Code,,
2fc53d32d529bfb2434da484df334f36a3ee82bf,2013-07-25T17:19:14Z,https://github.com/scikit-learn/scikit-learn/commit/2fc53d32d529bfb2434da484df334f36a3ee82bf,removed pickle test,1,Remove Dead Code,,
a8d4956571e3361bce34b09a0bd9730e29efc1ee,2013-07-25T14:52:35Z,https://github.com/scikit-learn/scikit-learn/commit/a8d4956571e3361bce34b09a0bd9730e29efc1ee,ENH remove inspect,1,Remove Dead Code,,
aac47a20fc0dd605521eb4170e38f420d7c9242d,2013-07-25T14:03:57Z,https://github.com/scikit-learn/scikit-learn/commit/aac47a20fc0dd605521eb4170e38f420d7c9242d,ENH remove deprecated things (2),1,Remove Dead Code,,
6fc30affe881f215f993b80b470c6b6c4eb2d001,2013-07-25T12:37:01Z,https://github.com/scikit-learn/scikit-learn/commit/6fc30affe881f215f993b80b470c6b6c4eb2d001,ENH remove deprecated,1,Remove Dead Code,,
4914657fdf1861b24dd212be7c34c27f87140f12,2013-07-25T08:22:33Z,https://github.com/scikit-learn/scikit-learn/commit/4914657fdf1861b24dd212be7c34c27f87140f12,TEST remove deprecated stuff from fastica tests,1,Remove Dead Code,,
950bbfd66043281b1e126bd1e3f5befdb2e78505,2013-07-25T08:21:24Z,https://github.com/scikit-learn/scikit-learn/commit/950bbfd66043281b1e126bd1e3f5befdb2e78505,Remove redundant shape check already done by check_arrays,1,Remove Dead Code,,
c9bd6eab5237d923695fdc13bcbfb036e01632d7,2013-07-25T08:21:23Z,https://github.com/scikit-learn/scikit-learn/commit/c9bd6eab5237d923695fdc13bcbfb036e01632d7,Remove the class_prior partial_fit param,1,Remove Dead Code,,
5c5890ac672a07568ce8ffb5712b3d89e9dc1f66,2013-07-24T16:47:53Z,https://github.com/scikit-learn/scikit-learn/commit/5c5890ac672a07568ce8ffb5712b3d89e9dc1f66,Removed unused import,1,Remove Dead Code,,
5a1097e8d114c30d6f729c190da38d4a63cb5cd4,2013-07-24T15:27:24Z,https://github.com/scikit-learn/scikit-learn/commit/5a1097e8d114c30d6f729c190da38d4a63cb5cd4,Remove redundant test,1,Remove Dead Code,,
539bb3921549600cfd8bc7e0fcf2b3f8eee8a87d,2013-07-24T15:27:23Z,https://github.com/scikit-learn/scikit-learn/commit/539bb3921549600cfd8bc7e0fcf2b3f8eee8a87d,"MISC: remove unecessary dtype  With the cast in check_arrays, this works even with 'safe casting' numpys",1,Remove Dead Code,,
0454a0e867f6b96fd8bafe5fe9d63cce03a11542,2013-07-22T13:49:30Z,https://github.com/scikit-learn/scikit-learn/commit/0454a0e867f6b96fd8bafe5fe9d63cce03a11542,ENH remove _is_1d and _check_1d_array thanks to @GaelVaroquaux,1,Remove Dead Code,,
d1e72c5e01fc1832b89a35adaa9f23f13726552a,2013-07-22T10:20:00Z,https://github.com/scikit-learn/scikit-learn/commit/d1e72c5e01fc1832b89a35adaa9f23f13726552a,WIP: remove partition_features,1,Remove Dead Code,,
247172e9f8e95d7ca7bc694e20a3c1ed688652aa,2013-07-22T10:20:00Z,https://github.com/scikit-learn/scikit-learn/commit/247172e9f8e95d7ca7bc694e20a3c1ed688652aa,WIP: remove BreimanSplitter,1,Remove Dead Code,,
9f0e56e83e71ca4e8f451899c98ebc13c3483ed7,2013-07-22T10:19:57Z,https://github.com/scikit-learn/scikit-learn/commit/9f0e56e83e71ca4e8f451899c98ebc13c3483ed7,WIP: remove asserts,1,Remove Dead Code,,
7e03c7d9d3571515b67c3d463bb8a5ffded6aa0b,2013-07-22T10:19:56Z,https://github.com/scikit-learn/scikit-learn/commit/7e03c7d9d3571515b67c3d463bb8a5ffded6aa0b,removed min_density example - dropped param,1,Remove Dead Code,,
8c82dcd12b71d1fe9aabe6946ef8bbeea1f33cfd,2013-07-22T10:19:56Z,https://github.com/scikit-learn/scikit-learn/commit/8c82dcd12b71d1fe9aabe6946ef8bbeea1f33cfd,WIP: cleanup,1,Remove Dead Code,,
09b6ce9efda90c458ac32918737d3c2f872f8ab3,2013-07-22T08:27:25Z,https://github.com/scikit-learn/scikit-learn/commit/09b6ce9efda90c458ac32918737d3c2f872f8ab3,"Removed actual _csgraph file, tests still all pass",1,Remove Dead Code,,
1d4d66468a42d8360836277c09570ee26c52c78c,2013-07-22T08:27:25Z,https://github.com/scikit-learn/scikit-learn/commit/1d4d66468a42d8360836277c09570ee26c52c78c,Removed reference from spectral_clustering to old csgraph,1,Remove Dead Code,,
40f4e943703ec6f6348fd46ad406d0c3442c26c7,2013-07-14T00:08:29Z,https://github.com/scikit-learn/scikit-learn/commit/40f4e943703ec6f6348fd46ad406d0c3442c26c7,MISC: remove unused imports,1,Remove Dead Code,,
6e1ca5dbeb504d7c810c0662ad10b7fe35b585b0,2013-07-04T12:17:57Z,https://github.com/scikit-learn/scikit-learn/commit/6e1ca5dbeb504d7c810c0662ad10b7fe35b585b0,Remove unused variable.,1,Remove Dead Code,,
58529988ab1585a1aa08f4a77cdd4ab0da2905a2,2013-07-04T10:39:23Z,https://github.com/scikit-learn/scikit-learn/commit/58529988ab1585a1aa08f4a77cdd4ab0da2905a2,Remove if statement.,1,Remove Dead Code,,
4ce2038771c8b89cf90d4cdbb22d3cd51994ce02,2013-07-04T10:39:22Z,https://github.com/scikit-learn/scikit-learn/commit/4ce2038771c8b89cf90d4cdbb22d3cd51994ce02,"removed elaborate testing in ridge.fit, not necessary anymore",1,Remove Dead Code,,
7f9b7834686c7498c6977c7363b87c9cc4ea64a1,2013-06-28T16:13:38Z,https://github.com/scikit-learn/scikit-learn/commit/7f9b7834686c7498c6977c7363b87c9cc4ea64a1,remove scipy cKDTree support from neighbors,1,Remove Dead Code,,
a73fd1a630d3d3cfb8f0a4ee8d81c37204fae347,2013-06-13T08:57:52Z,https://github.com/scikit-learn/scikit-learn/commit/a73fd1a630d3d3cfb8f0a4ee8d81c37204fae347,ENH: removed leftover condition to get a wider application of the import all consistency check,1,Remove Dead Code,,
b036dbc32f0e40a0aa06766f5d0568f1139380e0,2013-05-31T12:09:09Z,https://github.com/scikit-learn/scikit-learn/commit/b036dbc32f0e40a0aa06766f5d0568f1139380e0,remove forgotten print,1,Remove Dead Code,,
aaaa95cf89f1ecb0b20e536c329a5f33141d5b82,2013-05-07T12:43:01Z,https://github.com/scikit-learn/scikit-learn/commit/aaaa95cf89f1ecb0b20e536c329a5f33141d5b82,COSMIT Remove redundant code in CountVectorizer,1,Remove Dead Code,,
9c84263339c053165f370374a6f37c11be0eadc9,2013-05-02T09:48:37Z,https://github.com/scikit-learn/scikit-learn/commit/9c84263339c053165f370374a6f37c11be0eadc9,Remove unnecessary code in ridge svd,1,Remove Dead Code,,
cdb9ef2d58ce4af980e88095055e592734f30b5b,2013-03-17T11:30:17Z,https://github.com/scikit-learn/scikit-learn/commit/cdb9ef2d58ce4af980e88095055e592734f30b5b,COSMIT prevent a copy in randomized LR  Also remove some superseded Py3 compat code.,1,Remove Dead Code,,
1920b88f518c414369d729dbfdc46f7bf3df13ee,2013-03-02T15:39:42Z,https://github.com/scikit-learn/scikit-learn/commit/1920b88f518c414369d729dbfdc46f7bf3df13ee,Removed an unnecessary if statement in KFold __iter__ method.,1,Remove Dead Code,,
018d6adfd8b9e362070e1328ec278461bc9df03b,2013-02-28T17:20:59Z,https://github.com/scikit-learn/scikit-learn/commit/018d6adfd8b9e362070e1328ec278461bc9df03b,StratifiedKFold: remove pointless copy of labels,1,Remove Dead Code,,
f7f54244643f68c8ff2640ca0c6c7f0822463a96,2013-02-05T15:19:32Z,https://github.com/scikit-learn/scikit-learn/commit/f7f54244643f68c8ff2640ca0c6c7f0822463a96,Remove compute_importances parameter,1,Remove Dead Code,,
7d4034a21c78279aa0803adc98ca12102c2c743d,2013-02-04T19:53:20Z,https://github.com/scikit-learn/scikit-learn/commit/7d4034a21c78279aa0803adc98ca12102c2c743d,"COSMIT removed unused imports, fixed error message in test of boosting",1,Remove Dead Code,,
c23dd7482ecd0b1f7d146a5b3b57738f31ceb8b6,2013-02-02T18:52:15Z,https://github.com/scikit-learn/scikit-learn/commit/c23dd7482ecd0b1f7d146a5b3b57738f31ceb8b6,remove check for fit_predict,1,Remove Dead Code,,
e369c4339d548d722a773b8451d111682f2e381e,2013-01-26T17:26:20Z,https://github.com/scikit-learn/scikit-learn/commit/e369c4339d548d722a773b8451d111682f2e381e,"COSMIT remove unused imports, pep8",1,Remove Dead Code,,
c83ce41b0d66ded5f749d84cf003e77e6343f89c,2013-01-26T17:01:28Z,https://github.com/scikit-learn/scikit-learn/commit/c83ce41b0d66ded5f749d84cf003e77e6343f89c,remove warning,1,Remove Dead Code,,
1ba8f074c6ad0373837ddfa8844e7937294baf44,2013-01-26T17:01:28Z,https://github.com/scikit-learn/scikit-learn/commit/1ba8f074c6ad0373837ddfa8844e7937294baf44,"remove the equaldistance code warning, replace with doc warnings",1,Remove Dead Code,,
872ea4b2cef00c047a99e6160bb02a9153e1b586,2013-01-14T10:12:18Z,https://github.com/scikit-learn/scikit-learn/commit/872ea4b2cef00c047a99e6160bb02a9153e1b586,remove weighted_r2_score (leave for next PR scikit-learn#1574),1,Remove Dead Code,,
51b3cefd89f911e1ade03b6419e7b91416223620,2013-01-05T12:54:57Z,https://github.com/scikit-learn/scikit-learn/commit/51b3cefd89f911e1ade03b6419e7b91416223620,remove duplicated dimension check in metrics/pairwise.py,1,Remove Dead Code,,
0665e748a83a1c2f0c996abe317ad150b6c12379,2013-01-05T12:54:57Z,https://github.com/scikit-learn/scikit-learn/commit/0665e748a83a1c2f0c996abe317ad150b6c12379,remove duplicated test_cosine_kernel() in metrics/tests/test_pairwise.py,1,Remove Dead Code,,
2881702f3728d322118d47bae3b2ff5328f82ab9,2013-01-03T12:21:51Z,https://github.com/scikit-learn/scikit-learn/commit/2881702f3728d322118d47bae3b2ff5328f82ab9,ENH removed unused old function,1,Remove Dead Code,,
7d11aaa28b0460bc0273192aeef328e0a5e10771,2013-01-03T12:21:51Z,https://github.com/scikit-learn/scikit-learn/commit/7d11aaa28b0460bc0273192aeef328e0a5e10771,ENH remove class_weight_label from LibLinear python side.,1,Remove Dead Code,,
6782658257c7c4519014070074b60e9bcce750e8,2012-12-26T13:09:52Z,https://github.com/scikit-learn/scikit-learn/commit/6782658257c7c4519014070074b60e9bcce750e8,ENH clean up redundant code in pairwise,1,Remove Dead Code,,
ce7ea536ca34a3b16f425301a1d4d677ba9829d2,2012-12-11T08:33:10Z,https://github.com/scikit-learn/scikit-learn/commit/ce7ea536ca34a3b16f425301a1d4d677ba9829d2,COSMIT Remove duplicated assignement,1,Remove Dead Code,,
742072b656d6578b707189ebeac7d6bb8d4efe9f,2012-12-02T09:32:27Z,https://github.com/scikit-learn/scikit-learn/commit/742072b656d6578b707189ebeac7d6bb8d4efe9f,removed unnecessary repeat,1,Remove Dead Code,,
55bbbc13e6794cb34d33899bff2bc5091d61f935,2012-11-22T11:51:39Z,https://github.com/scikit-learn/scikit-learn/commit/55bbbc13e6794cb34d33899bff2bc5091d61f935,Remove unused import.,1,Remove Dead Code,,
93e4390eec815f7e634500eb558baf481f5bdf34,2012-11-09T20:29:50Z,https://github.com/scikit-learn/scikit-learn/commit/93e4390eec815f7e634500eb558baf481f5bdf34,ENH removed ``remove_zeros`` parameter.,1,Remove Dead Code,,
2d0ab3c4cdc21583b83a799dfe66e4e30564dc13,2012-11-08T08:50:33Z,https://github.com/scikit-learn/scikit-learn/commit/2d0ab3c4cdc21583b83a799dfe66e4e30564dc13,MISC: remove unused import,1,Remove Dead Code,,
0f92da491443fc774833a689b00f0a894a4d427b,2012-11-05T15:53:50Z,https://github.com/scikit-learn/scikit-learn/commit/0f92da491443fc774833a689b00f0a894a4d427b,Remove sample_weight and class_weight from PassiveAggressive*.,1,Remove Dead Code,,
bbc272c1b52822a9c3ba6778756e88380d66493b,2012-11-03T11:23:11Z,https://github.com/scikit-learn/scikit-learn/commit/bbc272c1b52822a9c3ba6778756e88380d66493b,Remove stale test code,1,Remove Dead Code,,
bd87dee1c6faedb63ec457f6a9c6f276c7059cec,2012-11-02T16:26:36Z,https://github.com/scikit-learn/scikit-learn/commit/bd87dee1c6faedb63ec457f6a9c6f276c7059cec,Remove unused code branch.  (_hmmc must be always available nowadays.),1,Remove Dead Code,,
906b942c9fff651383bc2e7ec5ceb5d13c26e8a7,2012-10-28T18:25:30Z,https://github.com/scikit-learn/scikit-learn/commit/906b942c9fff651383bc2e7ec5ceb5d13c26e8a7,remove legacy code,1,Remove Dead Code,,
d3f1d77e5997bb4f65743b4a3441869c3c91dd6b,2012-10-27T18:40:06Z,https://github.com/scikit-learn/scikit-learn/commit/d3f1d77e5997bb4f65743b4a3441869c3c91dd6b,Removed savefig,1,Remove Dead Code,,
cfed074b56d107b51d393bb446a579c24ca28738,2012-10-14T20:44:46Z,https://github.com/scikit-learn/scikit-learn/commit/cfed074b56d107b51d393bb446a579c24ca28738,ENH remove some unreachable code from gridsearch,1,Remove Dead Code,,
f18295c8aeea9361d56f200de2586083a6f8ef7f,2012-10-07T21:25:06Z,https://github.com/scikit-learn/scikit-learn/commit/f18295c8aeea9361d56f200de2586083a6f8ef7f,"TST improve test-coverage in base, remove unreachable code-path",1,Remove Dead Code,,
094c6363e66cfe9677deb9b57b461893ef41d644,2012-10-04T14:11:51Z,https://github.com/scikit-learn/scikit-learn/commit/094c6363e66cfe9677deb9b57b461893ef41d644,COSMIT removed unused import,1,Remove Dead Code,,
7a75fa3e1afdabeadda61a723df19343dc23ea02,2012-10-01T21:19:53Z,https://github.com/scikit-learn/scikit-learn/commit/7a75fa3e1afdabeadda61a723df19343dc23ea02,ENH remove deprecated sparse SVM class from cross-validation test.,1,Remove Dead Code,,
4c11ccd539edd6949aae63e4e461e240b62ad306,2012-09-21T11:31:42Z,https://github.com/scikit-learn/scikit-learn/commit/4c11ccd539edd6949aae63e4e461e240b62ad306,COSMIT remove unused import,1,Remove Dead Code,,
ea511019240bff88c0e90a26d89fe55e7ea65ef3,2012-09-18T18:34:53Z,https://github.com/scikit-learn/scikit-learn/commit/ea511019240bff88c0e90a26d89fe55e7ea65ef3,COSMIT remove unused imports,1,Remove Dead Code,,
65cf66540d8fc3c02077577483b0cf5e5e60589f,2012-09-15T15:43:08Z,https://github.com/scikit-learn/scikit-learn/commit/65cf66540d8fc3c02077577483b0cf5e5e60589f,ENH remove some deprecated parameters / functions /estimators,1,Remove Dead Code,,
af22f290fd294ed9f2ba2f824fa4fcc9eb938655,2012-09-15T14:40:43Z,https://github.com/scikit-learn/scikit-learn/commit/af22f290fd294ed9f2ba2f824fa4fcc9eb938655,remove support for extrapolation,1,Remove Dead Code,,
a8a04c6e737dc5a48ecdf6e664938399c6470c28,2012-09-04T05:56:53Z,https://github.com/scikit-learn/scikit-learn/commit/a8a04c6e737dc5a48ecdf6e664938399c6470c28,remove CV class legacy,1,Remove Dead Code,,
e6f0b1d6644fcbfc349a909d93054623259deeaa,2012-09-04T05:56:52Z,https://github.com/scikit-learn/scikit-learn/commit/e6f0b1d6644fcbfc349a909d93054623259deeaa,remove *CV classes - only pick decision_function and staged predict refactoring,1,Remove Dead Code,,
b515066ee46222ad0267f45dc8b734f6229cce95,2012-09-01T18:02:14Z,https://github.com/scikit-learn/scikit-learn/commit/b515066ee46222ad0267f45dc8b734f6229cce95,Remove deprecated properties in naive_bayes  These were scheduled for removal in 0.12.,1,Remove Dead Code,,
2769dbd77063ccecafe2ee7de1c3012e73d97d5d,2012-09-01T18:02:13Z,https://github.com/scikit-learn/scikit-learn/commit/2769dbd77063ccecafe2ee7de1c3012e73d97d5d,Remove _get_params  This was scheduled for removal in 0.12.,1,Remove Dead Code,,
2516b6217f0c20e684fd7448060a054b23d2e24d,2012-09-01T18:02:13Z,https://github.com/scikit-learn/scikit-learn/commit/2516b6217f0c20e684fd7448060a054b23d2e24d,Remove fast_svd.  This was deprecated in version 0.9.,1,Remove Dead Code,,
02a831a0106eac7ec03d091abe5480442c4c9be3,2012-09-01T18:02:13Z,https://github.com/scikit-learn/scikit-learn/commit/02a831a0106eac7ec03d091abe5480442c4c9be3,Remove LARS and LassoLARS  These classes were renamed and deprecated in version 0.9.,1,Remove Dead Code,,
89813e9ec1cf6c74e7d46e7c60fa7bc13172319a,2012-09-01T18:02:13Z,https://github.com/scikit-learn/scikit-learn/commit/89813e9ec1cf6c74e7d46e7c60fa7bc13172319a,Removed deprecated parameters in GridSearchCV  These were scheduled for removal in 0.12.,1,Remove Dead Code,,
4575b322c1df02f0fb51612dd982715602da3a36,2012-09-01T18:02:13Z,https://github.com/scikit-learn/scikit-learn/commit/4575b322c1df02f0fb51612dd982715602da3a36,Remove sparse_encode_parallel  This was deprecated in 0.10 as far as I can tell.,1,Remove Dead Code,,
f692fafe28bee270a63c4030ec27374828698e1c,2012-09-01T18:02:12Z,https://github.com/scikit-learn/scikit-learn/commit/f692fafe28bee270a63c4030ec27374828698e1c,Removed load_filenames and load_20newsgroups  These were deprecated in 0.9 as far as I can tell,1,Remove Dead Code,,
fc3e680cf383a100da64162738c4054e2f812891,2012-09-01T18:02:12Z,https://github.com/scikit-learn/scikit-learn/commit/fc3e680cf383a100da64162738c4054e2f812891,Remove chunk_size from k_means  This was deprecated in 0.10 as far as I can tell.,1,Remove Dead Code,,
d0efa6f6b3de47800a355e68e5a436a1a41b17c9,2012-09-01T18:02:12Z,https://github.com/scikit-learn/scikit-learn/commit/d0efa6f6b3de47800a355e68e5a436a1a41b17c9,Remove deprecated _set_params and the call in grid_search  This was added prior to 0.9 as far as I can tell.,1,Remove Dead Code,,
d5db0fa6ade724574e44094a973f45862fd98350,2012-08-29T20:26:22Z,https://github.com/scikit-learn/scikit-learn/commit/d5db0fa6ade724574e44094a973f45862fd98350,Removed redefinition of variable i in SSS,1,Remove Dead Code,,
fb167dab8c1130bd0d9f0f5a0f0d50d3b26b08a5,2012-08-16T07:59:41Z,https://github.com/scikit-learn/scikit-learn/commit/fb167dab8c1130bd0d9f0f5a0f0d50d3b26b08a5,Remove unused import,1,Remove Dead Code,,
440cafbe276c028a705c41c1e4e2038977d94ab4,2012-08-05T13:56:20Z,https://github.com/scikit-learn/scikit-learn/commit/440cafbe276c028a705c41c1e4e2038977d94ab4,ENH Removed stupid ``_pairwise`` property in BaseEstimator.,1,Remove Dead Code,,
d4a020b8970ca4d6507f81445d56989a890d8ac4,2012-07-30T09:39:36Z,https://github.com/scikit-learn/scikit-learn/commit/d4a020b8970ca4d6507f81445d56989a890d8ac4,Clean: remove debug print,1,Remove Dead Code,,
9dbc576951fe0ca674cd1772400ec7965718ef9c,2012-07-26T07:15:57Z,https://github.com/scikit-learn/scikit-learn/commit/9dbc576951fe0ca674cd1772400ec7965718ef9c,COSMIT: remove left over profiling,1,Remove Dead Code,,
91c6c3b84c1ab90f28c63a2dd8b09542ac789f1c,2012-07-23T11:03:15Z,https://github.com/scikit-learn/scikit-learn/commit/91c6c3b84c1ab90f28c63a2dd8b09542ac789f1c,"Distance matrix doesn't matter, and was therefore removed",1,Remove Dead Code,,
fb9b7ce79ebb95974bbb9b171322e5a415bc380e,2012-07-20T23:38:25Z,https://github.com/scikit-learn/scikit-learn/commit/fb9b7ce79ebb95974bbb9b171322e5a415bc380e,COSMIT remove some dead code,1,Remove Dead Code,,
2fe48dc0fd1add3455f75c8896749ed6ebe09803,2012-07-16T11:47:20Z,https://github.com/scikit-learn/scikit-learn/commit/2fe48dc0fd1add3455f75c8896749ed6ebe09803,Tree refactoring (19),1,Remove Dead Code,,
89cb7056b7da9b8d87d62af1394e9dcd1b64d80f,2012-07-07T17:08:07Z,https://github.com/scikit-learn/scikit-learn/commit/89cb7056b7da9b8d87d62af1394e9dcd1b64d80f,removed quantile regression example,1,Remove Dead Code,,
bd94b49a2d75efed045a3ca2c68c0474e0350caf,2012-06-26T17:01:24Z,https://github.com/scikit-learn/scikit-learn/commit/bd94b49a2d75efed045a3ca2c68c0474e0350caf,MISC cleanup common testing,1,Remove Dead Code,,
5709d53134f01c760f91e715315db3584e844e2b,2012-06-13T06:28:38Z,https://github.com/scikit-learn/scikit-learn/commit/5709d53134f01c760f91e715315db3584e844e2b,Removed needless method redefinition.,1,Remove Dead Code,,
3f1b1899c3d91fc4da4e8b6d3091696e9b0f2c7f,2012-06-12T17:30:41Z,https://github.com/scikit-learn/scikit-learn/commit/3f1b1899c3d91fc4da4e8b6d3091696e9b0f2c7f,CLEANUP remove linear_model.sparse.setup.py,1,Remove Dead Code,,
3b3242020f6bbafbca08c6fec10aa900a4c41a60,2012-06-09T08:49:44Z,https://github.com/scikit-learn/scikit-learn/commit/3b3242020f6bbafbca08c6fec10aa900a4c41a60,remove unused imports,1,Remove Dead Code,,
b2815619d3a6b0c8acefc2df4641d0723fb28f57,2012-06-07T14:34:37Z,https://github.com/scikit-learn/scikit-learn/commit/b2815619d3a6b0c8acefc2df4641d0723fb28f57,code removed and deprecated message added,1,Remove Dead Code,,
313bf63418f2f94974727da7b89039c3ceb9f925,2012-06-07T14:33:15Z,https://github.com/scikit-learn/scikit-learn/commit/313bf63418f2f94974727da7b89039c3ceb9f925,remove redundant tests,1,Remove Dead Code,,
84ddd60cf3667eb86a07af00bbe36d7c9c45a7a5,2012-06-06T18:45:44Z,https://github.com/scikit-learn/scikit-learn/commit/84ddd60cf3667eb86a07af00bbe36d7c9c45a7a5,Test is redundant since _set_coef function as been removed.,1,Remove Dead Code,,
8f397b6d8188d4e957455c6176365e8e8a9af83f,2012-06-06T18:28:46Z,https://github.com/scikit-learn/scikit-learn/commit/8f397b6d8188d4e957455c6176365e8e8a9af83f,remove sparse_coef_,1,Remove Dead Code,,
4a12b248bf7ff939c1c46422bfedcab600dd1213,2012-06-01T15:47:16Z,https://github.com/scikit-learn/scikit-learn/commit/4a12b248bf7ff939c1c46422bfedcab600dd1213,decision logic removed from __init__,1,Remove Dead Code,,
48ba97f13d9788ebfd9e4e9818f744d2ba22957f,2012-05-16T05:58:05Z,https://github.com/scikit-learn/scikit-learn/commit/48ba97f13d9788ebfd9e4e9818f744d2ba22957f,Removed undeed functions,1,Remove Dead Code,,
fb9d18d2bb5bf03d5d71a4847b871c531f3586c2,2012-05-16T05:57:18Z,https://github.com/scikit-learn/scikit-learn/commit/fb9d18d2bb5bf03d5d71a4847b871c531f3586c2,Removed duplicate definition of csc_mean_variance_axis0,1,Remove Dead Code,,
beef9a852c559c24f81b6f802b613c52b75b1488,2012-05-16T05:57:16Z,https://github.com/scikit-learn/scikit-learn/commit/beef9a852c559c24f81b6f802b613c52b75b1488,Removed most python function calls,1,Remove Dead Code,,
8a354dd3eae8166a6f673d3662f52ce4101889ae,2012-05-06T12:29:24Z,https://github.com/scikit-learn/scikit-learn/commit/8a354dd3eae8166a6f673d3662f52ce4101889ae,COSMIT: remove print,1,Remove Dead Code,,
a707c34d1c91dbd8ea076e137c658327bdc1fe8e,2012-05-06T09:11:02Z,https://github.com/scikit-learn/scikit-learn/commit/a707c34d1c91dbd8ea076e137c658327bdc1fe8e,"ENH remove duplicate definition of ""assert_lower"" in tests",1,Remove Dead Code,,
66d00f4748286c7388a83fbae1417166832e16c4,2012-05-05T19:57:04Z,https://github.com/scikit-learn/scikit-learn/commit/66d00f4748286c7388a83fbae1417166832e16c4,MISC trying to remove scale_C,1,Remove Dead Code,,
b75833f720d0d816be6a88f0420919b757238df3,2012-05-04T21:16:15Z,https://github.com/scikit-learn/scikit-learn/commit/b75833f720d0d816be6a88f0420919b757238df3,COSMIT removed unused import in test,1,Remove Dead Code,,
3a0414efd06a73d1878c9ea898cc5b3d88d1ccc2,2012-04-04T20:56:13Z,https://github.com/scikit-learn/scikit-learn/commit/3a0414efd06a73d1878c9ea898cc5b3d88d1ccc2,removed useless assert,1,Remove Dead Code,,
91d3797db93dd92eaac67a42eccc6a745177e7fa,2012-03-26T08:41:37Z,https://github.com/scikit-learn/scikit-learn/commit/91d3797db93dd92eaac67a42eccc6a745177e7fa,Removed asserts in code,1,Remove Dead Code,,
6079a8d8171be4d88125bd22867a00607b9df126,2012-03-20T15:04:01Z,https://github.com/scikit-learn/scikit-learn/commit/6079a8d8171be4d88125bd22867a00607b9df126,remove np.seterr,1,Remove Dead Code,,
86bb50946117216323286f9ec0175619677dc59e,2012-03-18T10:56:52Z,https://github.com/scikit-learn/scikit-learn/commit/86bb50946117216323286f9ec0175619677dc59e,removed ``store_terminal_region`` from ``build_tree``. removed redundant ``predict_tree`` from ext module.,1,Remove Dead Code,,
75e2d1073a3e313f46e0f94ba111cc7b292a4e66,2012-03-05T15:44:18Z,https://github.com/scikit-learn/scikit-learn/commit/75e2d1073a3e313f46e0f94ba111cc7b292a4e66,removed redundant file,1,Remove Dead Code,,
c6f3824d6d17153476e07ebeba1c936cdf7f6598,2012-03-05T15:00:21Z,https://github.com/scikit-learn/scikit-learn/commit/c6f3824d6d17153476e07ebeba1c936cdf7f6598,remove redundant file,1,Remove Dead Code,,
84edda6ba75a02ebbe5479d0e7d2da51443d9d22,2012-03-04T18:07:03Z,https://github.com/scikit-learn/scikit-learn/commit/84edda6ba75a02ebbe5479d0e7d2da51443d9d22,COSMIT removed debugging print,1,Remove Dead Code,,
f8b605dc768e0452ccac80cf9b2189196ca9e10f,2012-02-29T21:53:41Z,https://github.com/scikit-learn/scikit-learn/commit/f8b605dc768e0452ccac80cf9b2189196ca9e10f,MISC remove ball_tree and cross_val namespaces,1,Remove Dead Code,,
331eaf36509d04d67e46bdd3be911a07a7d16149,2012-02-17T21:42:17Z,https://github.com/scikit-learn/scikit-learn/commit/331eaf36509d04d67e46bdd3be911a07a7d16149,MISC Issue #639. Remove unused member types in linear_model CVs,1,Remove Dead Code,,
ad8e4912cb9b3d617bcddc7808490215ff803e85,2012-02-11T14:43:03Z,https://github.com/scikit-learn/scikit-learn/commit/ad8e4912cb9b3d617bcddc7808490215ff803e85,TST: use assert_true instead of assert + remove some relative imports,1,Remove Dead Code,,
16727b4105ff98c965989408e02bda39ddc7134c,2012-02-08T22:14:44Z,https://github.com/scikit-learn/scikit-learn/commit/16727b4105ff98c965989408e02bda39ddc7134c,MISC cleanup,1,Remove Dead Code,,
4faf20e85be6959a07b4defc227b6fa15cc9a6ef,2012-02-05T22:36:04Z,https://github.com/scikit-learn/scikit-learn/commit/4faf20e85be6959a07b4defc227b6fa15cc9a6ef,MISC: remove custom __repr__,1,Remove Dead Code,,
3242c6a04168b99c91ad67dd1e6d71ff5385ec7f,2012-02-02T14:16:26Z,https://github.com/scikit-learn/scikit-learn/commit/3242c6a04168b99c91ad67dd1e6d71ff5385ec7f,"removed get_means, set_means, get_weights, set_weights",1,Remove Dead Code,,
06d1d3b08dc923b96a80b7df70b61318a04790f1,2012-01-31T20:34:48Z,https://github.com/scikit-learn/scikit-learn/commit/06d1d3b08dc923b96a80b7df70b61318a04790f1,COSMIT removed unused import,1,Remove Dead Code,,
85e986cb2707a4ffec4bdfcef4b2bf1f817f1ccc,2012-01-28T14:32:37Z,https://github.com/scikit-learn/scikit-learn/commit/85e986cb2707a4ffec4bdfcef4b2bf1f817f1ccc,COSMIT removed unused imports,1,Remove Dead Code,,
5c2a8696e3184fdb5e2ca5c55e61fe29ebd37fbb,2012-01-23T20:13:55Z,https://github.com/scikit-learn/scikit-learn/commit/5c2a8696e3184fdb5e2ca5c55e61fe29ebd37fbb,COSMIT removed unused imports,1,Remove Dead Code,,
24477d410924b7d4c34e1da8ed0faa049d2bc0b9,2012-01-23T17:19:32Z,https://github.com/scikit-learn/scikit-learn/commit/24477d410924b7d4c34e1da8ed0faa049d2bc0b9,Cosmit: remove unused imports,1,Remove Dead Code,,
d21ef4fcc6bc655384885995ccb37d656fd1d03c,2012-01-19T05:01:53Z,https://github.com/scikit-learn/scikit-learn/commit/d21ef4fcc6bc655384885995ccb37d656fd1d03c,Remove if statement.,1,Remove Dead Code,,
b6f98fe02e3fd51763ec951ea7a981ef220a031d,2012-01-11T16:25:37Z,https://github.com/scikit-learn/scikit-learn/commit/b6f98fe02e3fd51763ec951ea7a981ef220a031d,"remove deprecated Neighbors{Classifier,Regressor}",1,Remove Dead Code,,
e52da1e7a5d587952e3bdd652e7d01622ac67ca7,2012-01-09T21:03:21Z,https://github.com/scikit-learn/scikit-learn/commit/e52da1e7a5d587952e3bdd652e7d01622ac67ca7,removed feature_importances_ property in tree module,1,Remove Dead Code,,
a6e7178d20c37a9d6725a5fc7cd82b783a1aac90,2012-01-08T21:17:21Z,https://github.com/scikit-learn/scikit-learn/commit/a6e7178d20c37a9d6725a5fc7cd82b783a1aac90,COSMIT remove superfluous imports in svm/sparse/base.py,1,Remove Dead Code,,
116dc6e4e684866cfb39ae37cb1d98540cbcca38,2011-12-23T19:48:23Z,https://github.com/scikit-learn/scikit-learn/commit/116dc6e4e684866cfb39ae37cb1d98540cbcca38,COSMIT remove Methods section,1,Remove Dead Code,,
7f53024ae9eae8cd838372efc893befc329a49db,2011-12-23T17:27:40Z,https://github.com/scikit-learn/scikit-learn/commit/7f53024ae9eae8cd838372efc893befc329a49db,remove unused imports,1,Remove Dead Code,,
1725ecb090d8f8fc4f3dd62e041b396cd5f0456d,2011-12-23T14:26:44Z,https://github.com/scikit-learn/scikit-learn/commit/1725ecb090d8f8fc4f3dd62e041b396cd5f0456d,remove unused import,1,Remove Dead Code,,
75af0615d725216700254681eef4aa87367944f6,2011-12-23T13:32:55Z,https://github.com/scikit-learn/scikit-learn/commit/75af0615d725216700254681eef4aa87367944f6,remove useless dependency on pylab,1,Remove Dead Code,,
3a67aa0ab53e4186ff280822a7fe2a63744b28ed,2011-12-23T13:30:44Z,https://github.com/scikit-learn/scikit-learn/commit/3a67aa0ab53e4186ff280822a7fe2a63744b28ed,Removed unused imports in species dataset,1,Remove Dead Code,,
b32253947895792d2632f25abf297c64d7568887,2011-12-21T15:30:49Z,https://github.com/scikit-learn/scikit-learn/commit/b32253947895792d2632f25abf297c64d7568887,remove unneeded import,1,Remove Dead Code,,
c85c89068b1cb82437fec6c18681641381bf9ccb,2011-12-21T09:49:07Z,https://github.com/scikit-learn/scikit-learn/commit/c85c89068b1cb82437fec6c18681641381bf9ccb,simplify stability evaluation example,1,Remove Dead Code,,
b1a41dca4416bdedf4b7aa1fb130e192ebd131f8,2011-12-21T00:15:15Z,https://github.com/scikit-learn/scikit-learn/commit/b1a41dca4416bdedf4b7aa1fb130e192ebd131f8,clean up species distribution example,1,Remove Dead Code,,
39771fa4535528e820092316f087838f2a35e890,2011-12-20T13:17:51Z,https://github.com/scikit-learn/scikit-learn/commit/39771fa4535528e820092316f087838f2a35e890,ENH Remove redundant example,1,Remove Dead Code,,
0690438ceec17db5f1c0880d2488deb5a44ebe6e,2011-12-19T19:06:14Z,https://github.com/scikit-learn/scikit-learn/commit/0690438ceec17db5f1c0880d2488deb5a44ebe6e,remove duplicative utils.fixes.arpack_eigsh,1,Remove Dead Code,,
10a16a2add5b31fecc58777cf4cac73462631cf8,2011-12-19T17:57:15Z,https://github.com/scikit-learn/scikit-learn/commit/10a16a2add5b31fecc58777cf4cac73462631cf8,EXAMPLES: Removed useless import,1,Remove Dead Code,,
666c92bb66a4b9dff763f386eb2e268031862337,2011-12-19T10:17:38Z,https://github.com/scikit-learn/scikit-learn/commit/666c92bb66a4b9dff763f386eb2e268031862337,remove unused return_log keyword in GMM,1,Remove Dead Code,,
81cc31229ec6984eedca973baec0a99865185e87,2011-12-16T23:10:45Z,https://github.com/scikit-learn/scikit-learn/commit/81cc31229ec6984eedca973baec0a99865185e87,COSMIT removed unused import math in utils/extmath.py,1,Remove Dead Code,,
49e7b0d4c572e977406b9e1d48d5db157479dfb5,2011-12-09T11:43:14Z,https://github.com/scikit-learn/scikit-learn/commit/49e7b0d4c572e977406b9e1d48d5db157479dfb5,OPT: (minor) remove useless determinant computation in FastMCD.,1,Remove Dead Code,,
d137da16cf694c1d60a6fef9b4fcdfa99334bd8b,2011-11-20T19:33:57Z,https://github.com/scikit-learn/scikit-learn/commit/d137da16cf694c1d60a6fef9b4fcdfa99334bd8b,"COSMIT pep8 in cluster module, removed unused import",1,Remove Dead Code,,
a0a876e3e5e2c497f0a3117e58728a7430e7b448,2011-11-20T19:32:13Z,https://github.com/scikit-learn/scikit-learn/commit/a0a876e3e5e2c497f0a3117e58728a7430e7b448,"COSMIT removed unused import, pep8",1,Remove Dead Code,,
02f275108a10b9fdfd69e951a9ef9aa6d37cc33a,2011-11-16T09:50:50Z,https://github.com/scikit-learn/scikit-learn/commit/02f275108a10b9fdfd69e951a9ef9aa6d37cc33a,Removed Bagging and Boosting modules from this PR,1,Remove Dead Code,,
5975f4ce3846b9e3f2b61be78a5045e45d514df3,2011-11-09T20:04:25Z,https://github.com/scikit-learn/scikit-learn/commit/5975f4ce3846b9e3f2b61be78a5045e45d514df3,Removed extra-trees from __init__,1,Remove Dead Code,,
3485737b5f5e1dabc0182d766a880a6158d61be9,2011-11-09T19:51:11Z,https://github.com/scikit-learn/scikit-learn/commit/3485737b5f5e1dabc0182d766a880a6158d61be9,Removed extra-trees (for now),1,Remove Dead Code,,
9e8b97337cee19fb35f2dc710b8cdef8fa19091f,2011-11-07T10:34:55Z,https://github.com/scikit-learn/scikit-learn/commit/9e8b97337cee19fb35f2dc710b8cdef8fa19091f,Removed old random forest files,1,Remove Dead Code,,
e473f70be46e583f3bb6f50d72a7f740c7b0ea33,2011-10-19T10:46:07Z,https://github.com/scikit-learn/scikit-learn/commit/e473f70be46e583f3bb6f50d72a7f740c7b0ea33,Remove phantom double v-measure !?,1,Remove Dead Code,,
aa13538fdfc0dda14619426764c7c96544ee5209,2011-10-13T23:19:53Z,https://github.com/scikit-learn/scikit-learn/commit/aa13538fdfc0dda14619426764c7c96544ee5209,compute inertia + remove code :),1,Remove Dead Code,,
f90c8ab2789f4b8ce6befa936624a6bb16ba7564,2011-10-01T13:48:25Z,https://github.com/scikit-learn/scikit-learn/commit/f90c8ab2789f4b8ce6befa936624a6bb16ba7564,ENH: remove useless call to strip while staying robust to empty lines,1,Remove Dead Code,,
4dfbe746e0f3504e0a70d34dfa6c92b19ef9f01a,2011-09-28T15:12:14Z,https://github.com/scikit-learn/scikit-learn/commit/4dfbe746e0f3504e0a70d34dfa6c92b19ef9f01a,Refactor/simplify naive Bayes tests,1,Remove Dead Code,,
b029a5bb1e86c4aedbb5e2b5f524d5ef020863e5,2011-09-26T11:05:56Z,https://github.com/scikit-learn/scikit-learn/commit/b029a5bb1e86c4aedbb5e2b5f524d5ef020863e5,removed duplicate tests (already in fit),1,Remove Dead Code,,
7addd701539ce763acaf0f55249fb9faea80b061,2011-09-25T16:57:49Z,https://github.com/scikit-learn/scikit-learn/commit/7addd701539ce763acaf0f55249fb9faea80b061,ENH: move parameter checking to fit  Parameters can be changed after the __init__,1,Remove Dead Code,,
5891d987d4a78f3b3d91a36647ce93ebc491b0ba,2011-09-23T22:57:10Z,https://github.com/scikit-learn/scikit-learn/commit/5891d987d4a78f3b3d91a36647ce93ebc491b0ba,Remove BaseLibLinear.predict_proba not implemented,1,Remove Dead Code,,
95e75dfd7f2d9edac04af22dec2839e0722d6776,2011-09-22T18:10:06Z,https://github.com/scikit-learn/scikit-learn/commit/95e75dfd7f2d9edac04af22dec2839e0722d6776,remove obsolete tests,1,Remove Dead Code,,
beaab34e216bbc4f62388e4ee5c653d6233d22dd,2011-09-22T13:21:08Z,https://github.com/scikit-learn/scikit-learn/commit/beaab34e216bbc4f62388e4ee5c653d6233d22dd,removed leftover class_counter,1,Remove Dead Code,,
52cc1031d505fc1305931c8674a8b3086abce44e,2011-09-13T21:05:52Z,https://github.com/scikit-learn/scikit-learn/commit/52cc1031d505fc1305931c8674a8b3086abce44e,Removes useless (and time consuming) statement.,1,Remove Dead Code,,
42b06b7b911d5c297c19f3d30ddaa399fce18bcc,2011-09-09T03:06:50Z,https://github.com/scikit-learn/scikit-learn/commit/42b06b7b911d5c297c19f3d30ddaa399fce18bcc,Removed test_checks,1,Remove Dead Code,,
97a5241de5263ad6d849cb6863a03c3188caf2cd,2011-09-07T12:03:33Z,https://github.com/scikit-learn/scikit-learn/commit/97a5241de5263ad6d849cb6863a03c3188caf2cd,Actually removed l1_distances this time,1,Remove Dead Code,,
a0eb59988741c1face017f6e95840acf6b5bce59,2011-09-03T09:07:36Z,https://github.com/scikit-learn/scikit-learn/commit/a0eb59988741c1face017f6e95840acf6b5bce59,"removed unused import, removed unnecessary backslash",1,Remove Dead Code,,
947735a362bb848b4ccd1aa2f7548b2c1c879d5d,2011-08-28T09:49:35Z,https://github.com/scikit-learn/scikit-learn/commit/947735a362bb848b4ccd1aa2f7548b2c1c879d5d,removed unused imports,1,Remove Dead Code,,
b6d0d2ee64ee6a3c9b0d11d33440afd142b3e5a6,2011-08-24T17:09:30Z,https://github.com/scikit-learn/scikit-learn/commit/b6d0d2ee64ee6a3c9b0d11d33440afd142b3e5a6,removed fit_transform for dict learning,1,Remove Dead Code,,
32bbe8b6352c314147f489225c6a9a59b21ae3fb,2011-08-23T19:43:28Z,https://github.com/scikit-learn/scikit-learn/commit/32bbe8b6352c314147f489225c6a9a59b21ae3fb,completely removed the duplicated example,1,Remove Dead Code,,
1aec07335c8c2f4a3f3b14056673d2266fc3be3b,2011-08-23T14:11:11Z,https://github.com/scikit-learn/scikit-learn/commit/1aec07335c8c2f4a3f3b14056673d2266fc3be3b,Removed print in digits classification example,1,Remove Dead Code,,
d0e4757855624eb2367dc35dbb6592b5b8594ff0,2011-08-22T21:08:51Z,https://github.com/scikit-learn/scikit-learn/commit/d0e4757855624eb2367dc35dbb6592b5b8594ff0,Removed unnecessary import,1,Remove Dead Code,,
d69251405280863668e905e440822d7c93e840e5,2011-08-21T22:31:55Z,https://github.com/scikit-learn/scikit-learn/commit/d69251405280863668e905e440822d7c93e840e5,completely removed thresholding from denoising example,1,Remove Dead Code,,
67d38466ad25ef2a6fcda7eef248f6b0600614fa,2011-08-21T22:31:32Z,https://github.com/scikit-learn/scikit-learn/commit/67d38466ad25ef2a6fcda7eef248f6b0600614fa,removed thresholding from denoising example,1,Remove Dead Code,,
d3dfd65fb3fdd4589431ec46d08b951cfacfc5af,2011-08-18T16:54:33Z,https://github.com/scikit-learn/scikit-learn/commit/d3dfd65fb3fdd4589431ec46d08b951cfacfc5af,"Removed obsolete import of izip, made description of complexity more concise and accurate",1,Remove Dead Code,,
9d1da53b3fa63901dd032e680fd8d87dda7ada5c,2011-08-14T00:25:21Z,https://github.com/scikit-learn/scikit-learn/commit/9d1da53b3fa63901dd032e680fd8d87dda7ada5c,removed unused imports,1,Remove Dead Code,,
6a99439b99104815c7917a1b41c48ba596630d7e,2011-08-14T00:24:41Z,https://github.com/scikit-learn/scikit-learn/commit/6a99439b99104815c7917a1b41c48ba596630d7e,"removed old, useless code",1,Remove Dead Code,,
95b17a4752de98aebcf54531bb2a273987b6e818,2011-08-13T12:23:50Z,https://github.com/scikit-learn/scikit-learn/commit/95b17a4752de98aebcf54531bb2a273987b6e818,Removed unused import,1,Remove Dead Code,,
af9eef311f18fd719b35cfaa89b57a2ea9805e56,2011-08-12T05:30:35Z,https://github.com/scikit-learn/scikit-learn/commit/af9eef311f18fd719b35cfaa89b57a2ea9805e56,COSMIT: remove unused import,1,Remove Dead Code,,
3493ac509cd1022f1d0bd28c430a6fb6afdf3e2b,2011-08-11T09:17:28Z,https://github.com/scikit-learn/scikit-learn/commit/3493ac509cd1022f1d0bd28c430a6fb6afdf3e2b,removed everything except the plain and simple decision tree to make reviewing easier,1,Remove Dead Code,,
ba62ae792d402f36faf3b645126b26df70a3089d,2011-08-06T08:13:22Z,https://github.com/scikit-learn/scikit-learn/commit/ba62ae792d402f36faf3b645126b26df70a3089d,Remove automatically generated auto examples.,1,Remove Dead Code,,
9c5a1bf56435d90d175a1657343a546b3b47a541,2011-08-04T08:06:44Z,https://github.com/scikit-learn/scikit-learn/commit/9c5a1bf56435d90d175a1657343a546b3b47a541,Remove unnecessary import.,1,Remove Dead Code,,
c431799dde83316a3d96f4ab0421c0e926d9cc3d,2011-08-02T22:56:56Z,https://github.com/scikit-learn/scikit-learn/commit/c431799dde83316a3d96f4ab0421c0e926d9cc3d,remove unused imports,1,Remove Dead Code,,
6af2d2a34584a778caf8f7b68c30b077d4ae4a5b,2011-08-02T15:56:54Z,https://github.com/scikit-learn/scikit-learn/commit/6af2d2a34584a778caf8f7b68c30b077d4ae4a5b,removed occurances of tree_model,1,Remove Dead Code,,
a913997e3982294f6aad3c4db264327a9cbc1df6,2011-07-31T05:12:47Z,https://github.com/scikit-learn/scikit-learn/commit/a913997e3982294f6aad3c4db264327a9cbc1df6,Extra example removed,1,Remove Dead Code,,
68871955639b19b1e66427c814b0a41bb9f3e18e,2011-07-29T12:49:45Z,https://github.com/scikit-learn/scikit-learn/commit/68871955639b19b1e66427c814b0a41bb9f3e18e,Remove hardcoded n_jobs from examples.,1,Remove Dead Code,,
00af49f313ffb090827d3a2d850205c195e059fd,2011-07-25T11:08:27Z,https://github.com/scikit-learn/scikit-learn/commit/00af49f313ffb090827d3a2d850205c195e059fd,Remove useless prints in example,1,Remove Dead Code,,
02375b3c2da1adc570ebcc1045ec045b8441b93f,2011-07-23T11:04:56Z,https://github.com/scikit-learn/scikit-learn/commit/02375b3c2da1adc570ebcc1045ec045b8441b93f,COSMIT: remove unused import  Rnn pyflakes people! (or use a pyflakes plugin in your editor),1,Remove Dead Code,,
3e15bc6874cc35b89ab3d698200cca643fee12ed,2011-07-18T21:01:01Z,https://github.com/scikit-learn/scikit-learn/commit/3e15bc6874cc35b89ab3d698200cca643fee12ed,remove assert_warns from test case (not supported by build bots numpy version).,1,Remove Dead Code,,
8fdd8275d5186c15973106837f6255236a9edb25,2011-07-18T19:48:53Z,https://github.com/scikit-learn/scikit-learn/commit/8fdd8275d5186c15973106837f6255236a9edb25,remove leading _ in _gen_even_slices and duplicate implementation in sparse_pca,1,Remove Dead Code,,
d8da0ca0700117c32e9ee2d690b9b2312d9ef14d,2011-07-16T21:54:07Z,https://github.com/scikit-learn/scikit-learn/commit/d8da0ca0700117c32e9ee2d690b9b2312d9ef14d,Remove 'load_' alias for 'fetch_',1,Remove Dead Code,,
fe3c8d952adfde2087f2997f6f62ae492902f88d,2011-07-15T09:16:48Z,https://github.com/scikit-learn/scikit-learn/commit/fe3c8d952adfde2087f2997f6f62ae492902f88d,removed fit_transform overload,1,Remove Dead Code,,
415be5d517e3f4601deb124e4f98609cb73137a0,2011-07-11T18:30:53Z,https://github.com/scikit-learn/scikit-learn/commit/415be5d517e3f4601deb124e4f98609cb73137a0,Remove unnecessary submethod.,1,Remove Dead Code,,
5fe3ea96ff9eb70993daeb27b55ee3a2f941d3ae,2011-07-09T17:43:32Z,https://github.com/scikit-learn/scikit-learn/commit/5fe3ea96ff9eb70993daeb27b55ee3a2f941d3ae,Better test and remove old garbage.,1,Remove Dead Code,,
cad248cee00534c7bf85bcbf5b6de691de4e8d74,2011-06-25T14:35:33Z,https://github.com/scikit-learn/scikit-learn/commit/cad248cee00534c7bf85bcbf5b6de691de4e8d74,MISC: minor cleanups,1,Remove Dead Code,,
213ac0cc143729123bd64439fb4792506711509a,2011-06-25T14:16:15Z,https://github.com/scikit-learn/scikit-learn/commit/213ac0cc143729123bd64439fb4792506711509a,Removed print statement from test. Whoopsie!,1,Remove Dead Code,,
afd860a8b1cc2bb82734378b55ae70f06a693b3e,2011-06-22T10:35:39Z,https://github.com/scikit-learn/scikit-learn/commit/afd860a8b1cc2bb82734378b55ae70f06a693b3e,cleanup,1,Remove Dead Code,,
6ee443a1f1811f0abe0a73b28558207b845ecfa1,2011-06-19T15:30:02Z,https://github.com/scikit-learn/scikit-learn/commit/6ee443a1f1811f0abe0a73b28558207b845ecfa1,cleanup,1,Remove Dead Code,,
c0187b996ab89b7106a25673fb905408ac941095,2011-06-14T23:07:45Z,https://github.com/scikit-learn/scikit-learn/commit/c0187b996ab89b7106a25673fb905408ac941095,Removed print statement from test. Whoopsie!,1,Remove Dead Code,,
1d8bcae70d86506f3c5d9d734227f6052d540be8,2011-05-21T22:33:59Z,https://github.com/scikit-learn/scikit-learn/commit/1d8bcae70d86506f3c5d9d734227f6052d540be8,cleanup leftover,1,Remove Dead Code,,
90b32d489d4c11152db3a69c7207e86ab7afc0b7,2011-05-15T13:55:48Z,https://github.com/scikit-learn/scikit-learn/commit/90b32d489d4c11152db3a69c7207e86ab7afc0b7,COSMIT: Remove unused import,1,Remove Dead Code,,
323fb80744e63a322fe5ed70d86130aa61aa3c19,2011-05-15T13:41:31Z,https://github.com/scikit-learn/scikit-learn/commit/323fb80744e63a322fe5ed70d86130aa61aa3c19,MISC: Remove unused imports,1,Remove Dead Code,,
6deb88efbdce119d67cdfde2ec84aee14bd6939f,2011-05-02T17:23:11Z,https://github.com/scikit-learn/scikit-learn/commit/6deb88efbdce119d67cdfde2ec84aee14bd6939f,COSMIT: Pep 8 and remove useless imports,1,Remove Dead Code,,
1409e01ea8244cbd9978d15336a15ccaa9a2f36f,2011-05-02T09:56:23Z,https://github.com/scikit-learn/scikit-learn/commit/1409e01ea8244cbd9978d15336a15ccaa9a2f36f,"Cleanup lib{linear,svm} C helper routines  * Plumb memory leaks in allocation * Don't cast return value from malloc * Remove unused variables * No more register keyword; is a no-op in modern compilers * Cosmetic changes",1,Remove Dead Code,,
21dceb26053d040ca8f2d9a8ee5066a2cc3d3a20,2011-04-17T16:22:12Z,https://github.com/scikit-learn/scikit-learn/commit/21dceb26053d040ca8f2d9a8ee5066a2cc3d3a20,removed old version of min_C,1,Remove Dead Code,,
d2702e16a13446a9effa75faff83bb75653b8c83,2011-04-15T19:44:27Z,https://github.com/scikit-learn/scikit-learn/commit/d2702e16a13446a9effa75faff83bb75653b8c83,[MiniBatchKMeans] Removed the unnecessary import in examples/cluster/mini_batch_kmeans.py,1,Remove Dead Code,,
c8d5baa7b721dd7002968dbd500631194e64832c,2011-04-13T09:53:32Z,https://github.com/scikit-learn/scikit-learn/commit/c8d5baa7b721dd7002968dbd500631194e64832c,removed float64 and int32 conversion  ... since we are not calling any native code,1,Remove Dead Code,,
b8d1be797145b0b299756e3ee103312a05b4152d,2011-04-08T21:26:56Z,https://github.com/scikit-learn/scikit-learn/commit/b8d1be797145b0b299756e3ee103312a05b4152d,removed classifier.py,1,Remove Dead Code,,
fa43d48d5f93579c6145197f463cbaa75e984f20,2011-04-08T10:38:20Z,https://github.com/scikit-learn/scikit-learn/commit/fa43d48d5f93579c6145197f463cbaa75e984f20,Remove useless calls to np.asanyarray and improve computation.,1,Remove Dead Code,,
914d3b169d7d56fcb61e6217ae3b7f5870a37d77,2011-04-05T18:45:25Z,https://github.com/scikit-learn/scikit-learn/commit/914d3b169d7d56fcb61e6217ae3b7f5870a37d77,"Refactored: deleted the batch_k_means function, and created an option for the batch_k_means to avoid code duplication - Added some documentation",1,Remove Dead Code,,
73e31ba011f9ca5a312c1a7ea25c7606ceb2ff73,2011-04-01T20:10:02Z,https://github.com/scikit-learn/scikit-learn/commit/73e31ba011f9ca5a312c1a7ea25c7606ceb2ff73,Removed CRO for now,1,Remove Dead Code,,
c6cfce44b21d2f56cb0a14566cd411b68c052987,2011-04-01T16:11:28Z,https://github.com/scikit-learn/scikit-learn/commit/c6cfce44b21d2f56cb0a14566cd411b68c052987,Removed useless _fit_transform,1,Remove Dead Code,,
46ce94bc15174d54a269dbd23ec0696edbfd2751,2011-04-01T15:21:46Z,https://github.com/scikit-learn/scikit-learn/commit/46ce94bc15174d54a269dbd23ec0696edbfd2751,removed the unused inerta stuff,1,Remove Dead Code,,
1d8e3f2bbeb59f6c67d93b6c94b7bc3752393a4e,2011-03-31T22:05:43Z,https://github.com/scikit-learn/scikit-learn/commit/1d8e3f2bbeb59f6c67d93b6c94b7bc3752393a4e,Removed print in CRO.fit; moved utils to top.,1,Remove Dead Code,,
d53bb58351b4292fc52c6f6e995f1347dccd9093,2011-03-09T14:17:20Z,https://github.com/scikit-learn/scikit-learn/commit/d53bb58351b4292fc52c6f6e995f1347dccd9093,samples generators: remove multivariate_normal_from_latent_variables  unhappy with the design,1,Remove Dead Code,,
6c45c01c47db85b588a7687cee1497e670c5149e,2011-02-21T14:13:47Z,https://github.com/scikit-learn/scikit-learn/commit/6c45c01c47db85b588a7687cee1497e670c5149e,Remove arbitrary code in tests.,1,Remove Dead Code,,
3a28fd366c87155889e13f358c1b03fd2f5c7c3e,2011-02-21T00:40:50Z,https://github.com/scikit-learn/scikit-learn/commit/3a28fd366c87155889e13f358c1b03fd2f5c7c3e,remove stupid color slicing 'feature' and shuffle the examples,1,Remove Dead Code,,
09028390e6da39b621144e0e9532459509c77adf,2011-02-17T09:23:33Z,https://github.com/scikit-learn/scikit-learn/commit/09028390e6da39b621144e0e9532459509c77adf,remove unused imports.,1,Remove Dead Code,,
eb60275ed4c601014f5be722891e2a9e015dfe91,2011-02-14T06:04:59Z,https://github.com/scikit-learn/scikit-learn/commit/eb60275ed4c601014f5be722891e2a9e015dfe91,Remove coef_ and get_support from Pipeline.,1,Remove Dead Code,,
a5aa0bd88a39dbbeb5d8dc2c3ad31f41888ecc2f,2011-02-08T10:39:10Z,https://github.com/scikit-learn/scikit-learn/commit/a5aa0bd88a39dbbeb5d8dc2c3ad31f41888ecc2f,remove unused.,1,Remove Dead Code,,
7f509e577e57158fc0940920fd723ab73c2b7894,2011-01-11T15:19:01Z,https://github.com/scikit-learn/scikit-learn/commit/7f509e577e57158fc0940920fd723ab73c2b7894,Remove unused imports,1,Remove Dead Code,,
758e5c560c9c9513956164662520bf7912a22256,2010-12-07T14:27:31Z,https://github.com/scikit-learn/scikit-learn/commit/758e5c560c9c9513956164662520bf7912a22256,Remove redundant site.cfg parsing.,1,Remove Dead Code,,
327be9e11d2f34604b809d0f907e598cc7afbd79,2010-11-28T16:24:41Z,https://github.com/scikit-learn/scikit-learn/commit/327be9e11d2f34604b809d0f907e598cc7afbd79,remove useless import,1,Remove Dead Code,,
c37538bfbdb5e292a87b3b8702b5e4ff4f38cf03,2010-11-25T06:43:24Z,https://github.com/scikit-learn/scikit-learn/commit/c37538bfbdb5e292a87b3b8702b5e4ff4f38cf03,API: Remove long-depreciated function,1,Remove Dead Code,,
569aac89bf7a79d7a663f6b9c6f3fe622617bed1,2010-11-22T12:04:03Z,https://github.com/scikit-learn/scikit-learn/commit/569aac89bf7a79d7a663f6b9c6f3fe622617bed1,MISC: Remove redundant code and cosmit,1,Remove Dead Code,,
9d35f4c102acef4e3a662d40a5126b7d87f3b913,2010-11-17T12:08:20Z,https://github.com/scikit-learn/scikit-learn/commit/9d35f4c102acef4e3a662d40a5126b7d87f3b913,Remove BaseLib class.  Also added this heuristic to liblinear.,1,Remove Dead Code,,
dc1c7e7eefcf04c01376065c48ba1921e5d6fd22,2010-11-16T22:06:49Z,https://github.com/scikit-learn/scikit-learn/commit/dc1c7e7eefcf04c01376065c48ba1921e5d6fd22,Removed plotting command from the examples in the GaussianProcess class docstring.,1,Remove Dead Code,,
68036a729b4fc8a903c690e31b2f0fd3a7727442,2010-11-15T22:21:55Z,https://github.com/scikit-learn/scikit-learn/commit/68036a729b4fc8a903c690e31b2f0fd3a7727442,I removed the time-consuming test and made a regression example from it.,1,Remove Dead Code,,
226a871d388f768ae6565b47d78f5ec88d2f4d28,2010-11-15T19:00:42Z,https://github.com/scikit-learn/scikit-learn/commit/226a871d388f768ae6565b47d78f5ec88d2f4d28,remove obsolete bench_lars.py  bench_lasso.py is far more informative.,1,Remove Dead Code,,
893a44761038ac726d01548f3d74dd5142bd12b1,2010-11-12T23:58:02Z,https://github.com/scikit-learn/scikit-learn/commit/893a44761038ac726d01548f3d74dd5142bd12b1,"Cleanup in libsvm bindings.  No API changes, just some cleanup.",1,Remove Dead Code,,
cb46e57a63318993948789f7a2b490bbd3c75b41,2010-11-07T17:49:10Z,https://github.com/scikit-learn/scikit-learn/commit/cb46e57a63318993948789f7a2b490bbd3c75b41,remove the dependency to explicit ABC to keep 2.5 compat + PEP8,1,Remove Dead Code,,
658002360d5bc3394ab199665498c8c262916e4f,2010-10-24T10:45:33Z,https://github.com/scikit-learn/scikit-learn/commit/658002360d5bc3394ab199665498c8c262916e4f,removed unnecessary print statements. added mlcomp example atheism vs. graphics.,1,Remove Dead Code,,
cca15155cf87d2e0b588bf8905d16316fe0a0ab6,2010-10-06T11:56:06Z,https://github.com/scikit-learn/scikit-learn/commit/cca15155cf87d2e0b588bf8905d16316fe0a0ab6,"Simplify test machinery.  Remove test.py script, use the simpler python -c ""..."", it also works across OS.",1,Remove Dead Code,,
5f8978d500cca378e14eb716d753d994a9ee7b17,2010-10-01T09:28:24Z,https://github.com/scikit-learn/scikit-learn/commit/5f8978d500cca378e14eb716d753d994a9ee7b17,"Remove the ann module.  This was marked deprecated several releases ago, and was scheduled for removal in 0.5.",1,Remove Dead Code,,
dbbe2efa25245941688c13b649c5b6950522ab04,2010-09-29T14:10:28Z,https://github.com/scikit-learn/scikit-learn/commit/dbbe2efa25245941688c13b649c5b6950522ab04,Remove obsolete debugging code from grid_search.,1,Remove Dead Code,,
a22d25e9c07d314a32a5336419d89c455d2ff0fd,2010-09-27T14:18:10Z,https://github.com/scikit-learn/scikit-learn/commit/a22d25e9c07d314a32a5336419d89c455d2ff0fd,Remove Minilearn C sources.,1,Remove Dead Code,,
06757705e205a8c19fda09f013c6229dfeb58789,2010-09-16T09:39:16Z,https://github.com/scikit-learn/scikit-learn/commit/06757705e205a8c19fda09f013c6229dfeb58789,Remove uncessary code.,1,Remove Dead Code,,
a31685ce65a46a93580076b5c83640045f958f19,2010-08-31T16:37:28Z,https://github.com/scikit-learn/scikit-learn/commit/a31685ce65a46a93580076b5c83640045f958f19,ENH: Remove 'import *' in glm/__init__,1,Remove Dead Code,,
78ec57a560de4858e05c13afb86208eb4f78a7d6,2010-08-23T12:24:27Z,https://github.com/scikit-learn/scikit-learn/commit/78ec57a560de4858e05c13afb86208eb4f78a7d6,"Remove install_requires line.  The problem is that setuptools does not recognize numpy if installed by some means (e.b. binary packages in OSX), thus I prefer to specify dependencies in README rather than fail at installation.",1,Remove Dead Code,,
f5a6620f431d3d8c75b766757fb0555693b875b4,2010-08-21T00:02:11Z,https://github.com/scikit-learn/scikit-learn/commit/f5a6620f431d3d8c75b766757fb0555693b875b4,remove extraneous tests from test_hmm.py  This includes many of the failing tests (which were failing due to extreme overfitting to the fake training data).,1,Remove Dead Code,,
10308fae39985c6cacca6708412597c129b67532,2010-08-20T22:31:14Z,https://github.com/scikit-learn/scikit-learn/commit/10308fae39985c6cacca6708412597c129b67532,remove hmm.HMM factory to simplify hmm module's interface,1,Remove Dead Code,,
d7c61d9be1423eb7c4a108c2b56b0581d7f8adb3,2010-08-20T16:10:06Z,https://github.com/scikit-learn/scikit-learn/commit/d7c61d9be1423eb7c4a108c2b56b0581d7f8adb3,remove GMM.lpdf method,1,Remove Dead Code,,
285d7f21f3279955b0c8c39cef239be03ddf24de,2010-08-18T19:27:12Z,https://github.com/scikit-learn/scikit-learn/commit/285d7f21f3279955b0c8c39cef239be03ddf24de,remove unused imports from setup.py,1,Remove Dead Code,,
b993498f810747e730a631ef2e352ca1779727af,2010-08-18T10:03:22Z,https://github.com/scikit-learn/scikit-learn/commit/b993498f810747e730a631ef2e352ca1779727af,remove unused imports from setup.py,1,Remove Dead Code,,
89f6a7f1a13538aeaaa4e33ef905008bbeb6a706,2010-08-17T13:01:16Z,https://github.com/scikit-learn/scikit-learn/commit/89f6a7f1a13538aeaaa4e33ef905008bbeb6a706,Remove unused imports from hmm module.,1,Remove Dead Code,,
e5f56aff27e270d0052b6fe315a45da870994c55,2010-08-17T07:03:14Z,https://github.com/scikit-learn/scikit-learn/commit/e5f56aff27e270d0052b6fe315a45da870994c55,Remove unused imports in qda module.,1,Remove Dead Code,,
f959fd3a37846a690c6253822390aecf7a493673,2010-08-16T21:35:48Z,https://github.com/scikit-learn/scikit-learn/commit/f959fd3a37846a690c6253822390aecf7a493673,MISC: remove debug,1,Remove Dead Code,,
4f31787920a31551686e894bc6fbf8d3fc3ad05c,2010-07-20T18:55:13Z,https://github.com/scikit-learn/scikit-learn/commit/4f31787920a31551686e894bc6fbf8d3fc3ad05c,"Refactoring of LibSVM bindings.  Just remove unnecessary code, and put all libsvm related code into a single folder.",1,Remove Dead Code,,
df165d3dfb8bd799de6b29c9b1c1c4ca6a490b83,2010-07-16T12:54:38Z,https://github.com/scikit-learn/scikit-learn/commit/df165d3dfb8bd799de6b29c9b1c1c4ca6a490b83,ENH: Temporarily remove the typing for the base_estimator,1,Remove Dead Code,,
56dc4d7641a974af29ca8899e465f1f935a37056,2010-07-06T18:32:51Z,https://github.com/scikit-learn/scikit-learn/commit/56dc4d7641a974af29ca8899e465f1f935a37056,removed init() method from hmm classes,1,Remove Dead Code,,
27aa259f62653caed62309e47aebfa96803cab0e,2010-07-03T04:21:43Z,https://github.com/scikit-learn/scikit-learn/commit/27aa259f62653caed62309e47aebfa96803cab0e,"removed logging, dependency on abc, and unnecessary imports",1,Remove Dead Code,,
8945d3d8591afcaaf6cf0ebbe6ae03b1e7e03cad,2010-06-27T14:05:58Z,https://github.com/scikit-learn/scikit-learn/commit/8945d3d8591afcaaf6cf0ebbe6ae03b1e7e03cad,Cleanup gmm example. Removed unused modules.,1,Remove Dead Code,,
e356827d6e99e449f6edddfb34189baf0c5ce892,2010-06-26T13:28:50Z,https://github.com/scikit-learn/scikit-learn/commit/e356827d6e99e449f6edddfb34189baf0c5ce892,Remove benchmarking code from lasso example.,1,Remove Dead Code,,
dca0ff8f70f2696804fc0eb691ea3627bee0d01d,2010-06-26T12:44:24Z,https://github.com/scikit-learn/scikit-learn/commit/dca0ff8f70f2696804fc0eb691ea3627bee0d01d,Remove redundant seed generator.,1,Remove Dead Code,,
60c047ce204001c0a17f8007a74c96830edcffc2,2010-06-25T22:46:43Z,https://github.com/scikit-learn/scikit-learn/commit/60c047ce204001c0a17f8007a74c96830edcffc2,Remove duplicate module univariate_selection.  This module is already inside module feature_selection/,1,Remove Dead Code,,
1a17e7958ed2f25e8c6ae2d0aabf6892ec91d036,2010-06-25T16:54:54Z,https://github.com/scikit-learn/scikit-learn/commit/1a17e7958ed2f25e8c6ae2d0aabf6892ec91d036,Remove examples from deprecated modules.,1,Remove Dead Code,,
6dddf5101caba0a1274eeafe034c6580375b8bab,2010-06-21T12:58:10Z,https://github.com/scikit-learn/scikit-learn/commit/6dddf5101caba0a1274eeafe034c6580375b8bab,Remove the shortcuts module.  (mea culpa: this was really a bad idea),1,Remove Dead Code,,
d293c6fb120ec3bf1f32aac182aea1e01b4f1825,2010-06-21T11:50:51Z,https://github.com/scikit-learn/scikit-learn/commit/d293c6fb120ec3bf1f32aac182aea1e01b4f1825,Remove manifold module.,1,Remove Dead Code,,
d8fc705314104414b49ed2f32df29def6cf63bf2,2010-06-10T11:55:33Z,https://github.com/scikit-learn/scikit-learn/commit/d8fc705314104414b49ed2f32df29def6cf63bf2,Remove logging from gmm module.,1,Remove Dead Code,,
229542d34c19d6d7db47f7283a2d385d8b4ebe32,2010-06-09T15:53:47Z,https://github.com/scikit-learn/scikit-learn/commit/229542d34c19d6d7db47f7283a2d385d8b4ebe32,LARS test clean-up,1,Remove Dead Code,,
f008ebee910115f393052934969db4ed7e554ae6,2010-05-26T21:13:10Z,https://github.com/scikit-learn/scikit-learn/commit/f008ebee910115f393052934969db4ed7e554ae6,cleaning up my mess...,1,Remove Dead Code,,
0276741d31e07edf6c2ac4d2d6a8f8a00da0c821,2010-05-13T20:07:13Z,https://github.com/scikit-learn/scikit-learn/commit/0276741d31e07edf6c2ac4d2d6a8f8a00da0c821,API: Remove the obsolate attrselect.py module.,1,Remove Dead Code,,
1be21882316dac4ff818888a7c9e9703b5a79a12,2010-05-09T09:27:43Z,https://github.com/scikit-learn/scikit-learn/commit/1be21882316dac4ff818888a7c9e9703b5a79a12,removing unnecessary imports,1,Remove Dead Code,,
5e3a7e0611809cad231ba51346d8a30a0393f6bd,2010-04-29T11:49:28Z,https://github.com/scikit-learn/scikit-learn/commit/5e3a7e0611809cad231ba51346d8a30a0393f6bd,Remove examples from module glm.coordinate_descent.  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@716 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8,1,Remove Dead Code,,
eb34e4360f1f5a02b0fbfef236e8d2e556aabe33,2010-04-29T09:53:08Z,https://github.com/scikit-learn/scikit-learn/commit/eb34e4360f1f5a02b0fbfef236e8d2e556aabe33,Remove unused inports from lasso_cd  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@714 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8,1,Remove Dead Code,,
c0fee47112c8d568a4376d9d2519071272b0cdbb,2010-04-21T07:00:24Z,https://github.com/scikit-learn/scikit-learn/commit/c0fee47112c8d568a4376d9d2519071272b0cdbb,"Remove liblinear-related code from SVC.  It's now in class LinearSVC, although this class is not yet finished.   git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@670 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8",1,Remove Dead Code,,
8d6bd0b7e58ed7eb7637eed1294a14388de00fe1,2010-03-19T13:02:09Z,https://github.com/scikit-learn/scikit-learn/commit/8d6bd0b7e58ed7eb7637eed1294a14388de00fe1,"Removed test for em/tests/test_densities.py  It tested for an underflow of np.log. However, this is not true on 64 bit, and we should not test this sort of things.  From: Fabian Pedregosa <fabian.pedregosa@inria.fr>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@586 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8",1,Remove Dead Code,,
444aabfe92d14de4a25eedfc715e219717b53cdb,2010-03-18T14:22:14Z,https://github.com/scikit-learn/scikit-learn/commit/444aabfe92d14de4a25eedfc715e219717b53cdb,Remove unused functions from svm module.  From: Fabian Pedregosa <fabian.pedregosa@inria.fr>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@569 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8,1,Remove Dead Code,,
567f7668e244301f925166c837ad9c6ecb4353e2,2010-03-11T09:53:44Z,https://github.com/scikit-learn/scikit-learn/commit/567f7668e244301f925166c837ad9c6ecb4353e2,Remove unused imports from cython files in glm/  From: Fabian Pedregosa <fabian.pedregosa@inria.fr>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@514 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8,1,Remove Dead Code,,
6a1f4be94fa595af60f483fef56c45f2c770b711,2010-03-09T13:53:33Z,https://github.com/scikit-learn/scikit-learn/commit/6a1f4be94fa595af60f483fef56c45f2c770b711,Remove unused imports in svm's benchmarks  From: Fabian Pedregosa <fabian.pedregosa@inria.fr>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@510 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8,1,Remove Dead Code,,
6458d082e516fcfc436c0d04f3ecc2c662f7ed47,2010-03-03T16:22:14Z,https://github.com/scikit-learn/scikit-learn/commit/6458d082e516fcfc436c0d04f3ecc2c662f7ed47,cleaning Lasso + ElasticNet example  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@470 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8,1,Remove Dead Code,,
09f649dabc18869aa596aba0054e62136efdebe5,2010-03-01T14:29:21Z,https://github.com/scikit-learn/scikit-learn/commit/09f649dabc18869aa596aba0054e62136efdebe5,Remove redundant imports of cost_function  From: Fabian Pedregosa <fabian.pedregosa@inria.fr>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@409 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8,1,Remove Dead Code,,
7171d37eb98d5043b5b256ab7581c862bd79bf6a,2010-01-29T15:38:43Z,https://github.com/scikit-learn/scikit-learn/commit/7171d37eb98d5043b5b256ab7581c862bd79bf6a,"Remove tests that depend on weka.  This had no sense anymore, since loadarff is now part of scipy and it was only making test fail.  From: Fabian Pedregosa <fabian.pedregosa@inria.fr>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@390 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8",1,Remove Dead Code,,
04b256b20d373383850e3d96112a941f21fabf2c,2010-01-29T15:37:53Z,https://github.com/scikit-learn/scikit-learn/commit/04b256b20d373383850e3d96112a941f21fabf2c,Remove em2 module.  I remove temporarily this module because it is not mature enough to be included in the release. I've moved the code temporarily to http://github.com/fseoane/em2 .  From: Fabian Pedregosa <fabian.pedregosa@inria.fr>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@389 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8,1,Remove Dead Code,,
6b82d6d034f415fda88ed3bdd917741e47b2a66c,2010-01-22T17:09:40Z,https://github.com/scikit-learn/scikit-learn/commit/6b82d6d034f415fda88ed3bdd917741e47b2a66c,"Remove genetic algorithms.  I decided to remove this module for the following reasons: the module does not quite fit the package's thematic, has references to scipy.ga (which has been removed) and there are already some great genetic algorithm frameworks in Python.  This thread discussed the removal: http://mail.scipy.org/pipermail/scipy-dev/2010-January/013705.html  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@365 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8",1,Remove Dead Code,,
43784411f57a5852c5c651da52aed87ff191f06d,2010-01-18T15:11:01Z,https://github.com/scikit-learn/scikit-learn/commit/43784411f57a5852c5c651da52aed87ff191f06d,Remove old testing framework.  I believe this is the last bit that remained.  From: Fabian Pedregosa <fabian.pedregosa@inria.fr>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@352 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8,1,Remove Dead Code,,
75e331dda805095c410448b47444cf71d9b8f0d8,2010-01-14T15:23:22Z,https://github.com/scikit-learn/scikit-learn/commit/75e331dda805095c410448b47444cf71d9b8f0d8,"Remove deprecated path hack.  The functions numpy.testing.set_package_path,restore_path are not in numpy's development version and they are not neede anymore since we are doing relative imports. Remove them.  From: Fabian Pedregosa <fabian.pedregosa@inria.fr>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@347 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8",1,Remove Dead Code,,
61cd53ee83a9f58bcad5eae82b3cabe6701ea352,2010-01-14T15:19:23Z,https://github.com/scikit-learn/scikit-learn/commit/61cd53ee83a9f58bcad5eae82b3cabe6701ea352,"Remove old testing framework.  We use nosetests now, no need for run_test_suite().  From: Fabian Pedregosa <fabian.pedregosa@inria.fr>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@343 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8",1,Remove Dead Code,,
9cd44a04a28d86d55d9849e766554170f5de3364,2010-01-06T13:30:15Z,https://github.com/scikit-learn/scikit-learn/commit/9cd44a04a28d86d55d9849e766554170f5de3364,Remove old testing framework  From: Fabian Pedregosa <fabian@fseoane.net>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@326 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8,1,Remove Dead Code,,
649dead0fd7d18aa8006a249469d2bf54f953916,2010-01-06T10:42:23Z,https://github.com/scikit-learn/scikit-learn/commit/649dead0fd7d18aa8006a249469d2bf54f953916,Remove GMM class.  From: cdavid <cdavid@cb17146a-f446-4be1-a4f7-bd7c5bb65646>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@293 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8,1,Remove Dead Code,,
f00ae3046436f09e62460a8468e031a0c2027e7f,2010-01-06T10:11:33Z,https://github.com/scikit-learn/scikit-learn/commit/f00ae3046436f09e62460a8468e031a0c2027e7f,Remove deprecated test runned for em machine.  From: cdavid <cdavid@cb17146a-f446-4be1-a4f7-bd7c5bb65646>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@271 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8,1,Remove Dead Code,,
2f77054086322c4279349da013e35c7ec5c85d83,2010-01-06T10:05:01Z,https://github.com/scikit-learn/scikit-learn/commit/2f77054086322c4279349da013e35c7ec5c85d83,"Remove path madness, which is deprecated anyway.  From: cdavid <cdavid@cb17146a-f446-4be1-a4f7-bd7c5bb65646>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@268 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8",1,Remove Dead Code,,
e846b095d1e023440b59641a9833396bc27539df,2010-01-06T09:32:25Z,https://github.com/scikit-learn/scikit-learn/commit/e846b095d1e023440b59641a9833396bc27539df,"Remove the arff reader: an improved version is available in scipy.io, under the name loadarff.  From: cdavid <cdavid@cb17146a-f446-4be1-a4f7-bd7c5bb65646>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@254 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8",1,Remove Dead Code,,
0203715f50e52de994620555541d0b77c5729f26,2010-01-06T09:32:05Z,https://github.com/scikit-learn/scikit-learn/commit/0203715f50e52de994620555541d0b77c5729f26,Remove fake pyem package.  From: cdavid <cdavid@cb17146a-f446-4be1-a4f7-bd7c5bb65646>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@253 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8,1,Remove Dead Code,,
430ed93f3e5873ae0f3a661e9580893adb7e994e,2010-01-05T14:54:24Z,https://github.com/scikit-learn/scikit-learn/commit/430ed93f3e5873ae0f3a661e9580893adb7e994e,remove duplicate definition of __float__  From: timl <timl@cb17146a-f446-4be1-a4f7-bd7c5bb65646>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@64 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8,1,Remove Dead Code,,
6169fc6ba318e648ccae1db20c14d33ffb3b9871,2010-01-05T14:54:00Z,https://github.com/scikit-learn/scikit-learn/commit/6169fc6ba318e648ccae1db20c14d33ffb3b9871,remove unused imports  From: timl <timl@cb17146a-f446-4be1-a4f7-bd7c5bb65646>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@63 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8,1,Remove Dead Code,,
3e6e77011a1ea44c726c06c49e557624197a95df,2010-01-05T13:47:58Z,https://github.com/scikit-learn/scikit-learn/commit/3e6e77011a1ea44c726c06c49e557624197a95df,Heavily refactored MLP. Only leastsq used for optimization.  From: fred.mailhot <fred.mailhot@cb17146a-f446-4be1-a4f7-bd7c5bb65646>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@27 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8,1,Remove Dead Code,,
738ecd17d869577d263eb1fba3fee0ab8ec5b5a2,2023-08-29T07:22:14Z,https://github.com/huggingface/transformers/commit/738ecd17d869577d263eb1fba3fee0ab8ec5b5a2,Arde/fsdp activation checkpointing (#25771)  * add FSDP config option to enable activation-checkpointing  * update docs  * add checks and remove redundant code  * fix formatting error,1,Remove Dead Code,,
5347d00092c4f2429389269dd912417e8daff848,2023-08-17T15:03:41Z,https://github.com/huggingface/transformers/commit/5347d00092c4f2429389269dd912417e8daff848,[`SwitchTransformers`] Remove unused module (#25427)  * remove unused module  * remove old feed_forward_proj  * fixup,1,Remove Dead Code,,
b1b0fc4f56408225e99b06e8a9b36ecef3822b18,2023-08-14T13:22:15Z,https://github.com/huggingface/transformers/commit/b1b0fc4f56408225e99b06e8a9b36ecef3822b18,Remove logging code in TF Longformer that fails to compile (#25496)  Remove wonky logger block,1,Remove Dead Code,,
4692d2619433f1eb064f3da4f3573f060a115eac,2023-08-11T12:16:01Z,https://github.com/huggingface/transformers/commit/4692d2619433f1eb064f3da4f3573f060a115eac,Switch Transformers: remove overwritten beam sample test (#25458),1,Remove Dead Code,,
7d65697da746066aa75238347d8c86bde1acbf1b,2023-08-07T14:38:24Z,https://github.com/huggingface/transformers/commit/7d65697da746066aa75238347d8c86bde1acbf1b,Generate: remove Marian hack (#25294)  Remove Marian hack,1,Remove Dead Code,,
a6e6b1c622d8d08e2510a82cb6266d7b654f1cbf,2023-08-04T17:36:57Z,https://github.com/huggingface/transformers/commit/a6e6b1c622d8d08e2510a82cb6266d7b654f1cbf,Remove jnp.DeviceArray since it is deprecated. (#24875)  * Remove jnp.DeviceArray since it is deprecated.  * Replace all instances of jnp.DeviceArray with jax.Array  * Update src/transformers/models/bert/modeling_flax_bert.py  ---------  Co-authored-by: Sanchit Gandhi <93869735+sanchit-gandhi@users.noreply.github.com>,1,Remove Dead Code,,
f0fd73a2de0a611a3826885c0f529493ab32ace0,2023-08-04T12:56:29Z,https://github.com/huggingface/transformers/commit/f0fd73a2de0a611a3826885c0f529493ab32ace0,Document check copies (#25291)  * Document check copies better and add tests  * Include header in check for copies  * Manual fixes  * Try autofix  * Fixes  * Clean tests  * Finalize doc  * Remove debug print  * More fixes,1,Remove Dead Code,,
30409af6e1b2b5efb6d9932b3e3b4ce20cfdb30e,2023-08-03T10:01:10Z,https://github.com/huggingface/transformers/commit/30409af6e1b2b5efb6d9932b3e3b4ce20cfdb30e,Update InstructBLIP & Align values after rescale update (#25209)  * Update InstructBLIP values Note: the tests are not independent. Running the test independentely produces different logits compared to running all the integration tests  * Update test values after rescale update  * Remove left over commented out code  * Revert to previous rescaling logic  * Update rescale tests,1,Remove Dead Code,,
dcb183f4bdcd9491efb68b3c28d51614a11e59dc,2023-07-25T12:32:40Z,https://github.com/huggingface/transformers/commit/dcb183f4bdcd9491efb68b3c28d51614a11e59dc,[`MPT`] Add MosaicML's `MPT` model to transformers (#24629)  * draft add new model like  * some cleaning of the config  * nits  * add nested configs  * nits  * update  * update  * added layer norms + triton kernels  * consider only LPLayerNorm for now.  * update  * all keys match.  * Update  * fixing nits here and there  * working forward pass.  * removed einops dependency  * nits  * format  * add alibi  * byebye head mask  * refactor attention  * nits.  * format  * fix nits.  * nuke ande updates  * nuke tokenizer test  * don't reshape query with kv heads  * added a bit of documentation.  * remove unneeded things  * nuke more stuff  * nit  * logits match - same generations  * rm unneeded methods  * 1 remaining failing CI test  * nit  * fix nits  * fix docs  * fix docs  * rm tokenizer  * fixup  * fixup  * fixup and fix tests  * fixed configuration object.  * use correct activation  * few minor fixes  * clarify docs a bit  * logits match à 1e-12  * skip and unskip a test  * added some slow tests.  * fix readme  * add more details  * Update docs/source/en/model_doc/mpt.md  Co-authored-by: Arthur <48595927+ArthurZucker@users.noreply.github.com>  * Apply suggestions from code review  Co-authored-by: Arthur <48595927+ArthurZucker@users.noreply.github.com>  * fix configuration issues  * more fixes in config  * added more models  * Apply suggestions from code review  Co-authored-by: Arthur <48595927+ArthurZucker@users.noreply.github.com>  * remove unneeded position ids  * fix some  comments  * Apply suggestions from code review  Co-authored-by: Arthur <48595927+ArthurZucker@users.noreply.github.com>  * revert suggestion  * mpt alibi + added batched generation  * Update src/transformers/models/mpt/__init__.py  Co-authored-by: Arthur <48595927+ArthurZucker@users.noreply.github.com>  * remove init config  * Update src/transformers/models/mpt/configuration_mpt.py  Co-authored-by: Arthur <48595927+ArthurZucker@users.noreply.github.com>  * fix nit  * add another slow test  * Apply suggestions from code review  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * fits in one line  * some refactor because make fixup doesn't pass  * add ft notebook  * update md  * correct doc path  ---------  Co-authored-by: younesbelkada <younesbelkada@gmail.com> Co-authored-by: Younes Belkada <49240599+younesbelkada@users.noreply.github.com> Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>,1,Remove Dead Code,,
37d8611ac9aab61d4a738e511d738847882ef47a,2023-07-20T11:09:04Z,https://github.com/huggingface/transformers/commit/37d8611ac9aab61d4a738e511d738847882ef47a,replace no_cuda with use_cpu in test_pytorch_examples (#24944)  * replace no_cuda with use_cpu in test_pytorch_examples  * remove codes that never be used  * fix style,1,Remove Dead Code,,
2ab75add4b30c2fc44a8bf575156d448d9ed87a7,2023-07-17T20:37:28Z,https://github.com/huggingface/transformers/commit/2ab75add4b30c2fc44a8bf575156d448d9ed87a7,Remove `tests/onnx` (#24868)  fix  Co-authored-by: ydshieh <ydshieh@users.noreply.github.com>,1,Remove Dead Code,,
0f4502d335e98b189276b58220a7531035c91fab,2023-07-17T18:45:59Z,https://github.com/huggingface/transformers/commit/0f4502d335e98b189276b58220a7531035c91fab,Remove deprecated codes (#24837)  * remove `xpu_backend` training argument  * always call `contextlib.nullcontext()` since transformers updated to python3.8  * these codes will not be executed,1,Remove Dead Code,,
18d42bfd23eff8b5bd6464769079c0ad01b6a2aa,2023-07-17T11:07:47Z,https://github.com/huggingface/transformers/commit/18d42bfd23eff8b5bd6464769079c0ad01b6a2aa,Remove unused code in GPT-Neo (#24826)  1,1,Remove Dead Code,,
1f6f32c24338ad1ff17475b836c7b4505da77714,2023-07-13T09:30:22Z,https://github.com/huggingface/transformers/commit/1f6f32c24338ad1ff17475b836c7b4505da77714,Removing unnecessary `device=device` in modeling_llama.py (#24696)  * Update modeling_llama.py  Removing unnecessary `device=device`  * fix in all occurrences of _make_causal_mask,1,Remove Dead Code,,
53194991e9f1d25a86d66f36f2774cf462391f13,2023-06-27T17:33:55Z,https://github.com/huggingface/transformers/commit/53194991e9f1d25a86d66f36f2774cf462391f13,[Mask2Former] Remove SwinConfig (#24259)  Remove SwinConfig,1,Remove Dead Code,,
127e81c272060709e451627903082fd3b55a7039,2023-06-21T15:51:27Z,https://github.com/huggingface/transformers/commit/127e81c272060709e451627903082fd3b55a7039,Remove redundant code from TrainingArgs (#24401)  Remove redundant code,1,Remove Dead Code,,
a6b4d1ad83d4dc0fa5b92fb92ae1889b236fd90a,2023-06-20T15:14:29Z,https://github.com/huggingface/transformers/commit/a6b4d1ad83d4dc0fa5b92fb92ae1889b236fd90a,Remove print statement,1,Remove Dead Code,,
a611ac9b3f9493a80e2d0adf491f4868c71f71c5,2023-06-15T10:39:32Z,https://github.com/huggingface/transformers/commit/a611ac9b3f9493a80e2d0adf491f4868c71f71c5,remove unused is_decoder parameter in DetrAttention (#24226)  * issue#24161 remove unused is_decoder parameter in DetrAttention  * #24161 fix check_repository_consistency fail,1,Remove Dead Code,,
3bd1fe431585e233efb4564d12d751b3174996c3,2023-06-13T18:04:22Z,https://github.com/huggingface/transformers/commit/3bd1fe431585e233efb4564d12d751b3174996c3,"Stop storing references to bound methods via tf.function (#24146)  * Stop storing references to bound methods in tf.functions  * Remove the gc.collect calls now that we resolved the underlying problem  * Remove the default signature from model.serving entirely, big cleanup  * Remove _prune_signature as self.input_signature can prune itself  * Restore serving docstring  * Update int support test to check the input signature  * Make sure other tests also use model.input_signature and not serving.input_signature  * Restore _prune_signature  * Remove the doctest GC now it's no longer needed  * Correct core tests to use the pruned sig  * order lines correctly in core tests  * Add eager_serving back with a deprecation warning",1,Remove Dead Code,,
d13021e35fb391c88c48b085f29462625d8f4090,2023-05-31T17:34:55Z,https://github.com/huggingface/transformers/commit/d13021e35fb391c88c48b085f29462625d8f4090,remove the extra `accelerator.prepare`  (#23914)  remove the extra `accelerator.prepare` that slipped in with multiple update from main 😅,1,Remove Dead Code,,
4b6a5a7caa1ea31a3321eb17e6dcc9baff4f55d9,2023-05-30T08:23:32Z,https://github.com/huggingface/transformers/commit/4b6a5a7caa1ea31a3321eb17e6dcc9baff4f55d9,"[Time-Series] Autoformer model (#21891)  * ran `transformers-cli add-new-model-like`  * added `AutoformerLayernorm` and `AutoformerSeriesDecomposition`  * added `decomposition_layer` in `init` and `moving_avg` to config  * added `AutoformerAutoCorrelation` to encoder & decoder  * removed caninical self attention `AutoformerAttention`  * added arguments in config and model tester. Init works! 😁  * WIP autoformer attention with autocorrlation  * fixed `attn_weights` size  * wip time_delay_agg_training  * fixing sizes and debug time_delay_agg_training  * aggregation in training works! 😁  * `top_k_delays` -> `top_k_delays_index` and added `contiguous()`  * wip time_delay_agg_inference  * finish time_delay_agg_inference 😎  * added resize to autocorrelation  * bug fix: added the length of the output signal to `irfft`  * `attention_mask = None` in the decoder  * fixed test: changed attention expected size, `test_attention_outputs` works!  * removed unnecessary code  * apply AutoformerLayernorm in final norm in enc & dec  * added series decomposition to the encoder  * added series decomp to decoder, with inputs  * added trend todos  * added autoformer to README  * added to index  * added autoformer.mdx  * remove scaling and init attention_mask in the decoder  * make style  * fix copies  * make fix-copies  * inital fix-copies  * fix from https://github.com/huggingface/transformers/pull/22076  * make style  * fix class names  * added trend  * added d_model and projection layers  * added `trend_projection` source, and decomp layer init  * added trend & seasonal init for decoder input  * AutoformerModel cannot be copied as it has the decomp layer too  * encoder can be copied from time series transformer  * fixed generation and made distrb. out more robust  * use context window to calculate decomposition  * use the context_window for decomposition  * use output_params helper  * clean up AutoformerAttention  * subsequences_length off by 1  * make fix copies  * fix test  * added init for nn.Conv1d  * fix IGNORE_NON_TESTED  * added model_doc  * fix ruff  * ignore tests  * remove dup  * fix SPECIAL_CASES_TO_ALLOW  * do not copy due to conv1d weight init  * remove unused imports  * added short summary  * added label_length and made the model non-autoregressive  * added params docs  * better doc for `factor`  * fix tests  * renamed `moving_avg` to `moving_average`  * renamed `factor` to `autocorrelation_factor`  * make style  * Update src/transformers/models/autoformer/configuration_autoformer.py  Co-authored-by: NielsRogge <48327001+NielsRogge@users.noreply.github.com>  * Update src/transformers/models/autoformer/configuration_autoformer.py  Co-authored-by: NielsRogge <48327001+NielsRogge@users.noreply.github.com>  * fix configurations  * fix integration tests  * Update src/transformers/models/autoformer/configuration_autoformer.py  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>  * fixing `lags_sequence` doc  * Revert ""fixing `lags_sequence` doc""  This reverts commit 21e34911e36a6f8f45f25cbf43584a49e5316c55.  * Update src/transformers/models/autoformer/modeling_autoformer.py  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>  * Update src/transformers/models/autoformer/modeling_autoformer.py  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>  * Update src/transformers/models/autoformer/modeling_autoformer.py  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>  * Apply suggestions from code review  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>  * Update src/transformers/models/autoformer/configuration_autoformer.py  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>  * model layers now take the config  * added `layer_norm_eps` to the config  * Update src/transformers/models/autoformer/modeling_autoformer.py  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>  * added `config.layer_norm_eps` to AutoformerLayernorm  * added `config.layer_norm_eps` to all layernorm layers  * Update src/transformers/models/autoformer/configuration_autoformer.py  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>  * Update src/transformers/models/autoformer/configuration_autoformer.py  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>  * Update src/transformers/models/autoformer/configuration_autoformer.py  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>  * Update src/transformers/models/autoformer/configuration_autoformer.py  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>  * fix variable names  * added inital pretrained model  * added use_cache docstring  * doc strings for trend and use_cache  * fix order of args  * imports on one line  * fixed get_lagged_subsequences docs  * add docstring for create_network_inputs  * get rid of layer_norm_eps config  * add back layernorm  * update fixture location  * fix signature  * use AutoformerModelOutput dataclass  * fix pretrain config  * no need as default exists  * subclass ModelOutput  * remove layer_norm_eps config  * fix test_model_outputs_equivalence test  * test hidden_states_output  * make fix-copies  * Update src/transformers/models/autoformer/configuration_autoformer.py  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>  * removed unused attr  * Update tests/models/autoformer/test_modeling_autoformer.py  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>  * Update src/transformers/models/autoformer/modeling_autoformer.py  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>  * Update src/transformers/models/autoformer/modeling_autoformer.py  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>  * Update src/transformers/models/autoformer/modeling_autoformer.py  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>  * Update src/transformers/models/autoformer/modeling_autoformer.py  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>  * Update src/transformers/models/autoformer/modeling_autoformer.py  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>  * Update src/transformers/models/autoformer/modeling_autoformer.py  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>  * use AutoFormerDecoderOutput  * fix formatting  * fix formatting  ---------  Co-authored-by: Kashif Rasul <kashif.rasul@gmail.com> Co-authored-by: NielsRogge <48327001+NielsRogge@users.noreply.github.com> Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>",1,Remove Dead Code,,
3416bba7c70c358ac17efd3be31e9090135969ab,2023-05-25T14:06:14Z,https://github.com/huggingface/transformers/commit/3416bba7c70c358ac17efd3be31e9090135969ab,"[LongFormer] code nits, removed unused parameters  (#23749)  * remove unused parameters  * remove unused parameters in config",1,Remove Dead Code,,
e45e756d22206ca8fa9fb057c8c3d8fa79bf81c6,2023-05-24T20:19:44Z,https://github.com/huggingface/transformers/commit/e45e756d22206ca8fa9fb057c8c3d8fa79bf81c6,Remove the last few TF serving sigs (#23738)  Remove some more serving methods that (I think?) turned up while this PR was open,1,Remove Dead Code,,
3cb9309024aeeeba5cf820539119f2f12aa4eac7,2023-05-19T17:14:16Z,https://github.com/huggingface/transformers/commit/3cb9309024aeeeba5cf820539119f2f12aa4eac7,[`Blip`] Remove redundant shift right (#23153)  * remove redundant shit right  * fix failing tests  * this time fix tests,1,Remove Dead Code,,
f2d2880bbbd7769e12c37471af0b067b379dfc43,2023-05-18T10:34:33Z,https://github.com/huggingface/transformers/commit/f2d2880bbbd7769e12c37471af0b067b379dfc43,remove unnecessary print in gpt neox sequence classifier (#23433),1,Remove Dead Code,,
ba6815e82438f0816726fcbd5cbbe9d1c964db4a,2023-05-16T09:54:19Z,https://github.com/huggingface/transformers/commit/ba6815e82438f0816726fcbd5cbbe9d1c964db4a,"Replace NumPy Operations with JAX NumPy Equivalents for JIT Compilation Compatibility (#23356)  * Replace numpy operations with jax.numpy for JIT compatibility  Replaced numpy operations with their jax.numpy equivalents in the transformer library. This change was necessary to prevent errors during JIT compilation. Specifically, the modifications involve changing numpy's in-place assignments to jax.numpy's immutable update methods.  * rm numpy import  * rm numpy import and fix np->jnp  * fixed slices bug  * fixed decoder_start_tokens -> decoder_start_token_id  * fixed jnp in modleing mt5  * doc fix  * rm numpy import  * make",1,Remove Dead Code,,
364ced6893cd136de4c4f82c96b4301d691d4140,2023-05-12T10:11:20Z,https://github.com/huggingface/transformers/commit/364ced6893cd136de4c4f82c96b4301d691d4140,Remove `LanguageIdentificationTool` in `__init__.py` as we don't have it yet (#23326)  remove LanguageIdentificationTool  Co-authored-by: ydshieh <ydshieh@users.noreply.github.com>,1,Remove Dead Code,,
b2846afda87164ffc7e6633cc609c775f54c88b9,2023-05-10T19:10:06Z,https://github.com/huggingface/transformers/commit/b2846afda87164ffc7e6633cc609c775f54c88b9,Remove missplaced test file (#23275),1,Remove Dead Code,,
6f8a02844a0eeaf15f29acb7fe40126768936fba,2023-05-07T22:55:04Z,https://github.com/huggingface/transformers/commit/6f8a02844a0eeaf15f29acb7fe40126768936fba,"fix random attention for pytorch's bigbird/pegasus_bigbird (#23056)  * fix random attention usage for bigbird and pegasus_bigbird  * remove staticmethod, update tests target valus  * revert style changes",1,Remove Dead Code,,
b0a78091a5b2f7e872140cf2d3795e4c56c9c95d,2023-05-03T17:04:48Z,https://github.com/huggingface/transformers/commit/b0a78091a5b2f7e872140cf2d3795e4c56c9c95d,Remove redundant print statements (#23133)  remove redundant print statements,1,Remove Dead Code,,
d337631b915ceb4ec18f3a9a1e807603fb7c9b71,2023-04-28T16:24:51Z,https://github.com/huggingface/transformers/commit/d337631b915ceb4ec18f3a9a1e807603fb7c9b71,🚨🚨🚨 [`Blip`] remove labels masking (#23024)  * remove labels masking  * add fix on blip tf,1,Remove Dead Code,,
e577bd0f13e1820650810f6864253d70dc76ce08,2023-04-05T17:43:14Z,https://github.com/huggingface/transformers/commit/e577bd0f13e1820650810f6864253d70dc76ce08,Use native TF checkpoints for the BLIP TF tests (#22593)  * Use native TF checkpoints for the TF tests  * Remove unneeded exceptions,1,Remove Dead Code,,
28fcf006076f28b37ba3879356811347577053db,2023-04-04T13:20:13Z,https://github.com/huggingface/transformers/commit/28fcf006076f28b37ba3879356811347577053db,Remove hack for dynamic modules and use Python functions instead (#22537),1,Remove Dead Code,,
4169dc84bf0072a26f10096a187907d661dcc383,2023-04-03T18:03:41Z,https://github.com/huggingface/transformers/commit/4169dc84bf0072a26f10096a187907d661dcc383,[setup] migrate setup script to `pyproject.toml` (#22539)  * [setup] migrate setup script to `pyproject.toml`  * [setup] cleanup configurations  * remove unused imports,1,Remove Dead Code,,
67c2dbdb54cd1d52d01ecdb1968f9ffafb79ee83,2023-03-21T18:22:01Z,https://github.com/huggingface/transformers/commit/67c2dbdb54cd1d52d01ecdb1968f9ffafb79ee83,"Time to Say Goodbye, torch 1.7 and 1.8 (#22291)  * time to say goodbye, torch 1.7 and 1.8  * clean up torch_int_div  * clean up is_torch_less_than_1_8-9  * update  ---------  Co-authored-by: ydshieh <ydshieh@users.noreply.github.com>",1,Remove Dead Code,,
102b5ff4a813eea848bb82ff2f451e0f6b17b30c,2023-03-13T10:11:31Z,https://github.com/huggingface/transformers/commit/102b5ff4a813eea848bb82ff2f451e0f6b17b30c,add new model of MGP-STR (#21418)  * add new model of MGP-STR  * fix the check failings  * remove torch and numpy from mgp_tokenization  * remove unused import from modeling_mgp_str  * add test_processing_mgp_str  * rm test_processing_mgp_str.py  * add test_processing_mgp_str  * add test_processing_mgp_str  * add test_processing_mgp_str  * rm test_processing_mgp_str and add softmax outs to model  * rm test_processing_mgp_str and add softmax outs to model  * rewrite the code of mgp-str according to PR suggestions  * rewrite the code of mgp-str according to PR suggestions  * add new model of MGP-STR  * fix the check failings  * remove torch and numpy from mgp_tokenization  * remove unused import from modeling_mgp_str  * add test_processing_mgp_str  * rm test_processing_mgp_str.py  * add test_processing_mgp_str  * add test_processing_mgp_str  * add test_processing_mgp_str  * rm test_processing_mgp_str and add softmax outs to model  * rewrite the code of mgp-str according to PR suggestions  * rewrite the code of mgp-str according to PR suggestions  * remove representation_size from MGPSTRConfig  * reformat configuration_mgp_str.py  * format test_processor_mgp_str.py  * add test for tokenizer and complete model/processer test and model file  * rm Unnecessary tupple in modeling_mgp_str  * reduce hidden_size/layers/label_size in test_model  * add integration tests and change MGPSTR to Mgpstr  * add test for logit values  * reformat test model file  ---------  Co-authored-by: yue kun <yuekun.wp@alibaba-inc.com>,1,Remove Dead Code,,
923110b74fbef83909035b88c7eb6f7c4b6a8397,2023-03-09T14:23:48Z,https://github.com/huggingface/transformers/commit/923110b74fbef83909035b88c7eb6f7c4b6a8397,Remove set_access_token usage + fail tests if FutureWarning (#22051)  * Remove set_access_token usage + fail tests if FutureWarning  * do not fail on FutureWarning in CI  ---------  Co-authored-by: testbot <lucainp@hf.co>,1,Remove Dead Code,,
4446b6b094a7c036d09059885bec679279c9b488,2023-02-24T07:20:52Z,https://github.com/huggingface/transformers/commit/4446b6b094a7c036d09059885bec679279c9b488,Graphormer fix  (#21699)  * Removed useless check for backend  * fix style check for graphormer  * Reverted change and corrected requires_backend for cython  * code qual,1,Remove Dead Code,,
2840272c5f872315a5c37b8aee0454d2129b8bc7,2023-02-20T08:17:40Z,https://github.com/huggingface/transformers/commit/2840272c5f872315a5c37b8aee0454d2129b8bc7,add flax whisper implementation (#20479)  * add flax whisper implementation  * rever change to setup  * remove unused imports  * revert generation changes  * flax whisper docs  * docs  * import order  * import sorting  * isort  * add dummy objects  * doc formatting  * formatting  * remove trailing whitespaces  * fix flax whisper docs  * add generation logic to unlock flax whisper  * remove scans  * give credits to Flax Bart implementation  * remove unused imports  * add license  * remove assert  * more credits to Bart  * fix style  * formatting  * support left padding  * add flax whisper generation test  * remove copied from comments whenever not a full copy  * fix docstrings for logits processors  * revert change to FlaxForceTokensLogitsProcessor  * revert doc changes  * improve generation docs  * reorganize  * formatting  * cleanup docs  * add tests  * handle empty list case  * fix forced decoder ids in flax tests  * add flax whisper to inits  * upate dummy objects  * docs for FlaxAutoModelForSpeechSeq2Seq  * fix decoder_position_ids computation in pretrained model decode/__call__ fns  * add Copied from statements as necessary  * compute position_ids only in __call__ and decode methods of pretrained model subclasses  * improve readabilityof compute positional embeddings  * check dimensionality of input_features instead of hidden_states  * copied from statement for init_cache  * formatting  * fix copies  * fix copies  * pass attention mask to encoder layers  * fix decoder module outputs  * set dtype  Co-authored-by: Sanchit Gandhi <93869735+sanchit-gandhi@users.noreply.github.com>  * smaller flax model for whisper test  * Update src/transformers/generation/flax_utils.py  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * Update src/transformers/models/whisper/modeling_flax_whisper.py  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * Update tests/models/whisper/test_modeling_flax_whisper.py  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * cleanup  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * Update src/transformers/models/whisper/modeling_flax_whisper.py  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * bias cleanup  * doc fix  * align style for force tokens processor  * readability  * fix input shape in tests  * revert FlaxGenerationMixin docstring  * formatting  * fix tests  * fix imports  * consistent encoder hidden states  * consistent hidden states  * input shapes  * typo  * partial class trick  * partial class for input shape  * base_class with correct input shape  * partial base classes  * match by name  * set main_input_name  * compare on names  * formatting  * remove unused import  * safer position ids computation  * safer position id computation  * Update src/transformers/models/whisper/modeling_flax_whisper.py  Co-authored-by: Sanchit Gandhi <93869735+sanchit-gandhi@users.noreply.github.com>  * Update src/transformers/models/whisper/modeling_flax_whisper.py  Co-authored-by: Sanchit Gandhi <93869735+sanchit-gandhi@users.noreply.github.com>  * remove identical inherited tests  * fix prompt ids in tests  * use generation config  * use jnp array  * better var names  * more explicit bias use  * import transformers  * formatting  * test formatting  * remove unused imports  * remove unused imports  * formatting  * isort  * docs  * fix ln orders for encoder hidden states  * whisper unique generation stuff  * flake  * use finfo for attention bias  * docs  * Update src/transformers/generation/flax_utils.py  Co-authored-by: Arthur <48595927+ArthurZucker@users.noreply.github.com>  * docs  * add timestamp flax test  * jit for timestamps  * formatting  * clean up timestamps processor  * formatting  * remove if_true  * cleanup  ---------  Co-authored-by: Sanchit Gandhi <93869735+sanchit-gandhi@users.noreply.github.com> Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com> Co-authored-by: Arthur <48595927+ArthurZucker@users.noreply.github.com>,1,Remove Dead Code,,
fc28c006a612d643505d4a00b07c59023382069c,2023-02-15T14:17:26Z,https://github.com/huggingface/transformers/commit/fc28c006a612d643505d4a00b07c59023382069c,Skip wav2vec2 hubert high mem tests (#21643)  * Skip high memory tests  * Skip high memory tests  * Remove unused import,1,Remove Dead Code,,
b47a16743bce02647e1b575a4b40b02618f3fa4d,2023-02-10T21:57:28Z,https://github.com/huggingface/transformers/commit/b47a16743bce02647e1b575a4b40b02618f3fa4d,Remove more unused attributes in config classes (#21543)  * Remove unused decoder_layerdrop  * Update SPECIAL_CASES_TO_ALLOW for MT5Config  * Remove unused position_embedding_init_scale  * Remove unused decoder_max_relative_position  * Use unused decoder_max_relative_position  * Remove unused init_std  * Remove unused forgotten attributes  * Remove unused patch_norm  * Remove unused max_seq_len  * Update SPECIAL_CASES_TO_ALLOW for OneFormerConfig  ---------  Co-authored-by: ydshieh <ydshieh@users.noreply.github.com>,1,Remove Dead Code,,
5b72b3412b8efb3177d2daf90798e2ee20cb21e9,2023-02-10T14:15:16Z,https://github.com/huggingface/transformers/commit/5b72b3412b8efb3177d2daf90798e2ee20cb21e9,"Remove CLI spams with Whisper FeatureExtractor (#21267)  * Remove CLI spams with Whisper FeatureExtractor  Whisper feature extractor representation includes the MEL filters, a list of list that is represented as ~16,000 lines. This needlessly spams the command line. I added a `__repr__` method that replaces this list with a string ""<array of shape (80, 201)>""  * Remove mel_filters from to_dict output    Credits to @ArthurZucker  * remove unused import  * update feature extraction tests for the changes in to_dict",1,Remove Dead Code,,
e4bacf6614744c7d5e637fea9498bdb0dcd61eb7,2023-02-03T17:43:46Z,https://github.com/huggingface/transformers/commit/e4bacf6614744c7d5e637fea9498bdb0dcd61eb7,"[WIP] add SpeechT5 model (#18922)  * make SpeechT5 model by copying Wav2Vec2  * add paper to docs  * whoops added docs in wrong file  * remove SpeechT5Tokenizer + put CTC back in the name  * remove deprecated class  * remove unused docstring  * delete SpeechT5FeatureExtractor, use Wav2Vec2FeatureExtractor instead  * remove classes we don't need right now  * initial stab at speech encoder prenet  * add more speech encoder prenet stuff  * improve SpeechEncoderPrenet  * add encoder (not finished yet)  * add relative position bias to self-attention  * add encoder CTC layers  * fix formatting  * add decoder from BART, doesn't work yet  * make it work with generate loop  * wrap the encoder into a speech encoder class  * wrap the decoder in a text decoder class  * changed my mind  * changed my mind again ;-)  * load decoder weights, make it work  * add weights for text decoder postnet  * add SpeechT5ForCTC model that uses only the encoder  * clean up EncoderLayer and DecoderLayer  * implement _init_weights in SpeechT5PreTrainedModel  * cleanup config + Encoder and Decoder  * add head + cross attention masks  * improve doc comments  * fixup  * more cleanup  * more fixup  * TextDecoderPrenet works now, thanks Kendall  * add CTC loss  * add placeholders for other pre/postnets  * add type annotation  * fix freeze_feature_encoder  * set padding tokens to 0 in decoder attention mask  * encoder attention mask downsampling  * remove features_pen calculation  * disable the padding tokens thing again  * fixup  * more fixup  * code review fixes  * rename encoder/decoder wrapper classes  * allow checkpoints to be loaded into SpeechT5Model  * put encoder into wrapper for CTC model  * clean up conversion script  * add encoder for TTS model  * add speech decoder prenet  * add speech decoder post-net  * attempt to reconstruct the generation loop  * add speech generation loop  * clean up generate_speech  * small tweaks  * fix forward pass  * enable always dropout on speech decoder prenet  * sort declaration  * rename models  * fixup  * fix copies  * more fixup  * make consistency checker happy  * add Seq2SeqSpectrogramOutput class  * doc comments  * quick note about loss and labels  * add HiFi-GAN implementation (from Speech2Speech PR)  * rename file  * add vocoder to TTS model  * improve vocoder  * working on tokenizer  * more better tokenizer  * add CTC tokenizer  * fix decode and batch_code in CTC tokenizer  * fix processor  * two processors and feature extractors  * use SpeechT5WaveformFeatureExtractor instead of Wav2Vec2  * cleanup  * more cleanup  * even more fixup  * notebooks  * fix log-mel spectrograms  * support reduction factor  * fixup  * shift spectrograms to right to create decoder inputs  * return correct labels  * add labels for stop token prediction  * fix doc comments  * fixup  * remove SpeechT5ForPreTraining  * more fixup  * update copyright headers  * add usage examples  * add SpeechT5ProcessorForCTC  * fixup  * push unofficial checkpoints to hub  * initial version of tokenizer unit tests  * add slow test  * fix failing tests  * tests for CTC tokenizer  * finish CTC tokenizer tests  * processor tests  * initial test for feature extractors  * tests for spectrogram feature extractor  * fixup  * more fixup  * add decorators  * require speech for tests  * modeling tests  * more tests for ASR model  * fix imports  * add fake tests for the other models  * fixup  * remove jupyter notebooks  * add missing SpeechT5Model tests  * add missing tests for SpeechT5ForCTC  * add missing tests for SpeechT5ForTextToSpeech  * sort tests by name  * fix Hi-Fi GAN tests  * fixup  * add speech-to-speech model  * refactor duplicate speech generation code  * add processor for SpeechToSpeech model  * add usage example  * add tests for speech-to-speech model  * fixup  * enable gradient checkpointing for SpeechT5FeatureEncoder  * code review  * push_to_hub now takes repo_id  * improve doc comments for HiFi-GAN config  * add missing test  * add integration tests  * make number of layers in speech decoder prenet configurable  * rename variable  * rename variables  * add auto classes for TTS and S2S  * REMOVE CTC!!!  * S2S processor does not support save/load_pretrained  * fixup  * these models are now in an auto mapping  * fix doc links  * rename HiFiGAN to HifiGan, remove separate config file  * REMOVE auto classes  * there can be only one  * fixup  * replace assert  * reformat  * feature extractor can process input and target at same time  * update checkpoint names  * fix commit hash",1,Remove Dead Code,,
f726d53ea30e300feff452f5d0312a408dc8301d,2023-02-03T12:41:15Z,https://github.com/huggingface/transformers/commit/f726d53ea30e300feff452f5d0312a408dc8301d,Remove more unused attributes in config classes (#21392)  * * Remove unused type_vocab_size  * Remove unused initializer_factor  * Remove unused n_embd  * Remove unused scale_embedding  * Remove unused scale_attn_weights  * fix  * fix  * Remove unused head_hidden_scale  * Remove unused activation_dropout  ---------  Co-authored-by: ydshieh <ydshieh@users.noreply.github.com>,1,Remove Dead Code,,
ea55bd86b9a452c87c5383afc707ab7d710a3043,2023-02-02T19:45:35Z,https://github.com/huggingface/transformers/commit/ea55bd86b9a452c87c5383afc707ab7d710a3043,"Add VQGAN-CLIP research project (#21329)  * Add VQGAN-CLIP research project  * fixed style issues  * Update examples/research_projects/vqgan-clip/README.md  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>  * Update examples/research_projects/vqgan-clip/VQGAN_CLIP.py  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>  * Update examples/research_projects/vqgan-clip/requirements.txt  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>  * Update examples/research_projects/vqgan-clip/README.md  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>  * Update examples/research_projects/vqgan-clip/VQGAN_CLIP.py  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>  * Update examples/research_projects/vqgan-clip/VQGAN_CLIP.py  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>  * Update examples/research_projects/vqgan-clip/VQGAN_CLIP.py  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>  * Update examples/research_projects/vqgan-clip/loaders.py  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>  * replace CLIPProcessor with tokenizer, change asserts to exceptions  * rm unused import  * remove large files (jupyter notebook linked in readme, imgs migrated to hf dataset)  * add tokenizers dependency  * Remove comment  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>  * rm model checkpoints  ---------  Co-authored-by: Erwann Millon <erwann@Erwanns-MacBook-Air.local> Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>",1,Remove Dead Code,,
634242735367a4ae934776399adba0c8474adfca,2023-01-31T15:35:38Z,https://github.com/huggingface/transformers/commit/634242735367a4ae934776399adba0c8474adfca,Remove more unused attributes in config classes (#21327)  * remove unused classifier_dropout  * remove unused dropout  * remove unused pooler_fn  * remove unnecessary is_encoder_decoder  * remove unnecessary drop_rate  * remove unused classifier_dropout  * remove unused classifier_dropout  * remove unused dropout  * remove unused dropout  * remove unused summary_* attributes  * remove unused tie_word_embeddings  * remove unused summary_* attributes  * fix  ---------  Co-authored-by: ydshieh <ydshieh@users.noreply.github.com>,1,Remove Dead Code,,
7a2e13204ff93cba13b711409e075c3564508ba0,2023-01-30T15:03:19Z,https://github.com/huggingface/transformers/commit/7a2e13204ff93cba13b711409e075c3564508ba0,Remove duplicate declarations in dummy inputs for TFLongformer (#21352)  Remove duplicate declarations,1,Remove Dead Code,,
73a2ff69740123ef85343580cbfa9ee8ce5e6fd5,2023-01-27T18:19:28Z,https://github.com/huggingface/transformers/commit/73a2ff69740123ef85343580cbfa9ee8ce5e6fd5,"Automated compatible models list for task guides (#21338)  * initial commit. added tip placeholders and a script  * removed unused imports, fixed paths  * fixed generated links  * make style  * split language modeling doc into two: causal language modeling and masked language modeling  * added check_task_guides.py to make fix-copies  * review feedback addressed",1,Remove Dead Code,,
125f137562598d42ab15ca81d43e833c50a7affe,2023-01-16T13:26:56Z,https://github.com/huggingface/transformers/commit/125f137562598d42ab15ca81d43e833c50a7affe,[LongT5] Remove duplicate encoder_attention_mask default value check (#21124)  - Remove duplicate encoder_attention_mask default value assignment,1,Remove Dead Code,,
056218dab1e59939a14f085ce5edcdd166053073,2023-01-14T18:47:32Z,https://github.com/huggingface/transformers/commit/056218dab1e59939a14f085ce5edcdd166053073,[CI-doc-daily] Remove RobertaPreLayernorm random tests (#20992)  * Remove random output  * remove values  * fix copy statements,1,Remove Dead Code,,
212829ade6c719c044937a56d1478c64e4b73882,2023-01-12T12:32:04Z,https://github.com/huggingface/transformers/commit/212829ade6c719c044937a56d1478c64e4b73882,Remove more unused attributes in config classes (#21000)  * Remove gradient_checkpointing from MarkupLMConfig  * Remove predict_special_tokens from OpenAIGPTConfig  * Remove enable_cls from RoCBertConfig  * Remove batch_size from TrajectoryTransformerConfig  * Remove searcher_seq_len from RealmConfig  * Remove feat_quantizer_dropout from WavLMConfig  * Remove position_biased_input from SEWDConfig  * Remove max_source_positions from Speech2Text2Config  Co-authored-by: ydshieh <ydshieh@users.noreply.github.com>,1,Remove Dead Code,,
e697c912c26f77ee8e1e62ae5ff8b25f3a451e48,2023-01-03T13:37:40Z,https://github.com/huggingface/transformers/commit/e697c912c26f77ee8e1e62ae5ff8b25f3a451e48,Remove more unused attributes in config classes (#20858)  Remove more unused attributes in config classes  Co-authored-by: ydshieh <ydshieh@users.noreply.github.com>,1,Remove Dead Code,,
2280880cb79f28618f16047bc55c38f956549605,2022-12-20T15:46:43Z,https://github.com/huggingface/transformers/commit/2280880cb79f28618f16047bc55c38f956549605,remove unused `use_cache` in config classes (#20844)  remove unused use_cache in config classes  Co-authored-by: ydshieh <ydshieh@users.noreply.github.com>,1,Remove Dead Code,,
244dd0f150d02573df954f5c12b5068bc2ea7296,2022-12-20T09:09:34Z,https://github.com/huggingface/transformers/commit/244dd0f150d02573df954f5c12b5068bc2ea7296,Remove unused `max_position_embeddings ` in config classes (#20836)  Removed unused max_position_embeddings in config classes  Co-authored-by: ydshieh <ydshieh@users.noreply.github.com>,1,Remove Dead Code,,
7c9e2f248c82c4201665d02d30cec79eb46f2221,2022-12-14T14:36:04Z,https://github.com/huggingface/transformers/commit/7c9e2f248c82c4201665d02d30cec79eb46f2221,[CI-Test] Fixes but also skips the mT5 tests (#20755)  * weight -> weights  * model embedding resize does not work with both v2 and noraml  * remove useless test,1,Remove Dead Code,,
9bafedc0fa51180e52507458f77a6411e2e52f9b,2022-12-14T10:17:11Z,https://github.com/huggingface/transformers/commit/9bafedc0fa51180e52507458f77a6411e2e52f9b,Remove image_transforms functions from init (#20704),1,Remove Dead Code,,
721764028e7aa58e5166a29fe417e309b5e8a449,2022-11-30T18:22:23Z,https://github.com/huggingface/transformers/commit/721764028e7aa58e5166a29fe417e309b5e8a449,"Add Chinese-CLIP implementation (#20368)  * init chinese-clip model from clip  * init model tests and docs  * implement chinese-clip into hf  * implement chinese-clip into hf  * implement chinese-clip into hf  * implement chinese-clip into hf  * implement chinese-clip into hf  * update usecase example in model implementation  * fix codestyle  * fix model_type typo in readme  * add placeholder in doc  * add placeholder in doc  * update the init script  * update usecase  * fix codestyle  * update testcase  * update testcase  * update testcase  * update testcase  * update testcase  * update testcase  * update testcase  * update testcase  * update testcase  * update testcase  * update testcase  * update testcase  * forward the convert_rgb  * update testcase  * update testcase  * update testcase  * merge the recent update from clip about model_input_name property  * update the doc  * update the doc  * update the doc  * update the doc  * remove unused imports  * reformat code style  * update the doc  * fix isort style  * bypass a weird failed unit test which is unrelated with my PR  * update the doc  * implement independent vision config class  * implement independent vision model class  * fix refactor bug  * fix refactor bug  * fix refactor bug  * make style  * fix refactor bug  * make style  * fix refactor bug  * fix refactor bug  * make style  * fix refactor bug  * fix refactor bug  * doc-build restyle  * implement independent text config class  * implement independent text model class  * implement independent text model class  * make style  * make fix-copies  * fix refactor bug  * fix refactor bug  * fix refactor bug  * fix refactor bug  * fix refactor bug  * fix refactor bug  * fix refactor bug  * fix refactor bug  * fix refactor bug  * fix refactor bug  * make style  * update doc  * black and isort  * update doc  * Update src/transformers/models/chinese_clip/configuration_chinese_clip.py  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * Update src/transformers/models/auto/tokenization_auto.py  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * modify the model type from chinese-clip to chinese_clip  * format the example comment of ChineseCLIPVisionConfig  * correct the copyright comment  * fix the tokenizer specification  * add copied from for loss function  * remove unused class  * update CHINESE_CLIP_TEXT_INPUTS_DOCSTRING  * update CHINESE_CLIP_INPUTS_DOCSTRING  * update doc  * update doc  * update code comment in config  * update copied from statement  * make style  * rename the doc file  * add copied statement  * remove unused attention_mask, causal_attention_mask in ChineseCLIPVisionEncoder  * remove ChineseCLIPTextPreTrainedModel  * fix bug  * fix bug  * fix bug  * update doc  * make style  * Update src/transformers/models/chinese_clip/configuration_chinese_clip.py  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * Update src/transformers/models/chinese_clip/configuration_chinese_clip.py  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * update ChineseCLIPImageProcessor in image_processing_auto  * fix config_class of chinesecliptextmodel  * fix the test case  * update the docs  * remove the copied from comment for ChineseCLIPTextModel, since it has diverged from BertModel with customed config_class  * update the testcase  * final fix  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com> Co-authored-by: ydshieh <ydshieh@users.noreply.github.com>",1,Remove Dead Code,,
d0c1ded5f36e27cd74728c0127add5afdf1f2afa,2022-11-30T10:46:01Z,https://github.com/huggingface/transformers/commit/d0c1ded5f36e27cd74728c0127add5afdf1f2afa,remove `attention_mask` truncation in whisper (#20488)  * remove truncation  * For TFWhisper  Co-authored-by: ydshieh <ydshieh@users.noreply.github.com>,1,Remove Dead Code,,
bac2d29a802803a7f2db8e8597a2ec81730afcc9,2022-11-09T15:03:36Z,https://github.com/huggingface/transformers/commit/bac2d29a802803a7f2db8e8597a2ec81730afcc9,"Attempting to test automatically the `_keys_to_ignore`. (#20042)  * Attempting to test automatically the `_keys_to_ignore`.  * Style.  * First fix pass.  * Moving test on its own.  * Another batch.  * Second round removing BatchNorm  * Fixing layoutlmv{2,3} + support older Python.  * Disable miss missing warning.  * Removing dodgy additions.  * Big pass.  * mbart.  * More corrections.  * Fixup.  * Updating test_correct_missing_keys  * Add escape hatch for when the head has no extra params so doesn't need  the missing keys check.  * Fixing test.  * Greener.  * Green ! (except for weird splinter bug).  * Adding a test about `named_parameters` usage.  * Shorten message.  * Apply suggestions from code review  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * After rebase modifications.  * More explicit condition checking.  * Fixing slow tests issues.  * Remove extra pdb.  * Remove print.  * Attempt to make failure consistent + fixing roc_bert.  * Removing the seed  (all tests passing with it).  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>",1,Remove Dead Code,,
3936411b9d3e0b4040ec15e0b1a86182e7e2443e,2022-11-04T13:52:58Z,https://github.com/huggingface/transformers/commit/3936411b9d3e0b4040ec15e0b1a86182e7e2443e,PoolformerImageProcessor defaults to match previous FE (#20048)  * Poolformer image processor defaults to previous FE  * Remove unnecessary math.floor,1,Remove Dead Code,,
c766a2d70a9e8520cda7efb2f4f62cb911b72d77,2022-10-27T14:56:48Z,https://github.com/huggingface/transformers/commit/c766a2d70a9e8520cda7efb2f4f62cb911b72d77,Remove embarrassing debug print() in save_pretrained (#19922),1,Remove Dead Code,,
ebee0a27940adfbb30444d83387b9ea0f1173f40,2022-10-18T17:58:09Z,https://github.com/huggingface/transformers/commit/ebee0a27940adfbb30444d83387b9ea0f1173f40,Remove debug statement,1,Remove Dead Code,,
2d4572b5c96661a301a44b149766e56e383104aa,2022-10-14T14:46:38Z,https://github.com/huggingface/transformers/commit/2d4572b5c96661a301a44b149766e56e383104aa,GPTTokenizer dependency removed from deberta class (#19551)  * GPTTOkenizer dependency removed from deberta class  Fixup  made the Deberta Tokenizer fast independent of GPT-2 tokenizer  Copied annotation added  Done the dependency removal  * Added some missing copied statement  * Added some copied statements,1,Remove Dead Code,,
462cd641d9b1fbe408964ffe60ee255bb94fd042,2022-10-11T15:48:03Z,https://github.com/huggingface/transformers/commit/462cd641d9b1fbe408964ffe60ee255bb94fd042,🚨🚨🚨  TF: Remove `TFWrappedEmbeddings` (breaking: TF embedding initialization updated for encoder-decoder models) (#19263)  * added test  * correct embedding init  * some changes in blenderbot (incomplete)  * update blenderbot (diff to be used as reference)  * update blenderbot_small  * update LED  * update marian  * update T5 and remove TFWrappedEmbeddings  * nullcontext() -> ContextManagers()  * fix embedding init,1,Remove Dead Code,,
3080bb4754e641b169ee5485441f4f79872f587e,2022-10-10T13:20:19Z,https://github.com/huggingface/transformers/commit/3080bb4754e641b169ee5485441f4f79872f587e,Add onnx support for VisionEncoderDecoder (#19254)  * Add onnx support for VisionEncoderDecoder  * Add onnx support for VisionEncoderDecoder  * Removed unused import  * Rename encoder hidden state  Co-authored-by: lewtun <lewis.c.tunstall@gmail.com>  * Update docstrings and removed redundant code  * Added test function for enc-dec models  * Update doc string text  Co-authored-by: lewtun <lewis.c.tunstall@gmail.com>  * fixed code style  Co-authored-by: lewtun <lewis.c.tunstall@gmail.com>,1,Remove Dead Code,,
298f6a98c210541fa2ab64f1d13ee9ac801032cc,2022-10-10T13:19:33Z,https://github.com/huggingface/transformers/commit/298f6a98c210541fa2ab64f1d13ee9ac801032cc,Stop relying on huggingface_hub's private methods (#19392)  * Leverage hfh for move cache  * Style,1,Remove Dead Code,,
071df6eb1333d2525ffbda81f292e199393598e4,2022-10-05T17:03:49Z,https://github.com/huggingface/transformers/commit/071df6eb1333d2525ffbda81f292e199393598e4,"Call _set_save_spec() when creating TF models (#19321)  * Add a build_from_serving_sig_and_dummies method and replace all calls like model(model.dummy_inputs) with it.  * make fixup  * Remove the overridden save() as this is no longer necessary  * Also call _set_save_spec(), the last missing piece  * Ensure we set the save spec when loading from config too  * Turn this whole thing into a one-line PR  * Turn this whole thing into a one-line PR  * Turn this whole thing into a one-line PR  Co-authored-by: Your Name <you@example.com>",1,Remove Dead Code,,
c54bb1ad79b596d19799b6160171cf631f8e1d73,2022-10-05T13:19:04Z,https://github.com/huggingface/transformers/commit/c54bb1ad79b596d19799b6160171cf631f8e1d73,[WIP]remove XLMTokenizer inheritance from FlaubertTokenizer (#19330)  * remove XLMTokenizer inheritance from FlaubertTokenizer  * remove XLMTokenizer inheritance from FlaubertTokenizer  * remove XLMTokenizer inheritance from FlaubertTokenizer  * remove XLMTokenizer inheritance from FlaubertTokenizer: fixed styling  * removed repo-consistensy issue,1,Remove Dead Code,,
c28d04e9e252a1a099944e325685f14d242ecdcd,2022-10-03T13:21:51Z,https://github.com/huggingface/transformers/commit/c28d04e9e252a1a099944e325685f14d242ecdcd,Update no_trainer script for summarization (#19277)  * Update no_trainer script for summarization  * removed unnecessary import  * fixes notation mistake  * removed: unused variable,1,Remove Dead Code,,
7132d55ca1824d5bd804755ce10db5e182823549,2022-09-27T08:39:31Z,https://github.com/huggingface/transformers/commit/7132d55ca1824d5bd804755ce10db5e182823549,Remove unused `cur_len` in generation_utils.py (#18874)  * remove unused cur_len in generation_utils.py  * linting,1,Remove Dead Code,,
adbf3a40de3524dcdce556914e2cb974d81854e5,2022-09-12T14:32:38Z,https://github.com/huggingface/transformers/commit/adbf3a40de3524dcdce556914e2cb974d81854e5,Remove dropout in embedding layer of OPT (#18845),1,Remove Dead Code,,
0b36970371c7848c02d50b6b7fd5d2a53fd6ef74,2022-09-12T13:19:48Z,https://github.com/huggingface/transformers/commit/0b36970371c7848c02d50b6b7fd5d2a53fd6ef74,Remove `decoder_position_ids` from `check_decoder_model_past_large_inputs` (#18980)  Co-authored-by: ydshieh <ydshieh@users.noreply.github.com>,1,Remove Dead Code,,
9faa9f9dacf8c818ab2513da3ef92ce66f39515d,2022-09-12T09:00:24Z,https://github.com/huggingface/transformers/commit/9faa9f9dacf8c818ab2513da3ef92ce66f39515d,remove unused activation dropout (#18842),1,Remove Dead Code,,
d90a36d192e2981a41122c30a765c63158dd0557,2022-08-22T15:16:27Z,https://github.com/huggingface/transformers/commit/d90a36d192e2981a41122c30a765c63158dd0557, remove check for main process for trackers initialization (#18706),1,Remove Dead Code,,
f62cb8313c2d7051e38f845823c1f4a7307aac3e,2022-08-10T19:47:31Z,https://github.com/huggingface/transformers/commit/f62cb8313c2d7051e38f845823c1f4a7307aac3e,"Adds CLIP to models exportable with ONNX (#18515)  * onnx config for clip  * default opset as 14  * changes from the original repo  * input values order fix  * outputs fix  * remove unused import  * ran make fix-copies  * black format  * review comments: forward ref, import fix, model change revert, .to cleanup  * make style  * formatting fixes  * revert groupvit  * comment for cast to int32  * comment fix  * make .T as .t() for onnx conversion  * ran make fix-copies  * remove unneeded comment  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * fix copies  * remove comment  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>",1,Remove Dead Code,,
aff5117f4695666f1fe9400f159e2a137f806544,2022-08-08T13:54:10Z,https://github.com/huggingface/transformers/commit/aff5117f4695666f1fe9400f159e2a137f806544,Remove debug statement,1,Remove Dead Code,,
377cdded7af50e7c023dc91bf69f4eef10ac8551,2022-08-08T12:48:10Z,https://github.com/huggingface/transformers/commit/377cdded7af50e7c023dc91bf69f4eef10ac8551,Clean up hub (#18497)  * Clean up utils.hub  * Remove imports  * More fixes  * Last fix,1,Remove Dead Code,,
0bf1e1aca46176fca99b46798867fcd7e9d75791,2022-08-04T17:22:19Z,https://github.com/huggingface/transformers/commit/0bf1e1aca46176fca99b46798867fcd7e9d75791,Update no trainer examples for QA and Semantic Segmentation (#18474)  * swag_no_trainer updated for with gather_metrics  * Removed unused variable samples_seen  * updated examples with gather_for_metrics,1,Remove Dead Code,,
330247ede2d8265aae9ab0b7a0d1a811c344960d,2022-08-04T11:29:32Z,https://github.com/huggingface/transformers/commit/330247ede2d8265aae9ab0b7a0d1a811c344960d,Update no trainer scripts for multiple-choice (#18468)  * swag_no_trainer updated for with gather_metrics  * Removed unused variable samples_seen,1,Remove Dead Code,,
1f843991716bba3b73071f1a2d819b0aebc05375,2022-08-01T11:40:25Z,https://github.com/huggingface/transformers/commit/1f843991716bba3b73071f1a2d819b0aebc05375,Migrate metric to Evaluate in Pytorch examples (#18369)  * Migrate metric to Evaluate in pytorch examples  * Remove unused imports,1,Remove Dead Code,,
cf32b2ee42bc2cbf816576e1b1b292d63aa66d1d,2022-07-27T12:39:09Z,https://github.com/huggingface/transformers/commit/cf32b2ee42bc2cbf816576e1b1b292d63aa66d1d,Remove all uses of six (#18318)  * Remove all uses of six  * fix quality,1,Remove Dead Code,,
5dfec704da2c1495247c7abe81a620c6e9913ea5,2022-07-27T08:00:47Z,https://github.com/huggingface/transformers/commit/5dfec704da2c1495247c7abe81a620c6e9913ea5,Remove duplicated line (#18310)  Removes a duplicated instantiation of device. I removed the second instance of the line to maintain code alignment with the GPT-J implementation of forward.,1,Remove Dead Code,,
4bea6584e30180d618a5c4b35861a07d76dff6a0,2022-07-19T06:13:20Z,https://github.com/huggingface/transformers/commit/4bea6584e30180d618a5c4b35861a07d76dff6a0,Remove use_auth_token from the from_config method (#18192)  * remove use_auth_token from from_config  * restore use_auth_token from_pretrained run_t5_mlm_flax,1,Remove Dead Code,,
6a1b1bf7a6abb303ccf655d53a0e1f9b30890470,2022-07-18T17:18:19Z,https://github.com/huggingface/transformers/commit/6a1b1bf7a6abb303ccf655d53a0e1f9b30890470,BLOOM minor fixes small test (#18175)  * minor fixes  - add correct revision - corrected dosctring for test - removed a test  * contrib credits  Co-authored-by: Yih-Dar <2521628+ydshieh@users.noreply.github.com> Co-authored-by: Nouamane Tazi <nouamane98@gmail.com>  Co-authored-by: Yih-Dar <2521628+ydshieh@users.noreply.github.com> Co-authored-by: Nouamane Tazi <nouamane98@gmail.com>,1,Remove Dead Code,,
14fb8a63b99326186951370828e2752857076df7,2022-07-01T13:04:38Z,https://github.com/huggingface/transformers/commit/14fb8a63b99326186951370828e2752857076df7,skip some gpt_neox tests that require 80G RAM (#17923)  * skip some gpt_neox tests that require 80G RAM  * remove tests  * fix quality  Co-authored-by: ydshieh <ydshieh@users.noreply.github.com>,1,Remove Dead Code,,
47b9165109dc19ef285179ced9ef856053ebcbc9,2022-06-29T13:02:53Z,https://github.com/huggingface/transformers/commit/47b9165109dc19ef285179ced9ef856053ebcbc9,Remove imports and use forward references in ONNX feature (#17926),1,Remove Dead Code,,
3ccff0d400ffd1b0c5074e15afb2b1f2af0e7b44,2022-06-21T19:30:40Z,https://github.com/huggingface/transformers/commit/3ccff0d400ffd1b0c5074e15afb2b1f2af0e7b44,Remove duplicate code (#17708),1,Remove Dead Code,,
9d99489f2f79b81fa9131c9299c236006dff94fb,2022-06-08T13:03:18Z,https://github.com/huggingface/transformers/commit/9d99489f2f79b81fa9131c9299c236006dff94fb,"Add TFData2VecVision for semantic segmentation (#17271)  * feat: initial implementation of data2vec segmentation model in TF.  * chore: minor corrections to make the segmenter work.  * chore: removed unncessary files.  * chore: add tests and other modifications.  * fix: loss computation for segmentation.  * chore: remove unused variable.  * chore: formatting.  * added a dummy adaptive pooling layer.  * removed unnecessary file.  * potentially add identifiers to layer names.  * fix: layer naming.  * chore: removed unnecessary print.  * Skipping unneeded test  * chore: add logging to debug tolerance.  * fix: segmentation tests for tfdata2vecvision  * chore: make style.  * fix: layer names, assertion to be resolved.  * Bumping test tolerance a bit  * chore: bump the tol in PT test.  Co-authored-by: matt <rocketknight1@gmail.com>",1,Remove Dead Code,,
ad7196524695f3bb3e178d57d280bd18fa175ca6,2022-06-06T20:41:41Z,https://github.com/huggingface/transformers/commit/ad7196524695f3bb3e178d57d280bd18fa175ca6,Remove circular imports in layoutlm/__init__.py (#17576),1,Remove Dead Code,,
2e37ef35d11ee0f9b892610f95014611c8bba2dd,2022-06-06T13:29:06Z,https://github.com/huggingface/transformers/commit/2e37ef35d11ee0f9b892610f95014611c8bba2dd,Remove RuntimeErrors for NaN-checking in 20B (#17563),1,Remove Dead Code,,
fe28eb94526131f942e852c84a7ca23ad9041bc4,2022-05-18T14:06:41Z,https://github.com/huggingface/transformers/commit/fe28eb94526131f942e852c84a7ca23ad9041bc4,remove (#17325)  Co-authored-by: ydshieh <ydshieh@users.noreply.github.com>,1,Remove Dead Code,,
d1d5ebb16cc8500a3e4e1b30047312cc563ca87f,2022-05-12T00:28:32Z,https://github.com/huggingface/transformers/commit/d1d5ebb16cc8500a3e4e1b30047312cc563ca87f,Remove duplicated os.path.join (#17192),1,Remove Dead Code,,
edcc66d27ca34f0d7f4c1f18e0c671ab9659555a,2022-05-11T15:11:26Z,https://github.com/huggingface/transformers/commit/edcc66d27ca34f0d7f4c1f18e0c671ab9659555a,Remove unnecessary columns for all dataset types in `Trainer` (#17166)  * Remove unneeded columns for IterableDataset  * Add test  * Update trainer tests  * Edit docstring  * Lint  * Apply feedback  * Apply feedback,1,Remove Dead Code,,
63517fdf4840505425c5f516ade17112dc769ebf,2022-05-11T11:16:46Z,https://github.com/huggingface/transformers/commit/63517fdf4840505425c5f516ade17112dc769ebf,[M2M100 doc] remove duplicate example (#17175)  * remove duplicate example  * remove code block,1,Remove Dead Code,,
b96e82c80a918f6348d89e4871051f7f04a56316,2022-04-19T14:32:08Z,https://github.com/huggingface/transformers/commit/b96e82c80a918f6348d89e4871051f7f04a56316,"Add image classification script, no trainer (#16727)  * Add first draft  * Improve README and run fixup  * Make script aligned with other scripts, improve README  * Improve script and add test  * Remove print statement  * Apply suggestions from code review  * Add num_labels to make test pass  * Improve README",1,Remove Dead Code,,
d7f7f29f29f7267ad895514e3a5054b35091d152,2022-04-12T16:51:47Z,https://github.com/huggingface/transformers/commit/d7f7f29f29f7267ad895514e3a5054b35091d152,TF: remove set_tensor_by_indices_to_value (#16729),1,Remove Dead Code,,
389f66151d84eaa8cfb30ad125bb7177d9c34123,2022-04-07T15:05:10Z,https://github.com/huggingface/transformers/commit/389f66151d84eaa8cfb30ad125bb7177d9c34123,Remove parent/child tests in auto model tests (#16653),1,Remove Dead Code,,
a8b6443e065a14af755f8f0ad1d3b5d70cc5f3ed,2022-03-31T07:32:33Z,https://github.com/huggingface/transformers/commit/a8b6443e065a14af755f8f0ad1d3b5d70cc5f3ed,Refactor Modeling Outputs (#16341)  * first proposal  * replace model outputs in various models  * conflicts  * docstring  * update poolformer  * minor change in docstring  * CI  * removed poolformer specific outputs from doc  * removed convnext specific outputs from doc  * CI  * weird char in segformer  * conversations  * reverted docstring for BaseModelOutputWithPooling  * update outputs  * changed docstring in BaseModelOutput  * updated docstring in modeling outputs  * typos :)  * fixed typo after copy & paste it all around  * CI  * Apply suggestions from code review  Co-authored-by: NielsRogge <48327001+NielsRogge@users.noreply.github.com>  * segformer  Co-authored-by: NielsRogge <48327001+NielsRogge@users.noreply.github.com>,1,Remove Dead Code,,
81ac45f85c35244831f11f73c09ea10eee4f953a,2022-03-30T20:28:35Z,https://github.com/huggingface/transformers/commit/81ac45f85c35244831f11f73c09ea10eee4f953a,update smddp api to v1.4.0 (#16371)  * update smddp api to v1.4.0  * Update src/transformers/trainer.py  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * Update src/transformers/trainer.py  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * address comments  * fix style  * remove unused import  * fix indent  * disable style check for import  * fix space  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>,1,Remove Dead Code,,
3dc82427166239e2764196c07fa4c5dcc25b1590,2022-03-27T17:09:15Z,https://github.com/huggingface/transformers/commit/3dc82427166239e2764196c07fa4c5dcc25b1590,TF: removed inputs_processing and replaced with decorator in lxmert (#16414),1,Remove Dead Code,,
319cbbe19153d935f1e706b9bb2e9a294defe9e5,2022-03-21T09:15:38Z,https://github.com/huggingface/transformers/commit/319cbbe19153d935f1e706b9bb2e9a294defe9e5,Deberta v2 code simplification (#15732)  * Removed spurious substraction  * Fixed condition checking for attention type  * Fixed sew_d copy of DeBERTa v2 attention  * Removed unused `p2p` attention type from DebertaV2-class models  * Fixed docs style,1,Remove Dead Code,,
c1c17bd0b3e0503dfd55c757587a546b1426406b,2022-03-15T14:00:18Z,https://github.com/huggingface/transformers/commit/c1c17bd0b3e0503dfd55c757587a546b1426406b,update transformer XL with tf decorator (#16166)  * update transformer XL with tf decorator  * code fixup  * remove unused variables,1,Remove Dead Code,,
5b369dc5d8b398a63d6e35226ee9e0335d922493,2022-03-11T13:27:59Z,https://github.com/huggingface/transformers/commit/5b369dc5d8b398a63d6e35226ee9e0335d922493,Remove assertion over possible activation functions in DistilBERT (#16066)  * Remove assertion over possible activation functions  * Same for TF and Flax,1,Remove Dead Code,,
cec89e1a0e6f6df92de8976daacc765eeca198bc,2022-03-09T13:47:58Z,https://github.com/huggingface/transformers/commit/cec89e1a0e6f6df92de8976daacc765eeca198bc,Simplify release utils (#15921)  * Simplify release utils  * Quality,1,Remove Dead Code,,
3ea046995e316a5d10ed5d53b0da522392a9f655,2022-03-09T13:21:23Z,https://github.com/huggingface/transformers/commit/3ea046995e316a5d10ed5d53b0da522392a9f655,Removed an outdated check about hdf5_version (#16011)  * removed an outdated check about hdf5_version  Co-authored-by: ydshieh <ydshieh@users.noreply.github.com>,1,Remove Dead Code,,
70203b59379b1841013980b6941bddfd34bfe816,2022-03-08T14:46:44Z,https://github.com/huggingface/transformers/commit/70203b59379b1841013980b6941bddfd34bfe816,TF generate refactor - past without encoder outputs (#15944)  * Remove packed past from generation_tf_utils  * update models with the new past format  * update template accordingly,1,Remove Dead Code,,
60b81dfa6faae3aa90c34a7df9304036f513d055,2022-03-07T13:58:44Z,https://github.com/huggingface/transformers/commit/60b81dfa6faae3aa90c34a7df9304036f513d055,remove re-defination of FlaxWav2Vec2ForCTCModule (#15965),1,Remove Dead Code,,
a63bd3675f3fa1a6154c8bf1d085c66eaea67e56,2022-02-21T10:10:15Z,https://github.com/huggingface/transformers/commit/a63bd3675f3fa1a6154c8bf1d085c66eaea67e56,Remove input and target reset after preprocessing (#15741)  Remove input and target reset after preprocessing,1,Remove Dead Code,,
6775b211b6412ddda9494da9498773bbb498a3de,2022-02-07T16:32:13Z,https://github.com/huggingface/transformers/commit/6775b211b6412ddda9494da9498773bbb498a3de,Remove Longformers from ONNX-supported models (#15273),1,Remove Dead Code,,
af5c3329d727f21bb32ef952346e07ea96d8a0cc,2022-02-01T10:09:49Z,https://github.com/huggingface/transformers/commit/af5c3329d727f21bb32ef952346e07ea96d8a0cc,"remove ""inputs"" in tf common test script (no longer required) (#15262)  Co-authored-by: ydshieh <ydshieh@users.noreply.github.com>",1,Remove Dead Code,,
6915174e68f9a3951b6e00d260812c71f099c602,2022-01-31T18:50:25Z,https://github.com/huggingface/transformers/commit/6915174e68f9a3951b6e00d260812c71f099c602,[RobertaTokenizer] remove inheritance on GPT2Tokenizer (#15429)  * refactor roberta tokenizer  * refactor fast tokenizer  * remove old comment,1,Remove Dead Code,,
eac4aecc3df00f9fd3b0444a5d12d5fd0d6a04d8,2022-01-24T12:27:45Z,https://github.com/huggingface/transformers/commit/eac4aecc3df00f9fd3b0444a5d12d5fd0d6a04d8,Remove old debug code leftover. (#15306),1,Remove Dead Code,,
d1f5ca1afd03e38f45062b2a06f1846a7c290da4,2022-01-19T11:04:51Z,https://github.com/huggingface/transformers/commit/d1f5ca1afd03e38f45062b2a06f1846a7c290da4,[FLAX] glue training example refactor (#13815)  * refactor run_flax_glue.py  * updated readme  * rm unused import and args typo fix  * refactor  * make consistent arg name across task  * has_tensorboard check  * argparse -> argument dataclasses  * refactor according to review  * fix,1,Remove Dead Code,,
96881729ce83cfc8e5fa04c903ee4296ad17cfbb,2022-01-13T22:34:41Z,https://github.com/huggingface/transformers/commit/96881729ce83cfc8e5fa04c903ee4296ad17cfbb,Remove assert on optional arg,1,Remove Dead Code,,
d1ba56d8d8a4da183bfe7f0b30e0ec1220ebf6ea,2021-12-29T22:18:03Z,https://github.com/huggingface/transformers/commit/d1ba56d8d8a4da183bfe7f0b30e0ec1220ebf6ea,remove absl workaround as it's no longer needed (#14909)  the absl workaround hasn't been needed since 2019-04 https://github.com/abseil/abseil-py/issues/99 so it should be safe to remove it.,1,Remove Dead Code,,
676643c6d6c36927725560926a8e8f7714666d5b,2021-12-23T19:18:07Z,https://github.com/huggingface/transformers/commit/676643c6d6c36927725560926a8e8f7714666d5b,Better logic for getting tokenizer config in AutoTokenizer (#14906)  * Better logic for getting tokenizer config in AutoTokenizer  * Remove needless import  * Remove debug statement  * Address review comments,1,Remove Dead Code,,
2a33734606aa25c6f05df157fff8c52b2a883c33,2021-12-21T08:11:25Z,https://github.com/huggingface/transformers/commit/2a33734606aa25c6f05df157fff8c52b2a883c33,Make the onnx submodule init lazy (#14855)  * Use lazy init for onnx submodule  * Remove debug statements,1,Remove Dead Code,,
d194d639abb51711ee212a61077fe91c0cfa727d,2021-12-16T19:34:14Z,https://github.com/huggingface/transformers/commit/d194d639abb51711ee212a61077fe91c0cfa727d,Remove datasets requirement (#14795),1,Remove Dead Code,,
e926ea2bdde094905d15bb512d4d18667948b24f,2021-12-13T17:46:49Z,https://github.com/huggingface/transformers/commit/e926ea2bdde094905d15bb512d4d18667948b24f,Improve perceiver (#14750)  * First draft  * Improve docstring + clean up tests  * Remove unused code  * Add check in case one doesn't provide a preprocessor,1,Remove Dead Code,,
15a9d0151907b49ba66aca9e084eee1fb626affa,2021-12-13T17:30:46Z,https://github.com/huggingface/transformers/commit/15a9d0151907b49ba66aca9e084eee1fb626affa,Avoid using tf.tile in embeddings for TF models (#14735)  * avoid tf.tile in embeddings  * remove more tf.tile in embeddings  * clean  Co-authored-by: ydshieh <ydshieh@users.noreply.github.com>,1,Remove Dead Code,,
babd0b9a5e37ce3f7f876f128d26cbae8fdda1da,2021-11-09T16:30:17Z,https://github.com/huggingface/transformers/commit/babd0b9a5e37ce3f7f876f128d26cbae8fdda1da,remove test_model_various_embeddings (#14341)  Co-authored-by: ydshieh <ydshieh@users.noreply.github.com>,1,Remove Dead Code,,
279ce5b705a0b8689f2a8e5d5258dbb5421c9e6c,2021-10-07T10:07:02Z,https://github.com/huggingface/transformers/commit/279ce5b705a0b8689f2a8e5d5258dbb5421c9e6c,Add an example of exporting BartModel + BeamSearch to ONNX module. (#13765)  * Add all example files.  * Reformat files by black.  * Style.  * Remove unused imports.  Co-authored-by: Morgan Funtowicz <funtowiczmo@gmail.com>,1,Remove Dead Code,,
73a038128227be14b1b6397667b4ff227918f81e,2021-09-01T08:41:46Z,https://github.com/huggingface/transformers/commit/73a038128227be14b1b6397667b4ff227918f81e,Torchscript test (#13350)  * Torchscript test  * Remove print statement,1,Remove Dead Code,,
0b54046ff8bbb60f0ec0ecbc1b6215be6bc1b2d9,2021-08-23T16:07:41Z,https://github.com/huggingface/transformers/commit/0b54046ff8bbb60f0ec0ecbc1b6215be6bc1b2d9,remove unwanted code (#13145),1,Remove Dead Code,,
78f5fe1416e74a2225e162e349cb8a53f1d39212,2021-07-13T19:07:32Z,https://github.com/huggingface/transformers/commit/78f5fe1416e74a2225e162e349cb8a53f1d39212,"[Deepspeed] adapt multiple models, add zero_to_fp32 tests (#12477)  * zero_to_fp32 tests  * args change  * remove unnecessary work  * use transformers.trainer_utils.get_last_checkpoint  * document the new features  * cleanup  * wip  * fix fsmt  * add bert  * cleanup  * add xlm-roberta  * electra works  * cleanup  * sync  * split off the model zoo tests  * cleanup  * cleanup  * cleanup  * cleanup  * reformat  * cleanup  * casing  * deepspeed>=0.4.3  * adjust distilbert  * Update docs/source/main_classes/deepspeed.rst  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * style  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>",1,Remove Dead Code,,
379f649434e8a3477b11f5e04aaf9692ebb65af4,2021-07-12T14:58:38Z,https://github.com/huggingface/transformers/commit/379f649434e8a3477b11f5e04aaf9692ebb65af4,TF summarization example (#12617)  * Adding a TF summarization example  * Style pass  * Style fixes  * Updates for review comments  * Adding README  * Style pass  * Remove unused import,1,Remove Dead Code,,
1ab147d648defff2071de253a3dbc1b1c4d24e4d,2021-05-31T14:29:04Z,https://github.com/huggingface/transformers/commit/1ab147d648defff2071de253a3dbc1b1c4d24e4d,"Remove redundant `nn.log_softmax` in `run_flax_glue.py` (#11920)  * Remove redundant `nn.log_softmax` in `run_flax_glue.py`  `optax.softmax_cross_entropy` expects unnormalized logits, and so it already calls `nn.log_softmax`, so I believe it is not needed here. `nn.log_softmax` is idempotent so mathematically it shouldn't have made a difference.  * Remove unused 'flax.linen' import",1,Remove Dead Code,,
226e74b610bd8d30c2faba627f245d693ced7b55,2021-05-04T18:31:18Z,https://github.com/huggingface/transformers/commit/226e74b610bd8d30c2faba627f245d693ced7b55,Removes SageMakerTrainer code but keeps class as wrapper (#11587)  * removed all old code  * make quality,1,Remove Dead Code,,
741d48f5c7bf0acdf9b40d0deb8560b997761f3a,2021-04-26T22:28:40Z,https://github.com/huggingface/transformers/commit/741d48f5c7bf0acdf9b40d0deb8560b997761f3a,Remove max length beam scorer (#11378)  * removed max_len  * removed max_length from BeamSearchScorer  * correct max length  * finish  * del vim  * finish & add test  Co-authored-by: Patrick von Platen <patrick.v.platen@gmail.com>,1,Remove Dead Code,,
bc2571e61c985ec82819cf01ad038342771c94d0,2021-04-26T17:40:32Z,https://github.com/huggingface/transformers/commit/bc2571e61c985ec82819cf01ad038342771c94d0,[Deepspeed] ZeRO-Infinity integration plus config revamp (#11418)  * adding Z-inf  * revamp config process  * up version requirement  * wip  * massive rewrite  * cleanup  * cleanup  * Apply suggestions from code review  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * consistent json commas  * act on suggestions  * leave this feature for 0.3.16  * style  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>,1,Remove Dead Code,,
f464f10a2c23c0e3a4bec04071ef15df565608bc,2021-04-20T12:16:02Z,https://github.com/huggingface/transformers/commit/f464f10a2c23c0e3a4bec04071ef15df565608bc,[Generate] Remove outdated code (#11331)  * remove update function  * update  * refactor more  * refactor,1,Remove Dead Code,,
4002f95eb66622a048ff01a383968af57023134d,2021-03-29T19:27:12Z,https://github.com/huggingface/transformers/commit/4002f95eb66622a048ff01a383968af57023134d,Remove duplicate code,1,Remove Dead Code,,
4684bfc7576e45f5af26752bb5f5e57e171ce56b,2021-03-25T16:32:38Z,https://github.com/huggingface/transformers/commit/4684bfc7576e45f5af26752bb5f5e57e171ce56b,"Layout lm tf 2 (#10636)  * Added embeddings layer  * Added layoutlm layers, main model, maskedlm and token classification classes  * Added model classes to tf auto models  * Added model to PT to TF conversion script  * Added model to doc README  * Added tests  * Removed unused imports  * Added layoutlm model, test, and doc for sequence classification, and fix imports in __init__.py  * Made tests pass!  * Fixed typos in imports and docs  * Fixed a typo in embeddings layer  * Removed imports  * Fixed formatting issues, imports, tests  * Added layoutlm layers, main model, maskedlm and token classification classes  * Added model classes to tf auto models  * Added model to PT to TF conversion script  * Removed unused imports  * Added layoutlm model, test, and doc for sequence classification, and fix imports in __init__.py  * Made tests pass!  * Fixed typos in imports and docs  * Removed imports  * Fixed small formatting issues  * Removed duplicates import from main __init__.py  * Chnaged deafult arg to true for adding  pooling layer to tf layoutlm  * Fixed formatting issues  * Style  * Added copied from to classes copied from bert  * Fixed doc strings examples to work with layoutlm inputs  * Removed PyTorch reference in doc strings example  * Added integration tests  * Cleaned up initialization file  * Updated model checkpoint identifiers  * Fixed imports  Co-authored-by: Amir Tahmasbi <amir@ehsai.ca> Co-authored-by: Lysandre <lysandre.debut@reseau.eseo.fr>",1,Remove Dead Code,,
01c7fb04be61ee02e85dc6554d00dec9aa8e6ea1,2021-03-17T17:21:03Z,https://github.com/huggingface/transformers/commit/01c7fb04be61ee02e85dc6554d00dec9aa8e6ea1,[DeepSpeed] simplify init (#10762),1,Remove Dead Code,,
87d685b8a9051c056af01adeea4e25326b27990a,2021-03-15T23:35:26Z,https://github.com/huggingface/transformers/commit/87d685b8a9051c056af01adeea4e25326b27990a,independent training / eval with local files (#10710)  * independent training / eval with local files  * remove redundant assert,1,Remove Dead Code,,
89693e170da06126147c6de44e74685bdfa74506,2021-03-11T16:11:56Z,https://github.com/huggingface/transformers/commit/89693e170da06126147c6de44e74685bdfa74506,Remove special treatment for custom vocab files (#10637)  * Remove special path for custom vocab files  * Update src/transformers/tokenization_utils_base.py  Co-authored-by: Patrick von Platen <patrick.v.platen@gmail.com>  * Expand error message  Co-authored-by: Patrick von Platen <patrick.v.platen@gmail.com>,1,Remove Dead Code,,
44f64132a5f50726f9de4467ed745421c3b11ab3,2021-03-10T04:22:31Z,https://github.com/huggingface/transformers/commit/44f64132a5f50726f9de4467ed745421c3b11ab3,remove final_logits_bias (#10606),1,Remove Dead Code,,
805c5200dc41aa7ca8dbb851688223df8627b411,2021-03-04T16:12:37Z,https://github.com/huggingface/transformers/commit/805c5200dc41aa7ca8dbb851688223df8627b411,Removes overwrites for output_dir  (#10521)  * removed overwrites  * remove default value for output_dir  * adjusted typing,1,Remove Dead Code,,
a85eb616f73c3e7eedb22146972ea41921164671,2021-02-27T00:06:08Z,https://github.com/huggingface/transformers/commit/a85eb616f73c3e7eedb22146972ea41921164671,Ray Tune Integration Bug Fixes (#10406)  * fixes  * update resources  * formatting  * remove import  * add log statement  * use fstring  * add period  * Update src/transformers/integrations.py,1,Remove Dead Code,,
c130e67dce56a092604949a8df6384a17f762189,2021-02-10T17:09:09Z,https://github.com/huggingface/transformers/commit/c130e67dce56a092604949a8df6384a17f762189,remove adjust_logits_during_generation method (#10087)  * add forced logits processors  * delete adjust_logits method  * add forced_eos_token_id argument in config  * add tests for forced logits processors  * update gen utils tests  * add forced option to tf generate  * remove adjust_logits method from tf models  * update adjust_logits for marian  * delete _force_token_id_to_be_generated method  * style  * import warnings  * pass max_length to _get_logits_processor  * set forced_eos_token_id to None  * set forced attributes in conf utils  * typo  * fix rag generate  * add forced_eos_token_id in rag config  * remove force_bos_token_to_be_generated from BartConfig  * remove _force_token_ids_generation from FSMT  * nit  * fix negative constant  * apply suggestions from code review,1,Remove Dead Code,,
714855bd8fbff69c93e76193bbf46aa9dee06412,2021-02-04T15:24:47Z,https://github.com/huggingface/transformers/commit/714855bd8fbff69c93e76193bbf46aa9dee06412,"Remove ""double"" assignment  in TF-BART like models (#9997)  * Replace `attn_weights = attn_wegihts = tf.reshape(...)` with `attn_weights = tf.reshape(...)` and thus remove unintentionally used ""double"" assignment.",1,Remove Dead Code,,
115d97dd2f752880715cd01aa915286e3d9a5442,2021-02-01T13:06:32Z,https://github.com/huggingface/transformers/commit/115d97dd2f752880715cd01aa915286e3d9a5442,Remove subclass for sortish sampler (#9907)  * Remove subclass for sortish sampler  * Use old Seq2SeqTrainer in script  * Styling,1,Remove Dead Code,,
4c3ae89ad3215c3252ebf8ce964795ba8813d810,2021-01-28T15:09:13Z,https://github.com/huggingface/transformers/commit/4c3ae89ad3215c3252ebf8ce964795ba8813d810,Remove redundant `test_head_masking  = True` flags in test files (#9858)  * Remove redundant test_head_masking = True flags  * Remove all redundant test_head_masking flags in PyTorch test_modeling_* files  * Make test_head_masking = True as a default choice in test_modeling_tf_commong.py  * Remove all redundant test_head_masking flags in TensorFlow test_modeling_tf_* files  * Put back test_head_masking=False fot TFT5 models,1,Remove Dead Code,,
72fc9abf17d9eafdfa666156415c56aa24285baf,2021-01-18T09:24:21Z,https://github.com/huggingface/transformers/commit/72fc9abf17d9eafdfa666156415c56aa24285baf,"Remove duplicated extra[""retrieval""] (#9621)",1,Remove Dead Code,,
d415882b41e61c962df5c2c8086ec83fa4b71629,2021-01-11T13:02:41Z,https://github.com/huggingface/transformers/commit/d415882b41e61c962df5c2c8086ec83fa4b71629,Remove tolerance + drop_rows_to_fit by default (#9507)  * Remove tolerance + drop_rows_to_fit by default  * remove drop_rows_to_fit,1,Remove Dead Code,,
3ec40299c18c370011a39e0576faf1e90c0a8164,2021-01-07T09:10:41Z,https://github.com/huggingface/transformers/commit/3ec40299c18c370011a39e0576faf1e90c0a8164,Remove nested lxmert (#9440),1,Remove Dead Code,,
ae333d04b29a25be1a70eaccd6260c294c243c5b,2020-12-30T09:09:51Z,https://github.com/huggingface/transformers/commit/ae333d04b29a25be1a70eaccd6260c294c243c5b,torch.cuda.is_available() is redundant as apex handles that internally (#9350),1,Remove Dead Code,,
cbe63949d76efd153a1f389f38fe9ce1287e06b0,2020-12-22T22:41:20Z,https://github.com/huggingface/transformers/commit/cbe63949d76efd153a1f389f38fe9ce1287e06b0,Model Templates for Seq2Seq (#9251)  * adapt cookie cutter  * fix copy past statement  * delete copy statements for now  * remove unused import from template  * make doc rst  * correct config docstring  * correct training  * correct inputs processing tf enc dec  * make style  * adapt templates  * clean tabs  * correct tensor -> Tensor naming  * correct indent  * correct templates  * fix the test  * break lines to avoid > 119  * Apply suggestions from code review,1,Remove Dead Code,,
abc573f51ac52c13cf127f614151b64faa54babf,2020-12-15T16:31:28Z,https://github.com/huggingface/transformers/commit/abc573f51ac52c13cf127f614151b64faa54babf,[TF Bart] Refactor TFBart (#9029)  * reorder file  * delete unnecesarry function  * make style  * save intermediate  * fix attention masks  * correct tf bart past key values  * solve merge conflict bug  * correct tensor dims  * save intermediate tf  * change attn layer  * fix typo re-order past  * inputs_embeds  * make fix copies  * finish tests  * fix graph mode  * appyl lysandres suggestions,1,Remove Dead Code,,
61abd50b98de4cd8f6024d77154a0326d16f1db5,2020-12-09T14:13:41Z,https://github.com/huggingface/transformers/commit/61abd50b98de4cd8f6024d77154a0326d16f1db5,Remove use of deprected method in Trainer HP search (#8996),1,Remove Dead Code,,
7809eb82ae0341b7a02b1ce7ab7d6d551e9855d9,2020-12-08T17:04:34Z,https://github.com/huggingface/transformers/commit/7809eb82ae0341b7a02b1ce7ab7d6d551e9855d9,Removed unused `encoder_hidden_states` and `encoder_attention_mask`  (#8972)  * Removed unused `encoder_hidden_states` and `encoder_attention_mask` from MobileBert  * Removed decoder tests for MobileBert  * Removed now unnecessary import,1,Remove Dead Code,,
7e1cb00c37365c8736f201e5152c741cde41c8b4,2020-12-02T17:07:42Z,https://github.com/huggingface/transformers/commit/7e1cb00c37365c8736f201e5152c741cde41c8b4,[trainer] improve code readability (#8903)  * [trainer] improve code  This PR: - removes redundant code  ``` self.model = model if model is not None else None ``` and ``` self.model = model ``` are the same.  * separate attribute assignment from code logic - which simplifies things further.  * whitespace,1,Remove Dead Code,,
4185b115d4b3fd408265ffd91581698325652c47,2020-11-10T01:49:51Z,https://github.com/huggingface/transformers/commit/4185b115d4b3fd408265ffd91581698325652c47,Changing XLNet default from not using memories to 512 context size following paper (#8417)  * Move XLNet memory length FutureWarning  * isort  * style  * Changed default XLNet memory length,1,Remove Dead Code,,
9c4aa4ac1aac8972b3c8472532a3b981389da0ce,2020-11-04T22:24:49Z,https://github.com/huggingface/transformers/commit/9c4aa4ac1aac8972b3c8472532a3b981389da0ce,Clean up data collators and datasets (#8308)  * Clean up data collators and datasets  * Apply suggestions from code review  Co-authored-by: Lysandre Debut <lysandre@huggingface.co>  * Remove needless clone  Co-authored-by: Lysandre Debut <lysandre@huggingface.co>,1,Remove Dead Code,,
825925dfaa5bd6f1dfb92a597ca89d69720772b6,2020-10-28T20:50:36Z,https://github.com/huggingface/transformers/commit/825925dfaa5bd6f1dfb92a597ca89d69720772b6,[s2s test] cleanup (#8131),1,Remove Dead Code,,
47dfa65b0cba3d4fb3f24e52bc2299e261119276,2020-10-28T14:38:58Z,https://github.com/huggingface/transformers/commit/47dfa65b0cba3d4fb3f24e52bc2299e261119276,New run_clm script (#8105)  * New run_clm script  * Formatting  * More comments  * Remove unused imports  * Apply suggestions from code review  Co-authored-by: Thomas Wolf <thomwolf@users.noreply.github.com>  * Address review comments  * Change link to the hub  Co-authored-by: Thomas Wolf <thomwolf@users.noreply.github.com>,1,Remove Dead Code,,
4acfd1a8dc8a025d45afd9567ed9440be2d12687,2020-10-23T14:29:15Z,https://github.com/huggingface/transformers/commit/4acfd1a8dc8a025d45afd9567ed9440be2d12687,[Reformer] remove reformer pad_token_id (#7991)  * remove reformer pad_token_id  * fix pegasus,1,Remove Dead Code,,
c65863ce5341c3dac162fb5e301ba7f6bee800fa,2020-10-17T21:31:53Z,https://github.com/huggingface/transformers/commit/c65863ce5341c3dac162fb5e301ba7f6bee800fa,Remove duplicated mish activation function (#7856)  * Remove duplicated mish activation function  * Update activations.py,1,Remove Dead Code,,
c6e865ac2bdad9f65c5bc51561563c46c427b506,2020-10-16T07:12:10Z,https://github.com/huggingface/transformers/commit/c6e865ac2bdad9f65c5bc51561563c46c427b506,Remove masked_lm_labels from returned dictionary (#7818),1,Remove Dead Code,,
95f792afb0f0ce5a7b4f0e8df108b10157a69134,2020-10-04T21:39:23Z,https://github.com/huggingface/transformers/commit/95f792afb0f0ce5a7b4f0e8df108b10157a69134,Remove labels from the RagModel example (#7560),1,Remove Dead Code,,
72d363d9791c64eff21ed7535c690de2c636d508,2020-10-01T16:19:29Z,https://github.com/huggingface/transformers/commit/72d363d9791c64eff21ed7535c690de2c636d508,[examples/s2s] clean up finetune_trainer (#7509),1,Remove Dead Code,,
48f23f92a80500b1475a84566841efe6581a94c0,2020-10-01T04:33:01Z,https://github.com/huggingface/transformers/commit/48f23f92a80500b1475a84566841efe6581a94c0,[s2sTrainer] test + code cleanup (#7467),1,Remove Dead Code,,
fdccf82e28faf626fa8a64004164f3cd7744de41,2020-09-30T13:03:25Z,https://github.com/huggingface/transformers/commit/fdccf82e28faf626fa8a64004164f3cd7744de41,Remove config assumption in Trainer (#7464)  * Remove config assumption in Trainer  * Initialize for eval,1,Remove Dead Code,,
38a1b03f4d0a2c6e459293b5239dbedc82478191,2020-09-25T15:01:07Z,https://github.com/huggingface/transformers/commit/38a1b03f4d0a2c6e459293b5239dbedc82478191,Remove unhelpful bart warning (#7391),1,Remove Dead Code,,
89edf504bf2abdb7d53a3b7770fc77e7849e0ab8,2020-09-22T13:52:29Z,https://github.com/huggingface/transformers/commit/89edf504bf2abdb7d53a3b7770fc77e7849e0ab8,Add possibility to evaluate every epoch (#7302)  * Add possibility to evaluate every epoch  * Remove multitype arg  * Remove needless import  * Use a proper enum  * Apply suggestions from @LysandreJik  Co-authored-by: Lysandre Debut <lysandre@huggingface.co>  * One else and formatting  Co-authored-by: Lysandre Debut <lysandre@huggingface.co>,1,Remove Dead Code,,
67d9fc50d917c63cf67281106214e1d9ae018dff,2020-09-17T22:32:31Z,https://github.com/huggingface/transformers/commit/67d9fc50d917c63cf67281106214e1d9ae018dff,[s2s] remove double assert (#7223),1,Remove Dead Code,,
709745927b119a0414a167a10e363d9a9ef1ef38,2020-09-17T10:10:34Z,https://github.com/huggingface/transformers/commit/709745927b119a0414a167a10e363d9a9ef1ef38,Transformer-XL: Remove unused parameters (#7087)  * Removed 'tgt_len' and 'ext_len' from Transfomer-XL   * Some changes are still to be done  * Removed 'tgt_len' and 'ext_len' from Transfomer-XL (2)   * Removed comments  * Fixed quality  * Changed warning to info,1,Remove Dead Code,,
0cdafbf7ecfe0f13335c2ea10fd92391e30c79f0,2020-09-17T09:51:40Z,https://github.com/huggingface/transformers/commit/0cdafbf7ecfe0f13335c2ea10fd92391e30c79f0,remove duplicated code (#7173),1,Remove Dead Code,,
b0cbcdb05b39e6c81db049d2b4d7dfc5d823210d,2020-09-15T08:01:14Z,https://github.com/huggingface/transformers/commit/b0cbcdb05b39e6c81db049d2b4d7dfc5d823210d,[logging] remove no longer needed verbosity override (#7100),1,Remove Dead Code,,
de9e2979647338bc9617dae68c5e9dccc413fb9f,2020-09-14T03:40:38Z,https://github.com/huggingface/transformers/commit/de9e2979647338bc9617dae68c5e9dccc413fb9f,[s2s] distributed eval cleanup (#7110),1,Remove Dead Code,,
0a8c17d53cf6ebd54204e307059f36c14035da93,2020-09-11T18:18:45Z,https://github.com/huggingface/transformers/commit/0a8c17d53cf6ebd54204e307059f36c14035da93,[T5Tokenizer] remove prefix_tokens (#7078),1,Remove Dead Code,,
4ebb52afdb4dc4bcd599e7cb503763e5d4afc962,2020-09-02T14:54:40Z,https://github.com/huggingface/transformers/commit/4ebb52afdb4dc4bcd599e7cb503763e5d4afc962,test_tf_common: remove un_used mixin class parameters (#6866),1,Remove Dead Code,,
6b4c617666fd26646d44d54f0c45dfe1332b12ca,2020-08-24T17:20:03Z,https://github.com/huggingface/transformers/commit/6b4c617666fd26646d44d54f0c45dfe1332b12ca,Move unused args to kwargs (#6694),1,Remove Dead Code,,
33bf42649884e11873322b3e01446bec67773a2f,2020-08-20T12:23:35Z,https://github.com/huggingface/transformers/commit/33bf42649884e11873322b3e01446bec67773a2f,removed redundant arg in prepare_inputs (#6614)  * removed redundant arg in prepare_inputs  * made same change in prediction_loop,1,Remove Dead Code,,
9a86321b11b0ee03d8803d7e21b50012252a76ac,2020-08-19T13:37:45Z,https://github.com/huggingface/transformers/commit/9a86321b11b0ee03d8803d7e21b50012252a76ac,tf generation utils: remove unused kwargs (#6591),1,Remove Dead Code,,
37709b59099bd984858ca1884c6c70403420347d,2020-08-17T09:13:58Z,https://github.com/huggingface/transformers/commit/37709b59099bd984858ca1884c6c70403420347d,Remove deprecated assertEquals (#6532)  `assertEquals` is deprecated: https://stackoverflow.com/questions/930995/assertequals-vs-assertequal-in-python/931011 This PR replaces these deprecated methods.,1,Remove Dead Code,,
6730ecdd3c92f068ddb598812c90baddd4ff22c7,2020-08-04T06:59:21Z,https://github.com/huggingface/transformers/commit/6730ecdd3c92f068ddb598812c90baddd4ff22c7,Remove redundant coverage (#6224),1,Remove Dead Code,,
b6b2f2270fe6c32852fc1b887afe354b7b79d18c,2020-08-03T14:36:26Z,https://github.com/huggingface/transformers/commit/b6b2f2270fe6c32852fc1b887afe354b7b79d18c,"s2s: fix LR logging, remove some dead code. (#6205)",1,Remove Dead Code,,
e642c7890875974963db09c09a393f9fbf65b48a,2020-07-30T18:11:39Z,https://github.com/huggingface/transformers/commit/e642c7890875974963db09c09a393f9fbf65b48a,"Addition of a DialoguePipeline (#5516)  * initial commit for pipeline implementation  Addition of input processing and history concatenation  * Conversation pipeline tested and working for single & multiple conversation inputs  * Added docstrings for dialogue pipeline  * Addition of dialogue pipeline integration tests  * Delete test_t5.py  * Fixed max code length  * Updated styling  * Fixed test broken by formatting tools  * Removed unused import  * Added unit test for DialoguePipeline  * Fixed Tensorflow compatibility  * Fixed multi-framework support using framework flag  * - Fixed docstring - Added `min_length_for_response` as an initialization parameter - Renamed `*args` to `conversations`, `conversations` being a `Conversation` or a `List[Conversation]` - Updated truncation to truncate entire segments of conversations, instead of cutting in the middle of a user/bot input  * - renamed pipeline name from dialogue to conversational - removed hardcoded default value of 1000 and use config.max_length instead - added `append_response` and `set_history` method to the Conversation class to avoid direct fields mutation - fixed bug in history truncation method  * - Updated ConversationalPipeline to accept only active conversations (otherwise a ValueError is raised)  * - Simplified input tensor conversion  * - Updated attention_mask value for Tensorflow compatibility  * - Updated last dialogue reference to conversational & fixed integration tests  * Fixed conflict with master  * Updates following review comments  * Updated formatting  * Added Conversation and ConversationalPipeline to the library __init__, addition of docstrings for Conversation, added both to the docs  * Update src/transformers/pipelines.py  Updated docsting following review  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>",1,Remove Dead Code,,
896300177bf9f35feac4698370212a80a5ab6138,2020-07-22T14:11:57Z,https://github.com/huggingface/transformers/commit/896300177bf9f35feac4698370212a80a5ab6138,Expose padding_strategy on squad processor to fix QA pipeline performance regression (#5932)  * Attempt to fix the way squad_convert_examples_to_features pad the elements for the QA pipeline.  Signed-off-by: Morgan Funtowicz <funtowiczmo@gmail.com>  * Quality  Signed-off-by: Morgan Funtowicz <funtowiczmo@gmail.com>  * Make the code easier to read and avoid testing multiple test the same thing.  Signed-off-by: Morgan Funtowicz <funtowiczmo@gmail.com>  * missing enum value on truncation_strategy.  Signed-off-by: Morgan Funtowicz <funtowiczmo@gmail.com>  * Rethinking for the easiest fix: expose the padding strategy on squad_convert_examples_to_features.  Signed-off-by: Morgan Funtowicz <funtowiczmo@gmail.com>  * Remove unused imports.  Signed-off-by: Morgan Funtowicz <funtowiczmo@gmail.com>,1,Remove Dead Code,,
d4886173b26d772b34afe20efa029b54a0f356a0,2020-07-07T14:06:48Z,https://github.com/huggingface/transformers/commit/d4886173b26d772b34afe20efa029b54a0f356a0,"[Bart] enable test_torchscript, update test_tie_weights (#5457)  * Passing all but one torchscript test  * Style  * move comment  * remove unneeded assert",1,Remove Dead Code,,
514410407019e9d20de7c2555595bab145c39ac0,2020-06-23T03:39:04Z,https://github.com/huggingface/transformers/commit/514410407019e9d20de7c2555595bab145c39ac0,[fix] remove unused import (#5206),1,Remove Dead Code,,
2db1e2f415ec276f02e16a463e79d42cac955295,2020-06-19T00:34:48Z,https://github.com/huggingface/transformers/commit/2db1e2f415ec276f02e16a463e79d42cac955295,[cleanup] remove redundant code in SummarizationDataset (#5119),1,Remove Dead Code,,
e8db8b845a971b0cf63a0896b9deb5b316028a8b,2020-06-10T00:05:09Z,https://github.com/huggingface/transformers/commit/e8db8b845a971b0cf63a0896b9deb5b316028a8b,Remove unused arguments in Multiple Choice example (#4853)  * Remove unused arguments  * Formatting  * Remove second todo comment,1,Remove Dead Code,,
3723f30a1867d9ed26a9a10c3fe494c00cf56a0c,2020-06-05T18:57:24Z,https://github.com/huggingface/transformers/commit/3723f30a1867d9ed26a9a10c3fe494c00cf56a0c,[cleanup] MarianTokenizer: delete unused constants (#4802),1,Remove Dead Code,,
48a05026def1e94ae08037a252472c030409857e,2020-06-04T22:07:49Z,https://github.com/huggingface/transformers/commit/48a05026def1e94ae08037a252472c030409857e,removed deprecared use of Variable api from pplm example,1,Remove Dead Code,,
2b8b6c929e282958a920ba2aa26ee59106986ec3,2020-06-04T12:13:52Z,https://github.com/huggingface/transformers/commit/2b8b6c929e282958a920ba2aa26ee59106986ec3,[cleanup] PretrainedModel.generate: remove unused kwargs (#4761),1,Remove Dead Code,,
15550ce0d18457e1b62634d0803c4cce835da417,2020-05-15T21:08:38Z,https://github.com/huggingface/transformers/commit/15550ce0d18457e1b62634d0803c4cce835da417,[skip ci] remove local rank,1,Remove Dead Code,,
e73595bd649a149879816a59b56f57c8b37c73d0,2020-04-29T13:53:19Z,https://github.com/huggingface/transformers/commit/e73595bd649a149879816a59b56f57c8b37c73d0,Remove jitted method so that our models are pickable. (#4050),1,Remove Dead Code,,
c4158a63141261ae51126990d6006f1c521ebc17,2020-04-20T18:39:16Z,https://github.com/huggingface/transformers/commit/c4158a63141261ae51126990d6006f1c521ebc17,[Pipelines] Encode to max length of input not max length of tokenizer for batch input (#3857)  * remove max_length = tokenizer.max_length when encoding  * make style,1,Remove Dead Code,,
baca8fa8e6ed6bf6855faea4bc421c9cc11d8c9d,2020-04-16T14:21:34Z,https://github.com/huggingface/transformers/commit/baca8fa8e6ed6bf6855faea4bc421c9cc11d8c9d,clean pipelines (#3795),1,Remove Dead Code,,
dbd041243d3c6827ae3dfad5e53619ee7838853c,2020-04-16T13:55:25Z,https://github.com/huggingface/transformers/commit/dbd041243d3c6827ae3dfad5e53619ee7838853c,"[cleanup] factor out get_head_mask, invert_attn_mask, get_exten?(#3806)  * Delete some copy pasted code",1,Remove Dead Code,,
8becb732931bbab5dd75cca5f5e7c75b2516d10b,2020-03-19T22:25:30Z,https://github.com/huggingface/transformers/commit/8becb732931bbab5dd75cca5f5e7c75b2516d10b,removing torch.cuda.empty_cache() from TF function (#3267)  torch.cuda.empty_cache() was being called from a TF function (even when torch is unavailable) not sure any replacement is needed if TF OOMs,1,Remove Dead Code,,
cf0629056509d72c2664247d364044af8040fde4,2020-03-11T10:06:56Z,https://github.com/huggingface/transformers/commit/cf0629056509d72c2664247d364044af8040fde4,remove ipdb,1,Remove Dead Code,,
4220fd52b92cd96da6ac461c8b6e99912dca8dfc,2020-03-05T12:36:21Z,https://github.com/huggingface/transformers/commit/4220fd52b92cd96da6ac461c8b6e99912dca8dfc,remove ipdb,1,Remove Dead Code,,
564fd75d65e66d3ac2a7c39558aa1079c9845152,2020-02-20T21:08:21Z,https://github.com/huggingface/transformers/commit/564fd75d65e66d3ac2a7c39558aa1079c9845152,Removed unused fields in DistilBert TransformerBlock (#2710)  * Removed unused fields in DistilBert TransformerBlock,1,Remove Dead Code,,
90ab15cb7a8fcf8bf58c05453ddf1aa6a4fa00c1,2020-02-04T15:59:32Z,https://github.com/huggingface/transformers/commit/90ab15cb7a8fcf8bf58c05453ddf1aa6a4fa00c1,Remove redundant hidden states,1,Remove Dead Code,,
adb8c93134f02fd0eac2b52189364af21977004c,2020-01-29T19:01:16Z,https://github.com/huggingface/transformers/commit/adb8c93134f02fd0eac2b52189364af21977004c,Remove lines causing a KeyError,1,Remove Dead Code,,
7bb42712916d2f82ada62a4195fd70a7c28b94de,2019-12-25T22:17:24Z,https://github.com/huggingface/transformers/commit/7bb42712916d2f82ada62a4195fd70a7c28b94de,remove ipdb debugging statements,1,Remove Dead Code,,
e6c0019c80d03b86e7fc051a9c51c55d9a4e7ba7,2019-12-23T21:38:18Z,https://github.com/huggingface/transformers/commit/e6c0019c80d03b86e7fc051a9c51c55d9a4e7ba7,Remove unused variables in tests.,1,Remove Dead Code,,
495580dad193b7a8405b717b60089574de6563c7,2019-12-23T21:38:18Z,https://github.com/huggingface/transformers/commit/495580dad193b7a8405b717b60089574de6563c7,Remove unused variables in templates.,1,Remove Dead Code,,
71f94a8a1c89577ec4482b3e5600fbcdfb3dd1a8,2019-12-23T21:38:09Z,https://github.com/huggingface/transformers/commit/71f94a8a1c89577ec4482b3e5600fbcdfb3dd1a8,Remove unused variables in src.,1,Remove Dead Code,,
81422c4e6d213767dc075f20049e8fd201675029,2019-12-23T21:29:02Z,https://github.com/huggingface/transformers/commit/81422c4e6d213767dc075f20049e8fd201675029,Remove unused variables in examples.,1,Remove Dead Code,,
75a23d24af359288f305e207dd84c7013d198f4a,2019-12-22T17:38:56Z,https://github.com/huggingface/transformers/commit/75a23d24af359288f305e207dd84c7013d198f4a,Remove import fallbacks.,1,Remove Dead Code,,
798b3b3899e786273ff280b3bffc332749cff348,2019-12-22T17:38:42Z,https://github.com/huggingface/transformers/commit/798b3b3899e786273ff280b3bffc332749cff348,Remove sys.version_info[0] == 2 or 3.,1,Remove Dead Code,,
8af25b166486ec0cedbd2ef9147c3700dba88e0b,2019-12-22T16:56:09Z,https://github.com/huggingface/transformers/commit/8af25b166486ec0cedbd2ef9147c3700dba88e0b,Remove six.,1,Remove Dead Code,,
c824d15aa1590ddb5d2fc977a8a1009a4b1d7262,2019-12-22T16:47:54Z,https://github.com/huggingface/transformers/commit/c824d15aa1590ddb5d2fc977a8a1009a4b1d7262,Remove __future__ imports.,1,Remove Dead Code,,
daf8bebcddb9cbef356e92c628cd9ca1a9e89923,2019-12-22T14:35:25Z,https://github.com/huggingface/transformers/commit/daf8bebcddb9cbef356e92c628cd9ca1a9e89923,Remove unused GPTModelTester.  It isn't imported anywhere.,1,Remove Dead Code,,
7e98e211f0e86e414b22946bd89391e49d2ea900,2019-12-22T13:42:03Z,https://github.com/huggingface/transformers/commit/7e98e211f0e86e414b22946bd89391e49d2ea900,"Remove unittest.main() in test modules.  This construct isn't used anymore these days.  Running python tests/test_foo.py puts the tests/ directory on PYTHONPATH, which isn't representative of how we run tests.  Use python -m unittest tests/test_foo.py instead.",1,Remove Dead Code,,
655fd068534b2a66b85f0bd05002e27f212ab6a0,2019-12-20T20:57:49Z,https://github.com/huggingface/transformers/commit/655fd068534b2a66b85f0bd05002e27f212ab6a0,clean up,1,Remove Dead Code,,
e5812462fc0f81e9808ad87a818cd8af26405722,2019-12-20T20:51:48Z,https://github.com/huggingface/transformers/commit/e5812462fc0f81e9808ad87a818cd8af26405722,clean up debug and less verbose tqdm,1,Remove Dead Code,,
641a8decdc6c34ce1837c9602fe84a65ec5b741a,2019-12-18T09:43:48Z,https://github.com/huggingface/transformers/commit/641a8decdc6c34ce1837c9602fe84a65ec5b741a,clean up code and add arbitrary number of return sequences,1,Remove Dead Code,,
77d397202ba3daa013c94696e9825de8e20145e8,2019-12-17T22:28:46Z,https://github.com/huggingface/transformers/commit/77d397202ba3daa013c94696e9825de8e20145e8,clean up dead code,1,Remove Dead Code,,
8938b546bf5f61dcb65fb6dd72b5b924f773c46a,2019-12-13T13:27:04Z,https://github.com/huggingface/transformers/commit/8938b546bf5f61dcb65fb6dd72b5b924f773c46a,Removed from_config,1,Remove Dead Code,,
0cb163865a4c761c226b151283309eedb2b1ca4d,2019-12-07T12:46:14Z,https://github.com/huggingface/transformers/commit/0cb163865a4c761c226b151283309eedb2b1ca4d,Remove pytest dependency. (#2093),1,Remove Dead Code,,
9ecd83dace3961eaa161405814b00ea595c86451,2019-12-05T19:44:57Z,https://github.com/huggingface/transformers/commit/9ecd83dace3961eaa161405814b00ea595c86451,Patch evaluation for impossible values + cleanup,1,Remove Dead Code,,
bebaa140398830ea8738234afd8f11f986ca6acf,2019-12-05T13:41:56Z,https://github.com/huggingface/transformers/commit/bebaa140398830ea8738234afd8f11f986ca6acf,Merge pull request #2045 from aaugustin/remove-dead-code  Remove dead code in tests.,1,Remove Dead Code,,
40255ab00207f343d5e913c616c20f0f79504bfe,2019-12-04T07:21:02Z,https://github.com/huggingface/transformers/commit/40255ab00207f343d5e913c616c20f0f79504bfe,Remove dead code in tests.,1,Remove Dead Code,,
d47402263964e30ee17cbc06811622bf2df50d6d,2019-11-27T16:07:22Z,https://github.com/huggingface/transformers/commit/d47402263964e30ee17cbc06811622bf2df50d6d,cleaning simple_accuracy since not used anymore,1,Remove Dead Code,,
c110c41fdb3b363528336ceda3b9fb46f026ad9c,2019-11-26T18:08:12Z,https://github.com/huggingface/transformers/commit/c110c41fdb3b363528336ceda3b9fb46f026ad9c,Run GLUE and remove LAMB,1,Remove Dead Code,,
33c01368b19701bc6e5ea886f108663752d31d86,2019-10-16T16:13:05Z,https://github.com/huggingface/transformers/commit/33c01368b19701bc6e5ea886f108663752d31d86,remove Bert2Rnd test,1,Remove Dead Code,,
8aa3b753bd0050e84b698cb3a56a6e7eb3fad0e5,2019-10-15T07:44:19Z,https://github.com/huggingface/transformers/commit/8aa3b753bd0050e84b698cb3a56a6e7eb3fad0e5,Merge pull request #1434 from bryant1410/patch-1  Remove unnecessary use of FusedLayerNorm in XLNet,1,Remove Dead Code,,
81ee29ee8d64c292c3fd5fc7e13b387acd1bfc39,2019-10-10T12:13:37Z,https://github.com/huggingface/transformers/commit/81ee29ee8d64c292c3fd5fc7e13b387acd1bfc39,remove the staticmethod used to load the config,1,Remove Dead Code,,
edfc8f822557f3df7d9057a6457a933cddf15299,2019-10-10T08:17:27Z,https://github.com/huggingface/transformers/commit/edfc8f822557f3df7d9057a6457a933cddf15299,Remove  and do the branching in,1,Remove Dead Code,,
09cfd122353347da7a62eb4f5af75d83b955684f,2019-10-10T08:15:27Z,https://github.com/huggingface/transformers/commit/09cfd122353347da7a62eb4f5af75d83b955684f,remove  and do the branching in,1,Remove Dead Code,,
a95158518d65fe640ecb35813280609e27ba3ab7,2019-10-02T06:44:15Z,https://github.com/huggingface/transformers/commit/a95158518d65fe640ecb35813280609e27ba3ab7,Moved duplicate token check,1,Remove Dead Code,,
2f071fcb022094cdf05a59332c47468c24cf5ee8,2019-09-26T08:09:45Z,https://github.com/huggingface/transformers/commit/2f071fcb022094cdf05a59332c47468c24cf5ee8,clean up TFConv1D API,1,Remove Dead Code,,
4a233e5b2c18f0cf508f6b917cd1e02954764699,2019-09-26T06:50:02Z,https://github.com/huggingface/transformers/commit/4a233e5b2c18f0cf508f6b917cd1e02954764699,Merge pull request #1315 from bryant1410/patch-1  Remove unnecessary use of FusedLayerNorm,1,Remove Dead Code,,
98dd19b96b351f481e1268ab6c7b035bb21d106e,2019-09-23T00:31:36Z,https://github.com/huggingface/transformers/commit/98dd19b96b351f481e1268ab6c7b035bb21d106e,Remove unnecessary use of FusedLayerNorm,1,Remove Dead Code,,
69bff89935a74cf429bd482543cf206c9c27be2f,2019-09-08T12:02:06Z,https://github.com/huggingface/transformers/commit/69bff89935a74cf429bd482543cf206c9c27be2f,clean ups,1,Remove Dead Code,,
d77abd4d08fa4b38b7d3fc7dfe970875eeaaa870,2019-09-04T22:41:24Z,https://github.com/huggingface/transformers/commit/d77abd4d08fa4b38b7d3fc7dfe970875eeaaa870,clean ups,1,Remove Dead Code,,
0b524b084857d0bf54eb613304a61bcdbd71e6fb,2019-08-05T17:08:19Z,https://github.com/huggingface/transformers/commit/0b524b084857d0bf54eb613304a61bcdbd71e6fb,remove derived classes for now,1,Remove Dead Code,,
4fb56c7729a2e08287476d9ae9fe74e9f8ef4f0a,2019-07-23T14:43:01Z,https://github.com/huggingface/transformers/commit/4fb56c7729a2e08287476d9ae9fe74e9f8ef4f0a,Remove unused *args parameter from PreTrainedConfig.from_pretrained,1,Remove Dead Code,,
74a24f0fe96d3ca19157171e333cfcc2ab4707c5,2019-07-15T11:49:01Z,https://github.com/huggingface/transformers/commit/74a24f0fe96d3ca19157171e333cfcc2ab4707c5,clean up file_utils,1,Remove Dead Code,,
56a47ce2b78cb4b5cb5bb8b1f18b0148f2a4fbef,2019-04-25T14:05:28Z,https://github.com/huggingface/transformers/commit/56a47ce2b78cb4b5cb5bb8b1f18b0148f2a4fbef,#NAME?,1,Remove Dead Code,,
34ae5bf8385cce8f792c803fa288eccf472003ff,2019-04-17T12:52:12Z,https://github.com/huggingface/transformers/commit/34ae5bf8385cce8f792c803fa288eccf472003ff,small clean up in tests,1,Remove Dead Code,,
f19ba35b2b6192dd55e4e6f974bcec5b8d3f8865,2019-03-20T16:47:06Z,https://github.com/huggingface/transformers/commit/f19ba35b2b6192dd55e4e6f974bcec5b8d3f8865,Move old finetuning script into the new folder,1,Remove Dead Code,,
eecaaa734ad6f2ef35355aa6e2f468fd6ff8d4f6,2019-03-14T08:03:32Z,https://github.com/huggingface/transformers/commit/eecaaa734ad6f2ef35355aa6e2f468fd6ff8d4f6,"Merge pull request #371 from yongbowin/patch-1  Simplify code, delete redundancy line",1,Remove Dead Code,,
22a465a91fb4f3708c8c9437db8765e38fad8ae0,2019-03-13T01:42:06Z,https://github.com/huggingface/transformers/commit/22a465a91fb4f3708c8c9437db8765e38fad8ae0,"Simplify code, delete redundancy line  delete redundancy line `if args.train`, simplify code.",1,Remove Dead Code,,
c9fd3505678d581388fb44ba1d79ac41e8fb28a4,2019-01-07T12:01:54Z,https://github.com/huggingface/transformers/commit/c9fd3505678d581388fb44ba1d79ac41e8fb28a4,remove default when action is store_true in arguments,1,Remove Dead Code,,
32167cdf4bd3ad30c7dde0d857243d8f9396bb65,2018-11-26T22:33:22Z,https://github.com/huggingface/transformers/commit/32167cdf4bd3ad30c7dde0d857243d8f9396bb65,remove convert_to_unicode and printable_text from examples,1,Remove Dead Code,,
9e95cd8cd610323327a981f8fd24a19677cccf22,2018-11-09T10:23:55Z,https://github.com/huggingface/transformers/commit/9e95cd8cd610323327a981f8fd24a19677cccf22,clean up optimizer from unused functions,1,Remove Dead Code,,
c6207d85b608fc6d5182a4e05c0a9e5f5e468f92,2018-11-04T14:34:00Z,https://github.com/huggingface/transformers/commit/c6207d85b608fc6d5182a4e05c0a9e5f5e468f92,remove old methods,1,Remove Dead Code,,
e128245e8c8fd7f79d55ca9192399e3772d758a7,2017-06-29T00:22:45Z,https://github.com/pytorch/pytorch/commit/e128245e8c8fd7f79d55ca9192399e3772d758a7,Move memonger graph equality into memongerSummary: Lets try this again. Verify graphs every time memonger is run. Will definitely check for time though.Reviewed By: akyrolaDifferential Revision: D5308188fbshipit-source-id: 512a76c759b670d31c49d1d492dd8ee1eaf3bafd,1,Remove Assertion,,
77e73b9b7a423633873afb8821fd3cb9ef99d584,2023-03-21T18:51:35Z,https://github.com/pytorch/pytorch/commit/77e73b9b7a423633873afb8821fd3cb9ef99d584,"Refactor NT offsets metadata to be a Tensor (#96909)  It's tedious work, but somebody's gotta do it.  Benefits: * Enable access to offsets metadata from Python via private API (for validation, etc.) * Consistency with nested sizes / strides metadata * Needed for SymInt-ifying offsets metadata * more TBD  Bonus: * Remove `_tensor` suffixes from metadata / getter names Pull Request resolved: https://github.com/pytorch/pytorch/pull/96909 Approved by: https://github.com/drisspg",1,Refactor Data Structure,,
523e24e8acf8ecc6d6b31e78cdc6e4c3967bbbdb,2016-02-08T06:34:24Z,https://github.com/keras-team/keras/commit/523e24e8acf8ecc6d6b31e78cdc6e4c3967bbbdb,Simplify Theano RNN when no mask is passed,1,Push Down Method,,
30a18fe3189d7c619641cf84a4d55e89834a08ff,2021-06-12T13:58:34Z,https://github.com/pytorch/pytorch/commit/30a18fe3189d7c619641cf84a4d55e89834a08ff,"refactor yaml loader import, no runtime change (#59850)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/59850  This whole stack does not change anything to the codegened code  Test Plan: Imported from OSS  Reviewed By: ailzhang  Differential Revision: D29063816  Pulled By: albanD  fbshipit-source-id: ca3067443d8e6282c1077d3dafa3b4f330d43b28",1,Push Down Method,,
83892c1861052240891924ccbab42f82d0835dfd,2021-06-01T20:26:09Z,https://github.com/pytorch/pytorch/commit/83892c1861052240891924ccbab42f82d0835dfd,[quant][graphmode][fx][refactor] Remove node_name_to_scope from Quantizer (#59032)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/59032  To remove Quantizer class and split prepare and convert functions to different files  Test Plan: python test/test_quantization.py TestQuantizeFx python test/test_quantization.py TestQuantizeFxOps  Imported from OSS  Reviewed By: vkuzo  Differential Revision: D28724868  fbshipit-source-id: 6df639f20076b480812b6dcf0fc7d2c87ca29d8b,1,Pull Up Variable,,
8cab7994a6e92b9b37e324be493c04e4660dc330,2023-05-23T03:59:55Z,https://github.com/pytorch/pytorch/commit/8cab7994a6e92b9b37e324be493c04e4660dc330,"[inductor] Move cpp wrapper dynamic shapes test to test_cpp_wrapper (#102017)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/102017 Approved by: https://github.com/ngimel, https://github.com/jansel",1,Pull Up Variable,,
e1551f16786e9898a8d7381dc43272dc21ccbfed,2021-05-18T19:50:00Z,https://github.com/pytorch/pytorch/commit/e1551f16786e9898a8d7381dc43272dc21ccbfed,"Clarify .github/scripts/generate_ci_workflows.py (#58498)  Summary: Followup to https://github.com/pytorch/pytorch/issues/58491:  - use f-string to remove the literal `generated` string from the generator script, so Phabricator no longer thinks it is a generated file - remove the special logic for `test_runner_type` and instead explicitly specify for every workflow  Pull Request resolved: https://github.com/pytorch/pytorch/pull/58498  Test Plan: ``` make generate-gha-workflows ``` Also, check that Phabricator doesn't classify `.github/scripts/generate_ci_workflows.py` as ""Generated changes"" in this diff.  Reviewed By: seemethere  Differential Revision: D28516291  Pulled By: samestep  fbshipit-source-id: 8736eaad5d28082490be0a9b2e271c9493c2ba9d",1,Pull Up Variable,,
e4b26843314b654f547389e448dbb2ebce7a2cdc,2021-06-01T20:44:08Z,https://github.com/pytorch/pytorch/commit/e4b26843314b654f547389e448dbb2ebce7a2cdc,[quant][graphmode][fx][refactor] Remove patterns from Quantizer class (#59033)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/59033  To remove Quantizer class and split prepare and convert functions to different files  Test Plan: python test/test_quantization.py TestQuantizeFx python test/test_quantization.py TestQuantizeFxOps  Imported from OSS  Reviewed By: vkuzo  Differential Revision: D28724861  fbshipit-source-id: 97b38e851b6bf581510a24636b1d8d6f1d977f5a,1,Pull Up Variable,,
979c5b4cf808d0825182ed28b05b0ed3aeba4818,2023-04-14T02:15:53Z,https://github.com/pytorch/pytorch/commit/979c5b4cf808d0825182ed28b05b0ed3aeba4818,"Move torchdynamo start tracing message earlier (#98990)  Currently, it lives inside run(), but this is too late; we do a lot of work initializing OutputGraph and those log messages will show up before ""start tracing"".  This is bad. Now the start of tracing is InstructionTranslator construction, which ensures we catch these sites.  Signed-off-by: Edward Z. Yang <ezyang@meta.com>  Pull Request resolved: https://github.com/pytorch/pytorch/pull/98990 Approved by: https://github.com/yanboliang",1,Pull Up Statement,,
2fc98ba7baf0118a25ff746ceebafe25343fe918,2022-02-23T02:03:47Z,https://github.com/keras-team/keras/commit/2fc98ba7baf0118a25ff746ceebafe25343fe918,"Refactor the RandomCrop logic for the boolean ""training"" flag handling.  In tf2, the training flag should always be python boolean.  PiperOrigin-RevId: 430336909",1,Pull Up Method,Move Statement,
2265d6359422275fc874b8f19b2c55638e24a0f0,2021-11-06T02:31:28Z,https://github.com/keras-team/keras/commit/2265d6359422275fc874b8f19b2c55638e24a0f0,Keras IoU  Modify `IoU` to return the mean of IoUs of the target classes instead of the list of values.  Simplify `MeanIoU` to inherit `IoU` where `target_class_ids` is generated from `num_classes`.  PiperOrigin-RevId: 407964551,1,Pull Up Method,,
bda64d14739f4d232cea179212189f62ba988df0,2021-11-02T16:55:49Z,https://github.com/keras-team/keras/commit/bda64d14739f4d232cea179212189f62ba988df0,Keras IoU Metrics.  1. Refactor `MeanIoU` to inherit `_IoUBase` which only updates the confusion matrix and can be used as the base class for several `IoU` metrics.  2. Implement `IoU`.  PiperOrigin-RevId: 407109259,1,Pull Up Method,,
adfec1e8440b3af64b642ea75bdb21bbee70cc80,2018-09-20T19:16:45Z,https://github.com/keras-team/keras/commit/adfec1e8440b3af64b642ea75bdb21bbee70cc80,Refactoring: Added a data_generator to the test_utils.py. (#11153)  * Refactoring: Added a data_generator to the test_utils.py.  * Fixed an issue with multiple inputs test.  * Made the change on only one file.,1,Pull Up Method,,
7da1523053f2e5f4fa15c87e019b3244c8653a53,2015-12-10T04:41:02Z,https://github.com/keras-team/keras/commit/7da1523053f2e5f4fa15c87e019b3244c8653a53,Replace unittest with pytest,1,Pull Up Method,,
1d37f415671976c36f6bf3fa4b83384db066fc2f,2021-06-02T01:01:22Z,https://github.com/pytorch/pytorch/commit/1d37f415671976c36f6bf3fa4b83384db066fc2f,[quant][graphmode][fx][refactor] Remove _prepare from Quantizer class (#59038)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/59038  To remove Quantizer class and split prepare and convert functions to different files  Test Plan: python test/test_quantization.py TestQuantizeFx python test/test_quantization.py TestQuantizeFxOps  Imported from OSS  Reviewed By: vkuzo  Differential Revision: D28724869  fbshipit-source-id: e8501c9720b5ddb654e78bc8fa08de0466c1d52b,1,Pull Up Method,,
46484e8dfe5213f91b9142aadb97e72cb1255c31,2021-05-18T18:49:51Z,https://github.com/pytorch/pytorch/commit/46484e8dfe5213f91b9142aadb97e72cb1255c31,"Simplify .github/scripts/generate_ci_workflows.py (#58491)  Summary: This PR simplifies `.github/scripts/generate_ci_workflows.py` by using the same strategy as https://github.com/pytorch/pytorch/issues/54344, representing workflows as plain data to avoid duplicating the definition of the `generate_workflow_file` function. This will make the script easier to maintain if/when that function is modified and/or more workflow types are added.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/58491  Test Plan: The Lint job in CI; specifically: ``` make generate-gha-workflows mypy --config mypy-strict.ini ```  Reviewed By: malfet, seemethere  Differential Revision: D28511918  Pulled By: samestep  fbshipit-source-id: aaf415a954d938a29aee7c9367c9bc2b9f44bb01",1,Pull Up Method,,
7d64fc675bab1d86c94db3ce00eb66864de55882,2021-06-01T22:52:57Z,https://github.com/pytorch/pytorch/commit/7d64fc675bab1d86c94db3ce00eb66864de55882,[quant][graphmode][fx][refactor] Remove fold_weights from Quantizer class (#59036)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/59036  To remove Quantizer class and split prepare and convert functions to different files  Test Plan: python test/test_quantization.py TestQuantizeFx python test/test_quantization.py TestQuantizeFxOps  Imported from OSS  Reviewed By: vkuzo  Differential Revision: D28724862  fbshipit-source-id: 5900420127fcc14846bc34c9ac29ff7e6a703f1e,1,Pull Up Method,,
bb85b43c0b9fec21909bdf761ded929b3edbe9d3,2023-03-28T14:08:51Z,https://github.com/pytorch/pytorch/commit/bb85b43c0b9fec21909bdf761ded929b3edbe9d3,"Move test_cpp_wrapper to its own file (#97634)  This test takes 5+ minutes to finish, this breaks it into smaller pieces.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/97634 Approved by: https://github.com/eellison",1,Pull Up Method,,
cc4891804cdc1026c05626c856a7dc4b1474a05e,2021-06-01T22:38:36Z,https://github.com/pytorch/pytorch/commit/cc4891804cdc1026c05626c856a7dc4b1474a05e,[quant][graphmode][fx][refactor] Remove save_state and restore_state from Quantizer class (#59035)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/59035  To remove Quantizer class and split prepare and convert functions to different files  Test Plan: python test/test_quantization.py TestQuantizeFx python test/test_quantization.py TestQuantizeFxOps  Imported from OSS  Reviewed By: vkuzo  Differential Revision: D28724872  fbshipit-source-id: d32752c635917c9820e5e7cc414ba9d48a258a19,1,Pull Up Method,,
fe4fec37a4e6f7b1f1b2536cbc5bc66add641d86,2023-03-07T02:23:06Z,https://github.com/pytorch/pytorch/commit/fe4fec37a4e6f7b1f1b2536cbc5bc66add641d86,[inductor] Refactor IR printing (#96024)  Reland #95567 part 2.  The previous version of this had a bug which that added test triggers.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/96024 Approved by: https://github.com/ngimel,1,Pull Up Method,,
de16d939696323002ec5abb57be6b2347fdcd97f,2022-12-28T13:16:50Z,https://github.com/scikit-learn/scikit-learn/commit/de16d939696323002ec5abb57be6b2347fdcd97f,MAINT Refactors __reduce__ to parent splitter (#25199),1,Pull Up Method,,
73e887b5c7ff4221637f947d5fa75c7eb3b7603d,2023-05-20T00:47:04Z,https://github.com/pytorch/pytorch/commit/73e887b5c7ff4221637f947d5fa75c7eb3b7603d,[easy] refactor signature flattening transform (#101886)  Move `ChangeInputOutputSignature` out of export function to avoid closed over variables that make dependencies hard to understand. Also rename it while we're at it.  Differential Revision: [D46029076](https://our.internmc.facebook.com/intern/diff/D46029076/)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/101886 Approved by: https://github.com/tugsbayasgalan,1,Pull Up Class,,
e00e42dbab11138434462d3e867fef3d72214875,2021-03-01T22:04:06Z,https://github.com/pytorch/pytorch/commit/e00e42dbab11138434462d3e867fef3d72214875,[reland][quant][graphmode][fx][test][refactor] Refactoring binary op tests to split int8 and float16 tests (#52807) (#53020)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/53020Test Plan:Imported from OSSImported from OSSReviewed By: vkuzoDifferential Revision: D26725351fbshipit-source-id: 35086ab19087501e1c9fdef4f16993ee9f364d0d,1,Pull Up Class,,
cbcde79023d2de1206376f038908669f39a359a6,2021-04-02T16:31:08Z,https://github.com/pytorch/pytorch/commit/cbcde79023d2de1206376f038908669f39a359a6,"ns for fx: refactor test cases (#54280)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/54280Some easy refactors to reduce duplicate logic in test casesfor NS for FX. In particular, we start reusing a common modelwithin this file, and we split the fp16 test cases to be moremodular.Test Plan:```python test/test_quantization.py TestFXGraphMatcherpython test/test_quantization.py TestFXNumericSuiteCoreAPIs```Imported from OSSReviewed By: hx89Differential Revision: D27173373fbshipit-source-id: cf3f21ee8b9b12dff89f1cd2d3ac1749f3f63fe6",1,Pull Up Class,Rename Class,
bd968bf156b4346ac58e679ccd92f02796294885,2021-04-28T02:54:38Z,https://github.com/keras-team/keras/commit/bd968bf156b4346ac58e679ccd92f02796294885,"Export legacy tf.layers code to keras.__internal__.legacy.layers.  The intension for this change is to export those endpoints into internal keras API, which then be exported as tf.layers when keras code is moved out of tf. We won't be able to access those API in the __init__ file if they are not exposed as Keras API.  PiperOrigin-RevId: 370814983",1,Namespace Refactoring,,
1e2a941351cfa2e324b1dcef2d9e695707f1a220,2020-06-12T17:52:27Z,https://github.com/tensorflow/tensorflow/commit/1e2a941351cfa2e324b1dcef2d9e695707f1a220,Move 'enabled' from _pywrap_traceme to tracePiperOrigin-RevId: 316134360Change-Id: I256ea280e7ddcd2df3853a943082ff63a52dfffa,1,Move Variable,,
1aa61f86eef01fd1db124ccb55f49dd914540e96,2019-09-18T10:35:49Z,https://github.com/tensorflow/tensorflow/commit/1aa61f86eef01fd1db124ccb55f49dd914540e96,Moved summary_ attributes out of Context into summary_ops_v2The summary state does not depend on the rest of the context and isonly used by summary_ops_v2.PiperOrigin-RevId: 269769173,1,Move Variable,,
81e91f29ea4862f7a3c08aa18002c217e5ef583a,2019-07-13T01:23:13Z,https://github.com/tensorflow/tensorflow/commit/81e91f29ea4862f7a3c08aa18002c217e5ef583a,Move the common attributes into the TFLiteConverter base class.PiperOrigin-RevId: 257904399,1,Move Variable,,
aa8bbb05ecdeb949105023fe298394e17a7e8162,2019-04-03T00:28:05Z,https://github.com/tensorflow/tensorflow/commit/aa8bbb05ecdeb949105023fe298394e17a7e8162,Move loss and weighted metrics graph compilation into its own function.PiperOrigin-RevId: 241637400,1,Move Variable,,
e9e534f3239d7cb7e2a815b49c1c3520d9566d70,2018-12-14T20:52:22Z,https://github.com/tensorflow/tensorflow/commit/e9e534f3239d7cb7e2a815b49c1c3520d9566d70,"Moved `Variable.constraint` to Keras.* The signatures of `VariableV1` and `variable_scope` were unchanged.* `backend.variable` and `Layer.add_weight` now manually set the  `constraint` attribute instead of passing it to `Variable`.* `ResourceVariable` and `Variable` no longer accepts `constraint`  in the constructor, nor expose it as a @property. This is a  non-backward compatible API change but it only affects  `ResourceVariable` users.PiperOrigin-RevId: 225589244",1,Move Variable,,
d37f771cc5a208cdc88a50a65f491b3c06c9f262,2018-09-29T01:41:31Z,https://github.com/tensorflow/tensorflow/commit/d37f771cc5a208cdc88a50a65f491b3c06c9f262,Move TPU variables to the TPU device in TPUStrategy.PiperOrigin-RevId: 215027511,1,Move Variable,,
7a6af158e972bfef4b23bf6812b5895abcdc5aef,2018-03-12T20:07:12Z,https://github.com/tensorflow/tensorflow/commit/7a6af158e972bfef4b23bf6812b5895abcdc5aef,Move `loss_reduction` argument from `replicate_model_fn` to `TowerOptimizer.PiperOrigin-RevId: 188766477,1,Move Variable,,
a2841a64372dce192c0e16e5d60a6c73adce403b,2018-02-20T18:18:59Z,https://github.com/tensorflow/tensorflow/commit/a2841a64372dce192c0e16e5d60a6c73adce403b,Move variable scope to outside of create_loss,1,Move Variable,,
69ac707731c32b0cb856bf4682aeee73c4391e9e,2018-02-19T04:32:18Z,https://github.com/tensorflow/tensorflow/commit/69ac707731c32b0cb856bf4682aeee73c4391e9e,"1. Moved estimator._device_fn to RunConfig as @property2. Made RunConfig.device_fn to return custom device function if one is specified, otherwise the result from `tf.train.replica_device_setter` call is used3. Added some basic unit tests, may need further tests.",1,Move Variable,,
8854fe4ee3e3ce724418aee9e4420de391b9408d,2017-08-17T20:56:35Z,https://github.com/tensorflow/tensorflow/commit/8854fe4ee3e3ce724418aee9e4420de391b9408d,Move shard_dimensions from tpu_config to TPUEstimator constructor.PiperOrigin-RevId: 165624831,1,Move Variable,,
4c77351ce66fae58ebfd9d0223366dfb44592e2c,2017-02-23T10:40:35Z,https://github.com/tensorflow/tensorflow/commit/4c77351ce66fae58ebfd9d0223366dfb44592e2c,Move constant definition inside KMeansClustering class so they can be used with no extra imports.This will allow users to skip the import of the (implementation) module of clustering_ops.Change: 148324266,1,Move Variable,,
5e18fb0fdc92c22509c051a9b127f5cdc69c88d2,2016-11-21T20:11:37Z,https://github.com/tensorflow/tensorflow/commit/5e18fb0fdc92c22509c051a9b127f5cdc69c88d2,Remove spurious unpack/shape from fully_connected if not needed.Change: 139815584,1,Move Variable,,
7d0573f0d7b551257dc013a98eaaead5f509c4d0,2016-11-17T19:15:51Z,https://github.com/tensorflow/tensorflow/commit/7d0573f0d7b551257dc013a98eaaead5f509c4d0,Remove spurious unpack/shape from fully_connected if not needed.Change: 139483354,1,Move Variable,,
4807604594d8000b89590c9e8d810f255a48f094,2016-10-28T21:19:42Z,https://github.com/tensorflow/tensorflow/commit/4807604594d8000b89590c9e8d810f255a48f094,Small cleanup.Change: 137552350,1,Move Variable,,
1819a3416c49b40b755399061bb7af85b41f4d09,2016-10-18T16:45:57Z,https://github.com/tensorflow/tensorflow/commit/1819a3416c49b40b755399061bb7af85b41f4d09,Removed default value for save_steps in SummarySaverHook.This way it's possible to pass save_secs alone as argument similarly toCheckpointSaverHook.Change: 136483250,1,Move Variable,,
f933c9956ee54dab78cae9ff83b11c2d09eebd8a,2016-02-22T03:07:30Z,https://github.com/tensorflow/tensorflow/commit/f933c9956ee54dab78cae9ff83b11c2d09eebd8a,Move monitor argument from model specification to fit,1,Move Variable,,
8e5f2292ac5541d7bef5de9d8f56c25ce36ada2b,2022-11-30T19:38:14Z,https://github.com/keras-team/keras/commit/8e5f2292ac5541d7bef5de9d8f56c25ce36ada2b,Moves serialization_lib out of keras/saving/experimental/ to keras/saving/ (no public API change)  PiperOrigin-RevId: 491975319,1,Move Variable,,
4bc0b6d9dcc325e2f85b931f1c593e6f92ab198f,2021-08-31T22:53:05Z,https://github.com/keras-team/keras/commit/4bc0b6d9dcc325e2f85b931f1c593e6f92ab198f,Slightly change the initializer validation logic.  There is no point to redefine a const list in the loop  PiperOrigin-RevId: 394103610,1,Move Variable,,
cbadaf00e28f7fe42762b55f52294e3a7bb90515,2018-05-11T09:04:00Z,https://github.com/keras-team/keras/commit/cbadaf00e28f7fe42762b55f52294e3a7bb90515,"Merge 2 functions together in applications MobileNetV2 (#10163)  * merge 2 functions together  _inverted_res_block() and _first_inverted_res_block() are nearly the same. Merged them into one function 1. skip ""Expand"" part for 0 block 2. made layers names similar to original TF graph names  * added ""mobl_"" to prefix, pep8 fix  * remove dropout parameter  * concise prefix name",1,Move Variable,,
9405be8f838f44cb9cd8924bbf7604de880ada6a,2017-03-26T14:27:09Z,https://github.com/keras-team/keras/commit/9405be8f838f44cb9cd8924bbf7604de880ada6a,refactor local test (#5973),1,Move Variable,,
b93d3b23f51ef282c90dcf924475eb1fcaa4151d,2017-05-04T20:07:26Z,https://github.com/keras-team/keras/commit/b93d3b23f51ef282c90dcf924475eb1fcaa4151d,Moved start/end (#6502),1,Move Variable,,
232530cc28bce864e04ab7af2a43873c37226a3a,2018-02-13T21:44:21Z,https://github.com/pytorch/pytorch/commit/232530cc28bce864e04ab7af2a43873c37226a3a,Move scalar tests from common_nn to legacy_nn. (#5223),1,Move Variable,,
425f173f9d8cb41988ff03fff316ff8424bcd521,2021-09-15T20:15:43Z,https://github.com/pytorch/pytorch/commit/3f27c1ae78ce77299b49c8ee47c5b06d3e768b23,"[quant][refactor] Change the structure of the ao migration tests (#64912)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/64912  The test naming was confusing and ambiguous. The file was changed to reflect the framework that is being migrated (""quantization"" instead of ""quantize""). Also, the common testing class was extracted out ghstack-source-id: 138157450  Test Plan: `buck test mode/dev //caffe2/test:quantization -- TestAOMigrationQuantization`  Reviewed By: vkuzo  Differential Revision: D30898214  fbshipit-source-id: 017f95995271d35bcdf6ff6a1b3974b837543e84",1,Move Variable,,
31d466f9250f7dbb000167ad4d4aa624b9486d62,2023-02-02T00:47:18Z,https://github.com/pytorch/pytorch/commit/31d466f9250f7dbb000167ad4d4aa624b9486d62,[BE][ez] Move hardcoded constants to function args (#93874)  Also use tail-recursion instead of for loop to dismantle pyramid of doom  Pull Request resolved: https://github.com/pytorch/pytorch/pull/93874 Approved by: https://github.com/clee2000,1,Move Variable,,
d9bdddde63247535f0de2890acaa531a423ddca4,2014-10-10T21:42:06Z,https://github.com/scikit-learn/scikit-learn/commit/d9bdddde63247535f0de2890acaa531a423ddca4,COSMIT: Moved epsilon to module level,1,Move Variable,,
6bf4b8e3865480e71f4aa16b6f1b5ffdb8009bae,2013-06-24T06:50:05Z,https://github.com/scikit-learn/scikit-learn/commit/6bf4b8e3865480e71f4aa16b6f1b5ffdb8009bae,COSMIT move deprecated parameter to end  Thanks @agramfort for pointing this out,1,Move Variable,,
5e826d17bbe75cf0954137fe62d54c13e93d66ee,2013-01-11T14:54:58Z,https://github.com/scikit-learn/scikit-learn/commit/5e826d17bbe75cf0954137fe62d54c13e93d66ee,MOD move generating matrix out of the loop,1,Move Variable,,
9cbdad8afb3b291068bdcf194c6675cf127d4933,2012-09-02T21:16:53Z,https://github.com/scikit-learn/scikit-learn/commit/9cbdad8afb3b291068bdcf194c6675cf127d4933,ENH : simplify handle of copy of Gram and X with array2d in OMP,1,Move Variable,,
f74f5f09e0bb0ae8dbdab916542cab59482c259f,2012-09-02T21:16:51Z,https://github.com/scikit-learn/scikit-learn/commit/f74f5f09e0bb0ae8dbdab916542cab59482c259f,ENH: move Gram precomputation outside of the loop,1,Move Variable,,
f4073722f13a8fc730f5659e9729bdd6f80eee56,2011-11-06T10:28:14Z,https://github.com/scikit-learn/scikit-learn/commit/f4073722f13a8fc730f5659e9729bdd6f80eee56,Moved start and finish outside of loop,1,Move Variable,,
14bbe7e43c449610436cfb76ed5cec6bd81d5a56,2011-04-24T10:20:37Z,https://github.com/scikit-learn/scikit-learn/commit/14bbe7e43c449610436cfb76ed5cec6bd81d5a56,"moving some parameters from fit to __init__.  What doesn't change:    n_iter: the tests rely on it     being passed at fit so we can run one iteration at a time     init_params: as __init__ never sees the data, it can't initialize     things, so it makes sense to have this is fit so it can reinitialize     everything if you want to run in different data, but also so you     can skip doing that if you just want to run one iteration at a     time, as in the tests     params: this doesn't seem to need to move, as it also makes sense to     control the fit if we do this iteration-by-iteration  A proposal: I think maybe we should have a public method to do all the initialization that happens in fit and another public method to do all the actual iterating that happens in fit. Then we can have a clean fit(X) and be done with it. What do you think?",1,Move Variable,,
a6c9643ce7a08fd2d387e98225e6ec192f99fa31,2023-05-17T10:25:29Z,https://github.com/huggingface/transformers/commit/a6c9643ce7a08fd2d387e98225e6ec192f99fa31,"Use dict.items to avoid unnecessary lookups. (#23415)  It's more efficient to iterate over key, value dict pairs instead of iterating over keys and performing value lookups on each iteration. It's also more idiomatic.",1,Move Variable,,
994b7a4eea02d493327b08b71b99e2dbd991ce73,2022-10-07T14:54:08Z,https://github.com/huggingface/transformers/commit/994b7a4eea02d493327b08b71b99e2dbd991ce73,update attention mask handling (#19385)  * update feature extractor params  * update attention mask handling,1,Move Variable,,
34fabe1697f653dc0f54ac8f510d6ba5578a1a53,2020-08-12T12:03:45Z,https://github.com/huggingface/transformers/commit/34fabe1697f653dc0f54ac8f510d6ba5578a1a53,Move prediction_loss_only to TrainingArguments (#6426),1,Move Variable,,
1bf4098e03afaed2c6e3671c69fd57e9ac304752,2020-06-15T18:06:17Z,https://github.com/huggingface/transformers/commit/1bf4098e03afaed2c6e3671c69fd57e9ac304752,feat(TFTrainer): improve logging (#4946)  * feat(tftrainer): improve logging  * fix(trainer): consider case with evaluation only  * refactor(tftrainer): address comments  * refactor(tftrainer): move self.epoch_logging to __init__,1,Move Variable,,
75904dae669249c9f5d4d4d57890fb6c537d1639,2019-12-03T15:14:02Z,https://github.com/huggingface/transformers/commit/75904dae669249c9f5d4d4d57890fb6c537d1639,Removed global variable device,1,Move Variable,,
27b0f86d36a1ee25dcc70ba602aefa556dc5f0a9,2019-07-26T15:09:21Z,https://github.com/huggingface/transformers/commit/27b0f86d36a1ee25dcc70ba602aefa556dc5f0a9,clean up pretrained,1,Move Variable,,
a1126237a9980df8255054c472d2894d05ec7315,2018-11-06T16:31:15Z,https://github.com/huggingface/transformers/commit/a1126237a9980df8255054c472d2894d05ec7315,clean up logits extraction logic,1,Move Variable,Rename Variable,
bdeedf139de7d4e30f2d5f3fa0a7fa813419e7d3,2021-02-05T04:35:40Z,https://github.com/tensorflow/tensorflow/commit/bdeedf139de7d4e30f2d5f3fa0a7fa813419e7d3,reorder 'size_splits' in array_ops.split to prevent creating redundant tensor in graph mode,1,Move Statement,,
a6b7e4b94ceb3471a268a57741fe1f32a1472119,2020-09-24T12:30:54Z,https://github.com/tensorflow/tensorflow/commit/a6b7e4b94ceb3471a268a57741fe1f32a1472119,Move V1 optimizer code to a separate file optimizer_v1.py from the generic utils in optimizers.py.PiperOrigin-RevId: 333495430Change-Id: I6bf730dc507f067f79f51b7a5952b50549c7c5a4,1,Move Statement,,
16d14e3e8e439078e071b29b269377d96282c592,2020-09-09T06:55:06Z,https://github.com/tensorflow/tensorflow/commit/16d14e3e8e439078e071b29b269377d96282c592,"PSv2: Move `connect_to_cluster` call from Client to ParameterServerStrategyV2 per recent discussion. This is mainly to accommodate `model.fit()` use case where users aren't expected to explicitly create a Client object, and Client object creation is likely after model creation, which has to be after `connect_to_cluster`. Concretely,```pythonresolver = TFConfigClusterResolver()# PSS.__init__ does tf.config.experimental_connect_to_cluster(resolver)strategy = PSStrategy(resolver, worker_job=""worker"", ps_job=""ps"")with strategy.scope():  model = get_model()  model.compile()  # Client is created with `compile`mode.fit()```PiperOrigin-RevId: 330665856Change-Id: I5802358436472cb7212e2b7c76bf10510ff59a2e",1,Move Statement,,
ef904af1c636ed200eab37d96ae7bbb9d5823d43,2020-08-06T18:05:43Z,https://github.com/tensorflow/tensorflow/commit/ef904af1c636ed200eab37d96ae7bbb9d5823d43,Move imports,1,Move Statement,,
ee2b673b5b7d1b184e1015acd5646f7aa470a187,2020-01-21T19:20:57Z,https://github.com/tensorflow/tensorflow/commit/ee2b673b5b7d1b184e1015acd5646f7aa470a187,Remove duplicate checks in StructuredTensor constructor,1,Move Statement,,
4d0aaeda9b3f8f2d174b0b20cc3c7bb83e044af5,2020-01-16T23:14:40Z,https://github.com/tensorflow/tensorflow/commit/4d0aaeda9b3f8f2d174b0b20cc3c7bb83e044af5,Moved the import statement to conform to alphabetical rules,1,Move Statement,,
ba8a0c934147fcf2a879f349677fc11676c73835,2020-01-14T01:59:47Z,https://github.com/tensorflow/tensorflow/commit/ba8a0c934147fcf2a879f349677fc11676c73835,Move shape assertion in confusion matrix function.PiperOrigin-RevId: 289559706Change-Id: Ia95efe2ecdc6c8531d5a29285ef5a05a0f043c32,1,Move Statement,,
6bd22dc43137c9508445550032af6167e06608ae,2020-01-07T00:29:10Z,https://github.com/tensorflow/tensorflow/commit/6bd22dc43137c9508445550032af6167e06608ae,remove arrangement in activations_test,1,Move Statement,,
336fcd6bd2a2a83e4908d30dfea363b09e789f83,2019-12-12T22:18:03Z,https://github.com/tensorflow/tensorflow/commit/336fcd6bd2a2a83e4908d30dfea363b09e789f83,Move extending of non-TRT optimizers to inside next if conditionThis is fine because CopyFrom of rewriter_config_template will overwritethe disablement of optimizers and thus we can skip them.,1,Move Statement,,
c67eadb2de70d89599a57d2995030fa3e44edc49,2019-12-12T21:45:13Z,https://github.com/tensorflow/tensorflow/commit/c67eadb2de70d89599a57d2995030fa3e44edc49,Move turnning off non-trt optimizers to after CopyFrom templateDisabling optimizers should happen after CopyFrom the temaplteotherwise the template can overwrite the disablement.,1,Move Statement,,
805e659f8ef383568e68f9b49adf78951582743d,2019-11-25T21:32:38Z,https://github.com/tensorflow/tensorflow/commit/805e659f8ef383568e68f9b49adf78951582743d,Move check for `local` to before check for `force` in TPU driverPiperOrigin-RevId: 282422376Change-Id: Ib0197d5d5edc60c2f0b615690b744872a064693d,1,Move Statement,,
7f4b1cb847dc246404d288983f9c74780a4a4e57,2019-10-09T21:51:33Z,https://github.com/tensorflow/tensorflow/commit/7f4b1cb847dc246404d288983f9c74780a4a4e57,Move compat call out of test's __main__.PiperOrigin-RevId: 273827323,1,Move Statement,,
e66c9a3944ba23cc7bee20873f9e7a54b3cb9740,2019-08-01T18:50:27Z,https://github.com/tensorflow/tensorflow/commit/e66c9a3944ba23cc7bee20873f9e7a54b3cb9740,Prepare rnn_cell_test for enabling v2 control flow by default.Moved the variable initialization to happen after building the gradient computation.PiperOrigin-RevId: 261166802,1,Move Statement,,
a93ef60cdd200449fdcb67a592bbdfb8eb5ff2f0,2019-07-25T20:34:12Z,https://github.com/tensorflow/tensorflow/commit/a93ef60cdd200449fdcb67a592bbdfb8eb5ff2f0,Simplify compile API for single execution path and re-compile when required in case we are falling back to v1 loops.PiperOrigin-RevId: 260010322,1,Move Statement,,
a7f5e36c2ad5a998e312a356bc85039fa7c575ad,2019-07-23T00:15:27Z,https://github.com/tensorflow/tensorflow/commit/a7f5e36c2ad5a998e312a356bc85039fa7c575ad,Remove redundant model.trainable_weight in Keras training_eagerPiperOrigin-RevId: 259438753,1,Move Statement,,
deeb18b4cf503de3ba414445e74b3b0055625e1c,2019-06-26T19:26:02Z,https://github.com/tensorflow/tensorflow/commit/deeb18b4cf503de3ba414445e74b3b0055625e1c,Refactor common code in MirroredExtended.PiperOrigin-RevId: 255240321,1,Move Statement,,
0a782f1b1b300ee37f3adfb4964c240dd199f216,2019-05-02T22:46:19Z,https://github.com/tensorflow/tensorflow/commit/0a782f1b1b300ee37f3adfb4964c240dd199f216,Refactor for Keras model attributes and model.compile().PiperOrigin-RevId: 246405829,1,Move Statement,,
812e8471c38243f0a1fb09d27f25c6b456720659,2019-04-16T22:25:31Z,https://github.com/tensorflow/tensorflow/commit/812e8471c38243f0a1fb09d27f25c6b456720659,Split manual renames into a separate file (all_renames_v2.py) so that we candepend on it when generating API.PiperOrigin-RevId: 243890882,1,Move Statement,,
1ffd1072d6c3d4b8647bca0f0602fa7339545491,2019-03-25T22:46:29Z,https://github.com/tensorflow/tensorflow/commit/1ffd1072d6c3d4b8647bca0f0602fa7339545491,Test refactoring: Move OpHint handling logic into toco_converter.PiperOrigin-RevId: 240234048,1,Move Statement,,
9ac2380a80b949586b0f03a4eee4cff5a7b03e34,2019-03-06T12:21:38Z,https://github.com/tensorflow/tensorflow/commit/9ac2380a80b949586b0f03a4eee4cff5a7b03e34,Move backend.get_graph() inside get_gradients(),1,Move Statement,,
9596d6dfaed8cac0f03279bd51e9839ff3bfe085,2019-02-07T16:28:59Z,https://github.com/tensorflow/tensorflow/commit/9596d6dfaed8cac0f03279bd51e9839ff3bfe085,Refactor setup of revived functions from a SavedModel.PiperOrigin-RevId: 232879303,1,Move Statement,,
793d66993c0210fd22eeda7c7048c379521ebd29,2019-01-17T21:52:51Z,https://github.com/tensorflow/tensorflow/commit/793d66993c0210fd22eeda7c7048c379521ebd29,internal changesPiperOrigin-RevId: 229811646,1,Move Statement,,
5f98ba7eba6538f6cb389fa7326a9549dcd1299a,2019-01-17T18:34:59Z,https://github.com/tensorflow/tensorflow/commit/5f98ba7eba6538f6cb389fa7326a9549dcd1299a,Refactor registering gradient of ConcreteFunction.PiperOrigin-RevId: 229775288,1,Move Statement,,
68340a644560241ca7098bb2d358a3cb6fb42a4d,2019-01-07T19:20:59Z,https://github.com/tensorflow/tensorflow/commit/68340a644560241ca7098bb2d358a3cb6fb42a4d,Move the fit-scope check to only error our when using numpyPiperOrigin-RevId: 228200832,1,Move Statement,,
6cb28e4889aab7124ea792d1d013bc6ae90f28b5,2019-01-02T18:27:12Z,https://github.com/tensorflow/tensorflow/commit/6cb28e4889aab7124ea792d1d013bc6ae90f28b5,Move TPU Initialization out of the TPU Strategy constructor.PiperOrigin-RevId: 227541646,1,Move Statement,,
f1102cacd4a3cb8eb9bb11af42b5e20a4f6f4162,2018-12-20T02:23:07Z,https://github.com/tensorflow/tensorflow/commit/f1102cacd4a3cb8eb9bb11af42b5e20a4f6f4162,Moving the repeat after the sloppy parallel interleave to make sure that each epoch is fully done before moving on. This removes the flakiness of the tests as well.PiperOrigin-RevId: 226266737,1,Move Statement,,
f9f50b6cf831cdfef15d952152f43ba6542a14ad,2018-12-08T00:44:06Z,https://github.com/tensorflow/tensorflow/commit/f9f50b6cf831cdfef15d952152f43ba6542a14ad,"Move skipping of test_session to setUp(), so child tests will also skip setUp(), which can be expensive.PiperOrigin-RevId: 224598690",1,Move Statement,,
c16394423c5226d7633d7255c37df762e85f6584,2018-11-21T18:48:49Z,https://github.com/tensorflow/tensorflow/commit/c16394423c5226d7633d7255c37df762e85f6584,Refactor to allow creation of an object graph proto with no variable valuesWill be useful for creating a SavedModel object protoPiperOrigin-RevId: 222430965,1,Move Statement,,
c1c63c936c4bc51b401b82fbe54ed1945f49a314,2018-10-01T10:27:05Z,https://github.com/tensorflow/tensorflow/commit/c1c63c936c4bc51b401b82fbe54ed1945f49a314,Moves the creation of regularizer ops in get_variable out of surrounding context.This resembles the behaviour for initializer ops.PiperOrigin-RevId: 215187942,1,Move Statement,,
d046dd6501af0ca7d90a6ce7611dfe23a99aa781,2018-09-05T01:45:42Z,https://github.com/tensorflow/tensorflow/commit/d046dd6501af0ca7d90a6ce7611dfe23a99aa781,Move iterator.get_next() to be called inside fit from inside of standardize function.PiperOrigin-RevId: 211564198,1,Move Statement,,
06ea8fb214b1b859b211ded0bbe31726214ee3f2,2018-08-31T03:35:06Z,https://github.com/tensorflow/tensorflow/commit/06ea8fb214b1b859b211ded0bbe31726214ee3f2,Move constructors to top of class pages.PiperOrigin-RevId: 211028025,1,Move Statement,,
42b61fbd380a7b6c3912e5a91ff09738ace7073c,2018-08-08T18:48:37Z,https://github.com/tensorflow/tensorflow/commit/42b61fbd380a7b6c3912e5a91ff09738ace7073c,Refactor Sequential model to make it behave exactly like a subclassed network unless it receives an input_shape argument with its first layer. In particular in graph mode no placeholder gets created by a Sequential model (unless an input shape is provided).PiperOrigin-RevId: 207921752,1,Move Statement,,
bb46cc3bf2f08fc67594828197f554c7d46db6db,2018-07-26T15:38:13Z,https://github.com/tensorflow/tensorflow/commit/bb46cc3bf2f08fc67594828197f554c7d46db6db,remove as much as possible from the try-blocks of contextlib context managers.PiperOrigin-RevId: 206163905,1,Move Statement,,
70b60d9cce9a7879fbff396f283f19bed3b39793,2018-03-05T13:08:19Z,https://github.com/tensorflow/tensorflow/commit/70b60d9cce9a7879fbff396f283f19bed3b39793,Move complex->float warning into tf.cast,1,Move Statement,,
f4c18a0eb05e21bae397c9c16527ff8080cae6b8,2017-11-18T01:00:30Z,https://github.com/tensorflow/tensorflow/commit/f4c18a0eb05e21bae397c9c16527ff8080cae6b8,"Call Graph._add_op in Operation.__init__ (and remove existing calls).Without this change, ops manually constructed via Operation.__init__must be passed to Graph._add_op to keep the graph in a consistentstate. Failure to do so is particularly disasterous with the C APIenabled, as more Operation methods rely on Graph._nodes_by_name, whichis updated in Graph._add_op (e.g. Operation.inputs will fail if theinputs have not been added to the graph).An alternative to this change is to require that allOperation.__init__ callers also call Graph._add_op (we don't currentlydo this in ops_test.py, although I imagine all non-test callersdo). While this is effectively the current contract, it forces callersof Operation.__init__, which is a public API, to use _add_op, which isprivate.One downside of this change is that it will break existingGraph._add_op calls, since the op will already have beenadded. However, _add_op is a private API.PiperOrigin-RevId: 176180386",1,Move Statement,,
7d126c49aea63a283386cd73d04ab1bed5eae2f0,2017-11-16T01:58:51Z,https://github.com/tensorflow/tensorflow/commit/7d126c49aea63a283386cd73d04ab1bed5eae2f0,"Refactor Operation.__init__ to create some state after creating _c_opThis change moves around the Operation.__init__ logic to create theTF_Operation before initializing _outputs and before adding the op tothe control flow context (if any). This is in preparation for creatingOperation objects around TF_Operations indirectly created by the C API(e.g. ops created by TF_ImportGraphDef).This also disables running HessianTest with the C API enabled, sinceit's broken for now (but will be fixed soon).PiperOrigin-RevId: 175910443",1,Move Statement,,
b1128a402d473cc6a43c99a081446c1b45305dd9,2017-10-16T20:10:20Z,https://github.com/tensorflow/tensorflow/commit/b1128a402d473cc6a43c99a081446c1b45305dd9,Move global_step_read dependency to model_fn instead of input_fn.PiperOrigin-RevId: 172366972,1,Move Statement,,
c280e8c48f8a4c32553990d02beef5ede4f8d39f,2017-10-02T23:01:17Z,https://github.com/tensorflow/tensorflow/commit/c280e8c48f8a4c32553990d02beef5ede4f8d39f,Move the logic for adding regularization losses to collectionsinto Layer.add_loss().PiperOrigin-RevId: 170768628,1,Move Statement,,
17f26f81bfaf8ee03e330b98f4297cb754676c35,2017-08-26T01:39:23Z,https://github.com/tensorflow/tensorflow/commit/17f26f81bfaf8ee03e330b98f4297cb754676c35,"Minor refactor of BatchNormalization's build, where we create gamma before beta.This fixes a major compatibility issue between tf.keras and multi-backend keras,in which the BN weights saved by one version would be incorrectly loaded bythe other version.This change will not have side effects outside of Keras.PiperOrigin-RevId: 166552455",1,Move Statement,,
4470dbe543da4ff1dda9dbd4eeb97888d4b55d7b,2017-06-23T02:45:27Z,https://github.com/tensorflow/tensorflow/commit/4470dbe543da4ff1dda9dbd4eeb97888d4b55d7b,Moved tpu_config.RunConfig check to inside of use_tpu block,1,Move Statement,,
b0852317b1e54ad6ab6cc462fdd3f687f158c338,2017-06-11T04:00:07Z,https://github.com/tensorflow/tensorflow/commit/b0852317b1e54ad6ab6cc462fdd3f687f158c338,"tfdbg: reduce test code boilerplate and clean up exceptions* debug_data.py simplify the logic of detecting nonexistent node names by pulling the logic into _infer_device_name()* session_debug_testlib.py: create helper ""_debug_run_and_get_dump()"" to reduce boilerplatePiperOrigin-RevId: 158635021",1,Move Statement,,
59ecde3ecfc83aeb8ec0682e4e39bf0a234bbef8,2017-03-15T18:32:45Z,https://github.com/tensorflow/tensorflow/commit/59ecde3ecfc83aeb8ec0682e4e39bf0a234bbef8,"Remove sigmoid by calling sigmoid before split (#7749)Remove one sigmoid function, by calling sigmoid before split",1,Move Statement,,
2455824ae071665a6a5ba3960cc5d2365f535aea,2017-03-08T23:22:28Z,https://github.com/tensorflow/tensorflow/commit/2455824ae071665a6a5ba3960cc5d2365f535aea,Move defined_in up to the top.Change: 149590447,1,Move Statement,,
b75ec694d8c189457da3ca0edc451cf0c6b16f2d,2016-09-01T23:40:58Z,https://github.com/tensorflow/tensorflow/commit/b75ec694d8c189457da3ca0edc451cf0c6b16f2d,Remove experimental small-alpha code from gamma random sampler.Samples in this regime have been providing incorrect distributional values.Go back to the older mechanism.Change: 132008554,1,Move Statement,,
5fb03099240dfdc5662f80454334a1a171f44262,2016-08-09T02:57:33Z,https://github.com/tensorflow/tensorflow/commit/5fb03099240dfdc5662f80454334a1a171f44262,Minor code refactoringChange: 129704508,1,Move Statement,,
99313dc49dee2273d02d988a84f155ef6ea35c53,2016-08-04T14:38:17Z,https://github.com/tensorflow/tensorflow/commit/99313dc49dee2273d02d988a84f155ef6ea35c53,Removes code duplication in feature_column.pyChange: 129328798,1,Move Statement,,
91a551c0bc29d09cd2f034741c1291bfad7346db,2016-05-16T12:36:37Z,https://github.com/tensorflow/tensorflow/commit/91a551c0bc29d09cd2f034741c1291bfad7346db,Move imports to beginning of code,1,Move Statement,,
8f806152f100aedf178254691806d6d81aaa55dc,2016-04-22T01:05:11Z,https://github.com/tensorflow/tensorflow/commit/8f806152f100aedf178254691806d6d81aaa55dc,Colocate Regularizers with Variables to avoid unnecessary communication.Change: 120505779,1,Move Statement,,
545a25a109ffe52bb6f2c7264d577055bc1f0923,2016-01-03T03:50:56Z,https://github.com/tensorflow/tensorflow/commit/545a25a109ffe52bb6f2c7264d577055bc1f0923,Moved out all data feeder logic into data_feeder.py,1,Move Statement,,
52dba5c91b4398a58c643481f6534d98b4013551,2015-12-14T02:14:48Z,https://github.com/tensorflow/tensorflow/commit/52dba5c91b4398a58c643481f6534d98b4013551,Moved filter for predict to better place,1,Move Statement,,
a0c9a21802f1af26578f0a5522aaa32cc2ee8c16,2015-11-25T04:09:14Z,https://github.com/tensorflow/tensorflow/commit/a0c9a21802f1af26578f0a5522aaa32cc2ee8c16,Moved shared code from predict and predict_proba to _predict. Added comments to fit/predict/predict_proba,1,Move Statement,,
8635720ce6223f1937096908858974014e619a5e,2022-03-14T19:46:13Z,https://github.com/keras-team/keras/commit/8635720ce6223f1937096908858974014e619a5e,Replace usages of the deprecated most_specific_compatible_type  PiperOrigin-RevId: 434540917,1,Move Statement,,
373ad97c72ed1ac4b6898e85b2cfd7b016e4b469,2022-02-08T21:20:46Z,https://github.com/keras-team/keras/commit/373ad97c72ed1ac4b6898e85b2cfd7b016e4b469,"Copy image utils from keras_preprocessing directly into core keras  This is not new code, we are just moving these utilities directly into keras from keras-preprocessing.  For the library code, just fixed linting errors. For the test code, had to do more major changes to port from pytest, but hopefully any errors have been caught by the tests themselves.  PiperOrigin-RevId: 427274651",1,Move Statement,,
8fb8accb055201146a8e1a74268f8eadca3d08fc,2017-02-23T18:47:11Z,https://github.com/keras-team/keras/commit/8fb8accb055201146a8e1a74268f8eadca3d08fc,Minimal refactoring of `compile`.,1,Move Statement,,
2a0b112d081186cd6bc6a3cf14e510feea11fc10,2016-12-12T22:17:59Z,https://github.com/keras-team/keras/commit/2a0b112d081186cd6bc6a3cf14e510feea11fc10,Use Theano's abstract interface for batch normalization (#4595)  * Simplify BatchNormalization code.  * Make Theano's K.batch_normalization similar to TensorFlow.  * Change default batch normalization epsilon to 1e-3.  * Use Theano's new batch normalization interface.,1,Move Statement,,
9f6acd960c0a0c699c79ca1d571783e1692568fb,2016-09-14T21:18:15Z,https://github.com/keras-team/keras/commit/9f6acd960c0a0c699c79ca1d571783e1692568fb,Simplify Conv1D ops.,1,Move Statement,,
8f41e41eda6e8ea96403cae5798a5a89c8bb5605,2018-12-20T17:36:33Z,https://github.com/keras-team/keras/commit/8f41e41eda6e8ea96403cae5798a5a89c8bb5605,Split Generators tests from Sequence tests (#11901)  * Split Sequence test from generator tests  * use_spawn check for windows  * Do not copy use_spawn  * Remove unused param,1,Move Statement,,
ff62eb251b04b8301e71aee970bdb157f2649fa9,2016-12-14T21:41:24Z,https://github.com/keras-team/keras/commit/ff62eb251b04b8301e71aee970bdb157f2649fa9,"Refactor regularizers and add add_weight method. (#4703)  * Refactor regularizers, introduce layer.add_weight  * Fix BN add_update syntax  * Fix eigenvalue regularizer  * Style fixes.",1,Move Statement,,
019048b3b6702c874fd77a4881ceaf7fff488602,2021-08-05T06:25:30Z,https://github.com/pytorch/pytorch/commit/019048b3b6702c874fd77a4881ceaf7fff488602,"[PyTorch Edge] Simplify Exception Handling (Take-2) (module.cpp) (#62634)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/62634  Apply the same set of changes as in D27688352 (https://github.com/pytorch/pytorch/commit/d728491fc1ab9e0ae44c0c773299759f3f8287d8) to `module.cpp` as instructed by xcheng16.  Basically, this simplifies exception handling and allows propagation of the original message undisturbed to the caller so that we can figure out the lineage of the exception in crash tasks such as t96812652 ghstack-source-id: 134877012  Test Plan: Build/Sandcastle  Reviewed By: raziel  Differential Revision: D30038867  fbshipit-source-id: 8dfd415c510bcd0ab49814f4eb559ec6fc8f72e5",1,Move Statement,,
03eec07956a61cb824f4685ba3630f553b1a0a6d,2020-07-08T15:41:10Z,https://github.com/pytorch/pytorch/commit/03eec07956a61cb824f4685ba3630f553b1a0a6d,"Move error messages in-line in `_vmap_internals.py` (#41077)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/41077This PR is a refactor that moves error messages into their callsites in`_vmap_internals.py`. Furthermore, because a little bird told me we'vedropped python 3.5 support, this PR adopts f-string syntax to clean upthe string replace logic. Together these changes make the error messagesread better IMO.Test Plan:- `python test/test_vmap.py -v`. There exists tests that invoke each of theerror messages.Differential Revision: D22420473Pulled By: zou3519fbshipit-source-id: cfd46b2141ac96f0a62864928a95f8eaa3052f4e",1,Move Statement,,
1fde373f2f4c5e1745f156919f050c0f93391866,2020-05-14T00:46:15Z,https://github.com/pytorch/pytorch/commit/1fde373f2f4c5e1745f156919f050c0f93391866,[quant][graphmode] Move clamp to general value ops map (#38163)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/38163Test Plan: Imported from OSSDifferential Revision: D21559805fbshipit-source-id: db02bd17fbc6d1335fe021265955d02d52d139e6,1,Move Statement,,
2e8557778b5873c7d2fc77b286c832be9a464a18,2019-08-09T15:13:30Z,https://github.com/pytorch/pytorch/commit/2e8557778b5873c7d2fc77b286c832be9a464a18,Refactor randperm test (#23526)Summary:CPU and CUDA testing code are largely the same.Pull Request resolved: https://github.com/pytorch/pytorch/pull/23526Reviewed By: ezyangDifferential Revision: D16586271Pulled By: VitalyFedyuninfbshipit-source-id: 91c70c05789120fde4718ce955de243087a8c993,1,Move Statement,,
59ac451ba314bbfb97435b186f236178d294104a,2021-08-09T23:47:46Z,https://github.com/pytorch/pytorch/commit/59ac451ba314bbfb97435b186f236178d294104a,"Simplify the logic of running ci workflow codegen (#62853)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/62853  wanted to simplify the logic in the `__post_int__`, and delegate the settings back to individual workflows, this gives us more flexibility in changing individual workflows, as well as reducing the complexity of understanding the mutation conditions.  Test Plan: Imported from OSS  Reviewed By: walterddr, seemethere  Differential Revision: D30149190  Pulled By: zhouzhuojie  fbshipit-source-id: 44df5b1e14184f3a81cb8004151525d0e0fb20d9",1,Move Statement,,
66adfcd25859ed92075969b7b8fd67b5341931c6,2021-01-20T17:32:16Z,https://github.com/pytorch/pytorch/commit/66adfcd25859ed92075969b7b8fd67b5341931c6,tools: Move sha check to else statement (#50773)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/50773Moves the sha check for version generation to the else clausesince it was causing issues for users building pytorch when the .gitdirectory was not present and PYTORCH_BUILD_VERSION was already setTest Plan:CICloses https://github.com/pytorch/pytorch/issues/50730Signed-off-by: Eli Uriegas <eliuriegas@fb.com>Reviewed By: janeyx99Differential Revision: D25963486Pulled By: seemetherefbshipit-source-id: ce1b315f878d074f2ffb6b658d59cbd13150f27f,1,Move Statement,,
6bb1c4a7ab534fa4d708a709e4ef070c3900bf8e,2020-05-12T16:15:54Z,https://github.com/pytorch/pytorch/commit/6bb1c4a7ab534fa4d708a709e4ef070c3900bf8e,Move (most) generated return statements for TH functions out of the switch. (#38073)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/38073Most of the generated return statements don't depend on the scalar type and it saves ~900 lines of generated code.Test Plan: Imported from OSSDifferential Revision: D21476010Pulled By: gchananfbshipit-source-id: 3fcc4db466d697c90abafb9da6c3f3644621810b,1,Move Statement,,
7ce733d218102cc633757286aa66638c088de477,2020-05-14T00:46:15Z,https://github.com/pytorch/pytorch/commit/7ce733d218102cc633757286aa66638c088de477,[quant][graphmode] Move leaky_relu to general value op map (#38166)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/38166Test Plan: Imported from OSSDifferential Revision: D21559813fbshipit-source-id: 8521f7ad2b0fcd6f87090fb40517d5d92c37ba54,1,Move Statement,,
80974dde4c23cd483de5971887b79ef8e95d48dc,2019-08-28T19:16:27Z,https://github.com/pytorch/pytorch/commit/80974dde4c23cd483de5971887b79ef8e95d48dc,Move new_criterion_tests from test_nn.py to common_nn.py (#25333)Summary:Moving so that `new_criterion_tests` can be used from `test_cpp_api_parity.py`.Pull Request resolved: https://github.com/pytorch/pytorch/pull/25333Differential Revision: D17097188Pulled By: yf225fbshipit-source-id: 7f7905cc6799bca8dc6b3c9cc43995313c6bc058,1,Move Statement,,
9a14c013c375c5c903e5e0dbe0e8e6dc72328f12,2017-06-28T02:32:37Z,https://github.com/pytorch/pytorch/commit/9a14c013c375c5c903e5e0dbe0e8e6dc72328f12,"Refactor data_parallel_model to take advantage of Gloo broadcast op in broadcasting across machines and GPUs in one operationSummary: Combine _AddDistributedParameterSync() and _SyncParams() into a single function to broadcast across distributes machines and all local GPU simultaneously. This is similar to how calls to Allreduce has already optimized using the functionalities of Gloo. All the refactoring work is contained in data_parallel_model.py.Reviewed By: akyrola, andrewwdyeDifferential Revision: D5329277fbshipit-source-id: 4407b88980cf396f2e0f994d796294fa79fd39ed",1,Move Statement,API Refactoring,Rename Method
a1deb2d47f28c0b5fa51ceb56896deae1cccd469,2017-10-14T06:48:23Z,https://github.com/pytorch/pytorch/commit/a1deb2d47f28c0b5fa51ceb56896deae1cccd469,Move the exception logic to the helper function,1,Move Statement,,
c4ee2b706739a1fbc1d643308b3a774d2ac9526a,2018-03-23T15:34:27Z,https://github.com/pytorch/pytorch/commit/c4ee2b706739a1fbc1d643308b3a774d2ac9526a,"Moved torch headers copy to build_deps (#5772)* Moved torch headers copy to build_depsPR #5706 initially moved headers under build_ext to fix bdist_wheel andbuild develop. This broke install and #5755 moved them back to installwhich broke bdist_wheel and build develop. Looks like build_ext is calledfrom install after it already tried to copy the headers to the python installdir and the headers were not installed correctly. Using build_deps workscorrect with all setup.py install, bdist_wheel and build develop.* Comment about the auto-generated filesAdded comment that the current solution will not include auto-generatedfiles which may be a problem if somebody needs to use them",1,Move Statement,,
e72385af2056b3c552c0b6c81688ef9e4d10f7b4,2023-05-09T05:30:55Z,https://github.com/pytorch/pytorch/commit/e72385af2056b3c552c0b6c81688ef9e4d10f7b4,"[Reducer] Move require_finalize_ (#100782)  This doesn't need to be set in the loop, just once.  Differential Revision: [D45632426](https://our.internmc.facebook.com/intern/diff/D45632426/) Pull Request resolved: https://github.com/pytorch/pytorch/pull/100782 Approved by: https://github.com/Skylion007, https://github.com/fegin",1,Move Statement,,
081069e8ca87201ca80a5cf8bdd2a6fb204c22fb,2019-10-04T14:48:19Z,https://github.com/pytorch/pytorch/commit/081069e8ca87201ca80a5cf8bdd2a6fb204c22fb,Remove CUDA_VERSION from Python script (which has already been detected in CMake) (#27316)Summary:(Intentionally left blank)Pull Request resolved: https://github.com/pytorch/pytorch/pull/27316Differential Revision: D17762715Pulled By: ezyangfbshipit-source-id: 044c0ea6e8c2d12912c946a9a50b934b5253d8c8,1,Move Statement,Remove Dead Code,
286b618b7d22b2de7c4929082e145111094be9f1,2023-04-14T14:41:10Z,https://github.com/pytorch/pytorch/commit/286b618b7d22b2de7c4929082e145111094be9f1,"[SPMD] Move some functions to IterGraphModule.setup() (#99076)  Since users will have to call these steps before calling `setup()`, moving these steps to `setup()` can reduce the API usage complexity.  Differential Revision: [D44973726](https://our.internmc.facebook.com/intern/diff/D44973726/) Pull Request resolved: https://github.com/pytorch/pytorch/pull/99076 Approved by: https://github.com/lessw2020",1,Move Statement,,
1f12941e7167731c437a62a9d1feefe04d55f80e,2023-01-24T17:08:51Z,https://github.com/scikit-learn/scikit-learn/commit/1f12941e7167731c437a62a9d1feefe04d55f80e,MAINT refactor spectral_clustering to call SpectralClustering (#25392),1,Move Statement,,
3014fcfcd0253ccfd7831bf85a36b763189a6417,2021-05-19T13:29:30Z,https://github.com/scikit-learn/scikit-learn/commit/3014fcfcd0253ccfd7831bf85a36b763189a6417,MNT Move parameter validation from `__init__` to `fit` in `neighbors` module (#20072),1,Move Statement,,
94337993ef1a29146c67d7e4a51e3053a79e92b7,2021-02-07T11:19:05Z,https://github.com/scikit-learn/scikit-learn/commit/94337993ef1a29146c67d7e4a51e3053a79e92b7,EXA remove warning when setting yticks in permutation importances examples (#19385),1,Move Statement,,
f35457f1fc3282d9efa21a6dc0bfe5a5e8a2f40f,2020-10-05T20:43:38Z,https://github.com/scikit-learn/scikit-learn/commit/f35457f1fc3282d9efa21a6dc0bfe5a5e8a2f40f,MNT Remove unnecessary assignments from LogisticRegression.fit (#18539),1,Move Statement,Remove Dead Code,
c2f5fe3e43f18f788dfad218abc6498a3fbbe20c,2020-03-31T21:18:21Z,https://github.com/scikit-learn/scikit-learn/commit/c2f5fe3e43f18f788dfad218abc6498a3fbbe20c,MNT remove deprecated externals.joblib (#16814),1,Move Statement,,
0f0f29a6fb8b01d09dc3e1e28e5a11404e23cabb,2020-03-03T20:14:15Z,https://github.com/scikit-learn/scikit-learn/commit/0f0f29a6fb8b01d09dc3e1e28e5a11404e23cabb,MNT refactoring of sgd utilities (#16528),1,Move Statement,,
0f53b63987311a8c247236b53ae1d1e02c7bd010,2019-07-22T19:33:58Z,https://github.com/scikit-learn/scikit-learn/commit/0f53b63987311a8c247236b53ae1d1e02c7bd010,CLN Moves threshold condition inside else block for OneVsRest.?(#14435),1,Move Statement,,
be4accf79d924e9afce0e124124de12bd8709ef2,2019-06-30T02:28:29Z,https://github.com/scikit-learn/scikit-learn/commit/be4accf79d924e9afce0e124124de12bd8709ef2,TST refactor test_numeric_stability (#14221),1,Move Statement,,
ccf0d9286dfb8e125dcbeb038076f659fdac22a3,2018-11-30T15:19:29Z,https://github.com/scikit-learn/scikit-learn/commit/ccf0d9286dfb8e125dcbeb038076f659fdac22a3,MNT Minor code refactoring in utils.testing (#12688),1,Move Statement,,
cedf023e20437db9ade3aa829f0c9d6267893583,2015-02-01T17:20:30Z,https://github.com/scikit-learn/scikit-learn/commit/cedf023e20437db9ade3aa829f0c9d6267893583,Move import statement,1,Move Statement,,
a98e0d361dd78a11a7c9c429ee5ccb02b4de8383,2014-12-16T10:35:55Z,https://github.com/scikit-learn/scikit-learn/commit/a98e0d361dd78a11a7c9c429ee5ccb02b4de8383,Moved some common code into helper function,1,Move Statement,,
93bab70f7986e9355c489f10f37adbead79db3cb,2014-12-01T08:57:15Z,https://github.com/scikit-learn/scikit-learn/commit/93bab70f7986e9355c489f10f37adbead79db3cb,ENH do not use plt.cm.jet in JL bound example  Also move the call to plt.show() to the end of the script to avoid blocking the execution.,1,Move Statement,,
5fe405bd6545cd1ebf8ed7aeb3fa94be087c7449,2014-09-29T10:58:30Z,https://github.com/scikit-learn/scikit-learn/commit/5fe405bd6545cd1ebf8ed7aeb3fa94be087c7449,"cleaning up floating point and unneeded todos, also removing constant learning rate for asgd",1,Move Statement,,
701a87fcfe83c95e97daa6e99aca546deac4867d,2014-09-19T14:04:50Z,https://github.com/scikit-learn/scikit-learn/commit/701a87fcfe83c95e97daa6e99aca546deac4867d,Refactored some logic code,1,Move Statement,,
1e1bd689c05ae91508e96a8dc1956b9353020d5a,2014-08-07T11:20:56Z,https://github.com/scikit-learn/scikit-learn/commit/1e1bd689c05ae91508e96a8dc1956b9353020d5a,COSMIT Move imports in example,1,Move Statement,,
44499fafadb77d8f463283e563d2f66f649e64c3,2014-08-01T20:19:27Z,https://github.com/scikit-learn/scikit-learn/commit/44499fafadb77d8f463283e563d2f66f649e64c3,"Move array intiialiaztions into dense conditional, nz_indices -> col_nonzero",1,Move Statement,,
6d881d3fb1e69938db4d184f2e79978cb12ca6a0,2014-07-19T12:37:52Z,https://github.com/scikit-learn/scikit-learn/commit/6d881d3fb1e69938db4d184f2e79978cb12ca6a0,MAINT split sklearn/metrics/metrics.py,1,Move Statement,,
712d3d0d904154000c8bc03dff864888d3a8f57b,2014-01-16T03:43:16Z,https://github.com/scikit-learn/scikit-learn/commit/712d3d0d904154000c8bc03dff864888d3a8f57b,Move set_params back to fit_grid_point,1,Move Statement,,
112befd2bd950c43db4a68922c9db72fa3cba757,2013-11-10T11:28:15Z,https://github.com/scikit-learn/scikit-learn/commit/112befd2bd950c43db4a68922c9db72fa3cba757,Simplify fast_dot.,1,Move Statement,,
098f630d7040cb4d84c0c0ab1906e9906f046b1b,2013-11-01T19:23:02Z,https://github.com/scikit-learn/scikit-learn/commit/098f630d7040cb4d84c0c0ab1906e9906f046b1b,GBRT enhancements:   Moved verbose output code to VerboseReporter class.   Cosmit: logical structured code blocks   Refactored: moved init state to method   Added partial_fit to GradientBoosting   Fix: is_classification not available; n_features not n_features_   Tests   Add ``partial_fit`` to docs,1,Move Statement,,
77b466e43c89e6469fb764fb68fd4c274e9ec959,2013-10-20T13:57:57Z,https://github.com/scikit-learn/scikit-learn/commit/77b466e43c89e6469fb764fb68fd4c274e9ec959,"Move estimator_, n_trials_, inlier_mask_ initialization to fit method and use LinearRegression and Perceptron as default base estimators.",1,Move Statement,,
5e375b59a6c08b4e61cd1d0c0c97b700edcb6dc7,2013-09-06T13:41:29Z,https://github.com/scikit-learn/scikit-learn/commit/5e375b59a6c08b4e61cd1d0c0c97b700edcb6dc7,Move __future__ import after license text,1,Move Statement,,
30dfa013284bb03ac0257c9275450459634fafac,2013-01-05T17:15:17Z,https://github.com/scikit-learn/scikit-learn/commit/30dfa013284bb03ac0257c9275450459634fafac,"Improving code coverage for datasets module. Moved dataset imports inside test_data_home, because it is preferable for import errors to only affect the tests that require those imported methods.  My first commit to scikit. -bcajes",1,Move Statement,,
af3ff357b7ff75748ca345aa9f9c6ce799162cfc,2013-01-03T12:21:51Z,https://github.com/scikit-learn/scikit-learn/commit/af3ff357b7ff75748ca345aa9f9c6ce799162cfc,"TST move test of ""classes_"" to the appropriate test in ""test_common"".",1,Move Statement,,
2430f416f20ba685e44ccef8e60bf4597d517da8,2012-12-31T11:44:11Z,https://github.com/scikit-learn/scikit-learn/commit/2430f416f20ba685e44ccef8e60bf4597d517da8,"Improving code coverage for datasets module. Moved dataset imports inside test_data_home, because it is preferable for import errors to only affect the tests that require those imported methods.  My first commit to scikit. -bcajes",1,Move Statement,,
028a33e3c35f8571b98d8161fe4eb29583fa02f7,2012-06-07T21:35:54Z,https://github.com/scikit-learn/scikit-learn/commit/028a33e3c35f8571b98d8161fe4eb29583fa02f7,MISC A bit more cleaning up in BaseLibSVM,1,Move Statement,,
bc45db950cef959a73b7f144bbf8cf0a9258a9c1,2011-09-26T12:27:31Z,https://github.com/scikit-learn/scikit-learn/commit/bc45db950cef959a73b7f144bbf8cf0a9258a9c1,COSMIT: GraphViz exporter cleaned up,1,Move Statement,,
cbaf29414271536c78081869a016df8e3044eef8,2011-08-31T12:29:57Z,https://github.com/scikit-learn/scikit-learn/commit/cbaf29414271536c78081869a016df8e3044eef8,Move initial entropy computation outside loop.,1,Move Statement,,
fceb4d4a09ce2a5ffe90139eae3853055922c08e,2011-08-03T12:59:53Z,https://github.com/scikit-learn/scikit-learn/commit/fceb4d4a09ce2a5ffe90139eae3853055922c08e,Split the transform method into a predict and a transform.,1,Move Statement,,
462e2ce858e195d42d382e754ebe8fb8c161ea52,2011-07-17T17:32:08Z,https://github.com/scikit-learn/scikit-learn/commit/462e2ce858e195d42d382e754ebe8fb8c161ea52,simplify np.seterr handling in sparse_pca,1,Move Statement,,
772b24a1abd41594b42661ad735c9d5d24d1931d,2011-06-13T11:16:18Z,https://github.com/scikit-learn/scikit-learn/commit/772b24a1abd41594b42661ad735c9d5d24d1931d,(Hopefully) full exception safety in SVMlight reader  Also some minor refactoring,1,Move Statement,,
8ddde2fb053000d3a2d31898d66101d0d02fe344,2011-04-05T10:38:43Z,https://github.com/scikit-learn/scikit-learn/commit/8ddde2fb053000d3a2d31898d66101d0d02fe344,"More covariance refactoring: separate MLE computation from object.  It had to be possible to fit a simple Maximum Likelihood Estimator of covariance without having to instantiate a new Covariance object, as is can result in a loss in code clarity and in performances.  The separation of algorithm and object follows the model used in shrun_covariance_.py classes.",1,Move Statement,,
2057dd9e2f9010eb1a8c6900644b9627588fc9e6,2010-12-03T15:22:03Z,https://github.com/scikit-learn/scikit-learn/commit/2057dd9e2f9010eb1a8c6900644b9627588fc9e6,Remove duplicates in linear_model/__init__.py,1,Move Statement,,
de98912813c394b107940777b5c26181646f6917,2010-01-14T15:22:10Z,https://github.com/scikit-learn/scikit-learn/commit/de98912813c394b107940777b5c26181646f6917,"Move examples to a common place.  For the nearest neighbors examples, knn2.py is copied from the source file regression.neighbors, but knn.py is a new example that makes use of matplotlib.  From: Fabian Pedregosa <fabian.pedregosa@inria.fr>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@346 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8",1,Move Statement,,
49b69fe0d4885e258dbf657e35c445a94ffd09ae,2023-09-04T18:34:04Z,https://github.com/huggingface/transformers/commit/49b69fe0d4885e258dbf657e35c445a94ffd09ae,[`Falcon`] Remove SDPA for falcon to support earlier versions of PyTorch (< 2.0) (#25947)  * remove SDPA for falcon  * revert previous behaviour and add warning  * nit  * Update src/transformers/models/falcon/modeling_falcon.py  Co-authored-by: Matt <Rocketknight1@users.noreply.github.com>  * Update src/transformers/models/falcon/modeling_falcon.py  ---------  Co-authored-by: Matt <Rocketknight1@users.noreply.github.com> Co-authored-by: Lysandre Debut <hi@lysand.re>,1,Move Statement,,
d27e4c18fe2970abcb9a48dcb8a824e48083b15f,2023-08-01T11:33:12Z,https://github.com/huggingface/transformers/commit/d27e4c18fe2970abcb9a48dcb8a824e48083b15f,Move rescale dtype recasting to match torchvision ToTensor (#25229)  Move dtype recasting to match torchvision ToTensor,1,Move Statement,Rename Variable,
66a378429d0e085e4e72bc63a4147889a3b65a14,2023-07-06T09:33:25Z,https://github.com/huggingface/transformers/commit/66a378429d0e085e4e72bc63a4147889a3b65a14,DeepSpeed/FSDP ckpt saving utils fixes and FSDP training args fixes (#24591)  * update ds and fsdp ckpt logic  * refactoring  * fix 🐛  * resolve comment  * fix issue with overriding of the fsdp config set by accelerate,1,Move Statement,,
84bac652f32e65ad0082f3fcb9e077aeff4f6fdd,2023-05-31T14:49:43Z,https://github.com/huggingface/transformers/commit/84bac652f32e65ad0082f3fcb9e077aeff4f6fdd,Move import check to before state reset (#23906)  * Move import check to before state reset  * Guard better,1,Move Statement,,
03db59104714f60b591ef48073840b288ee4cdc0,2023-05-31T09:12:07Z,https://github.com/huggingface/transformers/commit/03db59104714f60b591ef48073840b288ee4cdc0,shift torch dynamo handling to accelerate (#23168)  * mixed precision support via accelerate  * fix issues  * fix for the sharded ddp case  * fix flax and tf failing tests  * `refactor the place to create `Accelerator` object  * move ddp prep to accelerate  * fix 😅  * resolving comments  * move fsdp handling to accelerate  * fixex  * fix saving  * shift torch dynamo handling to accelerate,1,Move Statement,,
0b774074a5f7f2137d0f1743bb9990cfb7e7a1d8,2023-05-31T08:40:46Z,https://github.com/huggingface/transformers/commit/0b774074a5f7f2137d0f1743bb9990cfb7e7a1d8,move fsdp handling to accelerate (#23158)  * mixed precision support via accelerate  * fix issues  * fix for the sharded ddp case  * fix flax and tf failing tests  * `refactor the place to create `Accelerator` object  * move ddp prep to accelerate  * fix 😅  * resolving comments  * move fsdp handling to accelerate  * fixex  * fix saving,1,Move Statement,,
1cf148a6aaafcb0c483f341aababdfc05fd1da58,2023-05-31T08:12:49Z,https://github.com/huggingface/transformers/commit/1cf148a6aaafcb0c483f341aababdfc05fd1da58,Smangrul/accelerate ddp integrate (#23151)  * mixed precision support via accelerate  * fix issues  * fix for the sharded ddp case  * fix flax and tf failing tests  * `refactor the place to create `Accelerator` object  * move ddp prep to accelerate  * fix 😅  * resolving comments,1,Move Statement,,
9f0646a5550ccfb49a139abe14edb724edf785f5,2023-05-31T06:57:51Z,https://github.com/huggingface/transformers/commit/9f0646a5550ccfb49a139abe14edb724edf785f5,Smangrul/accelerate mp integrate (#23148)  * mixed precision support via accelerate  * fix issues  * fix for the sharded ddp case  * fix flax and tf failing tests  * `refactor the place to create `Accelerator` object  * address comments by removing debugging print statements,1,Move Statement,,
3d7baef1141e22520901310593c106b15493e6a9,2023-05-24T15:34:21Z,https://github.com/huggingface/transformers/commit/3d7baef1141e22520901310593c106b15493e6a9,"fix: Whisper generate, move text_prompt_ids trim up for max_new_tokens calculation (#23724)  move text_prompt_ids trimming to top",1,Move Statement,,
2acedf47214d7a634c193846124832a4686cc8fd,2023-05-19T08:33:11Z,https://github.com/huggingface/transformers/commit/2acedf47214d7a634c193846124832a4686cc8fd,"feat: Whisper prompting (#22496)  * initial working additions  * clean and rename, add cond stripping initial prompt to decode  * cleanup, edit create_initial_prompt_ids, add tests  * repo consistency, flip order of conditional  * fix error, move the processor fn to the tokenizer  * repo consistency, update test ids to corresponding tokenizer  * use convert_tokens_to_ids not get_vocab...  * use actual conditional in generate  * make sytle  * initial address comments  * initial working add new params to pipeline  * first draft of sequential generation for condition_on_previous_text  * add/update tests, make compatible with timestamps  * make compatible with diff. input kwargs and max length  * add None check  * add temperature check  * flip temp check operand  * refocusing to prev pr scope  * remove the params too  * make style  * edits, move max length incorporating prompt to whisper  * address comments  * remove asr pipeline prompt decoding, fix indexing  * address comments (more tests, validate prompt)  * un-comment out tests (from debug)  * remove old comment  * address comments  * fix typo  * remove timestamp token from test  * make style  * cleanup  * copy method to fast tokenizer, set max_new_tokens for test  * prompt_ids type just pt  * address Amy's comments  * make style",1,Move Statement,,
6bd8ae264026b19a982072a6625d893a7065437e,2023-04-19T12:53:47Z,https://github.com/huggingface/transformers/commit/6bd8ae264026b19a982072a6625d893a7065437e,move preprocess_logits_for_metrics before _nested_gather in trainer.e?(#22603)  * move preprocess_logits_for_metrics before _nested_gather in trainer.evaluation_loop  * fix  * Update src/transformers/trainer.py  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * fix  * fix  ---------  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>,1,Move Statement,,
10fab90fe22b21619ed1136792102a6a8142c4ed,2023-04-12T15:42:50Z,https://github.com/huggingface/transformers/commit/10fab90fe22b21619ed1136792102a6a8142c4ed,`torch.distributed` group initialization for `torch_neuron` disabled when `optimum-neuron` is installed (#22728)  * Make the process group initialization not happen if optimum_neuron is installed  * Add warning  * Remove list and added warning,1,Move Statement,,
12d51db243a00726a548a43cc333390ebae731e3,2023-04-06T12:50:15Z,https://github.com/huggingface/transformers/commit/12d51db243a00726a548a43cc333390ebae731e3,"Backbone add mixin tests (#22542)  * Add out_indices to backbones, deprecate out_features  * Update - can specify both out_features and out_indices but not both  * Add backbone mixin tests  * Test tidy up  * Add test_backbone for convnext  * Remove redefinition of method  * Update for Dinat and Nat backbones  * Update tests  * Smarter indexing  * Add checks on config creation for backbone  * PR comments",1,Move Statement,,
3ec7a47664ebe40c40f4b722f6bb1cd30c3821ec,2023-03-27T19:00:16Z,https://github.com/huggingface/transformers/commit/3ec7a47664ebe40c40f4b722f6bb1cd30c3821ec,[neptune] fix checkpoint bug with relative out_dir (#22102)  * [neptune] fix checkpoint bug with relative out_dir  * update imports  * reformat with black  * check neptune without imports  * fix typing-related issue  * run black on code  * use os.path.sep instead of raw \  * simplify imports and remove type annotation  * make ruff happy  * apply review suggestions  ---------  Co-authored-by: Aleksander Wojnarowicz <alwojnarowicz@gmail.com>,1,Move Statement,,
53155b520d6faab07ff185384ac04ee840106fc2,2023-03-27T15:39:26Z,https://github.com/huggingface/transformers/commit/53155b520d6faab07ff185384ac04ee840106fc2,Trainer: move Seq2SeqTrainer imports under the typing guard (#22401),1,Move Statement,,
fb0a38b4f275727d6228fb4a78c15c6dd8480e91,2023-03-20T17:54:01Z,https://github.com/huggingface/transformers/commit/fb0a38b4f275727d6228fb4a78c15c6dd8480e91,Move torch.compile() wrapping after DDP/FSDP wrapping to ensure correct graph breaks during training (#22279),1,Move Statement,,
db979f75882e5fecc55e8aca0c2800e53d4abce8,2023-03-02T19:43:35Z,https://github.com/huggingface/transformers/commit/db979f75882e5fecc55e8aca0c2800e53d4abce8,[time series] Add Time series inputs tests (#21846)  * intial test of inputs  * added test for generation  * remove asserts  * fixed test  * Update tests/models/time_series_transformer/test_modeling_time_series_transformer.py  Co-authored-by: NielsRogge <48327001+NielsRogge@users.noreply.github.com>  ---------  Co-authored-by: NielsRogge <48327001+NielsRogge@users.noreply.github.com>,1,Move Statement,,
216b2f9e8061599982b635f3c6b0240f79d21e95,2022-09-26T13:43:34Z,https://github.com/huggingface/transformers/commit/216b2f9e8061599982b635f3c6b0240f79d21e95,Move the model type check (#19027)  Co-authored-by: Ankur Goyal <ankur@impira.com>,1,Move Statement,,
7b95825d7dddb5896397c806119d1819325c25ff,2022-05-11T19:58:32Z,https://github.com/huggingface/transformers/commit/7b95825d7dddb5896397c806119d1819325c25ff,Remove columns before passing to data collator (#17187),1,Move Statement,,
e8efaecb87715e050e48fcad556d35f0436bbdbc,2022-03-04T17:53:54Z,https://github.com/huggingface/transformers/commit/e8efaecb87715e050e48fcad556d35f0436bbdbc,Move dependency to call method (#15941),1,Move Statement,,
45c7b5b1c7fafe835f16be820a9827422eb606a0,2022-02-10T17:29:27Z,https://github.com/huggingface/transformers/commit/45c7b5b1c7fafe835f16be820a9827422eb606a0,[Generate] Small refactor (#15611),1,Move Statement,,
c40ecfd7408ef6e975c3116c811db6d3a250bc99,2021-12-15T18:34:42Z,https://github.com/huggingface/transformers/commit/c40ecfd7408ef6e975c3116c811db6d3a250bc99,Move import (#14787),1,Move Statement,,
ef8d6f2b4a2c3a5129438b7fa55ec29d4a4601ef,2021-08-31T10:51:25Z,https://github.com/huggingface/transformers/commit/ef8d6f2b4a2c3a5129438b7fa55ec29d4a4601ef,Set missing seq_length variable when using inputs_embeds with ALBERT & Remove code duplication (#13152)  * Set seq_length variable when using inputs_embeds  * remove code duplication,1,Move Statement,,
3fd85777eaed1f9ced24d04535637912a8e0d8e6,2021-07-06T15:44:47Z,https://github.com/huggingface/transformers/commit/3fd85777eaed1f9ced24d04535637912a8e0d8e6,implementing tflxmertmodel integration test (#12497)  * implementing tflxmertmodel integration test  * move import  * revert and fix,1,Move Statement,,
21e86f99e6b91af2e4df3790ba6c781e85fa0eb5,2021-03-19T20:17:13Z,https://github.com/huggingface/transformers/commit/21e86f99e6b91af2e4df3790ba6c781e85fa0eb5,Sort init import (#10801)  * Initial script  * Add script to properly sort imports in init.  * Add to the CI  * Update utils/custom_init_isort.py  Co-authored-by: Lysandre Debut <lysandre@huggingface.co>  * Separate scripts that change content from quality  * Move class_mapping_update to style_checks  Co-authored-by: Lysandre Debut <lysandre@huggingface.co>,1,Move Statement,,
1420b5ff675ccdc3296c6776b339a08a22d2e941,2021-01-29T16:18:04Z,https://github.com/huggingface/transformers/commit/1420b5ff675ccdc3296c6776b339a08a22d2e941,refactor deepspeed setup devices (#9880),1,Move Statement,,
aa60b230ecbe0509b36271cfd4566552e2ff9bd1,2020-12-03T22:15:47Z,https://github.com/huggingface/transformers/commit/aa60b230ecbe0509b36271cfd4566552e2ff9bd1,Patch model parallel test (#8920)  * Patch model parallel test  * Remove line  * Remove `ci_*` from scheduled branches,1,Move Statement,,
5ced23dc845c76d5851e534234b47a5aa9180d40,2020-11-29T15:57:43Z,https://github.com/huggingface/transformers/commit/5ced23dc845c76d5851e534234b47a5aa9180d40,[Pegasus] Refactor Tokenizer (#8731)  * refactor  * further refactor  * fix the rest tomorrow  * save intermediate  * finish slow tokenizer  * make more tests pass  * finish refactor  * fix comment  * clean further  * fix name  * fix naming  * Update src/transformers/models/reformer/tokenization_reformer.py  * Apply suggestions from code review  * Apply suggestions from code review  * refactor  * fix init tokenizers  * refactor  * improve convert  * refactor  * correct convert slow tokenizer  * final fix for Pegasus Tok  * remove ipdb  * improve links,1,Move Statement,,
9bd30f7cf42528543e5fe6a1e084370eee3b9dd6,2020-11-01T22:31:55Z,https://github.com/huggingface/transformers/commit/9bd30f7cf42528543e5fe6a1e084370eee3b9dd6,[Seq2SeqTrainer] Move import to init to make file self-contained (#8194)  * boom boom  * reverse order,1,Move Statement,,
edcb3ac59ab05d9afbc6b4f7bebfb2e5dfc662d2,2020-06-16T07:40:43Z,https://github.com/huggingface/transformers/commit/edcb3ac59ab05d9afbc6b4f7bebfb2e5dfc662d2,refactor(wandb): consolidate import (#5044),1,Move Statement,,
80a169451479f97d737e2be433a7cbd30c39c6bb,2020-04-16T18:00:41Z,https://github.com/huggingface/transformers/commit/80a169451479f97d737e2be433a7cbd30c39c6bb,"[Examples, T5] Change newstest2013 to newstest2014 and clean up  (#3817)  * Refactored use of newstest2013 to newstest2014. Fixed bug where argparse consumed first command line argument as model_size argument rather than using default model_size by forcing explicit --model_size flag inclusion  * More pythonic file handling through 'with' context  * COSMETIC - ran Black and isort  * Fixed reference to number of lines in newstest2014  * Fixed failing test. More pythonic file handling  * finish PR from tholiao  * remove outcommented lines  * make style  * make isort happy  Co-authored-by: Thomas Liao <tholiao@gmail.com>",1,Move Statement,,
6ffe03a0a1d472a4e5941793fd361d2b82c8be3f,2020-03-06T12:06:34Z,https://github.com/huggingface/transformers/commit/6ffe03a0a1d472a4e5941793fd361d2b82c8be3f,Merge pull request #3137 from tomhosking/bart-refactor  Refactor BartModel so that input checks are handled within enc/dec,1,Move Statement,,
06a6cb6f360e88866afdac5c0c4e295ab7da2c9b,2020-03-05T13:45:41Z,https://github.com/huggingface/transformers/commit/06a6cb6f360e88866afdac5c0c4e295ab7da2c9b,Refactor BartModel so that input checks are handled within BartEncoder and BartDecoder,1,Move Statement,,
af1ee9e648e644aae45c5250a46d4c25a4e0d04d,2020-01-10T10:42:53Z,https://github.com/huggingface/transformers/commit/af1ee9e648e644aae45c5250a46d4c25a4e0d04d,Move `torch.nn.utils.clip_grad_norm_`,1,Move Statement,,
a80778f40e4738071b5d01420a0328bb00cdb356,2019-12-20T22:21:24Z,https://github.com/huggingface/transformers/commit/a80778f40e4738071b5d01420a0328bb00cdb356,"small refactoring (only esthetic, not functional)",1,Move Statement,,
cb26b035c696f32b7f47df18a6d84b88b7b1745d,2019-10-28T09:49:49Z,https://github.com/huggingface/transformers/commit/cb26b035c696f32b7f47df18a6d84b88b7b1745d,remove potential UndefinedError,1,Move Statement,,
b219029c4566eebd4183219719c8e86f4671163c,2019-08-11T07:20:37Z,https://github.com/huggingface/transformers/commit/b219029c4566eebd4183219719c8e86f4671163c,refactoring old run_swag. This script is mainly refatored from run_squad in pytorch_transformers,1,Move Statement,,
fa0c5a2ea1da8ce9049a9e6f12a712b7c58a7119,2018-11-13T15:24:53Z,https://github.com/huggingface/transformers/commit/fa0c5a2ea1da8ce9049a9e6f12a712b7c58a7119,clean up pr,1,Move Statement,,
3ddff783c142f56b3b48cb1ab8ec919281ee9800,2018-11-04T20:26:44Z,https://github.com/huggingface/transformers/commit/3ddff783c142f56b3b48cb1ab8ec919281ee9800,clean up + mask is long,1,Move Statement,,
642c3e849899739682e7fc637bfbd4c7a0f2fdd7,2020-10-21T21:51:14Z,https://github.com/tensorflow/tensorflow/commit/642c3e849899739682e7fc637bfbd4c7a0f2fdd7,"Move mixed precision files out of experimental/ directory.This is a purely mechanical change. All that is done is:* Deleted python/keras/mixed_precision/experimental/__init__.py* All other files in python/keras/mixed_precision/experimental/ are moved one directly up, out of the experimental/ folder* All Python imports, BUILD dependencies, and other references to the old experimental files are adjusted to refer to the new locationThis changes the API golden files, but there is no API change. The golden files referred to the full paths of the classes in ""is_instance"" sections, and the full paths have changed.PiperOrigin-RevId: 338345459Change-Id: I9eefc2bea49b71f26ef7ec3563364a3f1d54abe6",1,Move Module,,
dd2b59ae182b731b1f0a913b0cfb9ed673f778c6,2020-07-31T16:01:10Z,https://github.com/tensorflow/tensorflow/commit/dd2b59ae182b731b1f0a913b0cfb9ed673f778c6,Move session_ops_test.py under ./v1_compat_tests/Session ops are V1 API.PiperOrigin-RevId: 324217477Change-Id: I11e03dc00dc0de23d327970715b6a387372500ee,1,Move Module,,
e1d3f777be8015dedb03fb2e5fe77c849acfdd76,2020-07-31T01:49:16Z,https://github.com/tensorflow/tensorflow/commit/e1d3f777be8015dedb03fb2e5fe77c849acfdd76,Move gradient_checker_test.py under ./v1_compat_tests/gradient_checker.py is v1 testing util and deprecated by gradient_checker_v2.pyPiperOrigin-RevId: 324128680Change-Id: I2b9b72bb37297c8c73e7560d3d23186c306a8a29,1,Move Module,,
393242481acb5bfb3bbd8ae074499888d5432ef2,2020-07-09T16:43:45Z,https://github.com/tensorflow/tensorflow/commit/393242481acb5bfb3bbd8ae074499888d5432ef2,Move the optimizer related combination/tests to keras/distribute.PiperOrigin-RevId: 320414544Change-Id: If367f96c1f37fd48c23d68411cbbbb407888186f,1,Move Module,,
5b61b7cc82cc2d5bc6b3998a30f30b2fc3629f0f,2020-07-09T03:59:47Z,https://github.com/tensorflow/tensorflow/commit/5b61b7cc82cc2d5bc6b3998a30f30b2fc3629f0f,Move keras model related combinations and tests to keras/distribute.PiperOrigin-RevId: 320323035Change-Id: Ib56fe5246339a43f69c6761bc0ced725c3368550,1,Move Module,,
86fa7c3fc791d16e1dc62d9765be168fa6c1bf64,2020-07-08T16:26:21Z,https://github.com/tensorflow/tensorflow/commit/86fa7c3fc791d16e1dc62d9765be168fa6c1bf64,Fork the checkpointing_test and move the keras related test to keras/distribute.PiperOrigin-RevId: 320202511Change-Id: I0c57c90847915bd702e4fa204653a76f7cd65c38,1,Move Module,,
225729dc760514be6ce3e8b4674e94cab4b2379f,2020-06-26T21:31:42Z,https://github.com/tensorflow/tensorflow/commit/225729dc760514be6ce3e8b4674e94cab4b2379f,Move Keras benchmark test from Keras/tests to Keras/benchmark.PiperOrigin-RevId: 318544697Change-Id: Ia0d372fdecae1b14fa5c8a24ef2cc1e7feada741,1,Move Module,,
2ff0335ff1b884a3cb2f36d36c5d37cf2753231a,2020-06-24T23:27:14Z,https://github.com/tensorflow/tensorflow/commit/2ff0335ff1b884a3cb2f36d36c5d37cf2753231a,Move keras_save_load_test to keras/distributePiperOrigin-RevId: 318163436Change-Id: Ia0d60bdf7d47de0efe32dfa84778168db4cee0b5,1,Move Module,,
68fe003b85997020d7d0d9bac03400230ba4bf63,2020-06-23T20:59:05Z,https://github.com/tensorflow/tensorflow/commit/68fe003b85997020d7d0d9bac03400230ba4bf63,Move the keras related CTL training test to keras/distribute.PiperOrigin-RevId: 317934704Change-Id: Iafccd476f87c2ff04c8fbbe9910239ac6d2b7cf3,1,Move Module,,
8d31fb4b765260a6d0bcaf825ca68766b5b798ee,2020-05-28T17:47:27Z,https://github.com/tensorflow/tensorflow/commit/8d31fb4b765260a6d0bcaf825ca68766b5b798ee,Refactor values.py into a utility file and a PS values file.PiperOrigin-RevId: 313617630Change-Id: Ie51b0f69af65b3f85701f58190da2c7eb46e1d29,1,Move Module,,
ff551c9f20606b9d23d4c89730669fa8db368192,2020-04-06T22:48:25Z,https://github.com/tensorflow/tensorflow/commit/ff551c9f20606b9d23d4c89730669fa8db368192,Internal cleanup: Move the bulk of the source code transformation infrastructure into the generic pyct module.PiperOrigin-RevId: 305135067Change-Id: Ifb84546c35a603942fd864769e7320a7ae95da3b,1,Move Module,,
3543d8daa5c3aec54ade348c0aeb98271d0afda9,2020-03-09T22:07:46Z,https://github.com/tensorflow/tensorflow/commit/3543d8daa5c3aec54ade348c0aeb98271d0afda9,Move keras utils to frozen_keras.PiperOrigin-RevId: 299945493Change-Id: I468280314287beda9811f8a7b24f5d9d6eedd238,1,Move Module,,
969d0f45bd3f93f2c782814af52909b482418936,2020-03-09T20:41:26Z,https://github.com/tensorflow/tensorflow/commit/969d0f45bd3f93f2c782814af52909b482418936,Move backend module to frozen_keras.Will remove all the unused functions in a follwo up CL so that this onecontains only clean copy.PiperOrigin-RevId: 299922955Change-Id: I0a6e262148b871dadcdb24a1da28093b8f04b065,1,Move Module,,
105c91f2c42e576a2b6cc5ff6e4d0e1992403eba,2020-03-09T17:49:29Z,https://github.com/tensorflow/tensorflow/commit/105c91f2c42e576a2b6cc5ff6e4d0e1992403eba,Move more layer related utils to frozen_keras.PiperOrigin-RevId: 299879819Change-Id: Iebf2ea84be845bb09b926bdb3391375965e150aa,1,Move Module,,
d58e8594e146636605e2669c646bd0bfcd454e0e,2019-12-06T22:02:05Z,https://github.com/tensorflow/tensorflow/commit/d58e8594e146636605e2669c646bd0bfcd454e0e,Move image preprocessing layers to `layers/preprocessing`PiperOrigin-RevId: 284257328Change-Id: I1118722d3084c456f982a7baaa8b65c97dae3292,1,Move Module,,
6d578bfc62e83b7b9c6d35c3bc8473b28068a974,2019-08-30T13:54:52Z,https://github.com/tensorflow/tensorflow/commit/6d578bfc62e83b7b9c6d35c3bc8473b28068a974,[TF:XLA] Move XLA tests that depend on contrib in preparation for TF 2.0PiperOrigin-RevId: 266370065,1,Move Module,,
4bdc9d0ee66b0e1038935d71988eff361d537d64,2019-07-31T23:25:50Z,https://github.com/tensorflow/tensorflow/commit/4bdc9d0ee66b0e1038935d71988eff361d537d64,Move GPU-only collective ops Python tests to a separate file.PiperOrigin-RevId: 261021178,1,Move Module,,
d1bf811d7a8542e535ea36b5c602490847d7fe61,2019-07-11T17:45:25Z,https://github.com/tensorflow/tensorflow/commit/d1bf811d7a8542e535ea36b5c602490847d7fe61,Move ObjectIdentity to python/utilsPiperOrigin-RevId: 257637727,1,Move Module,,
ef8dc7d15393bd3b189b672c2fd93578ffdf4e8b,2019-05-16T16:45:13Z,https://github.com/tensorflow/tensorflow/commit/ef8dc7d15393bd3b189b672c2fd93578ffdf4e8b,Tensor tracer refactor.PiperOrigin-RevId: 248544325,1,Move Module,,
ea6269d9795432869067c824e905a7e7277166e1,2019-04-03T02:23:50Z,https://github.com/tensorflow/tensorflow/commit/ea6269d9795432869067c824e905a7e7277166e1,Move distribute/keras_multi_worker_test.py from contrib to core.PiperOrigin-RevId: 241650752,1,Move Module,,
e98a897f188af80d1fdc04676283aaa649bcffbe,2019-01-29T03:37:42Z,https://github.com/tensorflow/tensorflow/commit/e98a897f188af80d1fdc04676283aaa649bcffbe,Move one_device_strategy from contrib to core.PiperOrigin-RevId: 231333409,1,Move Module,,
e14e62133cc72bafb2fd3251dc4e6b7116b2f4ad,2018-11-26T02:01:45Z,https://github.com/tensorflow/tensorflow/commit/e14e62133cc72bafb2fd3251dc4e6b7116b2f4ad,"Move distribute.py, distribution_strategy_context.py, and device_util.pyfrom training/ to distribute/.PiperOrigin-RevId: 222761376",1,Move Module,,
847ddaedf2cdd59c2d6bf49576466ef440a903f7,2018-10-02T07:07:44Z,https://github.com/tensorflow/tensorflow/commit/847ddaedf2cdd59c2d6bf49576466ef440a903f7,Move matching_files_dataset_serialization_test.py to tf.data.experimental,1,Move Module,,
7f265d14f9da8214a1868464baa7ea8f4ece7121,2018-06-15T03:08:22Z,https://github.com/tensorflow/tensorflow/commit/7f265d14f9da8214a1868464baa7ea8f4ece7121,Move xla_sharding related code to third_partyPiperOrigin-RevId: 200661547,1,Move Module,,
609b2ce3fe8ebecf4031670b8c2186468369b0ba,2018-05-18T04:36:39Z,https://github.com/tensorflow/tensorflow/commit/609b2ce3fe8ebecf4031670b8c2186468369b0ba,Move Keras code out of _impl folder and remove API files.PiperOrigin-RevId: 197097430,1,Move Module,,
ac39aec50ff359ae915d13a011fdb905b8c48af0,2018-03-30T01:15:34Z,https://github.com/tensorflow/tensorflow/commit/ac39aec50ff359ae915d13a011fdb905b8c48af0,Move the simple_estimator_example to the examples/ dir.PiperOrigin-RevId: 191017560,1,Move Module,,
3374643a2d1a00f57acf501023e487f101c7a04c,2018-03-09T20:39:41Z,https://github.com/tensorflow/tensorflow/commit/3374643a2d1a00f57acf501023e487f101c7a04c,"Move warm_starting_util from third_party/tensorflow/python/estimator to third_party/tensorflow/python/training (move WarmStartSettings definition to third_party/tensorflow/python/estimator/estimator.py), and make _warm_start() public under tf.train.warm_start().  WarmStartSettings and VocabInfo are both available under tf.estimator, and VocabInfo is also available under tf.train.PiperOrigin-RevId: 188522820",1,Move Module,,
620348fb6d045dc1f644925a3828ebb12de944d7,2018-02-26T18:24:56Z,https://github.com/tensorflow/tensorflow/commit/620348fb6d045dc1f644925a3828ebb12de944d7,Move accumulate_n_v2 to core.PiperOrigin-RevId: 187042001,1,Move Module,,
3ce1adbdf7b1f9a4a53d5438985d12b6526dbd14,2018-02-26T18:24:56Z,https://github.com/tensorflow/tensorflow/commit/3ce1adbdf7b1f9a4a53d5438985d12b6526dbd14,Move accumulate_n_v2 to core.PiperOrigin-RevId: 187042001,1,Move Module,,
53700ca21a4521ad62904fc596cf5f14c4cc46d1,2018-02-20T20:19:02Z,https://github.com/tensorflow/tensorflow/commit/53700ca21a4521ad62904fc596cf5f14c4cc46d1,"Move the `maxout` layer implementation to contrib.In September 2017, a contributor from GitHub added a MaxOut layer in tf.layers.It was never added to the public API. Instead, it was only listed as part of theAPI of tf.contrib.layers. This CL moves it out of tf.layers.PiperOrigin-RevId: 186343115",1,Move Module,,
38a1921ae911d2a7ade487bf3f80ba932dd53988,2018-01-19T20:00:33Z,https://github.com/tensorflow/tensorflow/commit/38a1921ae911d2a7ade487bf3f80ba932dd53988,Move layers_dense_variational_impl.py to layers_dense_variational.py.PiperOrigin-RevId: 182568201,1,Move Module,,
f080052284a4a39113051fb1178d91365e9872a8,2017-10-19T22:27:52Z,https://github.com/tensorflow/tensorflow/commit/f080052284a4a39113051fb1178d91365e9872a8,Move text_classification_character_rnn from .contrib utils to .core utils.Also removes sklearn comparison.PiperOrigin-RevId: 172808535,1,Move Module,,
2b91b812ef50384cd0526ea513f1cf585adb6ef7,2017-10-18T23:03:56Z,https://github.com/tensorflow/tensorflow/commit/2b91b812ef50384cd0526ea513f1cf585adb6ef7,Move random tests to a separate subdirectory.This in preparation for refactoring the tests to use a common library.PiperOrigin-RevId: 172670730,1,Move Module,,
66ed3d877ff6f2639339e7661e7fa8b2664190a5,2017-08-30T23:41:50Z,https://github.com/tensorflow/tensorflow/commit/66ed3d877ff6f2639339e7661e7fa8b2664190a5,Move most of checkpoint_ops and tests from contrib to core (private in core with public contrib alias).  Modified unit tests to use ephemeral checkpoints / vocabularies instead of checked-in testdata.PiperOrigin-RevId: 167068777,1,Move Module,,
a16a92f104fea20da6c0a62ebe2d91ab03429e29,2017-05-02T21:15:17Z,https://github.com/tensorflow/tensorflow/commit/a16a92f104fea20da6c0a62ebe2d91ab03429e29,[tf distributions] Move the remaining whitelisted distributions to core.Change: 154878206,1,Move Module,,
68c514faa9470d2bd8aed797339f048c50ed6317,2017-05-01T21:44:57Z,https://github.com/tensorflow/tensorflow/commit/68c514faa9470d2bd8aed797339f048c50ed6317,"[tf distributions] Move kullback_leibler, special_math, and Normal into TF core.Also, renamed distributions.kl to distributions.kl_divergence.In core, scipy can't be required for unit tests, so added some lazy importingand checking for scipy modules in the normal and special_math tests.Change: 154763133",1,Move Module,,
2c558ed16f142b5fe7d74ae4a2dc45d69ef8ce89,2017-04-19T01:10:14Z,https://github.com/tensorflow/tensorflow/commit/2c558ed16f142b5fe7d74ae4a2dc45d69ef8ce89,Move checkpoint_utils to core.Change: 153538294,1,Move Module,,
9e940ec9f130065027796de3765f14d2dd863a13,2017-04-10T17:05:22Z,https://github.com/tensorflow/tensorflow/commit/9e940ec9f130065027796de3765f14d2dd863a13,Move the TensorBoard debugger plugin to be internal.This feature is currently not open-source anyway.Change: 152700267,1,Move Module,,
411f26595861ca28809e3178f79fadcf378cabd6,2017-03-10T10:44:38Z,https://github.com/tensorflow/tensorflow/commit/411f26595861ca28809e3178f79fadcf378cabd6,graph_editor: move match.py into the the test folder as it is not meant to be part of the graph_editor public API.Change: 149741516,1,Move Module,,
6e63cd2afb9e47a7e4f236c42786f94450be04ec,2017-02-16T02:25:55Z,https://github.com/tensorflow/tensorflow/commit/6e63cd2afb9e47a7e4f236c42786f94450be04ec,Move bijectors into distinct files.Change: 147671926,1,Move Module,,
66d8b006d5607a523fa60e0a58db31316b06943e,2017-01-31T00:42:53Z,https://github.com/tensorflow/tensorflow/commit/66d8b006d5607a523fa60e0a58db31316b06943e,Move bayesflow.special_math to distributions where it belongs.Change: 146056965,1,Move Module,,
37fbebdd6c3c8f274896cc36e6feb5b7e2097a59,2016-12-22T05:14:42Z,https://github.com/tensorflow/tensorflow/commit/37fbebdd6c3c8f274896cc36e6feb5b7e2097a59,Move the implementation code of rnn_cells to contrib.Change: 142730769,1,Move Module,,
0e5015bb7d58dc273e019a19875b55bf9c362950,2016-12-03T01:43:26Z,https://github.com/tensorflow/tensorflow/commit/0e5015bb7d58dc273e019a19875b55bf9c362950,Moves most metrics from contrib into core.Change: 140914784,1,Move Module,,
896285a8dca7bddbf328b3728683acf619f26c13,2016-12-02T16:56:45Z,https://github.com/tensorflow/tensorflow/commit/896285a8dca7bddbf328b3728683acf619f26c13,"Moves tf.contrib.losses into core, with changes.Change: 140855283",1,Move Module,,
f9b6d55ffd630082efd088fca927f7d991fdf3fa,2016-11-02T23:31:56Z,https://github.com/tensorflow/tensorflow/commit/f9b6d55ffd630082efd088fca927f7d991fdf3fa,"Move the last skflow examples into learn examples. Remove skflow examples folder. Fixes #2606. Deleted usage of learn.models.logistic_regression, learn.ops.*.Change: 138010275",1,Move Module,,
6bd7f4d7d7866db1d1406266f25d656bc5f54364,2016-11-01T18:41:24Z,https://github.com/tensorflow/tensorflow/commit/6bd7f4d7d7866db1d1406266f25d656bc5f54364,Move deprecation module into core framework from contrib/frameworkChange: 137850119,1,Move Module,,
8a162085d1e448b9b376656b170c7023477eccc8,2016-10-13T22:38:44Z,https://github.com/tensorflow/tensorflow/commit/8a162085d1e448b9b376656b170c7023477eccc8,Moves tests from contrib/learn/tests to a better place whenever possible.Change: 136095744,1,Move Module,,
09d8a0c16a1e5212e345dcb0358cf0bab2440bda,2016-10-13T21:33:15Z,https://github.com/tensorflow/tensorflow/commit/09d8a0c16a1e5212e345dcb0358cf0bab2440bda,Moves tests in contrib/learn/python/learn/ops/tests one directory up.Change: 136087206,1,Move Module,,
130a6b924f0507f6bd25e1cbd6b10705aa848250,2016-09-05T04:15:03Z,https://github.com/tensorflow/tensorflow/commit/130a6b924f0507f6bd25e1cbd6b10705aa848250,Move metric_spec_test to tests/ directory. If mixed in with code python caching confuses io imports.Change: 132209654,1,Move Module,,
e00866a19bd2c46ecd51f51e8da7f025246be775,2016-08-23T19:06:36Z,https://github.com/tensorflow/tensorflow/commit/e00866a19bd2c46ecd51f51e8da7f025246be775,Move `stratified_sample` from contrib/framework to contrib/training.Change: 131082787,1,Move Module,,
d6ffea69b3b13de8b9620989d8b91f6d3c961190,2016-07-26T21:42:15Z,https://github.com/tensorflow/tensorflow/commit/d6ffea69b3b13de8b9620989d8b91f6d3c961190,"Change assignment_map in 'init_from_checkpoint' so it can support initializing partitioned variables by passing in list of tf.Variables. Also, move contrib/learn/python/learn/utils/checkpoints.py to contrib/framework/python/framework/checkpoint_utils.pyChange: 128516396",1,Move Module,,
6290ac2c25a4f4310e072cf1472afea38031bf59,2016-06-21T16:43:07Z,https://github.com/tensorflow/tensorflow/commit/6290ac2c25a4f4310e072cf1472afea38031bf59,Move library 'gradient_checker' out of kernel_tests/ into ops/.Change: 125460867,1,Move Module,,
4c7fde3025c70bfd19291511f0360eaab48f8c0d,2016-06-15T10:23:39Z,https://github.com/tensorflow/tensorflow/commit/4c7fde3025c70bfd19291511f0360eaab48f8c0d,Move nest utilities to util.Change: 124934349,1,Move Module,,
48bbc913c9b5a01bea6f5329032d99d949b49aac,2016-05-04T14:17:15Z,https://github.com/tensorflow/tensorflow/commit/48bbc913c9b5a01bea6f5329032d99d949b49aac,Move graph_actions.py to opensource tf.learnChange: 121478283,1,Move Module,,
86ddfc7a007d7e26f7c00df488969e302f5cd7a1,2016-03-14T21:20:59Z,https://github.com/tensorflow/tensorflow/commit/86ddfc7a007d7e26f7c00df488969e302f5cd7a1,Moved session_manager and supervisor to third_party.Change: 117170777,1,Move Module,,
6d7e23d98e516988e04455d93bde9a66d8e79566,2022-12-06T18:37:06Z,https://github.com/keras-team/keras/commit/6d7e23d98e516988e04455d93bde9a66d8e79566,Move saving_lib to core.  PiperOrigin-RevId: 493348338,1,Move Module,,
3aa346492630e5d93f0bcbb1024e93db37cc5429,2022-11-18T19:23:35Z,https://github.com/keras-team/keras/commit/3aa346492630e5d93f0bcbb1024e93db37cc5429,Move utils.py out of optimizer_v2/ as it is used by both new and old optimizer.  PiperOrigin-RevId: 489521018,1,Move Module,,
5a105aadbdc6fde2c2529280c4789864adbb81c7,2022-11-16T19:50:08Z,https://github.com/keras-team/keras/commit/5a105aadbdc6fde2c2529280c4789864adbb81c7,Move new optimizer out of optimizer_experimental/ directory.  PiperOrigin-RevId: 488998585,1,Move Module,,
eaaea7fd451adb82149603efa4478a820651be79,2022-10-06T03:04:37Z,https://github.com/keras-team/keras/commit/eaaea7fd451adb82149603efa4478a820651be79,Move saving/experimental out of saving/legacy.  PiperOrigin-RevId: 479205833,1,Move Module,,
c06aa015e900a2029b5b379f374e5d4dc615fcbf,2022-10-05T17:08:56Z,https://github.com/keras-team/keras/commit/c06aa015e900a2029b5b379f374e5d4dc615fcbf,"Moves all files currently in saving/ to saving/legacy/ (except for pickle_utils, object_registation, and their tests).  PiperOrigin-RevId: 479075288",1,Move Module,,
e4c420847998af168cec18aa71ceac3c170157a2,2022-09-23T22:23:45Z,https://github.com/keras-team/keras/commit/e4c420847998af168cec18aa71ceac3c170157a2,Moving SidecarEvaluator API from keras.distribute to keras.utils.  PiperOrigin-RevId: 476474678,1,Move Module,,
b3505ddac4a7f1d20ae28fd6474a96ca9e37b3fc,2022-09-21T04:00:21Z,https://github.com/keras-team/keras/commit/b3505ddac4a7f1d20ae28fd6474a96ca9e37b3fc,Move object registration logic to keras/saving/.  PiperOrigin-RevId: 475724528,1,Move Module,,
bd9768c799be6691734501afde664e5e0dc4b53e,2022-03-17T18:28:36Z,https://github.com/keras-team/keras/commit/bd9768c799be6691734501afde664e5e0dc4b53e,Move the keras dataset utilities to utils directory  PiperOrigin-RevId: 435400313,1,Move Module,,
d0379e270c90ce4556a2a98a39a10ca3ff8991b9,2022-03-09T21:02:46Z,https://github.com/keras-team/keras/commit/d0379e270c90ce4556a2a98a39a10ca3ff8991b9,Move `Embedding` layer files in the `core` directory.  PiperOrigin-RevId: 433554044,1,Move Module,,
b96518a22bfd92a29811e507dec0b34248a8a3f5,2022-02-06T21:31:39Z,https://github.com/keras-team/keras/commit/b96518a22bfd92a29811e507dec0b34248a8a3f5,"- Consolidate disparate test-related files into a single testing_infra folder. - Cleanup TODO related to removing testing infra as a dependency of the Keras target. - Standardize import naming: there is now only ""test_combinations"" for test combinations, and ""test_utils"" for utilities. The TF utilities module ""test_util"" is now always imported as ""tf_test_utils"" to avoid confusion.  PiperOrigin-RevId: 426773173",1,Move Module,,
56c8e70854f85df4fa8bf4b91bbb264174450e85,2022-02-03T20:32:48Z,https://github.com/keras-team/keras/commit/56c8e70854f85df4fa8bf4b91bbb264174450e85,Consolidate disparate optimizer-related files into a single `optimizers` folder.  PiperOrigin-RevId: 426212662,1,Move Module,,
622d125d5f145dd6809da0646f57c644103e62d5,2022-01-31T17:50:50Z,https://github.com/keras-team/keras/commit/622d125d5f145dd6809da0646f57c644103e62d5,"Rename ""premade"" (the meaning of which was ambiguous) to ""premade_models"" (clearer).  PiperOrigin-RevId: 425391668",1,Move Module,,
3e6db0e99ef56b23b3977b5969413d0b636a6fad,2019-02-16T00:47:42Z,https://github.com/keras-team/keras/commit/3e6db0e99ef56b23b3977b5969413d0b636a6fad,Moved the documentation tests in a subdirectory. (#12228),1,Move Module,,
4bcb8c95d8bba3147dd86446cd91be77051cef96,2018-08-25T22:00:07Z,https://github.com/keras-team/keras/commit/4bcb8c95d8bba3147dd86446cd91be77051cef96,Moved the preprocessing tests into the integration directory. (#10963)  * Moved the preprocessing tests into the integration directory. Allow us to removed the installation of PIL/Pillow in most builds.  * Enable the install of PIL/ Pillow for pep8.  * Added a coverage exception for keras/preprocessing/*,1,Move Module,,
22c54e9615f91dda7bf791e85bec8cbc58638023,2018-02-21T18:07:15Z,https://github.com/keras-team/keras/commit/22c54e9615f91dda7bf791e85bec8cbc58638023,Move tests for datasets (#9439),1,Move Module,,
1ebeff8ee304833a3df421d0de3b9f9480570eb9,2016-03-07T01:31:57Z,https://github.com/keras-team/keras/commit/1ebeff8ee304833a3df421d0de3b9f9480570eb9,Move data_utils to utils.data_utils.,1,Move Module,,
421a2cdf04b636a582a1b952332553339e9d70be,2016-01-01T19:07:19Z,https://github.com/keras-team/keras/commit/421a2cdf04b636a582a1b952332553339e9d70be,Move batch norm tests to tests/keras/layers/,1,Move Module,,
57d5a7ca78a057dffee1c162359453b387b7ced1,2015-12-08T12:48:59Z,https://github.com/keras-team/keras/commit/57d5a7ca78a057dffee1c162359453b387b7ced1,Move embedding test to keras/layers,1,Move Module,,
fe6c554e7a9ac970a8f7881019d8bd535bead304,2015-12-08T12:44:03Z,https://github.com/keras-team/keras/commit/fe6c554e7a9ac970a8f7881019d8bd535bead304,Moved dataset tests to keras/datasets,1,Move Module,,
ef4250fc05b23522b356e83ca8368197804923a9,2015-06-22T19:05:01Z,https://github.com/keras-team/keras/commit/ef4250fc05b23522b356e83ca8368197804923a9,Move recurrent mask tests into new directory layout,1,Move Module,,
f89b3397bbb6377186fe050b421cd2e0fa75ebee,2018-06-02T17:21:06Z,https://github.com/keras-team/keras/commit/f89b3397bbb6377186fe050b421cd2e0fa75ebee,Move tests for applications (#10341),1,Move Module,,
151483e25dca71b9fb8e78d084a9eb3583da1b05,2019-10-14T22:57:21Z,https://github.com/pytorch/pytorch/commit/151483e25dca71b9fb8e78d084a9eb3583da1b05,move import_class_test files around (#26722)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/26722Put them in a directory under jit/ to prep for test splittingTest Plan: Imported from OSSDifferential Revision: D17550582Pulled By: suofbshipit-source-id: a592b671ffe808f02d0a597d441bd98a18c9109e,1,Move Module,,
2b0d7e63f0c146152ec4786fe8799ce2ec17fe7c,2023-02-02T20:42:17Z,https://github.com/pytorch/pytorch/commit/2b0d7e63f0c146152ec4786fe8799ce2ec17fe7c,Move dynamo.optimizations.distributed to backends (#93408)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/93408 Approved by: https://github.com/wconstab,1,Move Module,,
3329f36f1a40666a0a92918ec0ad43eb0dd8fd20,2018-01-04T01:08:17Z,https://github.com/pytorch/pytorch/commit/3329f36f1a40666a0a92918ec0ad43eb0dd8fd20,Move load_save_test.py from caffe2/python/ to caffe2/python/operator_test/Summary: Move load_save_test.py from caffe2/python to caffe2/python/operator_test/Reviewed By: boryiingsuDifferential Revision: D6657724fbshipit-source-id: 030942316444ec93c3bc2970902d7b3980e60cfc,1,Move Module,,
4bd8ae13c68644b977e10ab87ac57e7332fb7994,2019-10-08T00:22:33Z,https://github.com/pytorch/pytorch/commit/4bd8ae13c68644b977e10ab87ac57e7332fb7994,"Move hipify to torch/utils to bundle them into torch package (#27425)Summary:Similar to https://github.com/pytorch/pytorch/pull/27418 but try to put it under ""torch"" namespacePull Request resolved: https://github.com/pytorch/pytorch/pull/27425Differential Revision: D17779490Pulled By: bddppqfbshipit-source-id: 688338d143509b37dfc110df17af3331db48a42b",1,Move Module,,
515dff78112e47ceb0fb832a29381230aa32d6d1,2023-01-12T19:15:41Z,https://github.com/pytorch/pytorch/commit/515dff78112e47ceb0fb832a29381230aa32d6d1,[functorch] move batch_norm_replacement to torch.func (#91412)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/91412 Approved by: https://github.com/zou3519,1,Move Module,,
6273c0af9513895f0597ae1801f37164d7b46d2a,2023-03-22T17:19:26Z,https://github.com/pytorch/pytorch/commit/6273c0af9513895f0597ae1801f37164d7b46d2a,move caffe2/proto/ to its own Bazel package (#97324)  move caffe2/proto/ to its own Bazel package  Summary: This is just to break up build files and make the system easier to reason about during the transition to the common build system.  Test Plan: Verified locally and rely on CI.  Reviewers: sahanp  Subscribers:  Tasks:  Tags:  --- Stack created with [Sapling](https://sapling-scm.com). Best reviewed with [ReviewStack](https://reviewstack.dev/pytorch/pytorch/pull/97324). * #97337 * #97336 * #97335 * #97334 * #97325 * __->__ #97324 * #97323 * #97322 Pull Request resolved: https://github.com/pytorch/pytorch/pull/97324 Approved by: https://github.com/malfet,1,Move Module,,
6fb8423904f6a05e847f3c66e7c6ca3bd58c2906,2022-11-30T20:31:55Z,https://github.com/pytorch/pytorch/commit/6fb8423904f6a05e847f3c66e7c6ca3bd58c2906,"[FSDP] Slightly refactor fx symbolic tracer (#89917)  I made a pass over Linjian's `_symbolic_trace.py` and tidied it up a bit. Aside from simple stylistic changes, this PR makes the following changes: - Save `visited_params: Set[nn.Parameter]` to avoid linear overhead to check a parameter already being visited when appending to the parameter execution order list (`param_forward_order`) - Move the tracer patching logic to a class `_ExecOrderTracer` to have a reference to `self.exec_info` without having a fragmented 2-step initialization (like the old `_init_execution_info(root_module)` plus `_patch_tracer(tracer, root_module, execution_info)`) - Define `_ParamUsageInfo` to formalize the `Tuple[nn.Module, List[str, nn.Parameter]]` elements being mapped to in the execution info `dict`, and clarify the documentation regarding what this represents - Change the unit test to use `TestCase`, not `FSDPTest`, to avoid initializing a process group  Pull Request resolved: https://github.com/pytorch/pytorch/pull/89917 Approved by: https://github.com/zhaojuanmao, https://github.com/fegin",1,Move Module,,
74089a0d34ec9fd2dda8860ac2638e68271955dd,2021-05-27T06:02:12Z,https://github.com/pytorch/pytorch/commit/74089a0d34ec9fd2dda8860ac2638e68271955dd,[quant][refactor tests] Move quantization tests into subfolders (#59007)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/59007  Create folders for each test category and move the tests. Will follow-up with a cleanup of test_quantization.py  Test Plan: python test/test_quantization.py  Imported from OSS  Reviewed By: HDCharles  Differential Revision: D28718742  fbshipit-source-id: 4c2dbbf36db35d289df9708565b7e88e2381ff04,1,Move Module,,
741d0f41d643fe61160a6481d86dc0d86dda66c5,2021-03-11T00:03:53Z,https://github.com/pytorch/pytorch/commit/741d0f41d643fe61160a6481d86dc0d86dda66c5,"[package] split tests (#53749)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/53749Split up tests into cases that cover specific functionality. Goals:1. Avoid the omnibus test file mess (see: test_jit.py) by imposing early   structure and deliberately avoiding a generic TestPackage test case.2. Encourage testing of individual APIs and components by example.3. Hide the fake modules we created for these tests in their own folder.You can either run the test files individually, or still usetest/test_package.py like before.Also this isort + black formats all the tests.Test Plan: Imported from OSSReviewed By: SplitInfinityDifferential Revision: D26958535Pulled By: suofbshipit-source-id: 8a63048b95ca71f4f1aa94e53c48442686076034",1,Move Module,,
778fd1922ae127250126e845ecd4a1cb9e335fb5,2023-04-11T17:26:29Z,https://github.com/pytorch/pytorch/commit/778fd1922ae127250126e845ecd4a1cb9e335fb5,[core][pruning][be] Rename sparsifier folder to pruner (#98758)  Summary: att  Test Plan: ``` python test/test_ao_sparsity.py ``` Pull Request resolved: https://github.com/pytorch/pytorch/pull/98758 Approved by: https://github.com/jerryzh168,1,Move Module,,
7f44c0d01167ad8e85b16d2f248daa5fa262a9ef,2018-03-09T03:17:59Z,https://github.com/pytorch/pytorch/commit/7f44c0d01167ad8e85b16d2f248daa5fa262a9ef,rename onnx/utils/__init__.py -> onnx/utils.py (#5639),1,Move Module,,
a1c5eba4bd797a62c580627e687e7c23f62f1742,2021-02-02T02:52:26Z,https://github.com/pytorch/pytorch/commit/a1c5eba4bd797a62c580627e687e7c23f62f1742,[FX] Move some heavily used passes out of experimental (#51392)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/51392Test Plan: Imported from OSSReviewed By: ChilleeDifferential Revision: D26161172Pulled By: jamesr66afbshipit-source-id: 04bfe606555bdf1988f527231d4de2e0196e6b37,1,Move Module,,
a6d26ce135de1a810da7eed05fe2f8c04b63adca,2019-10-08T18:22:18Z,https://github.com/pytorch/pytorch/commit/a6d26ce135de1a810da7eed05fe2f8c04b63adca,Move internal functions to torch.distributed.rpcSummary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/27289Test Plan: Imported from OSSDifferential Revision: D17808214Pulled By: pieternfbshipit-source-id: 4c453028e431c3e951d439784017ef07037ba1a9,1,Move Module,,
bcf63930242cd79866072e3e51d06d7d4838f50b,2023-04-17T16:07:03Z,https://github.com/pytorch/pytorch/commit/bcf63930242cd79866072e3e51d06d7d4838f50b,"[PT2E][Quant][BE] Move pt2e quantization test to separate folder (#99064)  Move it out of fx for better code organizations  Differential Revision: [D44918496](https://our.internmc.facebook.com/intern/diff/D44918496/)  **NOTE FOR REVIEWERS**: This PR has internal Meta-specific changes or comments, please review them on [Phabricator](https://our.internmc.facebook.com/intern/diff/D44918496/)! Pull Request resolved: https://github.com/pytorch/pytorch/pull/99064 Approved by: https://github.com/jerryzh168",1,Move Module,,
d8b7166251aac7fa115d1ee964209462edad8be7,2017-02-17T01:47:27Z,https://github.com/pytorch/pytorch/commit/d8b7166251aac7fa115d1ee964209462edad8be7,"Move build_ftrl to open source directorySummary:Move the open source version of build_ftrl to the open source directory.Because build_ftrl can use several engines, the SIMD engine is fb specific.We keep the build_ftrl in the fb/optimizers/sgd.py file.So, if the caller only uses the open source engine, it can import theopen source build_ftrl. If the caller may use the SIMD engine, it needsto import the fb specific build_ftrl.Also move the tests to python directory.Reviewed By: salexspbDifferential Revision: D4560384fbshipit-source-id: 84fc915d3bbe42fd19503ef132d3277088f6fab3",1,Move Module,,
dc1f60a9a2616946e2c3e82b915871e8a8993f31,2021-06-15T20:37:19Z,https://github.com/pytorch/pytorch/commit/dc1f60a9a2616946e2c3e82b915871e8a8993f31,[sparsity][refactor] Restructure the tests folders (#60032)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/60032  There will be more sparse tests coming. This PR creates a separate folder for the sparse tests  Test Plan: `python test/test_ao.py`  Reviewed By: raghuramank100  Differential Revision: D29139265  fbshipit-source-id: d0db915f00e6bc8d89a5651f08f72e362a912a6b,1,Move Module,,
fef6c617d407b7c8481f45772946b246a68f0aa2,2020-04-01T03:20:05Z,https://github.com/pytorch/pytorch/commit/fef6c617d407b7c8481f45772946b246a68f0aa2,[quant] Move quantization tests into test/quantization (#35688)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/35688Test Plan:.Imported from OSSDifferential Revision: D20771828fbshipit-source-id: 5f1df5e86c29f7bdfbdc6563450e909b3bfdc07a,1,Move Module,,
ab26dfb44e06f1149a21304fd867a7a9ea1e22ca,2020-04-01T19:33:02Z,https://github.com/pytorch/pytorch/commit/ab26dfb44e06f1149a21304fd867a7a9ea1e22ca,[quant] Move quantization tests into test/quantization (#35812)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/35812Test Plan:.Imported from OSSDifferential Revision: D20795329fbshipit-source-id: 42cc905c44ce7b86720aeef512d747ff6788d7a2,1,Move Module,,
f050b16dd95b2bcce9853882fd3fb07a6fd80378,2020-01-23T05:05:28Z,https://github.com/pytorch/pytorch/commit/f050b16dd95b2bcce9853882fd3fb07a6fd80378,Move pytorch distributed tests to separate folder for contbuild. (#30445)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/30445Create distributed and rpc directories under caffe/test for better managementof unit tests.Differential Revision: D18702786fbshipit-source-id: e9daeed0cfb846ef68806f6decfcb57c0e0e3606,1,Move Module,,
038c5cd04558e572b6a4dea7383a515ff10090e5,2021-06-11T20:56:55Z,https://github.com/scikit-learn/scikit-learn/commit/038c5cd04558e572b6a4dea7383a515ff10090e5,MAINT Move conftest up a level (#20208)    Co-authored-by: Olivier Grisel <olivier.grisel@ensta.org>,1,Move Module,,
1ea9ae2245046a6194dfc3f7125c1140804e18a2,2020-10-14T14:11:05Z,https://github.com/scikit-learn/scikit-learn/commit/1ea9ae2245046a6194dfc3f7125c1140804e18a2,MNT Move min_dependencies up a level (#18610),1,Move Module,,
99d2624f646d18d5f52172ba4f67c6a9d9dcc53a,2013-10-20T13:57:55Z,https://github.com/scikit-learn/scikit-learn/commit/99d2624f646d18d5f52172ba4f67c6a9d9dcc53a,Move ransac.py to _ransac.py to avoid nosetest namespace conflict,1,Move Module,,
d5ac03caa061dc3412b40ac9fd1abce09c02cb73,2013-08-25T09:33:40Z,https://github.com/scikit-learn/scikit-learn/commit/d5ac03caa061dc3412b40ac9fd1abce09c02cb73,MISC: move fast_dict to utils,1,Move Module,,
732003ef0050816d7d006433ba13b96d57c72473,2013-08-25T09:28:35Z,https://github.com/scikit-learn/scikit-learn/commit/732003ef0050816d7d006433ba13b96d57c72473,MISC: move fast_dict to utils,1,Move Module,,
ec68d8fde3fa939ed3cc53b41920325930dbaabe,2012-11-27T14:35:12Z,https://github.com/scikit-learn/scikit-learn/commit/ec68d8fde3fa939ed3cc53b41920325930dbaabe,MOV move spectra_embedding from decomposition to manifold,1,Move Module,,
c9d27f3dc03592508c16aa0a6408e71e1c6670f8,2012-01-20T20:39:34Z,https://github.com/scikit-learn/scikit-learn/commit/c9d27f3dc03592508c16aa0a6408e71e1c6670f8,Move preprocessing.py to sklearn/.,1,Move Module,,
96ea318b8bcbbcba02f6f1524d960144d99076f7,2011-12-19T18:59:00Z,https://github.com/scikit-learn/scikit-learn/commit/96ea318b8bcbbcba02f6f1524d960144d99076f7,Move graph_shortest_path to utils/graph.py,1,Move Module,,
ddf4b7210979b60265efbcc81f86d053c50c5ce2,2011-09-02T10:06:57Z,https://github.com/scikit-learn/scikit-learn/commit/ddf4b7210979b60265efbcc81f86d053c50c5ce2,Move project directory from scikits.learn to sklearn,1,Move Module,,
fd0d3b879d419015dbd8423d8b22f3fb288bf7d6,2011-09-02T09:38:24Z,https://github.com/scikit-learn/scikit-learn/commit/fd0d3b879d419015dbd8423d8b22f3fb288bf7d6,Move project directory from scikits.learn to sklearn,1,Move Module,,
6633648a4b961602b1a377839299434511ec689d,2011-08-29T10:12:46Z,https://github.com/scikit-learn/scikit-learn/commit/6633648a4b961602b1a377839299434511ec689d,Moved multiclass module to top-level module.,1,Move Module,,
1b427d95fef12433ec633605fae0cc57a205d332,2011-06-29T07:54:33Z,https://github.com/scikit-learn/scikit-learn/commit/1b427d95fef12433ec633605fae0cc57a205d332,Move scipy_future into utils.arpack,1,Move Module,,
7ec2f915c0ea49ea9ecd8f5b601c25e3a7b201bb,2011-06-14T21:02:16Z,https://github.com/scikit-learn/scikit-learn/commit/7ec2f915c0ea49ea9ecd8f5b601c25e3a7b201bb,removed old files; moved example to examples directory,1,Move Module,,
5c49a6a5c7523de424821abf7cd4aaa2c837e5e4,2010-11-05T13:38:58Z,https://github.com/scikit-learn/scikit-learn/commit/5c49a6a5c7523de424821abf7cd4aaa2c837e5e4,Moved sgd extension modules from sgd/src to sgd. Updated setup accordingly.,1,Move Module,,
4e13e86c660f6d6f359d352000884dc3bebc07e8,2010-08-30T12:22:46Z,https://github.com/scikit-learn/scikit-learn/commit/4e13e86c660f6d6f359d352000884dc3bebc07e8,Refactoring: put all gmm examples in its own directory.,1,Move Module,,
97a2ec2ba0556a24e979f4955089adfbeb854fb9,2010-06-26T13:24:09Z,https://github.com/scikit-learn/scikit-learn/commit/97a2ec2ba0556a24e979f4955089adfbeb854fb9,Move glm examples to common directory.,1,Move Module,,
b30abe7497f025785f702e1fff3e84f001c9a07c,2010-05-05T09:42:04Z,https://github.com/scikit-learn/scikit-learn/commit/b30abe7497f025785f702e1fff3e84f001c9a07c,"ENH/API: Change the cross-validation utilities from generators to objects that expose an iterator. Also, move the module from utils.crossval to cross_val.",1,Move Module,,
8b6b770f637e77b198c959896c7d55f3c7bcd4a4,2010-03-03T13:11:20Z,https://github.com/scikit-learn/scikit-learn/commit/8b6b770f637e77b198c959896c7d55f3c7bcd4a4,Move samples_generator to datasets   git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@441 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8,1,Move Module,,
61abe3290bf1f3c37ee2ea63c056f1c611a9834e,2023-02-16T14:18:25Z,https://github.com/huggingface/transformers/commit/61abe3290bf1f3c37ee2ea63c056f1c611a9834e,[WIP] Move X-MOD models to facebook organization (#21640)  Move X-MOD models to facebook org,1,Move Module,,
0400b2263d4b604d5a34aa90f2fdf6ae70f15bfd,2022-02-23T20:46:37Z,https://github.com/huggingface/transformers/commit/0400b2263d4b604d5a34aa90f2fdf6ae70f15bfd,[Test refactor 2/5] Tests fetcher (#15726)  * Tests fetcher  * Review comments  Co-authored-by: sgugger <sylvain.gugger@gmail.com> Review comments,1,Move Module,,
090d28e32d7dd05127e968a5fe035c611db99a5c,2021-01-06T08:33:50Z,https://github.com/huggingface/transformers/commit/090d28e32d7dd05127e968a5fe035c611db99a5c,"[Refactor] Splitting pipelines.py into its own module. (#9279)  * Splitting pipelines into its own module.  * Moving everything into base.py  * Moving FeatureExtractionPipeline into its own file.  * TextGenerationPipeline.  * TextClassifictionPipeline  * ZeroShot + get_framework import.  * FillMaskPipeline  * NerPipeline + TokenClassificationPipeline  * QuestionAnsweringPipeline  * TableQuestionAnsweringPipeline  * ConversationnalPipeline  * Text2TextGenerationPipeline, TranslationPipeline, SummarizationPipeline  * Typo import fix.  * Relative imports.",1,Move Module,,
13deb95a405bbd1037ad233c692d7fd1de9d31e3,2020-07-01T14:31:17Z,https://github.com/huggingface/transformers/commit/13deb95a405bbd1037ad233c692d7fd1de9d31e3,Move tests/utils.py -> transformers/testing_utils.py (#5350),1,Move Module,,
c4d4e8bdbd25d9463d41de6398940329c89b7fb6,2020-06-30T14:42:08Z,https://github.com/huggingface/transformers/commit/c4d4e8bdbd25d9463d41de6398940329c89b7fb6,Move GenerationMixin to separate file (#5254)  * separate_generation_code  * isort  * renamed  * rename_files  * move_shapelit,1,Move Module,,
f12e4d8da783a535cd8978656f0a3ca108a2e2ed,2019-11-16T05:11:07Z,https://github.com/huggingface/transformers/commit/f12e4d8da783a535cd8978656f0a3ca108a2e2ed,Move demo_camembert.py to examples/contrib,1,Move Module,,
4a210c9fc67661e48a0146a6833381bfd0a4ea07,2019-05-31T04:28:00Z,https://github.com/huggingface/transformers/commit/4a210c9fc67661e48a0146a6833381bfd0a4ea07,Move bert_hubconf to hubconfs,1,Move Module,,
574e20a92e79d93d78d85fc93fda56b525d2b896,2018-11-03T11:22:06Z,https://github.com/huggingface/transformers/commit/574e20a92e79d93d78d85fc93fda56b525d2b896,Move modeling_test.py to /tensorflow_code,1,Move Module,,
4df6027453507b7bd56e0c1f3c5b51d5273bef63,2018-11-03T10:33:10Z,https://github.com/huggingface/transformers/commit/4df6027453507b7bd56e0c1f3c5b51d5273bef63,clean up,1,Move Module,,
a58d44afc8c22423afbc04275477ac7ee46befe1,2021-02-04T18:14:33Z,https://github.com/tensorflow/tensorflow/commit/a58d44afc8c22423afbc04275477ac7ee46befe1,[retry]Move enclosing_tpu_context to a separate util fileThis is part of the variable refactor work to avoid dependency cycles.PiperOrigin-RevId: 355654271Change-Id: I92f0d00ddff6655c174d999abd0290ae3e4c1849,1,Move Method,,
ace531b56d6793d1f311ad7339d185ec05f696a1,2021-02-03T20:25:29Z,https://github.com/tensorflow/tensorflow/commit/ace531b56d6793d1f311ad7339d185ec05f696a1,Move enclosing_tpu_context to a separate util fileThis is part of the variable refactor work to avoid dependency cycles.PiperOrigin-RevId: 355456079Change-Id: I7a8afc89d17eee9372afb3fd4c6da8126791e499,1,Move Method,,
428ce93ee46089896c0fcfc9460bd0691e57a0e9,2021-02-03T17:32:15Z,https://github.com/tensorflow/tensorflow/commit/428ce93ee46089896c0fcfc9460bd0691e57a0e9,Move enclosing_tpu_context to a separate util fileThis is part of the variable refactor work to avoid dependency cycles.PiperOrigin-RevId: 355414142Change-Id: I36651a7be6462c198aae477923bc2ef0f7e7d0fb,1,Move Method,,
20cfb32577d2950b97e6a3a0497d5c0bd30109a5,2020-11-16T19:00:54Z,https://github.com/tensorflow/tensorflow/commit/20cfb32577d2950b97e6a3a0497d5c0bd30109a5,Move the test with the private symbol `variable_scope.EagerVariableStore` from Keras to TF.PiperOrigin-RevId: 342674107Change-Id: If9b2baf08d720c2dc86708fffcde949a0f57205a,1,Move Method,Rename Method,
b39bc5f1f0739b4c276a0550b09454ce25b966f3,2020-10-21T12:44:58Z,https://github.com/tensorflow/tensorflow/commit/b39bc5f1f0739b4c276a0550b09454ce25b966f3,More cleanup of dead Python 2 code.PiperOrigin-RevId: 338246558Change-Id: Id26f592e991446cebc5b9eced9028c971b283b0e,1,Move Method,,
bbbacb1d649fe22b3629c67477e5d93d2bc79cc4,2020-10-03T00:40:46Z,https://github.com/tensorflow/tensorflow/commit/bbbacb1d649fe22b3629c67477e5d93d2bc79cc4,Move tests from strategy_reduce_test.py to strategy_common_test.py.strategy_common_test is a now a kitchen sink for testing methods that are common in all strategies. We can consider breaking it down if it grows significantly.PiperOrigin-RevId: 335133163Change-Id: I744bcd96ba27a49e1f79d71a5e53331c0bc42b74,1,Move Method,,
90631e3c6deccf89f9e2718404c75424873fa9d1,2020-09-15T08:09:45Z,https://github.com/tensorflow/tensorflow/commit/90631e3c6deccf89f9e2718404c75424873fa9d1,Remove model parallelism API from non-TPU distribution strategies.PiperOrigin-RevId: 331718021Change-Id: Ib9a5fe49207ebec8078405383c87e58f20f55e8f,1,Move Method,,
951be80fc6873434b8ab2bef65d437b094037c86,2020-09-11T19:03:14Z,https://github.com/tensorflow/tensorflow/commit/951be80fc6873434b8ab2bef65d437b094037c86,"Refactor sharded variable creator scope into StrategyExtendedV2._create_variable.This is almost a non-functional change, except that the code that handles checkpoint initial value can now benefit the creation of sharded variable:https://github.com/tensorflow/tensorflow/blob/7d0114f5e10942bf8462e9c663cc75238c99ad5e/tensorflow/python/distribute/distribute_lib.py#L2126PiperOrigin-RevId: 331194711Change-Id: Ic363abcf27b206f8168f258182188285c3d29277",1,Move Method,,
e98f54f469829b0813d34bec358503fce4b1a2c6,2020-08-21T19:52:01Z,https://github.com/tensorflow/tensorflow/commit/e98f54f469829b0813d34bec358503fce4b1a2c6,Move `lstm_model_with_dynamic_batch` test to a separate file.PiperOrigin-RevId: 327858513Change-Id: I907a6b808a540fc36a19d721c7361efd2f00ff99,1,Move Method,,
57e69437b44e7e66e7b760524202fcca949456f6,2020-08-14T17:09:39Z,https://github.com/tensorflow/tensorflow/commit/57e69437b44e7e66e7b760524202fcca949456f6,Move cached_per_instance to keras utils since its only used in Keras.PiperOrigin-RevId: 326677839Change-Id: I04fb71d17241b65fc1d5ae8f69e4d40770357bf7,1,Move Method,,
aa462dd2507703ebbafc3ffe1e207f3a4ca0b53e,2020-07-29T18:36:14Z,https://github.com/tensorflow/tensorflow/commit/aa462dd2507703ebbafc3ffe1e207f3a4ca0b53e,Create Optimizer utilities file and move gradient aggregation and filteringfunctions to this file.PiperOrigin-RevId: 323831904Change-Id: I59ff3f42771eba8c7fb27ea68c53296bd2425011,1,Move Method,,
9c4aaa21db2c8133e41e7bfdbe3a09d6e055af23,2020-07-15T01:08:16Z,https://github.com/tensorflow/tensorflow/commit/9c4aaa21db2c8133e41e7bfdbe3a09d6e055af23,Internal cleanup: consolidate and simplify tests.PiperOrigin-RevId: 321274479Change-Id: I3399f4f60b5ef2c9c74911f0bdbc0ae556bb11ec,1,Move Method,,
2f5fbf92c8b3697285b35f9e7977825ba76e402c,2020-07-14T21:08:54Z,https://github.com/tensorflow/tensorflow/commit/2f5fbf92c8b3697285b35f9e7977825ba76e402c,Split tpu_embedding_v2_test.py into two files to reduce test timeouts.PiperOrigin-RevId: 321231814Change-Id: Id9e42801a6212509ab7ca17048252da4630e2396,1,Move Method,,
cf599cade160e40d9f7051afebe89672f60e7137,2020-06-16T16:30:51Z,https://github.com/tensorflow/tensorflow/commit/cf599cade160e40d9f7051afebe89672f60e7137,Move the serialization_test to keras/testsPiperOrigin-RevId: 316697481Change-Id: I918b29a976b166662acf9045f87512aef485441b,1,Move Method,,
12ec80d2395da75c18db5b8371c68f07889dba11,2020-06-16T16:18:02Z,https://github.com/tensorflow/tensorflow/commit/12ec80d2395da75c18db5b8371c68f07889dba11,Move the module test wrt to Keras private API to keras test.PiperOrigin-RevId: 316695477Change-Id: I4201f62e97bb1acb768b980a51d26bf0c76853ab,1,Move Method,,
0f3562ba77d62abef6c55c7c7649f836398dbc6e,2020-06-12T18:54:05Z,https://github.com/tensorflow/tensorflow/commit/0f3562ba77d62abef6c55c7c7649f836398dbc6e,Another round of refactoring of values.py to split utility functions that use distributed Variable types defined in values.py.PiperOrigin-RevId: 316147517Change-Id: I72e17b02e8f41c9cee40f4ec7f56fec2f7d860a9,1,Move Method,,
3dcf574c5bc24e1897b99ae61df69906653f9afc,2020-06-09T23:14:26Z,https://github.com/tensorflow/tensorflow/commit/3dcf574c5bc24e1897b99ae61df69906653f9afc,Move Keras eager microbenchmarks to keras/benchmark.Adds overhead benchmarking for __call__ for Layer and Layer subclasses in layers/corePiperOrigin-RevId: 315581358Change-Id: Icb76f6d9e3d1829386c22a454c91105c20b28280,1,Move Method,,
b2f3e8f5639a9370c9f8987a733ab3496eb87a97,2020-05-18T13:16:05Z,https://github.com/tensorflow/tensorflow/commit/b2f3e8f5639a9370c9f8987a733ab3496eb87a97,numerics_test.py: Move tfdbg2-specific test methods to debug_v2_ops_test.pyPiperOrigin-RevId: 312065934Change-Id: Idf576fd41ae96ed19f815bcce8848eabef036834,1,Move Method,,
efa3fb28d94b7937edaafb5874c191ad0e2149ca,2020-05-15T02:07:07Z,https://github.com/tensorflow/tensorflow/commit/efa3fb28d94b7937edaafb5874c191ad0e2149ca,Split index_lookup into string_lookup and integer_lookup.PiperOrigin-RevId: 311651579Change-Id: Ie033727dbe1026a7c7a88e4b31653840a17ac3d1,1,Move Method,,
431d009ecbb7d3b128a5cb4298261d4531a95b32,2020-05-09T02:35:23Z,https://github.com/tensorflow/tensorflow/commit/431d009ecbb7d3b128a5cb4298261d4531a95b32,Split table management off into a table_utils file.PiperOrigin-RevId: 310671808Change-Id: Ifd6b18aff3e7873225887e03dfa171e7577a1cae,1,Move Method,,
c65d6c3a1b50dca1f2251af925043efc6cdb4176,2020-05-04T22:23:29Z,https://github.com/tensorflow/tensorflow/commit/c65d6c3a1b50dca1f2251af925043efc6cdb4176,Move assign* and scatter* override to DistributedVariableIdeally sub classes should only need to override _update_cross_replica and _update_replica. Though in reality they still need to override some assign/scatter methods since their behavior are not 100% consistent yet.PiperOrigin-RevId: 309827960Change-Id: Ie0d5c4b4434c24b4ea868bb1dcfdf6e4cdf631c6,1,Move Method,,
f7f727388c79b2456335ab9e30fd9aa7dd804ff2,2020-04-28T21:11:46Z,https://github.com/tensorflow/tensorflow/commit/f7f727388c79b2456335ab9e30fd9aa7dd804ff2,Refactor SyncOnReadVariable update methods to be consistent with MirroredVariable.This brings the behaivor of SyncOnReadVariable consistent with MirroredVariable.E.g. previously it always returns a tf.Operation in cross replica context.After the last refactoring SyncOnReadVariable only needs to override _update_replica to have the desired behavior.This change also moves assign* and scatter* override to DistributedVariablelevel.This is part of the effort to make DistributedVariable.assign* returns a variable.PiperOrigin-RevId: 308894562Change-Id: I1a58352e2af2ff57402d8fc744fcfc9610a48d8b,1,Move Method,,
b40be9c5e76a79ed5513375baeab1ae427ae2592,2020-04-25T05:51:37Z,https://github.com/tensorflow/tensorflow/commit/b40be9c5e76a79ed5513375baeab1ae427ae2592,Refactor SyncOnReadVariable update methods to be consistent with MirroredVariable.This brings the behaivor of SyncOnReadVariable consistent with MirroredVariable.E.g. previously it always returns a tf.Operation in cross replica context.After the last refactoring SyncOnReadVariable only needs to override _update_replica to have the desired behavior.This change also moves assign* and scatter* override to DistributedVariablelevel.This is part of the effort to make DistributedVariable.assign* returns a variable.PiperOrigin-RevId: 308384727Change-Id: If936ca5589bcffd9b77653657d6ac2b860b577d7,1,Move Method,,
04bee75e68d322339ff165af6bc4afb67564383f,2020-04-21T20:57:14Z,https://github.com/tensorflow/tensorflow/commit/04bee75e68d322339ff165af6bc4afb67564383f,refactor eager micro benchmarksPiperOrigin-RevId: 307674785Change-Id: I1b543698824136139813320402660b7afef43a3f,1,Move Method,Rename Method,
8c849c65503fef22f49f7ab843803fca9c439bdf,2020-04-15T20:31:13Z,https://github.com/tensorflow/tensorflow/commit/8c849c65503fef22f49f7ab843803fca9c439bdf,Move Keras related parallel ops test to keras/integrationPiperOrigin-RevId: 306709806Change-Id: I9e59adba1ec7c0192c17ab74f8fa9759f2d4ee58,1,Move Method,,
8575c534b4fa5621463d6742cd2902fd8ffdb6a1,2020-04-15T18:39:39Z,https://github.com/tensorflow/tensorflow/commit/8575c534b4fa5621463d6742cd2902fd8ffdb6a1,Move keras related module test to keras/integration_test.PiperOrigin-RevId: 306685976Change-Id: I3d674da22e5a919048298773ebe32c60338e5fba,1,Move Method,,
89633dfaf5a16767c2590f227b7bb6acbabc45b5,2020-04-15T02:10:44Z,https://github.com/tensorflow/tensorflow/commit/89633dfaf5a16767c2590f227b7bb6acbabc45b5,Move keras related summary_ops_test to keras/tests.PiperOrigin-RevId: 306560299Change-Id: I100c3e23973276bc4f395c46b08705c0f277fb3b,1,Move Method,,
75dae0460335b6c469bf5c7b591065de793565f9,2020-04-13T03:28:20Z,https://github.com/tensorflow/tensorflow/commit/75dae0460335b6c469bf5c7b591065de793565f9,Move keras related op_callbacks_test to keras/tests.PiperOrigin-RevId: 306169821Change-Id: If19f6a3c31068754bd4885f754f0ef767c3221e6,1,Move Method,,
421741965fe5795b462d50d5e60300db8e3a6a91,2020-04-12T03:58:20Z,https://github.com/tensorflow/tensorflow/commit/421741965fe5795b462d50d5e60300db8e3a6a91,Move Keras related test case in graph_util_test to keras/tests.This will remove the dependency from TF to Keras.PiperOrigin-RevId: 306082751Change-Id: I8b87f32653c1c366992f9a3088e59889c3ef934f,1,Move Method,,
d8ff19311da5d783baee5e53089e220680d7e994,2020-04-12T03:38:29Z,https://github.com/tensorflow/tensorflow/commit/d8ff19311da5d783baee5e53089e220680d7e994,Move keras related memory_checker_test to keras/tests.PiperOrigin-RevId: 306081516Change-Id: I759c0b0283ac02324637e6be71499036e5ed48de,1,Move Method,,
b737d47b533ec0abfc12977022f8fb8e550e7f44,2020-04-11T21:03:45Z,https://github.com/tensorflow/tensorflow/commit/b737d47b533ec0abfc12977022f8fb8e550e7f44,Move keras related convert_to_constants_test to keras/tests.PiperOrigin-RevId: 306056993Change-Id: I220960a74da3563de424bf50fbac6739b3c5df6a,1,Move Method,,
b57674fe1d8847975309c7603589a3fa204ada9d,2020-04-06T17:41:53Z,https://github.com/tensorflow/tensorflow/commit/b57674fe1d8847975309c7603589a3fa204ada9d,Move Keras related auto control-deps test to Keras integration test.PiperOrigin-RevId: 305064564Change-Id: I4568e37345cf15988a58f3af4ff47a1f49e7b9b4,1,Move Method,,
21bbc9b07e1db33a4062b78c59da5793d2099013,2020-04-05T05:42:16Z,https://github.com/tensorflow/tensorflow/commit/21bbc9b07e1db33a4062b78c59da5793d2099013,Move keras related eager/forwardprop_test.py to keras integration test.PiperOrigin-RevId: 304852741Change-Id: Id3715909087779b17e5078d065e84e64e44e8e87,1,Move Method,,
be2c7869f592c0fbfae31e1cd1c9bae317f58695,2020-03-25T18:12:10Z,https://github.com/tensorflow/tensorflow/commit/be2c7869f592c0fbfae31e1cd1c9bae317f58695,Move the namer into the generic pyct library. Clean up dead code.PiperOrigin-RevId: 302928833Change-Id: I3e065722bbf46c2f13faccd5265d559e55a3121b,1,Move Method,,
f452e85f3efadd6243b2ef3e15b3faaa950361a3,2020-03-10T17:38:26Z,https://github.com/tensorflow/tensorflow/commit/f452e85f3efadd6243b2ef3e15b3faaa950361a3,"Refactor quantization selection logic into single QuantizationMode class in TFLiteConverter.This has been a major source of confusion of all engineers reading this code and attempting to make changes in this code. This is a first stab at cleaning this up.There is only one behavior change in this CL:It should not be an error when supported_types=[float16, int8], it should perform int8 dynamic quantization. I removed the test cases checking for this error. This should never really be a case that the user provides to the converter anyways so its a minor point.PiperOrigin-RevId: 300125178Change-Id: I69ef523be14e2958a53e1a95e2c2878b068e93fd",1,Move Method,,
03b2a42ddfbd2bbeb81d32dad33a5ccb66484e41,2020-01-13T20:06:20Z,https://github.com/tensorflow/tensorflow/commit/03b2a42ddfbd2bbeb81d32dad33a5ccb66484e41,Move the test back to its original test file.PiperOrigin-RevId: 289490851Change-Id: Ic8ca3f3b4e5b3611edf07a235a267d4d66bdc3cf,1,Move Method,,
6d02d5ce80c6d6370d132867b06b3b9910fc7461,2019-10-10T01:56:47Z,https://github.com/tensorflow/tensorflow/commit/6d02d5ce80c6d6370d132867b06b3b9910fc7461,"Remove deprecate warning caused by usage of parallel_interleave in tf.dataWhile playing with make_csv_dataset the following warning showed up:```WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/data/experimental/ops/readers.py:521: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.Instructions for updating:Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.```This fix adds an wrapper of _parallel_interleave so that the deprecated warning could be removed.Signed-off-by: Yong Tang <yong.tang.github@outlook.com>",1,Move Method,,
54cca50083014a02aa6fcbcc218c07c362147fcc,2019-10-08T15:05:29Z,https://github.com/tensorflow/tensorflow/commit/54cca50083014a02aa6fcbcc218c07c362147fcc,Move `create_mirrored_variable` into `values.py`.PiperOrigin-RevId: 273520996,1,Move Method,,
98aa8bbca941a7b7544ba4ae073e012226cedc4a,2019-09-16T20:48:25Z,https://github.com/tensorflow/tensorflow/commit/98aa8bbca941a7b7544ba4ae073e012226cedc4a,Move the LegacyStructureAPI related test to dataset_test.py,1,Move Method,,
23231a1dd33315d986997674c77a116e22e4742d,2019-06-28T00:35:26Z,https://github.com/tensorflow/tensorflow/commit/23231a1dd33315d986997674c77a116e22e4742d,Minor refactoring for training utility function.PiperOrigin-RevId: 255513022,1,Move Method,Rename Method,
6d3c9aa4deb7b27d16ab63fd6d283dc94a51ecd4,2019-06-28T00:13:10Z,https://github.com/tensorflow/tensorflow/commit/6d3c9aa4deb7b27d16ab63fd6d283dc94a51ecd4,Replace _CheckpointRestoreCoordinatorDeleter.__del__() with a single-purposedeleter to avoid potential reference cycles which prevents GC.PiperOrigin-RevId: 255509944,1,Move Method,,
806cf17aec773cd16da1a06b5642635a4d588455,2019-06-27T18:58:22Z,https://github.com/tensorflow/tensorflow/commit/806cf17aec773cd16da1a06b5642635a4d588455,Minor refactor the training functions.Move some of the util functions from model class to training_utils. Those function can be further used by new training loop/data adapter without access model class.PiperOrigin-RevId: 255448795,1,Move Method,Rename Method,
819ff6dc640aaeaea5da2cf6d216b6a98a267910,2019-06-24T09:26:41Z,https://github.com/tensorflow/tensorflow/commit/819ff6dc640aaeaea5da2cf6d216b6a98a267910,Split NextAfter test into a sepatate test instance,1,Move Method,,
07213a6a76528278a4c0f2f42b61bbfdd81d8451,2019-05-20T23:57:05Z,https://github.com/tensorflow/tensorflow/commit/07213a6a76528278a4c0f2f42b61bbfdd81d8451,Changes to experimental_run for cleaner UX when writing the custom training loop.PiperOrigin-RevId: 249154921,1,Move Method,,
f78b725d10e1386b614621465810b9e79558bd08,2019-04-18T22:41:41Z,https://github.com/tensorflow/tensorflow/commit/f78b725d10e1386b614621465810b9e79558bd08,Refactor lite_test.py to run from_frozen_graph test on both 1.X and 2.0.PiperOrigin-RevId: 244273497,1,Move Method,,
7b81a79dbb18d2ef3a73ebdd24bad253dfa5b76c,2019-03-04T20:57:09Z,https://github.com/tensorflow/tensorflow/commit/7b81a79dbb18d2ef3a73ebdd24bad253dfa5b76c,Move common feature column helper functions to separate file.PiperOrigin-RevId: 236707892,1,Move Method,,
61aced4825c7a2b0ebc3003bcc4f821bef49f0a8,2019-02-22T20:53:41Z,https://github.com/tensorflow/tensorflow/commit/61aced4825c7a2b0ebc3003bcc4f821bef49f0a8,Splitting out the memory usage tests into their own test file as that was making the test suite for MultiDeviceIterator too big and timing out.PiperOrigin-RevId: 235242183,1,Move Method,,
7d7f2e71832f62d9012220cd33fd459fee038888,2019-02-04T12:14:45Z,https://github.com/tensorflow/tensorflow/commit/7d7f2e71832f62d9012220cd33fd459fee038888,Move inner functions into toplevel,1,Move Method,,
79d86aca647b5a3b8300eb104519332871d00947,2019-01-30T05:19:32Z,https://github.com/tensorflow/tensorflow/commit/79d86aca647b5a3b8300eb104519332871d00947,Move map_fn to separate filePiperOrigin-RevId: 231529445,1,Move Method,,
caf00d258648be6ad19c98830a63431e31209045,2019-01-14T17:33:38Z,https://github.com/tensorflow/tensorflow/commit/caf00d258648be6ad19c98830a63431e31209045,"Refactoring: move list_all_concrete_functions into PolymorphicFunction.This will enable overriding this function in a ""RestoredPolymorphicFunction"", which will be helpful for repeated saving/restoring.PiperOrigin-RevId: 229197202",1,Move Method,,
5269e3db18693866373a8c774936bbb7515fa027,2019-01-11T01:04:19Z,https://github.com/tensorflow/tensorflow/commit/5269e3db18693866373a8c774936bbb7515fa027,"Move Keras saving and loading functions into keras/saving/, and resolve circular dependencies with the SavedModel code.* saving.py has been split by format (hdf5 and model config)* saving.py will be deleted after dependencies to keras.engine.saving are all fixed.PiperOrigin-RevId: 228804552",1,Move Method,,
1c5e24f78aaf7c9630d30a3b0e3ff2b15eace597,2018-12-21T21:29:48Z,https://github.com/tensorflow/tensorflow/commit/1c5e24f78aaf7c9630d30a3b0e3ff2b15eace597,Move metric utility functions into metrics_utils.pyPiperOrigin-RevId: 226534485,1,Move Method,,
81e98fcb01d7abd40340be087f57ff543ab5012c,2018-12-19T20:20:47Z,https://github.com/tensorflow/tensorflow/commit/81e98fcb01d7abd40340be087f57ff543ab5012c,Refactoring the test to grow correctness (numerical) test to a separated file.PiperOrigin-RevId: 226214083,1,Move Method,,
2d28cb50cffd8360dbab52779b13320bd9fc0127,2018-12-18T00:53:42Z,https://github.com/tensorflow/tensorflow/commit/2d28cb50cffd8360dbab52779b13320bd9fc0127,"Move test from while_v2_test.py to control_flow_ops_py_test.py.This is to make sure we have coverage of explicitly instantiating aTensorArray and passing it to a while_loop in both v1 and v2 controlflow, in a way they're actually called (while_v2_test.py callswhile_v2 directly, instead of going throughcontrol_flow_ops.while_loop).PiperOrigin-RevId: 225913951",1,Move Method,,
8644b6d4c77646407758a2ef93eb3567f9f03577,2018-12-12T22:50:13Z,https://github.com/tensorflow/tensorflow/commit/8644b6d4c77646407758a2ef93eb3567f9f03577,Move reduce non distributed values and share the code with TPU Strategy and also improve print output of TPUMirroredVariable.PiperOrigin-RevId: 225259008,1,Move Method,,
2ecbae0e9cab99682187a6ffbce03e154fbf51bb,2018-11-22T00:35:40Z,https://github.com/tensorflow/tensorflow/commit/2ecbae0e9cab99682187a6ffbce03e154fbf51bb,Move gfile.* functions to io.gfile.* and change API for TF 2.0.PiperOrigin-RevId: 222475688,1,Move Method,,
7f369e9ccf8e63e049ee8309a6350cb95127f94f,2018-11-08T21:34:04Z,https://github.com/tensorflow/tensorflow/commit/7f369e9ccf8e63e049ee8309a6350cb95127f94f,Simple refactor to significantly speed up Keras tests.PiperOrigin-RevId: 220692418,1,Move Method,,
3629b2d9f46c94f4a91433f291f947e2456ee5b4,2018-10-29T16:34:57Z,https://github.com/tensorflow/tensorflow/commit/3629b2d9f46c94f4a91433f291f947e2456ee5b4,"[TPU] Move methods to map between TensorFlow task/device names and TPU device coordinates out of DeviceAssignment and into Topology.The mapping is a property of the Topology (which describes the machine and how to address it), not the DeviceAssignment, which describes a choice of devices for a particular job.PiperOrigin-RevId: 219141156",1,Move Method,,
05f6c0be09c7277ec6b89976c0dc30fb9133ec39,2018-10-18T09:09:01Z,https://github.com/tensorflow/tensorflow/commit/05f6c0be09c7277ec6b89976c0dc30fb9133ec39,Move tpu_function.check_function_argument_count to XLA libraryPiperOrigin-RevId: 217665852,1,Move Method,,
9989788be25c846d087ac70b76cf78759a209a3e,2018-10-09T20:31:58Z,https://github.com/tensorflow/tensorflow/commit/9989788be25c846d087ac70b76cf78759a209a3e,Small cleanup in function_test.PiperOrigin-RevId: 216412380,1,Move Method,,
da3ccfda9b75f3cf60eb237d9a4da68c436e9f18,2018-09-17T16:59:14Z,https://github.com/tensorflow/tensorflow/commit/da3ccfda9b75f3cf60eb237d9a4da68c436e9f18,Move test to callbacks_test,1,Move Method,,
fbdef63fe5849cde5423f8c3cc9c348ed4fe75c3,2018-08-17T23:17:48Z,https://github.com/tensorflow/tensorflow/commit/fbdef63fe5849cde5423f8c3cc9c348ed4fe75c3,Move clone and build function out of the estimator/keras library.PiperOrigin-RevId: 209223543,1,Move Method,,
77fabbeabb5b9061d8c606050c1ea79aec990c03,2018-08-14T18:22:19Z,https://github.com/tensorflow/tensorflow/commit/77fabbeabb5b9061d8c606050c1ea79aec990c03,1. Move distribution strategy context utility methods to a separate file with few dependencies. This allows us to import this in some places without creating circular dependencies as the original file imported many things.2. Move the stack used in distribution strategy context to the graph. This allows us to use different strategies in different graphs (for e.g. in train and eval).This fixes #21412 and #21180.PiperOrigin-RevId: 208680454,1,Move Method,,
1bf206bc82f600886f1e19c9860f09f18984346b,2018-08-02T22:47:43Z,https://github.com/tensorflow/tensorflow/commit/1bf206bc82f600886f1e19c9860f09f18984346b,"Split checkpoint management utility functions out of saver.pyPure refactor, in preparation for adding a higher level checkpoint management utility. This utility will also need to work with the Checkpoint proto, and globbing it on to saver.py seems dirty.PiperOrigin-RevId: 207179646",1,Move Method,,
9beaf7038c4f8ca5b6a5168c47efbb3fc669b64b,2018-07-27T02:27:30Z,https://github.com/tensorflow/tensorflow/commit/9beaf7038c4f8ca5b6a5168c47efbb3fc669b64b,Layers/Networks now have a default implementation for static shape inference in eager execution (when possible).Also move `build` implementation for subclassed networks from Model to Network (where it belongs) and slightly refactor it to minimize code duplication.PiperOrigin-RevId: 206260286,1,Move Method,,
da929851e2b5446a5aaee29a869428037a72f2b7,2018-07-20T18:11:42Z,https://github.com/tensorflow/tensorflow/commit/da929851e2b5446a5aaee29a869428037a72f2b7,Refactor properties and functions common to Mirrored and TowerLocal Variables.PiperOrigin-RevId: 205424692,1,Move Method,,
6b7198b495ae7a4acd9604dbeda41e7855f97bdd,2018-07-17T03:00:48Z,https://github.com/tensorflow/tensorflow/commit/6b7198b495ae7a4acd9604dbeda41e7855f97bdd,Refactor the test base class so each subclass can define its own graph.,1,Move Method,,
f8f0d7f000349ab573f0d912c37ebc3675cc6154,2018-07-16T21:38:44Z,https://github.com/tensorflow/tensorflow/commit/f8f0d7f000349ab573f0d912c37ebc3675cc6154,Refactoring some of the boosted trees code for growing ensemble.PiperOrigin-RevId: 204809484,1,Move Method,,
4254b2ca729858d5bff2bbd570b4f7b02d42fd35,2018-06-13T20:10:41Z,https://github.com/tensorflow/tensorflow/commit/4254b2ca729858d5bff2bbd570b4f7b02d42fd35,Splits testLargeCase in metric_ops_test into a dedicated file for slow-running tests and re-enables it as a 'large' test.PiperOrigin-RevId: 200440883,1,Move Method,,
9c82788d12037fc10b60b06092e94d513eb4aa14,2018-05-11T17:58:17Z,https://github.com/tensorflow/tensorflow/commit/9c82788d12037fc10b60b06092e94d513eb4aa14,Move fn_args utility into core TensorFlow from Estimator.Working on untangling TF/Estimator deps. Some core TF code depends on Estimatorby using the fn_args utility function within Estimator.PiperOrigin-RevId: 196277612,1,Move Method,,
9ecbb5574fb86d9f5280315141a11acd47e50dee,2018-05-08T02:54:04Z,https://github.com/tensorflow/tensorflow/commit/9ecbb5574fb86d9f5280315141a11acd47e50dee,refine unit test case coding style and move _should_add_regularizer function into add_weight,1,Move Method,,
de3e9830aae0904f0d40d37e9da5b113c4a9a0f0,2018-04-24T18:29:43Z,https://github.com/tensorflow/tensorflow/commit/de3e9830aae0904f0d40d37e9da5b113c4a9a0f0,Small refactor of tf.keras aiming at centralizing reusable utilities in `utils`.PiperOrigin-RevId: 194118244,1,Move Method,,
6583c9a693b122a49f17e7ec99463c6c3b7dbe98,2018-04-24T12:22:24Z,https://github.com/tensorflow/tensorflow/commit/6583c9a693b122a49f17e7ec99463c6c3b7dbe98,CLN: move _safe_embedding_lookup_sparse to embedding_ops and make it public,1,Move Method,,
f0bcd79ba07d7b759f5da2bf39fd5acaee148ba5,2018-02-13T18:16:03Z,https://github.com/tensorflow/tensorflow/commit/f0bcd79ba07d7b759f5da2bf39fd5acaee148ba5,Move two common utility functions used by training and training_eager classes to a utility class.PiperOrigin-RevId: 185548922,1,Move Method,,
2b19edf04637ce217c72a5b3cd2c64a9a9dd71e1,2018-01-29T22:53:23Z,https://github.com/tensorflow/tensorflow/commit/2b19edf04637ce217c72a5b3cd2c64a9a9dd71e1,Move noise_shape function to nn_ops.pyso that is could potentially be used by layers.Signed-off-by: Yong Tang <yong.tang.github@outlook.com>,1,Move Method,,
4e5da8880a1de695212777628f33db07833675c6,2018-01-24T17:20:45Z,https://github.com/tensorflow/tensorflow/commit/4e5da8880a1de695212777628f33db07833675c6,Remove path_to_str from the public API (#16339)* Remove path_to_str from the public API* Move path_to_str to another file,1,Move Method,,
25ea8bf4b58d8bdc6ca75afea8648aeef3cdb39f,2017-12-20T01:13:50Z,https://github.com/tensorflow/tensorflow/commit/25ea8bf4b58d8bdc6ca75afea8648aeef3cdb39f,"tfdbg: send graph traceback and source files from TensorBoard wrapper and hookTo this end:* Refactor some common, shared constants and methods to a new file: common.pyPiperOrigin-RevId: 179624165",1,Move Method,,
2139d204f038ed944cecf05873a565f7f7d424b2,2017-12-08T14:53:22Z,https://github.com/tensorflow/tensorflow/commit/2139d204f038ed944cecf05873a565f7f7d424b2,"Finishing the migration of the RNN / shared fully-connected layer blocks, and associated changes to LayerCollection.Moved check_registration function to LayerCollection which is a more natural home for it.Fixed major bug: make_inverse_update_ops was misspelled in FullyConnectedMultiKF meaning that inverses weren't being computed for these factors.Many other minor tweaks and fixes to code and documentation.PiperOrigin-RevId: 178372885",1,Move Method,,
48ce41e160c2dcd8fde82db5b4a2a44a5f36894f,2017-12-01T18:45:02Z,https://github.com/tensorflow/tensorflow/commit/48ce41e160c2dcd8fde82db5b4a2a44a5f36894f,"Moved compute_pi from utils.py to fisher_blocks.py and added global constant that controls the type of pi-based damping adjustment to use.  Current options are ""tracenorm"", which is what we were already doing and is the default, and ""off"".PiperOrigin-RevId: 177610677",1,Move Method,,
7eaa14b885124cbe1577d58d071db6bba5ee5cbe,2017-11-17T23:27:57Z,https://github.com/tensorflow/tensorflow/commit/7eaa14b885124cbe1577d58d071db6bba5ee5cbe,[tf.data] Move existing Saveable MapDataset tests to use dataset_serialization_test_base; add verify_restore_in_empty_graph and verify_save_with_errors methods to dataset_serialization_test_base.PiperOrigin-RevId: 176168789,1,Move Method,,
5f97262ae6f36000e141b01b33c55f8eb1ee94a1,2017-10-05T16:50:49Z,https://github.com/tensorflow/tensorflow/commit/5f97262ae6f36000e141b01b33c55f8eb1ee94a1,"Splits backprop.py in two files, one of which can be converted to CPiperOrigin-RevId: 171165855",1,Move Method,,
558d878d9189dfac42d518a6bf5aa35328689e48,2017-10-04T19:19:23Z,https://github.com/tensorflow/tensorflow/commit/558d878d9189dfac42d518a6bf5aa35328689e48,"TFTS: Move normalization to the base class, start using it for state space modelsPreivously, state space models adjusted their priors based on the data(e.g. setting initial variances to match sample variance) but did not normalizethe data itself. When the data has a rather extreme scale, this runs intoprecision issues. After this CL, state space models will first normalize, thenuse adjusted statistics on top of that normalization to estimate initialobservation/transition noise.Also fixes an issue where start-of-series statistics were incorrect for the firstbatch (which only shows up with large input scales).PiperOrigin-RevId: 171044863",1,Move Method,,
84b1d6d1d9d15b4c16ceb77dec9729e333a566f6,2017-10-03T18:36:01Z,https://github.com/tensorflow/tensorflow/commit/84b1d6d1d9d15b4c16ceb77dec9729e333a566f6,Split restore_variables_on_create out of tfe.SaverPiperOrigin-RevId: 170887352,1,Move Method,,
01620694d85653d8cc836db17945b0e349838b8c,2017-09-25T17:40:14Z,https://github.com/tensorflow/tensorflow/commit/01620694d85653d8cc836db17945b0e349838b8c,"Move 'make_export_strategy' utility function from .contrib to .core.That function depends on the utilities related to garbage collection.  They are moved too, but are kept private.PiperOrigin-RevId: 169927321",1,Move Method,,
c8b9e92f07aab8bf68271c370f91140cbc22a857,2017-09-08T20:46:41Z,https://github.com/tensorflow/tensorflow/commit/c8b9e92f07aab8bf68271c370f91140cbc22a857,"eager: Move ""register_function"" to context.pyThis will allow function registration from othermodules without having to import ""function.py"".(And besides, the function really does belong on the context).PiperOrigin-RevId: 168040411",1,Move Method,,
a6729325a3534ef4aeb2065be82bb2963b9b03de,2017-08-18T14:39:41Z,https://github.com/tensorflow/tensorflow/commit/a6729325a3534ef4aeb2065be82bb2963b9b03de,Deletes convert_n_to_eager_tensor. Moves convert_to_eager_tensor to constant_op.PiperOrigin-RevId: 165704074,1,Move Method,,
d30537a10529a73b712d805a1f26fd39ce5be609,2017-08-17T21:46:52Z,https://github.com/tensorflow/tensorflow/commit/d30537a10529a73b712d805a1f26fd39ce5be609,Moves tensor_id() from tape.py to framework/ops.py; breaks dependency cycle in subsequent CLs.PiperOrigin-RevId: 165632053,1,Move Method,,
9c08e99a02c682acca0dcb9be9f79c3a9d38b615,2017-07-22T00:51:03Z,https://github.com/tensorflow/tensorflow/commit/9c08e99a02c682acca0dcb9be9f79c3a9d38b615,Implement VIMCO-like objective for approx Csiszar f-Divergence. Simplify monte_carlo.expectation_v2 calculation when doing score-trick.PiperOrigin-RevId: 162806278,1,Move Method,,
f4ccadc2d4cea60001733dfa7626e8e13a85ba7c,2017-06-14T05:57:03Z,https://github.com/tensorflow/tensorflow/commit/f4ccadc2d4cea60001733dfa7626e8e13a85ba7c,"Refactor histogram compression into new moduleThis will be useful for pluginification, so we can access this functionindependently of the EventAccumulator.PiperOrigin-RevId: 158943129",1,Move Method,,
b73fea6e27b17dc4349754e585113e7a8138339e,2017-05-30T15:26:18Z,https://github.com/tensorflow/tensorflow/commit/b73fea6e27b17dc4349754e585113e7a8138339e,"Refactor `tf.Operation.traceback` implementation in to methods of tf.Graph.Adds an `_extract_frame_info` method to allow derived classes to extend theinformation available in each op traceback, if desired. The default result of`tf.Operation.traceback` is unchanged.Also fixes a poorly scoped `pylint disable=line-too-long`, so adds the necessaryenable/disable blocks to silence pylint for the offending docstrings.PiperOrigin-RevId: 157466174",1,Move Method,,
3e61d9fc094ce1136993bf6bdbed437c80aa7acd,2017-05-23T00:32:50Z,https://github.com/tensorflow/tensorflow/commit/3e61d9fc094ce1136993bf6bdbed437c80aa7acd,"Move many of the ""core"" RNNCells and rnn functions back to TF core.Unit test files will move in a followup PR.  This is the big API change.The old behavior (using tf.contrib.rnn....) will continue to work forbackwards compatibility.PiperOrigin-RevId: 156809677",1,Move Method,,
827d2e4b9180db67853f60c125e548d83986b96c,2017-05-23T00:32:50Z,https://github.com/tensorflow/tensorflow/commit/827d2e4b9180db67853f60c125e548d83986b96c,"Move many of the ""core"" RNNCells and rnn functions back to TF core.Unit test files will move in a followup PR.  This is the big API change.The old behavior (using tf.contrib.rnn....) will continue to work forbackwards compatibility.PiperOrigin-RevId: 156809677",1,Move Method,,
69249af5d1f2fe03235302ff5774ee61ee12e3d3,2017-05-12T09:33:15Z,https://github.com/tensorflow/tensorflow/commit/69249af5d1f2fe03235302ff5774ee61ee12e3d3,Move _maybe_save_assets and its helper functions to the top level.They do not depend on any state of class SavedModelBuilder.PiperOrigin-RevId: 155848011,1,Move Method,,
1bad658d63e5fb21d321cd680e7451c96e032f7e,2017-05-09T19:32:41Z,https://github.com/tensorflow/tensorflow/commit/1bad658d63e5fb21d321cd680e7451c96e032f7e,Moved transform_features.removed pylint lines from test.PiperOrigin-RevId: 155538004,1,Move Method,,
b93dd62e8ae9faed909c677781edc278632704f0,2017-05-03T16:20:17Z,https://github.com/tensorflow/tensorflow/commit/b93dd62e8ae9faed909c677781edc278632704f0,Move bucketized_column to core.Change: 154963963,1,Move Method,,
65283e269fac1306089303143daf550b7b1a6658,2017-05-01T17:50:31Z,https://github.com/tensorflow/tensorflow/commit/65283e269fac1306089303143daf550b7b1a6658,"Move bucketize op to math_ops. This exposes the method as math_op._bucketize, but does not expose it in tf public interface. The method is still exposed as tf.contrib.layers.bucketize.Change: 154731971",1,Move Method,,
fd561221d2fe782d320b97346dfffb41f38d2bcf,2017-04-17T23:20:31Z,https://github.com/tensorflow/tensorflow/commit/fd561221d2fe782d320b97346dfffb41f38d2bcf,Refactor Keras initializers to rely on core TF initializers; add serialization methods to core TF initializers.Change: 153403157,1,Move Method,,
6f6e590d0465cbd3d3606d81ce7f5a5ba1bfb481,2017-04-01T00:23:51Z,https://github.com/tensorflow/tensorflow/commit/6f6e590d0465cbd3d3606d81ce7f5a5ba1bfb481,Refactor factorization_ops_test in contrib/factorization.Change: 151887259,1,Move Method,,
313c629560f76c4a849bf6710653fb339ab34a77,2017-03-30T02:32:46Z,https://github.com/tensorflow/tensorflow/commit/313c629560f76c4a849bf6710653fb339ab34a77,Move some asserts and other code from contrib.framework to core.Change: 151657164,1,Move Method,,
e077e4885a8b2b3f31217056ca932757fe671696,2017-03-11T05:29:26Z,https://github.com/tensorflow/tensorflow/commit/e077e4885a8b2b3f31217056ca932757fe671696,Move Estimator.export_savedmodel() to core.Change: 149827847,1,Move Method,,
38c9f4664eb53472448523da5e9d6c071e25c3fa,2017-03-02T03:05:26Z,https://github.com/tensorflow/tensorflow/commit/38c9f4664eb53472448523da5e9d6c071e25c3fa,Move build_*_serving_input_fn to core as build_*_serving_input_receiver_fnChange: 148959101,1,Move Method,,
1617ffbc3df4066ff76325e889ce79d12e4b1c0f,2017-03-01T12:35:36Z,https://github.com/tensorflow/tensorflow/commit/1617ffbc3df4066ff76325e889ce79d12e4b1c0f,Move dynamic_rnn_estimator._construct_rnn_cell() into rnn_common and make itpublic.Change: 148875698,1,Move Method,,
28554fbc756454cd2a1f6f6bda2b2cc86c68bcff,2017-02-27T22:56:51Z,https://github.com/tensorflow/tensorflow/commit/28554fbc756454cd2a1f6f6bda2b2cc86c68bcff,Moved common code out of RNN Estimators.Change: 148698589,1,Move Method,,
0431511cedec7b3173576399de951c7e11360c4a,2017-02-25T21:31:27Z,https://github.com/tensorflow/tensorflow/commit/0431511cedec7b3173576399de951c7e11360c4a,Move numpy_input_fn and pandas_input_fn from contrib to core.Change: 148560715,1,Move Method,,
3e368f12824dcb2961e1d28647b85ef84b23e5c4,2017-02-24T22:51:28Z,https://github.com/tensorflow/tensorflow/commit/3e368f12824dcb2961e1d28647b85ef84b23e5c4,Move estimator.fit into core.Change: 148507023,1,Move Method,,
f772b5dc5c047660a54c9f6bf54db13c7f72c012,2017-02-24T19:12:22Z,https://github.com/tensorflow/tensorflow/commit/f772b5dc5c047660a54c9f6bf54db13c7f72c012,Moved common code out of RNN Estimators.Change: 148480357,1,Move Method,,
a00adb111401381f22f7be556271eb07c4224151,2017-02-23T18:18:25Z,https://github.com/tensorflow/tensorflow/commit/a00adb111401381f22f7be556271eb07c4224151,Split print_selective_registration_header into library and binary.Change: 148358318,1,Move Method,,
5a21e678bd8b0fe294717a0362d41c6dfc467cef,2016-12-15T17:00:04Z,https://github.com/tensorflow/tensorflow/commit/5a21e678bd8b0fe294717a0362d41c6dfc467cef,"Move the implementation code of static_rnn, static_bidirectional_rnn and static_state_saving_rnn from core to contrib.Change: 142148394",1,Move Method,,
d1c8a40dec3826a429c581ef523646baf7276bb2,2016-12-07T16:29:20Z,https://github.com/tensorflow/tensorflow/commit/d1c8a40dec3826a429c581ef523646baf7276bb2,tfdbg: Some changes that take effect only internally.Change: 141311719,1,Move Method,,
1af94c269874440373c1d18d823110b1f5eabc19,2016-12-02T00:28:32Z,https://github.com/tensorflow/tensorflow/commit/1af94c269874440373c1d18d823110b1f5eabc19,Moves metrics/sets and tensor_util.convert_to_tensor_or_sparse_tensor from contrib to core.Change: 140793359,1,Move Method,,
3f8fc30fbb6ae93997765d4fff4f11481c547d5f,2016-11-29T17:03:07Z,https://github.com/tensorflow/tensorflow/commit/3f8fc30fbb6ae93997765d4fff4f11481c547d5f,Removes `tf.graph_util.set_cpu0()` from the API.This function was only used internally.Change: 140485370,1,Move Method,,
7c76616124ab1a3667784cfb40d759b831eb708d,2016-10-20T00:35:59Z,https://github.com/tensorflow/tensorflow/commit/7c76616124ab1a3667784cfb40d759b831eb708d,"Move the large-tensor concat op test to another test file that can be markednomsan and notsan, and concat_op_test passes in msan and tsan.Change: 136664499",1,Move Method,,
adbad380a1fc3a446f274913fa0379a1f01f3866,2016-09-27T20:48:36Z,https://github.com/tensorflow/tensorflow/commit/adbad380a1fc3a446f274913fa0379a1f01f3866,Moving remove_squeezable_dimensions to framework/tensor_util so that it can be used outside metrics.Change: 134449221,1,Move Method,,
fddaa6b035492776f761e16003685b45ee9e6c60,2016-08-10T18:11:54Z,https://github.com/tensorflow/tensorflow/commit/fddaa6b035492776f761e16003685b45ee9e6c60,Move _BroadcastShape to a separate function in tensor_shape.Change: 129887373,1,Move Method,,
6550a20915c5ca3dd32784e34ff28e534aae2538,2016-08-01T22:11:49Z,https://github.com/tensorflow/tensorflow/commit/6550a20915c5ca3dd32784e34ff28e534aae2538,Move getting weights and biases into the ComposableModel.Change: 129032380,1,Move Method,,
0d534ca63d92596bd5efd4808e37cf39ba623fcf,2016-07-30T15:32:55Z,https://github.com/tensorflow/tensorflow/commit/0d534ca63d92596bd5efd4808e37cf39ba623fcf,Move binary_hinge_loss under contrib/losses/Change: 128892982,1,Move Method,,
333b69580537bf14a3072f1388de64eb3fb5ebc2,2016-07-15T03:57:00Z,https://github.com/tensorflow/tensorflow/commit/333b69580537bf14a3072f1388de64eb3fb5ebc2,Moves eval op from dnn_linear_combined to TargetColumn.Change: 127504952,1,Move Method,,
6ea8a70bd776fd1914a3517364a5e7c08f825096,2016-07-14T17:31:15Z,https://github.com/tensorflow/tensorflow/commit/6ea8a70bd776fd1914a3517364a5e7c08f825096,Move broadcasting out of OperatorX.  The OperatorX classes will now requireinput to follow the same (strict) shape requirements of TensorFlow batch matrixoperations.  Helper functions will reshape/brodcast vectors/matrices to makethem compatible.Change: 127446489,1,Move Method,,
76fcc17bb1252862f1a640e741142b20239387d6,2016-06-30T21:47:22Z,https://github.com/tensorflow/tensorflow/commit/76fcc17bb1252862f1a640e741142b20239387d6,Prepare move of safe_embedding_lookup_sparse from framework/ to layers/Change: 126346230,1,Move Method,,
7fef15aada5e95b790a801e2fbd691e03d935a67,2016-06-27T15:19:50Z,https://github.com/tensorflow/tensorflow/commit/7fef15aada5e95b790a801e2fbd691e03d935a67,Initial refactor of the DNNLinearCombinedEstimator. This factors outfunctionality for linear regression and DNN into ComposableModel objects. Theintent is to follow up this change with one that changes the implementations ofthe LinearEstimator and the DNNEstimator classes to use these compositionalblocks.Change: 125957646,1,Move Method,,
e8189db6bd65233108393291dc01d40d310275ad,2016-06-15T00:46:37Z,https://github.com/tensorflow/tensorflow/commit/e8189db6bd65233108393291dc01d40d310275ad,Move do_quantize_training_on_graphdef to tf.trainChange: 124903871,1,Move Method,,
d0dec7ccd438c29b7806baef849c78b7a95e4467,2016-06-02T22:17:12Z,https://github.com/tensorflow/tensorflow/commit/d0dec7ccd438c29b7806baef849c78b7a95e4467,"Refactoring TensorFlowLinearYYY to use LinearYYY and TensorFlowDNNClassifier / TensorFlowDNNYYY to use DNNYYY. Added DeprecatedMixin to support old interface before we remove them.* Added dropout to DNN/Linear/DNNLinearCombined.* Fixed tests and disabled few that are not useful at this point.* Addressed data feeders to work without n_classes properly (preserving dtype).* Fixing bug with LinearRegression, where loss was broadcasted into [batch_size, batch_size].Change: 123912829",1,Move Method,,
48ea574a3b9230a17cfc6f45cd7c56507e41cd4e,2016-06-02T01:19:15Z,https://github.com/tensorflow/tensorflow/commit/48ea574a3b9230a17cfc6f45cd7c56507e41cd4e,"Move functions that depend on problem type (loss, metric, predictions) from base class to Classifier and Regressor.Change: 123818693",1,Move Method,,
cf3bc09caffe50a538682928aaa716dfc4b08930,2016-05-28T00:55:53Z,https://github.com/tensorflow/tensorflow/commit/cf3bc09caffe50a538682928aaa716dfc4b08930,Moved get_variable_names and get_variable_value to BaseEstimator.Change: 123474276,1,Move Method,,
c7ab36c695d4f5dc9ccfd5db81366e04f4001208,2016-03-29T00:15:33Z,https://github.com/tensorflow/tensorflow/commit/c7ab36c695d4f5dc9ccfd5db81366e04f4001208,"Moved the higher order functions into functional_ops.py, to avoid some potential circular dependency.Change: 118412058",1,Move Method,,
250369c18bae02a2a6a855cca480e87d95d782f8,2016-02-16T17:52:47Z,https://github.com/tensorflow/tensorflow/commit/250369c18bae02a2a6a855cca480e87d95d782f8,Remove some trivial tests. Tidy up the code.Change: 114763128,1,Move Method,,
c4801e3624dec02091009b40dd9c7e28aed526b2,2016-02-11T21:23:00Z,https://github.com/tensorflow/tensorflow/commit/c4801e3624dec02091009b40dd9c7e28aed526b2,"Clean up saturate_cast, test, and move to tf.saturate_castChange: 114470777",1,Move Method,,
089d99ba704b33fa95a0a17cad5227aa45d59621,2016-01-07T06:38:28Z,https://github.com/tensorflow/tensorflow/commit/089d99ba704b33fa95a0a17cad5227aa45d59621,Moving extraction of pandas dataframe into io/data_feeder,1,Move Method,,
8b9f49cf0016322c08fec0f72c5a868da8b50fee,2016-01-03T04:23:37Z,https://github.com/tensorflow/tensorflow/commit/8b9f49cf0016322c08fec0f72c5a868da8b50fee,Move seq2seq operations from examples to ops/seq2seq_ops,1,Move Method,,
0c4ca59bce74231e877812279bc9f75baa464bbc,2015-11-18T03:08:33Z,https://github.com/tensorflow/tensorflow/commit/0c4ca59bce74231e877812279bc9f75baa464bbc,Moved out get_feed_dict_fn into a DataFeeder to allow customize it later,1,Move Method,,
67e33815af883113216001db33a8d4d14a674823,2015-11-13T04:33:48Z,https://github.com/tensorflow/tensorflow/commit/67e33815af883113216001db33a8d4d14a674823,Refactored out Trainer and ops from main file,1,Move Method,,
caaf8512e4d69f576e7582257fe9633f424395a9,2023-03-02T19:30:34Z,https://github.com/keras-team/keras/commit/caaf8512e4d69f576e7582257fe9633f424395a9,"Reorder the methods in BatchNorm layer.  All the public method will come first, and private methods are grouped based on their functionality.  PiperOrigin-RevId: 513593297",1,Move Method,,
3ba4d8dadb4db52cf066662f5068e4f99ebd87ee,2022-09-02T21:01:37Z,https://github.com/keras-team/keras/commit/3ba4d8dadb4db52cf066662f5068e4f99ebd87ee,Move optimizer methods not related to distributed training to the base class.  PiperOrigin-RevId: 471880396,1,Move Method,,
a0a55837cb002a1856bba361a44c6dfc566da76c,2022-07-07T17:37:02Z,https://github.com/keras-team/keras/commit/a0a55837cb002a1856bba361a44c6dfc566da76c,Move the RandomGenerator init logic from __init__ to build().  This will allow the tf.Variable created in the tf.random.Generator to have proper name scope.  PiperOrigin-RevId: 459547617,1,Move Method,,
558592f71e3210cfe3d01b0eb0d1e0622d04a6b5,2022-07-05T14:23:37Z,https://github.com/keras-team/keras/commit/558592f71e3210cfe3d01b0eb0d1e0622d04a6b5,"bad refactor on make_logs member, should've been in the CallbackList class",1,Move Method,,
6b27ac0aeedb2f0b4b48aad38094ecbab5b3ddcc,2022-03-30T21:53:50Z,https://github.com/keras-team/keras/commit/6b27ac0aeedb2f0b4b48aad38094ecbab5b3ddcc,Move image loading and saving utils to /utils  PiperOrigin-RevId: 438403293,1,Move Method,,
d022b8c987e470c33f8aac86606f6f7369f64feb,2022-03-30T18:01:32Z,https://github.com/keras-team/keras/commit/d022b8c987e470c33f8aac86606f6f7369f64feb,Move pad_sequences to /utils  PiperOrigin-RevId: 438345895,1,Move Method,,
62aab556c6252e54b9f3ee3fa65243aecd6aea52,2022-03-05T00:15:24Z,https://github.com/keras-team/keras/commit/62aab556c6252e54b9f3ee3fa65243aecd6aea52,"Refactor RNN classes such that V2 cells and layers no longer depend on V1 counterparts.  V2 GRU and LSTM cells no longer extend their V1 counterpart; instead the inheritance is the other way around. V2 GRU and LSTM layers no longer extend their V1 counterpart; instead the common code was duplicated. V2 cell wrappers and legacy cell wrappers no longer have a complex hierarchy with multiple inheritance to share code; instead, the common code was duplicated. Unit tests for GRU and LSTM layers were reorganized so that all generic tests that work for both V1 and V2 are in `gru_test.py` and `lstm_test.py`. The only tests in `gru_v1_test.py` and `lstm_v1_test.py` are the ones that compare V1 and V2 for accuracy or performance, and V1 specific tests. Also made cell wrappers API more consistent, all wrappers now expose a `wrapped_cell` property, not just `DropoutWrapper`.  PiperOrigin-RevId: 432554966",1,Move Method,,
e787c3d9cd6421c95c7088e2139145812ab2a100,2021-09-20T18:01:54Z,https://github.com/keras-team/keras/commit/e787c3d9cd6421c95c7088e2139145812ab2a100,Add a utility for encoding categorical perprocessing output  This will make it easier to bring uniform output modes to the full set of preprocessing layers with categorical output.  PiperOrigin-RevId: 397792405,1,Move Method,,
fe31a34aa3447c5a7a768a8f61dcfd022ac2467b,2021-06-21T19:59:57Z,https://github.com/keras-team/keras/commit/fe31a34aa3447c5a7a768a8f61dcfd022ac2467b,"Port keras lookup layers to new adapt, use a StaticHashTable during call  This is a significant refactor of the internals of the layer, which will break SavedModel compatibility with previous versions. The usage of the layer will remain the same, so a compatible layer should be generatable from the same training script.  This refactor has the following advantages:  - Static tables can be distributed to end workers in a multi-worker setting    allowing more efficient distributed training.  - File based vocabularies will only be scanned once.  - Static vocabularies passed on init will be consistently clonable with the    layer config, rather than clonable only in the file based case.  We now consistently enforce that a vocabulary must be set when calling the layer on anything besides a keras.Input.  PiperOrigin-RevId: 380645230",1,Move Method,,
4aba316b7973e246af94ab5ace18fd5d5ffe4f81,2019-01-28T22:43:34Z,https://github.com/keras-team/keras/commit/4aba316b7973e246af94ab5ace18fd5d5ffe4f81,Moved the backend __init__ into another file. (#12086)  * Moved the backend __init__ into another file.  * Used the private variable of load_backend.,1,Move Method,,
67d563c455072dd26e4612a0b050b9f8363385ca,2018-09-28T19:09:48Z,https://github.com/keras-team/keras/commit/67d563c455072dd26e4612a0b050b9f8363385ca,[updated] improve softmax implementation (#11189)  * adjust softmax implementation  * theano only handle 2-dim case for softmax  [theano softmax](http://deeplearning.net/software/theano/library/tensor/nnet/nnet.html#theano.tensor.nnet.nnet.softmax)  * clean softmax activation and add 3d softmax test  * fix axis  * fix 1d case and test case  * fix 1d case and test case  * change to standard test  * fix test case  * Update activations_test.py  * got the value error back.  * Moved correctness test to the backend tests.  * Added a correctness test to activations_test.py.,1,Move Method,,
8e5b8533ea819d0252d08f45648782ecd543ac70,2018-06-13T18:39:12Z,https://github.com/keras-team/keras/commit/8e5b8533ea819d0252d08f45648782ecd543ac70,Move `get_source_inputs` (#10415),1,Move Method,,
125f4234772c48f4eba6bda3022a98ba7f9c9e9c,2018-02-25T01:16:26Z,https://github.com/keras-team/keras/commit/125f4234772c48f4eba6bda3022a98ba7f9c9e9c,"Refactoring of ConvLSTM2D. Added ConvRNN2D and ConvLSTM2DCell. (#9094)  * Started refactoring.  * Added ConvRecurrent2D to legacy/layers.  * Updated docstrings.  * Fixed a small bug due to K.int_shape when using Theano.  * Fixed docstrings.  * Made ConvRNN2D sub-class of RNN.  * Used K.is_keras_tensor, made shorter lines, among various other fixes.  * Fixed Theano dropout issue.  * Fixed theano issue with keras shape.  * Fixed losses attribute of RNN class.",1,Move Method,Extract Method,Rename Method
c9642571c23004a10e8bca1a5b1446af399f80db,2016-02-16T21:22:53Z,https://github.com/keras-team/keras/commit/c9642571c23004a10e8bca1a5b1446af399f80db,Refactor callbacks,1,Move Method,,
e06f9df8782b6859cca4aeccb63ef3ca661a49df,2015-07-24T07:26:27Z,https://github.com/keras-team/keras/commit/e06f9df8782b6859cca4aeccb63ef3ca661a49df,Refactor model serialization,1,Move Method,,
d1387c1e871e726e6b75050f39809fd54fdacb81,2015-07-24T07:05:39Z,https://github.com/keras-team/keras/commit/d1387c1e871e726e6b75050f39809fd54fdacb81,Move model_utils to layer_utils,1,Move Method,,
4962f1885797f29754ebcbe25de2384cf1420c71,2015-06-24T19:09:26Z,https://github.com/keras-team/keras/commit/4962f1885797f29754ebcbe25de2384cf1420c71,Move the objective-weighting decorator out of get(),1,Move Method,,
cb02df95b28716a2d506941babbc817953b79fce,2015-04-16T03:21:58Z,https://github.com/keras-team/keras/commit/cb02df95b28716a2d506941babbc817953b79fce,"Modernize io_utils, move save_array, load_array",1,Move Method,,
5be73f1ab39a4bc2dfe278a199972e0a14ffa014,2017-04-24T18:47:11Z,https://github.com/keras-team/keras/commit/5be73f1ab39a4bc2dfe278a199972e0a14ffa014,Simplify implementation of BN layer.,1,Move Method,,
58fd1f0589d33aeb33c4129cfedfb7737495efc0,2018-04-25T04:06:54Z,https://github.com/keras-team/keras/commit/58fd1f0589d33aeb33c4129cfedfb7737495efc0,Refactor training part of `engine` module. (#10029)  * Refactor topological part of Keras engine.  * Fix imports  * Fix merge mixup.  * Refactor training part of the Keras engine.  * Fix unit tests.,1,Move Method,Rename Method,
e4204c5b99a6a27f526563f1f600df1fb0f27ad7,2023-03-22T00:20:34Z,https://github.com/keras-team/keras/commit/e4204c5b99a6a27f526563f1f600df1fb0f27ad7,Move the util methods for checking dtensor strategy to a common place.  This method will be used by optimizers/metrics in follow up cls.  PiperOrigin-RevId: 518424850,1,Move Method,Rename Method,
04ad23252a3ce592c5e5c30c6fd87000f8d178cf,2018-01-08T18:43:09Z,https://github.com/pytorch/pytorch/commit/04ad23252a3ce592c5e5c30c6fd87000f8d178cf,"Refactor gen_variable_type (#4487)The gen_variable_type.py script now is only responsible for generatingVariableType.h/cpp. The parent script, ""gen_autograd.py"", delegates togen_autograd_functions.py, gen_variable_type.py, andgen_python_functions.py.I've removed ""fallthrough"" functions. It's replaced byDONT_RECORD_TRACE, DONT_PROFILE, and DONT_REQUIRE_DERIVATIVE.In preparation for binding the _out variants, I changed some statictypes to Tensor (from Variable) and we now unpack and name tuple returnvalues.",1,Move Method,API Refactoring,
0a33c3f1a102cc2dc535643a799d116f36a3b8ed,2019-11-16T03:07:26Z,https://github.com/pytorch/pytorch/commit/0a33c3f1a102cc2dc535643a799d116f36a3b8ed,"split module interface tests (#29917)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/29917move test_module_interface to its own file, no code logic changeTest Plan: Imported from OSSDifferential Revision: D18543235fbshipit-source-id: ab5e233061ba45cb0c05cafdd289b859036c207c",1,Move Method,,
0a93e6db5abdcc9196199d68f0c8e56578a74315,2023-02-03T21:42:27Z,https://github.com/pytorch/pytorch/commit/0a93e6db5abdcc9196199d68f0c8e56578a74315,Fix/refactor dynamo ipex backend (#93863)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/93863 Approved by: https://github.com/desertfire,1,Move Method,,
0aa694ebe5615c1de01c8075a5084bc30c79e04d,2019-10-18T19:47:03Z,https://github.com/pytorch/pytorch/commit/0aa694ebe5615c1de01c8075a5084bc30c79e04d,"Move Method::lowered_graph to a separate pass out of the Method class. (#28242)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/28242There is no reason to have it in a general API of Module/Method - it'sjust another graph pass. It was there because some time ago modules werenot first class and all graphs were lowered. After that changed, thisAPI was added for easier transition, but now we don't need it anymore.Test Plan: Imported from OSSDifferential Revision: D17986724Pulled By: ZolotukhinMfbshipit-source-id: 279a1ec450cd8fac8164ee581515b09f1d755630",1,Move Method,,
0aa9f22f1a49bc8da2755dd9b5756c3f2da0ffaa,2021-03-03T14:57:00Z,https://github.com/pytorch/pytorch/commit/0aa9f22f1a49bc8da2755dd9b5756c3f2da0ffaa,Move groupbykey to grouping (#53122)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/53122Test Plan: Imported from OSSReviewed By: glaringleeDifferential Revision: D26756641Pulled By: ejguanfbshipit-source-id: c4bc5864d841ce20c49446a03cfd195245b2be6e,1,Move Method,,
10c4b98ade8349d841518d22f19a653a939e260c,2019-07-04T00:22:22Z,https://github.com/pytorch/pytorch/commit/10c4b98ade8349d841518d22f19a653a939e260c,"Remove weak script (#22212)Summary:* Deletes all weak script decorators / associated data structures / methods   * In order to keep supporting the standard library in script, this enables recursive script on any function defined in `torch.nn`   * Most changes in `torch/nn` are the result of `ag -Q ""weak"" torch/nn/ -l | xargs sed -i '/weak/d'`, only `rnn.py` needed manual editing to use the `ignore` and `export` to continue supporting the overloaded `forward` methods* `Sequential`/`ModuleList` no longer need to be added to constants since they are compiled on demandThis should also fix https://github.com/pytorch/pytorch/issues/22212Pull Request resolved: https://github.com/pytorch/pytorch/pull/22212Differential Revision: D15988346Pulled By: driazatifbshipit-source-id: af223e3ad0580be895377312949997a70e988e4f",1,Move Method,Rename Method,
1592d6842cc8d4fabca35a6f9ac3117c34348e70,2020-04-21T23:31:17Z,https://github.com/pytorch/pytorch/commit/1592d6842cc8d4fabca35a6f9ac3117c34348e70,[resubmit] Move profiler to a dispatch wrapper (#36766)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/36766Original commit changeset: dcb41d243369ghstack-source-id: 102614215Test Plan: waitforsadcastleDifferential Revision: D21076029fbshipit-source-id: c2461c57cfd364bd23ff99bc2cb5572d22e23391,1,Move Method,,
184bfbc3d7b37e8f202f4938f6ea9ba557c93b1e,2023-03-30T22:18:13Z,https://github.com/pytorch/pytorch/commit/184bfbc3d7b37e8f202f4938f6ea9ba557c93b1e,Move functional collectives to the right namespace (#97793)  This moves them from `torch._C._nn` to `torch._C._dist` Pull Request resolved: https://github.com/pytorch/pytorch/pull/97793 Approved by: https://github.com/albanD,1,Move Method,,
1c78a4a733d42cab6e01070c3f06f1166747fa72,2021-04-07T18:27:52Z,https://github.com/pytorch/pytorch/commit/1c78a4a733d42cab6e01070c3f06f1166747fa72,"move list dict and named tuple tests out of py3 and into test_list_dict.py (#55476)Summary:Hackathon: Split test_jit_py3 into jit/ individual testspart 1: move Dict, List, NamedTuplePull Request resolved: https://github.com/pytorch/pytorch/pull/55476Reviewed By: nikithamalgifbDifferential Revision: D27625646Pulled By: walterddrfbshipit-source-id: 2d68f0e24df2c26ea73860b9d36669e2a6e4ff44",1,Move Method,,
1d4d9ffca056ac4b638ae89ffa83f2b5ec9a4ffa,2021-05-11T20:46:07Z,https://github.com/pytorch/pytorch/commit/1d4d9ffca056ac4b638ae89ffa83f2b5ec9a4ffa,[torch/elastic] Refactor rendezvous store initialization logic (#58057)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/58057  This PR refactors the store initialization logic and moves it to the `create_backend` function for both C10d and etcd backends. ghstack-source-id: 128671579  Test Plan: Run the existing and revised tests.  Reviewed By: tierex  Differential Revision: D28356587  fbshipit-source-id: caf9416ab811eefe4834268d8a11a48f2236ed5b,1,Move Method,,
24c3ad78513c75d382621d5a419e5c09a0b35030,2022-12-13T14:14:02Z,https://github.com/pytorch/pytorch/commit/24c3ad78513c75d382621d5a419e5c09a0b35030,"Move private forward grad mode helpers to torch.autograd.forward_ad (#90240)  Motivation - These were previously defined in functorch. They are not functorch-specific, so I'm moving them to torch.autograd.forward_ad and the autograd python bindings. - I need this to avoid some of my cyclic import problems.  Should these be public APIs? Probably. Though this needs discussion, so punting it to the future.  Test Plan: - moved the tests of these from test/functorch/test_eager_transforms.py to test/test_autograd.py Pull Request resolved: https://github.com/pytorch/pytorch/pull/90240 Approved by: https://github.com/soulitzer",1,Move Method,,
2b30e7fe119dcd1f499035929b18cb7e56fd0e90,2020-04-09T15:45:03Z,https://github.com/pytorch/pytorch/commit/2b30e7fe119dcd1f499035929b18cb7e56fd0e90,Move inplace view tests to generic testing framework (#36281)Summary:So that all these tests run on CUDA as well.This PR is preparation for https://github.com/pytorch/pytorch/pull/36073Pull Request resolved: https://github.com/pytorch/pytorch/pull/36281Differential Revision: D20931467Pulled By: ailzhangfbshipit-source-id: e70c2c1981d9557c4b7ed5e0bd85345e298bf63c,1,Move Method,,
2c1b215b488c4c9cdffcd86ba25f5bfd549162b2,2020-09-15T22:49:55Z,https://github.com/pytorch/pytorch/commit/2c1b215b488c4c9cdffcd86ba25f5bfd549162b2,"[fx] remove delegate, replace with tracer (#44566)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/44566The Delegate objects were confusing. They were suppose to be a way toconfigure how tracing works, but in some cases they appeared necessaryfor consturcting graphs, which was not true. This makes the organizationclearer by removing Delgate and moving its functionality into a Tracer class,similar to how pickle has a Pickler class.Test Plan: Imported from OSSReviewed By: jamesr66aDifferential Revision: D23683177Pulled By: zdevitofbshipit-source-id: 7605a34e65dfac9a487c0bada39a23ca1327ab00",1,Move Method,Rename Class,
2dd867f30fef46fc85fd4e2e08dc32a60f171da0,2020-03-26T02:48:28Z,https://github.com/pytorch/pytorch/commit/2dd867f30fef46fc85fd4e2e08dc32a60f171da0,"Move normal() to DistributionTemplates (#35167)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/35167The purpose of this PR is to move `normal`/`normal_`/`normal_out` to `native/DistributionTemplates.h`, `native/cpu/DistributionTemplates.h` and `native/cuda/DistributionTemplates.h` to make it reusable for custom RNG, see cpu_rng_test.cpp as an example of custom RNG.Test Plan: Imported from OSSDifferential Revision: D20588248Pulled By: pbelevichfbshipit-source-id: 7ee60be97f81522cd68894ff1389007c05130a60",1,Move Method,,
2e49c5dc37bce5ce8ba463a59aacb5d3e4a638b6,2021-07-13T07:57:01Z,https://github.com/pytorch/pytorch/commit/2e49c5dc37bce5ce8ba463a59aacb5d3e4a638b6,Move GetArgumentNamesModule registration to InterpreterManager() (#61549)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/61549  Move GetArgumentNamesModule registration to InterpreterManager() such that the module is a permanent part of the interpreters and can be used by InterpreterSession.global() freely.  Test Plan: [... ~/fbsource/fbcode/caffe2] buck test mode/dev caffe2/fb/predictor:pytorch_predictor_test -- PyTorchDeployPredictor.GetArgumentNames  Reviewed By: wconstab  Differential Revision: D29643460  fbshipit-source-id: cf132d4795cbb334ce164ac715d590a105535508,1,Move Method,,
3099732017239c3efce9b41f205a9c9df376fd5a,2019-10-01T09:22:50Z,https://github.com/pytorch/pytorch/commit/3099732017239c3efce9b41f205a9c9df376fd5a,"Creates device generic cuDNN decorators (#26791)Summary:- Creates skipCUDAIfNoCudnn, skipCUDAIfCudnnVersionLessThan decorators- Makes several test_nn.py tests genericMany tests in test_nn.py test cuDNN. These tests are guarded on various conditionals using TEST_CUDNN and TEST_CUDNN_VERSION imported from common_cuda.py and custom error messages like 'CUDNN not available' and 'needs cudnn.'This PR suggests using the CUDA base test class instead of common_cuda.py to test cuDNN's availability, at least on generic tests. The CUDA base test class is preferable to common_cuda.py since it only creates a CUDA context if its tests are run. Importing from common_cuda.py, on the other hand, always creates a CUDA context. Using the CUDA base test class is also consistent with how other generic tests are guarded and provides consistent skip messages.One quirk to this approach is that it makes use of the self argument to the test functions to check for cuDNN availability during a test. See test_rnn_retain_variables. The self argument could also be used to check the device type instead of the more verbose torch.device(device).type == 'cuda'.An alternative approach to making test_nn.py generic would be to continue to use common_cuda.py imports, try to keep their skip messages consistent, and not worry about creating unnecessary CUDA contexts. This would preclude writing generic tests that can only run on CUDA if cuDNN is available, however, so tests like ""_test_RNN_cpu_vs_cudnn"" would require additional changes to make into device generic precision tests like ""_test_RNN_cpu_vs_xla.""For consistency, simplicity, and ease of use, I recommend we adopt the proposed decorators and make use of the self argument when productive.Pull Request resolved: https://github.com/pytorch/pytorch/pull/26791Differential Revision: D17678325Pulled By: mruberryfbshipit-source-id: 1794735ede9bc9f36856e72b3804b136ad3e0de2",1,Move Method,,
32e0cedc53de4611b23a6b8e78edd2cf69b80de8,2020-09-03T04:45:49Z,https://github.com/pytorch/pytorch/commit/32e0cedc53de4611b23a6b8e78edd2cf69b80de8,[ONNX] Move tests to test_pytorch_onnx_onnxruntime (#42684)Summary:Move tests to test_pytorch_onnx_onnxruntime from test_utility_funPull Request resolved: https://github.com/pytorch/pytorch/pull/42684Reviewed By: smessmerDifferential Revision: D23480360Pulled By: bzinodevfbshipit-source-id: 8876ba0a0c3e1d7104511de7a5cca5262b32f574,1,Move Method,Extract Method,
364ae10bb8813266aea1a708e89f9deea0c4a243,2018-09-25T17:48:02Z,https://github.com/pytorch/pytorch/commit/364ae10bb8813266aea1a708e89f9deea0c4a243,nomnigraph - easy - add some python test helper methods (#12020)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/12020- make it less verbose to create random blobs in python unit test by adding some test helper methods- move str_compare test helper method to test_util.pyReviewed By: ZolotukhinMDifferential Revision: D10003637fbshipit-source-id: cb79d2ad508341f750a1bb8f564e87d055c65652,1,Move Method,,
3baa67caeee9f45669167bda69dfaa1b9e1efead,2023-05-24T16:13:28Z,https://github.com/pytorch/pytorch/commit/3baa67caeee9f45669167bda69dfaa1b9e1efead,[quant][pt2e][be] Move annotate helper function to quantizer/utils.py (#102127)  Summary: att  Test Plan: ``` buck2 test mode/opt caffe2/test:quantization_pt2e -- --exact 'caffe2/test:quantization_pt2e - test_resnet18_with_quantizer_api (quantization.pt2e.test_quantize_pt2e.TestQuantizePT2EModels)' ```  Reviewed By: kimishpatel  Differential Revision: D46001285  Pull Request resolved: https://github.com/pytorch/pytorch/pull/102127 Approved by: https://github.com/kimishpatel,1,Move Method,,
4582ceb2c4a7316f09afd471a97d910347d21f01,2023-05-02T12:42:24Z,https://github.com/pytorch/pytorch/commit/4582ceb2c4a7316f09afd471a97d910347d21f01,[distributed][sharded_tensor] Move local_shards check from ShardedTensorBase to ShardedTensor (#100197)  Differential Revision: [D45369211](https://our.internmc.facebook.com/intern/diff/D45369211) Pull Request resolved: https://github.com/pytorch/pytorch/pull/100197 Approved by: https://github.com/fduwjj,1,Move Method,,
465138ec39b65cec55f67fb0712859eed921d541,2020-06-19T18:43:13Z,https://github.com/pytorch/pytorch/commit/465138ec39b65cec55f67fb0712859eed921d541,"refactoring TestQuantizeScript (#39677)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/39677Test Plan:Moved a test class suite between files, wanted to have same functionality (simple code refactor) so tested to make sure the test output was the same before/after the refactor.Image below shows the output of TestGraphModePostTrainingStatic before refactor{F239676498}This image shows the output of TestQuantizeScript (renamed version that is in test_quantize_script.py instead of test_quantize.py){F239676509}Differential Revision: D21940638Pulled By: edmundw314fbshipit-source-id: 54160a5151aadf3a34bdac2bcaeb52904e6653ed",1,Move Method,,
47b4136439add062ab080d981f759581ff82d6c5,2023-05-24T16:27:21Z,https://github.com/pytorch/pytorch/commit/47b4136439add062ab080d981f759581ff82d6c5,"Refactor normalize passes to use @register_graph_pattern (#101764)  Cleans up normalize passes by using register_graph_pattern decorator  Differential Revision: [D45973543](https://our.internmc.facebook.com/intern/diff/D45973543/)  **NOTE FOR REVIEWERS**: This PR has internal Meta-specific changes or comments, please review them on [Phabricator](https://our.internmc.facebook.com/intern/diff/D45973543/)!  Pull Request resolved: https://github.com/pytorch/pytorch/pull/101764 Approved by: https://github.com/jansel",1,Move Method,,
49d5b4d1e18929b5e99e042fba3043c82d8d4924,2020-11-10T04:34:10Z,https://github.com/pytorch/pytorch/commit/49d5b4d1e18929b5e99e042fba3043c82d8d4924,"move helper functions out of Partitioner class (#47515)Summary:This PR moves some helper functions out of Partitioner class. It will make Partitioner class cleaner and make these helper functions easier to use in the futurePull Request resolved: https://github.com/pytorch/pytorch/pull/47515Reviewed By: gcatron, heitorschueroffDifferential Revision: D24844751Pulled By: scottxu0730fbshipit-source-id: 04397d0ce995cf96943df0a2b9265a521177b4de",1,Move Method,,
4dba6743246eebded79aa1398f898b99370d6905,2017-12-21T22:07:46Z,https://github.com/pytorch/pytorch/commit/4dba6743246eebded79aa1398f898b99370d6905,Move factional max pooling to ATen (#4290),1,Move Method,,
569bdb4b774111571272180bea6033720e9187cc,2017-10-16T22:11:16Z,https://github.com/pytorch/pytorch/commit/569bdb4b774111571272180bea6033720e9187cc,"Refactor executor testSummary:Travis treats test_settings/test_model_names as tests, moving them intoexecutor_test_utilReviewed By: bddppqDifferential Revision: D6068920fbshipit-source-id: 01c5bf962b985398414f44a7849c0f6344fd7e1d",1,Move Method,,
59071ab1e71891d480ab77af0d619bc5e01094c2,2023-01-20T01:36:47Z,https://github.com/pytorch/pytorch/commit/59071ab1e71891d480ab77af0d619bc5e01094c2,[Executorch][Quantization][BE] Refactor Choose Qparams (#92592)  Summary: Should hopefully be a little faster. Definitely cleaner to not create an observer inside the op  Test Plan: ci  Differential Revision: D42154677  Pull Request resolved: https://github.com/pytorch/pytorch/pull/92592 Approved by: https://github.com/jerryzh168,1,Move Method,,
5cd73df8f8ddcfc3d370a26a27a558bc9d921ece,2021-04-13T03:33:51Z,https://github.com/pytorch/pytorch/commit/5cd73df8f8ddcfc3d370a26a27a558bc9d921ece,[Hackathon]Move complex tests to test_complex.py (#55514)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/55514Test Plan: Imported from OSSReviewed By: pbelevichDifferential Revision: D27679881Pulled By: nikithamalgifbfbshipit-source-id: 8a4f4ab8f375187b72ede6feaea37ab546da6d3e,1,Move Method,,
5e79b5b1c7ad676b5ab5a72ec0939a7ace545375,2019-09-28T01:04:13Z,https://github.com/pytorch/pytorch/commit/5e79b5b1c7ad676b5ab5a72ec0939a7ace545375,Move some class/functions in test_jit.py to jit_utils.py (#26839)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/26839attTest Plan:ciImported from OSSDifferential Revision: D17643010fbshipit-source-id: 5768b70410b7bdfdbee734d3a00296e5b1ad30d5,1,Move Method,Rename Class,
5f0463a6d793ba7b7dd5e884b89362a034feffb0,2023-05-24T15:41:06Z,https://github.com/pytorch/pytorch/commit/5f0463a6d793ba7b7dd5e884b89362a034feffb0,[inductor] Move two cpu tests to test_cpu_repro.py (#101887)  Summary: The two are cpu only tests.  Test Plan: ``` buck2 test @//mode/dev-nosan //caffe2/test/inductor:test_inductor -- --exact 'caffe2/test/inductor:test_inductor - test_in_out_buffer_cuda (caffe2.test.inductor.test_torchinductor.CudaTests)' --run-disabled ```  Reviewed By: bertmaher  Differential Revision: D46011571  Pull Request resolved: https://github.com/pytorch/pytorch/pull/101887 Approved by: https://github.com/bertmaher,1,Move Method,,
6400d27bbbbd7fb4d6d66c8d493fa6fa91d62998,2020-11-21T17:18:10Z,https://github.com/pytorch/pytorch/commit/6400d27bbbbd7fb4d6d66c8d493fa6fa91d62998,"[Gradient Compression] Define a customized state for PowerSGD comm hook (#48348)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/48348To support the features like error feedback, warm start, PowerSGD comm hook needs to maintain a state besides process group. Currently this state only includes a process group and a matrix approximation rank config.This diff is a pure refactoring. Plan to add more state fields later.Original PR issue: Investigate Applying PowerSGD to Communication Hook for Gradient Compression #47202ghstack-source-id: 117305280Test Plan:buck test mode/dev-nosan caffe2/test/distributed:c10d -- test_powerSGD_ddp_comm_hook_ncclbuck test mode/dev-nosan caffe2/test/distributed:c10d --test_powerSGD_ddp_comm_hook_nccl_grad_is_viewReviewed By: rohan-varmaDifferential Revision: D25137962fbshipit-source-id: cd72b8b01e20f80a92c7577d22f2c96e9eebdc52",1,Move Method,,
646ffd488685076c41a74bb2878dbfddfa53698c,2020-09-09T02:01:50Z,https://github.com/pytorch/pytorch/commit/646ffd488685076c41a74bb2878dbfddfa53698c,[quant] Move EmbeddingBag eager quantization to static (#44217)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/44217Move the tests to static ones as wellTest Plan:python test/test_quantization.py TestStaticQuantizedModule.test_embedding_bag_apiImported from OSSReviewed By: raghuramank100Differential Revision: D23547386fbshipit-source-id: 41f81c31e1613098ecf6a7eff601c7dcd4b09c76,1,Move Method,,
67c329bc9b93cd1e0620f232acd24aff13d37572,2023-03-08T23:00:26Z,https://github.com/pytorch/pytorch/commit/67c329bc9b93cd1e0620f232acd24aff13d37572,Refactor to reduce duplicate logic in torch._ops (#96302)  Signed-off-by: Edward Z. Yang <ezyang@meta.com> Pull Request resolved: https://github.com/pytorch/pytorch/pull/96302 Approved by: https://github.com/zou3519,1,Move Method,,
6b9a52d1a417876c5ca3cd484c476e5d8a2a91af,2023-04-14T18:24:24Z,https://github.com/pytorch/pytorch/commit/6b9a52d1a417876c5ca3cd484c476e5d8a2a91af,[inductor] Refactor post_grad.py (#99127)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/99127 Approved by: https://github.com/ngimel,1,Move Method,,
6bd58b75486372249226d9213014ff09852a88b2,2019-06-20T18:11:07Z,https://github.com/pytorch/pytorch/commit/6bd58b75486372249226d9213014ff09852a88b2,"Move list / dict tests to TestList and TestDict (#22000)Summary:There aren't any substantive changes aside from some test renames (e.g. `TestScript.test_dict_membership` -> `TestDict.test_membership`) and the addition of `TestDict.dict()`.Adding the rest of the dict ops was making the tests a mess and `TestScript` is already > 10000 lines by itself, so breaking them up should make things cleaner](https://our.intern.facebook.com/intern/diff/15911383/)Pull Request resolved: https://github.com/pytorch/pytorch/pull/22000Pulled By: driazatiDifferential Revision: D15911383fbshipit-source-id: 614428e03fbc14252f0e9cde74ab9a707169a860",1,Move Method,,
6e82b1c77d36386ba738af3287693105b4bbafe2,2019-05-14T15:37:48Z,https://github.com/pytorch/pytorch/commit/6e82b1c77d36386ba738af3287693105b4bbafe2,"Split nn.MultiHeadAttention into Module + functional (#20415)Summary:Moving functions from torch/nn/modules/activation.py to torch/nn/functional.py. For functions not implemented (_get_input_buffer and _set_input_buffer), a TODO is added.Pull Request resolved: https://github.com/pytorch/pytorch/pull/20415Differential Revision: D15318078Pulled By: jamarshonfbshipit-source-id: 5ca698e2913821442cf8609cc61ac8190496a3c6",1,Move Method,,
717e70a824afbf226c4cee7943c3840a4e666919,2021-03-29T15:43:56Z,https://github.com/pytorch/pytorch/commit/717e70a824afbf226c4cee7943c3840a4e666919,"(BE) Refactor get-test-times-from-S3 into s3_stat_parser (#54808)Summary:Moves more s3 parsing code to s3_stat_parser.py. This is another step in modularizing the parsing code more correctly. I will also be using this exact function in future slowTest code.Also replaces some Any's in the code to be Report.Pull Request resolved: https://github.com/pytorch/pytorch/pull/54808Test Plan:.pytorch-test-times generated before the code and after this code is the same.CI should pass, specifically the test tools GHA.Reviewed By: walterddrDifferential Revision: D27375783Pulled By: janeyx99fbshipit-source-id: bec28551668b2eb3fdd60d802200993e493eac83",1,Move Method,,
718db968b86899241ef2137e063be1780628e7b3,2021-07-06T16:06:42Z,https://github.com/pytorch/pytorch/commit/718db968b86899241ef2137e063be1780628e7b3,"move CI related functions out of run_test.py (#61124)  Summary: run_test.py currently does lots of downloading and test file/suite/case parsing. It doesn't work well outside of the CI environment  Restructured the run_test.py and created tools/test/test_selections.py and move all test selection logic (reordering, categorizing slow test, creating shards)  Follow up PRs should: - refactor those file read/write logic entangled inside test_selections.py into stats/ folder - restructure and add network independent test logics to test_test_selections.py  Pull Request resolved: https://github.com/pytorch/pytorch/pull/61124  Test Plan: - tools/test - CI  Related PR: This follows the refactoring example in: https://github.com/pytorch/pytorch/issues/60373  Reviewed By: malfet  Differential Revision: D29558981  Pulled By: walterddr  fbshipit-source-id: 7f0fd9b4720a918d82918766c002295e8df04169",1,Move Method,,
720c7b1e2c9580fa897110abca3a41ae676174da,2018-01-17T22:30:43Z,https://github.com/pytorch/pytorch/commit/720c7b1e2c9580fa897110abca3a41ae676174da,"Move repeat to torch/_utils.py (#4712)This moves the implementation of repeat to _utils so that the autogradfunction can call it directly instead of relying on forward being calledon tensors.This also removes _range, which was previously necessary because weshadowed the built-in range() function.",1,Move Method,,
7d8dfd6f76072ce13166cb0b177b6e11683f7662,2019-08-08T23:47:54Z,https://github.com/pytorch/pytorch/commit/7d8dfd6f76072ce13166cb0b177b6e11683f7662,make _overloads importable in nn/functional (#24049)Summary:Move `_overload` to `_jit_internal.py` so that it can be imported in nn/functional.py for `conv`Pull Request resolved: https://github.com/pytorch/pytorch/pull/24049Differential Revision: D16723339Pulled By: eellisonfbshipit-source-id: 527e6069dbfa81f8133c405be5350a8c76873a12,1,Move Method,,
814b5715ba42449f2231a40cdd93273ec6f7e76c,2018-11-30T20:10:49Z,https://github.com/pytorch/pytorch/commit/814b5715ba42449f2231a40cdd93273ec6f7e76c,Move module tests to common_nn (#14578)Summary:This moves `new_module_tests` from `test_nn.py` to `common_nn.py` sothat they can be used in `test_jit.py` without running any of`test_nn.py`Pull Request resolved: https://github.com/pytorch/pytorch/pull/14578Differential Revision: D13268286Pulled By: driazatifbshipit-source-id: 6e8654a4c29ab754d656ac83820c14d1c1843e03,1,Move Method,,
8915e2710c57cefd4bb5a7876216f08d3bc8c92f,2017-07-12T16:36:10Z,https://github.com/pytorch/pytorch/commit/8915e2710c57cefd4bb5a7876216f08d3bc8c92f,Refactor scatter/gather and add distributed docs,1,Move Method,,
89d78851e68867140169a920c94d084445cf528d,2021-05-28T00:04:15Z,https://github.com/pytorch/pytorch/commit/89d78851e68867140169a920c94d084445cf528d,[quant][refactor tests] Move qtensor serialization tests from test_deprecated_jit (#59089)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/59089  Move these tests into test_quantized_tensor  Test Plan: python test/test_quantization.py  Imported from OSS  Reviewed By: jerryzh168  Differential Revision: D28750065  fbshipit-source-id: 5c4350d49dd07710b86ba330de80369403c6013c,1,Move Method,,
8b0374f83c605c47b7c1ba9274011c4b961666ce,2023-04-06T14:06:16Z,https://github.com/pytorch/pytorch/commit/8b0374f83c605c47b7c1ba9274011c4b961666ce,"Move functional collectives implementation to python. (#98315)  This simplifies a lot the work we need to add new ops.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/98315 Approved by: https://github.com/albanD, https://github.com/wconstab, https://github.com/Neilblaze",1,Move Method,,
8f8dccd2edccb910adb168de51948781b18ed570,2017-07-26T20:24:29Z,https://github.com/pytorch/pytorch/commit/8f8dccd2edccb910adb168de51948781b18ed570,"distance_op_test from hypothesis_test refactoredSummary:Moved distance_op_test from hypothesis_test to distance_op_test andrefactoredReviewed By: akyrola, asaadaldienDifferential Revision: D5495104fbshipit-source-id: 4a90c75eabeb380ae9d150d6258e9b5b0fbfc5ca",1,Move Method,,
8fc16da649f05b0e032158ee66ebaf0f9d57a84b,2021-04-13T04:00:52Z,https://github.com/pytorch/pytorch/commit/8fc16da649f05b0e032158ee66ebaf0f9d57a84b,[Hackathon]Move tests for slice to test_slice.py (#55524)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/55524Test Plan: Imported from OSSReviewed By: driazatiDifferential Revision: D27686738Pulled By: nikithamalgifbfbshipit-source-id: f1896d739c3a3a7ece987f6eea4072477626231b,1,Move Method,,
931a4913b1c74697711cb0a51bb227b89ba27f24,2023-03-16T18:36:35Z,https://github.com/pytorch/pytorch/commit/931a4913b1c74697711cb0a51bb227b89ba27f24,[inductor] Refactor memory management code in wrapper codegen (#96768)  Summary: use inheritance to simplify CppWrapperCodeGen and to prepare for AOT codegen  Pull Request resolved: https://github.com/pytorch/pytorch/pull/96768 Approved by: https://github.com/jansel,1,Move Method,,
93c4f9f972ad0d07b5fb978bcebb40a8d6b99955,2021-02-04T17:10:34Z,https://github.com/pytorch/pytorch/commit/93c4f9f972ad0d07b5fb978bcebb40a8d6b99955,Split out RegisterDispatchKey to its own file (#51508)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/51508No substantive changes.  The codegen for this file was getting abit long so I moved it off into tools.codegen.dest submodule (Iwanted to do tools.codegen.gen but that conflicts with the existingmodule; oy vey!)  To do this I had to move some other functions aroundso that they were more generally accessible.  Otherwiseself-explanatory.Signed-off-by: Edward Z. Yang <ezyang@fb.com>Test Plan: Imported from OSSReviewed By: ljk53Differential Revision: D26187856Pulled By: ezyangfbshipit-source-id: fd3784571d03d01c4acb7ca589fcde4492526408,1,Move Method,,
96cedefd8ed031fa518ddbab8f185f73dbe4ba87,2021-01-28T20:07:52Z,https://github.com/pytorch/pytorch/commit/96cedefd8ed031fa518ddbab8f185f73dbe4ba87,"[Pipe] Refactor convert_to_balance under non-test package. (#50860)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/50860Since fairscale.nn.Pipe still uses 'balance' and 'devices' parameters,other frameworks like fairseq still use these parameters. As a result, the`convert_to_balance` method is a nice utility to use for migrating to PyTorchPipe without changing a lot of code in other frameworks.In addition to this I've renamed the method to be more illustrative of what itdoes and also allowed an optional devices parameter.ghstack-source-id: 120430775Test Plan:1) waitforbuildbot2) Tested with fairseqReviewed By: SciPioneerDifferential Revision: D25987273fbshipit-source-id: dccd42cf1a74b08c876090d3a10a94911cc46dd8",1,Move Method,,
98bbb7788ce466069a474d788b2d52b3e7fcce78,2019-09-24T05:46:52Z,https://github.com/pytorch/pytorch/commit/98bbb7788ce466069a474d788b2d52b3e7fcce78,Updates and extends TestNNDeviceType (#26638)Summary:- Moves several tests to TestNNDeviceType- Merges helper base with TestNNDeviceType<s>- Enables non-default stream for TestNN (like recent updates to TestTorch and TestCUDA)</s>Reverted non-default stream due to failure of test_variable_sequence_cuda (main.TestNN).Pull Request resolved: https://github.com/pytorch/pytorch/pull/26638Differential Revision: D17543899Pulled By: mruberryfbshipit-source-id: 001fa191f5fe424f2e7adc378b8fb5ee7f264f16,1,Move Method,,
991b97277ae50fcb5b3a949f2e18ec6da4612d2e,2020-03-20T03:15:19Z,https://github.com/pytorch/pytorch/commit/991b97277ae50fcb5b3a949f2e18ec6da4612d2e,"[RELAND] Eager autocasting, out-of-place ops only (with MSVC 2017 fix) (#35011)Summary:https://github.com/pytorch/pytorch/pull/32140 was approved and merged, but [reverted](https://github.com/pytorch/pytorch/commit/d0577e19f09a32a68f0f3faed635dec72971b019) because it broke builds with versions of Visual Studio older than 15.8 that were not represented in public CI.  The build failures were caused by a [known VS bug](https://developercommunity.visualstudio.com/content/problem/27729/allow-function-with-internal-linkage-as-template-n.html), fixed in versions 15.8 and newer.The present PR reverts the revert (restoring https://github.com/pytorch/pytorch/pull/32140 's diffs) and adds a workaround to enable compilation with VS < 15.8.  The workaround isn't pretty, but it's guarded by macros such that it's only used when compiling with VS < 15.8.  All other builds compile with the same code/control flow as was merged in https://github.com/pytorch/pytorch/pull/32140.Original description of https://github.com/pytorch/pytorch/pull/32140:> Initial integration of eager autocasting, supporting out-of-place ops only for easier review.Relevant issue/RFC: https://github.com/pytorch/pytorch/issues/25081> In-place ops and ops with user-supplied out=... can certainly be supported as well (my initial WIP https://github.com/pytorch/pytorch/issues/29552 handled many) but require substantially more complex special casing in the autocasting backend and tests. Support for these ops (much of which has already been written) will be broken into later PRs.Pull Request resolved: https://github.com/pytorch/pytorch/pull/35011Differential Revision: D20541921Pulled By: ezyangfbshipit-source-id: abb5488dca8620b0daac4306ebf2bb47fc36e4f5",1,Move Method,,
9e8e744efe9e5752abb522c23723b4bb74e08aea,2021-03-26T05:27:30Z,https://github.com/pytorch/pytorch/commit/9e8e744efe9e5752abb522c23723b4bb74e08aea,"ns for fx: move shadow lstm test to new API (#53828)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/53828Moves LSTM shadow activations test to new API. In orderto enable this, adds support for passing two args insteadof one arg when copying a subgraph from A to B.Since this was the last test of the old API, deletesthe old test case.Test Plan:```python test/test_quantization.py TestFXNumericSuiteCoreAPIsModels.test_compare_shadow_activations_lstm_dynamic```Imported from OSSReviewed By: hx89Differential Revision: D26982733fbshipit-source-id: 03f580688dd37f3ccd688d9f444e9e79cfa84734",1,Move Method,,
9f44a04613ec9f10d930a1de9a016c8c55b65fe6,2019-10-28T18:08:46Z,https://github.com/pytorch/pytorch/commit/9f44a04613ec9f10d930a1de9a016c8c55b65fe6,"separate PT and C2 to reduce build time (#28731)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/28731as titleTest Plan:```Before:buck run mode/opt caffe2/benchmarks/operator_benchmark:benchmark_all_test -- --operator sigmoidInvalidating internal cached state: Buck configuration options changed between invocations. This may cause slower builds.  Changed value project.buck_out='buck-out/opt' (was 'buck-out/dev')  ... and 69 more. See logs for all changesParsing buck files: finished in 7.2 secCreating action graph: finished in 10.0 secBuilding: finished in 06:38.4 min (100%) 29890/29890 jobs, 29890 updated  Total time: 06:55.7 min# ----------------------------------------# PyTorch/Caffe2 Operator Micro-benchmarks# ----------------------------------------# Tag : short# Benchmarking PyTorch: sigmoidWith this diffbuck run mode/opt caffe2/benchmarks/operator_benchmark:benchmark_all_test -- --operator sigmoidParsing buck files: finished in 6.4 secCreating action graph: finished in 9.8 secBuilding: finished in 06:35.9 min (100%) 29892/29892 jobs, 29892 updated  Total time: 06:52.1 minReviewed By: hl475Differential Revision: D18152071fbshipit-source-id: 80c29570581bbd2f0e78e2df32734c17a2b036ee",1,Move Method,,
9f75de278fd67b813eada6e6950462ffbc1a6bf9,2021-03-12T03:48:12Z,https://github.com/pytorch/pytorch/commit/9f75de278fd67b813eada6e6950462ffbc1a6bf9,Move common autograd utils functions from gen_variable_type.py to api/autograd.py. (#53340)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/53340Test Plan: Imported from OSSReviewed By: nikithamalgifbDifferential Revision: D26973914Pulled By: ailzhangfbshipit-source-id: 8367a08b27b25808782c77aadc3c67d07c354957,1,Move Method,,
a4cf4c24373374a775193cdb269c3638fcc72293,2020-08-27T21:31:53Z,https://github.com/pytorch/pytorch/commit/a4cf4c24373374a775193cdb269c3638fcc72293,"refactor tests (#43631)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/43631I added a new test for just profiler stuff - I don't think the test should go in test_jit.py. Maybe this should just go in test_tensorexpr_fuser, but I'm not really testing tensorexpr stuff either... LMKTest Plan: Imported from OSSReviewed By: bertmaherDifferential Revision: D23358810Pulled By: eellisonfbshipit-source-id: 074238e1b60e4c4a919a052b7a5312b790ad5d82",1,Move Method,,
a953a825cc976858861b0b3f192bec205ab1d470,2020-09-09T16:38:48Z,https://github.com/pytorch/pytorch/commit/a953a825cc976858861b0b3f192bec205ab1d470,"Moves some of TestTorchMathOps to OpInfos (#44277)Summary:This PR fixes three OpInfo-related bugs and moves some functions from TestTorchMathOps to be tested using the OpInfo pattern. The bugs are:- A skip test path in test_ops.py incorrectly formatted its string argument- Decorating the tests in common_device_type.py was incorrectly always applying decorators to the original test, not the op-specific variant of the test. This could cause the same decorator to be applied multiple times, overriding past applications.- make_tensor was incorrectly constructing tensors in some casesThe functions moved are:- asin- asinh- sinh- acosh- tan- atan- atanh- tanh- log- log10- log1p- log2In a follow-up PR more or all of the remaining functions in TestTorchMathOps will be refactored as OpInfo-based tests.Pull Request resolved: https://github.com/pytorch/pytorch/pull/44277Reviewed By: ngimelDifferential Revision: D23568330Pulled By: mruberryfbshipit-source-id: 03e69fccdbfd560217c34ce4e9a5f20e10d05a5e",1,Move Method,,
a9dc9535f6f0bff95d3b67069d3c6ce4c810a65f,2021-05-05T13:27:48Z,https://github.com/pytorch/pytorch/commit/a9dc9535f6f0bff95d3b67069d3c6ce4c810a65f,"ns for fx: move relatedness mapping to mappings file (#57171)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/57171No logic change, just moving the mapping to a file wherethe other mappings are.Test Plan:```python test/test_quantization.py TestFXNumericSuiteCoreAPIs```Imported from OSSReviewed By: jerryzh168Differential Revision: D28077978fbshipit-source-id: 4049d6a498156a5dffe3a03d2f4abc79da7bf907",1,Move Method,,
aad1ff9f184eb0e05083968a4e0ef484fea80b57,2020-08-20T01:46:39Z,https://github.com/pytorch/pytorch/commit/aad1ff9f184eb0e05083968a4e0ef484fea80b57,[quant][cleanup]test_qlinear_legacy should be under TestDynamicQuantizedLinear. (#40084)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/40084This is just a nit diff (got merge conflict) while writing some unit-tests.This move was nit as part of D21628596 (https://github.com/pytorch/pytorch/commit/655f1ea176c25dda88e96ffb05e4d84df7d0257d).Test Plan: buck test test:quantization -- test_qlinear_legacyReviewed By: supriyarDifferential Revision: D22065463fbshipit-source-id: 96ceaa53355349af7157f38b3a6366c550eeec6f,1,Move Method,,
ac791bddce6704b0be4e1d9e9cfdd0b12fc96fb4,2023-02-01T06:09:42Z,https://github.com/pytorch/pytorch/commit/ac791bddce6704b0be4e1d9e9cfdd0b12fc96fb4,Refactor dynamo distributed test helpers to be reusable (#93187)  The point is to let Test helpers previously defined and used in `test_dynamo_distributed.py` be used from a new file `test_traceable_collectives.py` later in this stack.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/93187 Approved by: https://github.com/kumpera,1,Move Method,,
b60d6e246ed3146d9644a577a8e83f2772986507,2023-03-14T22:55:12Z,https://github.com/pytorch/pytorch/commit/b60d6e246ed3146d9644a577a8e83f2772986507,[inductor] Consolidate codegen functions in sizevars.py into wrapper.py (#96654)  Summary: Refactor the code so that wrapper codegen doesn't mix Python and C++.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/96654 Approved by: https://github.com/jansel,1,Move Method,,
b97ce3774a403444d21845b0f42e2b98d8faa0f3,2023-03-10T21:07:03Z,https://github.com/pytorch/pytorch/commit/b97ce3774a403444d21845b0f42e2b98d8faa0f3,[ONNX] Move graph transform functions to 'passes' (#95664)  This PR only moved code to their new location. No other actual code changes. Pull Request resolved: https://github.com/pytorch/pytorch/pull/95664 Approved by: https://github.com/justinchuby,1,Move Method,,
bbc4e911c8acf7c0dea13c4aaf6f902fe6d4962f,2023-04-01T22:39:49Z,https://github.com/pytorch/pytorch/commit/bbc4e911c8acf7c0dea13c4aaf6f902fe6d4962f,"Move CPUReproTests to its own file (#97943)  test_torchinductor has gotten too big (almost 10k lines), this stack is trying to split it into smaller pieces.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/97943 Approved by: https://github.com/ngimel",1,Move Method,,
bc475cad671aafd9e1d4347801f35a12ca800edc,2016-12-25T15:28:11Z,https://github.com/pytorch/pytorch/commit/bc475cad671aafd9e1d4347801f35a12ca800edc,Move max pooling construction logic to functions (#343),1,Move Method,,
c48f511c7ef7cbdcd1615d1770ec5687ddbade5d,2020-09-11T00:29:44Z,https://github.com/pytorch/pytorch/commit/c48f511c7ef7cbdcd1615d1770ec5687ddbade5d,"Moves some of TestTorchMathOps to OpInfos (#44277)Summary:This PR fixes three OpInfo-related bugs and moves some functions from TestTorchMathOps to be tested using the OpInfo pattern. The bugs are:- A skip test path in test_ops.py incorrectly formatted its string argument- Decorating the tests in common_device_type.py was incorrectly always applying decorators to the original test, not the op-specific variant of the test. This could cause the same decorator to be applied multiple times, overriding past applications.- make_tensor was incorrectly constructing tensors in some casesThe functions moved are:- asin- asinh- sinh- acosh- tan- atan- atanh- tanh- log- log10- log1p- log2In a follow-up PR more or all of the remaining functions in TestTorchMathOps will be refactored as OpInfo-based tests.Pull Request resolved: https://github.com/pytorch/pytorch/pull/44277Reviewed By: mrshenli, ngimelDifferential Revision: D23617361Pulled By: mruberryfbshipit-source-id: edb292947769967de9383f6a84eb327f027509e0",1,Move Method,,
d033e185ed212a67a471881c1bc9308b769969f8,2020-12-08T23:33:13Z,https://github.com/pytorch/pytorch/commit/d033e185ed212a67a471881c1bc9308b769969f8,"fx quant: move more functions to utils (#48908)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/48908No logic change, improving readabilityTest Plan:CIImported from OSSReviewed By: jerryzh168Differential Revision: D25363080fbshipit-source-id: 1d73a875bd7abf671b544ebc835432fea5306dc3",1,Move Method,,
d5abc7bfeed2e1f85aea108cf510caefe02b88d5,2023-04-14T03:00:09Z,https://github.com/pytorch/pytorch/commit/d5abc7bfeed2e1f85aea108cf510caefe02b88d5,[Vulkan] Move convert_qconv2d_context to custom ops (#98548)  Summary: Move convert_qconv2d_context to it's own custom op library  Test Plan: ```buck run --target-platforms ovr_config//platform/macos:arm64-fbsource -c pt.vulkan_full_precision=1 //xplat/caffe2/fb/custom_ops/vulkan_quantized:pt_vulkan_quantized_test_binAppleMac\#macosx-arm64```  Differential Revision: D44688797  Pull Request resolved: https://github.com/pytorch/pytorch/pull/98548 Approved by: https://github.com/kirklandsign,1,Move Method,,
daf5100656c65cb6f1777f7e4173fd494624b565,2023-05-05T15:35:56Z,https://github.com/pytorch/pytorch/commit/daf5100656c65cb6f1777f7e4173fd494624b565,[EZ] move test decorator up in the class def (#100719)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/100719 Approved by: https://github.com/angelayi,1,Move Method,,
e3e786e35eb22cd963185c3eafb79b0430856070,2016-11-03T20:29:14Z,https://github.com/pytorch/pytorch/commit/e3e786e35eb22cd963185c3eafb79b0430856070,Move source code checks from __getstate__ to torch.load (#200)The __getstate__ and __setstate__ functions are called from copy.copy aswell as pickling. The source code inspection currently slows down thedata parallel code because it makes a copy of the object everyiteration.,1,Move Method,,
ed57f804fa76cd8e0565f9df1a3cd776929cf00f,2020-11-19T06:30:32Z,https://github.com/pytorch/pytorch/commit/ed57f804fa76cd8e0565f9df1a3cd776929cf00f,[quant][refactor] Move some util functions from torch/quantization/fx/utils.py to torch/quantization/utils.py (#48107)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/48107Test Plan: Imported from OSSReviewed By: supriyarDifferential Revision: D25026495fbshipit-source-id: 3634b6b95a18670232600874b1e593180ea9f44c,1,Move Method,,
efdd08a8d0deb963ffd3820eabdf577768c82bb4,2023-03-31T09:55:14Z,https://github.com/pytorch/pytorch/commit/efdd08a8d0deb963ffd3820eabdf577768c82bb4,"[MPS] Move impl functions to mps namespace (#97238)  This PR moves impl functions to `at::native::mps` to prevent them from being exposed in `at::native`.  Because of the moves of functions being hard to review, this PR only refactors part of functions in the MPS codebase. Will check everything is correctly moved again before merging. Pull Request resolved: https://github.com/pytorch/pytorch/pull/97238 Approved by: https://github.com/kulinseth",1,Move Method,,
f67d2df933340c1b604ef92e71f0baf5f5ddecad,2023-02-22T00:06:59Z,https://github.com/pytorch/pytorch/commit/f67d2df933340c1b604ef92e71f0baf5f5ddecad,[ONNX] Refactor validation op-level (#94920)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/94920 Approved by: https://github.com/BowenBao,1,Move Method,,
f879e70fc1ca86d9ce544bc3cd27c629ce09201d,2021-05-20T23:26:24Z,https://github.com/pytorch/pytorch/commit/f879e70fc1ca86d9ce544bc3cd27c629ce09201d,"[quant][fx][graphmode][refactor] Factor out generate_qconfig_map to qconfig_utils.py (#58453)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/58453  Move the class method generate_qconfig_map to qconfig_utils, will add more PRs to remove functions out of Quantizer and eventually remove the Quantizer object  Test Plan: python test/test_quantization.py TestQuantizeFx python test/test_quantization.py TestQuantizeFxOps  Imported from OSS  Reviewed By: vkuzo  Differential Revision: D28497965  fbshipit-source-id: 3c78cfe676965d20a8834a859ffed4d8e9ecade4",1,Move Method,,
a85c8351961cdf2547864dc6a20a66c1f30391db,2020-04-16T20:33:48Z,https://github.com/pytorch/pytorch/commit/a85c8351961cdf2547864dc6a20a66c1f30391db,[WIP] Move profiler to a dispatch wrapper (#33057)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/33057Test Plan: Imported from OSSDifferential Revision: D19775659Pulled By: jamesr66afbshipit-source-id: 5cbe5f736660c8543764ef62b16550638d9ceb72,1,Move Method,,
d71fac20ebf6b393e464d312b8a38ae1c45c3386,2018-12-17T05:50:43Z,https://github.com/pytorch/pytorch/commit/d71fac20ebf6b393e464d312b8a38ae1c45c3386,Refactor hotpatch_vars and apply it to libtorch (#14976)Summary:Fixes #14801.Pull Request resolved: https://github.com/pytorch/pytorch/pull/14976Differential Revision: D13485381Pulled By: soumithfbshipit-source-id: 0af3c2e1b90988d56f6f85632328d1e4b788ffd2,1,Move Method,,
d9b89a352c4ceeff24878f4f5321e16f059e98c3,2017-10-19T19:05:07Z,https://github.com/pytorch/pytorch/commit/d9b89a352c4ceeff24878f4f5321e16f059e98c3,"Replace StochasticFunctions v2 (#3165)This removes the StochasticFunctions for bernoulli, multinomial, andnormal and replaces them with classes in the torch.distributionspackage. Each distribution supports the differentiable log_prob functionthat returns the log of the pdf/pmf of the samples.The current StochasticFunction implementation has a few problems: it canbe painful to use when there are multiple stochastic outputs which needto be back-propagated through. It also requires that we store grad_fnson Variables that have requires_grad=False in order to find stochasticnodes.",1,Move Method,,
eea8ab1861d92b56386fcb659148166c2d8d5eb5,2018-08-14T19:29:11Z,https://github.com/pytorch/pytorch/commit/eea8ab1861d92b56386fcb659148166c2d8d5eb5,"Move common code to RNNCellBase. (#10399)Summary:There are three classes `RNNCell`, `LSTMCell`, `GRUCell` inherited from `RNNCellBase`, all defining the identical initialization function `reset_parameters`. Lets move it to the common base.Another option is to have different initialization for RNN, LSTM and GRU. Maybe those weights whose output is processed with sigmoid (i.e. gain=1) should be initialized differently from those going to tanh (gain=5/3)?Pull Request resolved: https://github.com/pytorch/pytorch/pull/10399Differential Revision: D9316978Pulled By: SsnLfbshipit-source-id: a2d9408f0b5c971a3e6c3d42e4673725cf03ecc1",1,Move Method,,
0dbff184e9db6b477221a5d0dc4b5e4200888211,2020-11-14T09:27:47Z,https://github.com/pytorch/pytorch/commit/0dbff184e9db6b477221a5d0dc4b5e4200888211,change file name to snake style (#47914)Summary:Change Partitioner.py file name to partitioner.pyChange GraphManipulation.py file name to graph_manipulation.pyMove test_replace_target_nodes_with() to test_fx_experimental.pyRemove the unnecessary argument in size_based_partition() in Partitioner classPull Request resolved: https://github.com/pytorch/pytorch/pull/47914Reviewed By: gcatronDifferential Revision: D24956653Pulled By: scottxu0730fbshipit-source-id: 25b65be7dc7d64e90ffdc59cf394446fee83c3e6,1,Move Method,Rename Module,
1dba53cbab96c9ee6c639c24ee3619496e8f1a5f,2023-04-27T21:32:04Z,https://github.com/pytorch/pytorch/commit/1dba53cbab96c9ee6c639c24ee3619496e8f1a5f,"[ONNX] Refactor test_op_consistenct.py and test_fx_op_consistency.py (#100172)  ## Summary <!-- copilot:summary --> ### <samp>🤖 Generated by Copilot at 9255aa3</samp>  This pull request refactors the ONNX operator testing code to use a common module `./test/onnx/onnx_test_common.py` that defines constants, types, classes, and functions for testing ONNX operators. This improves the code quality, readability, and maintainability.  ## Walkthrough <!-- copilot:walkthrough --> ### <samp>🤖 Generated by Copilot at 9255aa3</samp>  *  Refactor the common code for testing ONNX operators from different files into `./test/onnx/onnx_test_common.py` ([link](https://github.com/pytorch/pytorch/pull/100172/files?diff=unified&w=0#diff-1b38383dc1a0228a835d83bb7c4ba2d0c1bcd41297be5c6336572c525846166eL10-R24), [link](https://github.com/pytorch/pytorch/pull/100172/files?diff=unified&w=0#diff-1b38383dc1a0228a835d83bb7c4ba2d0c1bcd41297be5c6336572c525846166eR33), [link](https://github.com/pytorch/pytorch/pull/100172/files?diff=unified&w=0#diff-1b38383dc1a0228a835d83bb7c4ba2d0c1bcd41297be5c6336572c525846166eR367-R623)) * Remove the unused and duplicated imports, constants, types, and classes for testing ONNX operators from `./test/onnx/test_fx_op_consistency.py` and `./test/onnx/test_op_consistency.py` ([link](https://github.com/pytorch/pytorch/pull/100172/files?diff=unified&w=0#diff-db2f78a51511bb172cbfde1b2f68272b8b33049abe2571cded27bcd0f3ae5fa4L28-R29), [link](https://github.com/pytorch/pytorch/pull/100172/files?diff=unified&w=0#diff-db2f78a51511bb172cbfde1b2f68272b8b33049abe2571cded27bcd0f3ae5fa4L43-R42), [link](https://github.com/pytorch/pytorch/pull/100172/files?diff=unified&w=0#diff-e968c9cb6fc6631cab526cb3a9fe66358c4c6e757e2a223a224b976471bcb753L28-R29), [link](https://github.com/pytorch/pytorch/pull/100172/files?diff=unified&w=0#diff-e968c9cb6fc6631cab526cb3a9fe66358c4c6e757e2a223a224b976471bcb753L43-R44)) * Import the `unittest`, `opinfo_core`, and `onnx_test_common` modules and the `fixme`, `skip`, and `xfail` functions in `./test/onnx/test_fx_op_consistency.py` and `./test/onnx/test_op_consistency.py` ( [link](https://github.com/pytorch/pytorch/pull/100172/files?diff=unified&w=0#diff-db2f78a51511bb172cbfde1b2f68272b8b33049abe2571cded27bcd0f3ae5fa4R36), [link](https://github.com/pytorch/pytorch/pull/100172/files?diff=unified&w=0#diff-e968c9cb6fc6631cab526cb3a9fe66358c4c6e757e2a223a224b976471bcb753L37-R37)) * Update the references to the constants, types, functions, and classes for testing ONNX operators in `./test/onnx/test_fx_op_consistency.py` and `./test/onnx/test_op_consistency.py` to use the definitions from `./test/onnx/onnx_test_common.py` ([link](https://github.com/pytorch/pytorch/pull/100172/files?diff=unified&w=0#diff-db2f78a51511bb172cbfde1b2f68272b8b33049abe2571cded27bcd0f3ae5fa4L324-R80), [link](https://github.com/pytorch/pytorch/pull/100172/files?diff=unified&w=0#diff-db2f78a51511bb172cbfde1b2f68272b8b33049abe2571cded27bcd0f3ae5fa4L389-R135), [link](https://github.com/pytorch/pytorch/pull/100172/files?diff=unified&w=0#diff-db2f78a51511bb172cbfde1b2f68272b8b33049abe2571cded27bcd0f3ae5fa4L405-R151), [link](https://github.com/pytorch/pytorch/pull/100172/files?diff=unified&w=0#diff-db2f78a51511bb172cbfde1b2f68272b8b33049abe2571cded27bcd0f3ae5fa4L455-R204), [link](https://github.com/pytorch/pytorch/pull/100172/files?diff=unified&w=0#diff-e968c9cb6fc6631cab526cb3a9fe66358c4c6e757e2a223a224b976471bcb753L333-R107), [link](https://github.com/pytorch/pytorch/pull/100172/files?diff=unified&w=0#diff-e968c9cb6fc6631cab526cb3a9fe66358c4c6e757e2a223a224b976471bcb753L434-R183), [link](https://github.com/pytorch/pytorch/pull/100172/files?diff=unified&w=0#diff-e968c9cb6fc6631cab526cb3a9fe66358c4c6e757e2a223a224b976471bcb753L448-R197), [link](https://github.com/pytorch/pytorch/pull/100172/files?diff=unified&w=0#diff-e968c9cb6fc6631cab526cb3a9fe66358c4c6e757e2a223a224b976471bcb753L494-R246)) Pull Request resolved: https://github.com/pytorch/pytorch/pull/100172 Approved by: https://github.com/justinchuby",1,Move Method,Move Variable,
20348fb32edd192e11827363eeb64f154d358e2e,2021-06-01T23:07:07Z,https://github.com/pytorch/pytorch/commit/20348fb32edd192e11827363eeb64f154d358e2e,[quant][graphmode][fx][refactor] Remove find_matches from Quantizer class (#59037)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/59037  To remove Quantizer class and split prepare and convert functions to different files  Test Plan: python test/test_quantization.py TestQuantizeFx python test/test_quantization.py TestQuantizeFxOps  Imported from OSS  Reviewed By: vkuzo  Differential Revision: D28724865  fbshipit-source-id: 6c6824d0af7dd47d4c111d6a08e373bc65f33e08,1,Move Method,API Refactoring,
47386722da66d5d7f12322c500474794756ea8d7,2020-11-12T05:28:53Z,https://github.com/pytorch/pytorch/commit/47386722da66d5d7f12322c500474794756ea8d7,[quant][graphmode][fx][refactor] insert_observer (#47782)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/47782Test Plan:python test/test_quantization.py TestQuantizeFxImported from OSSReviewed By: supriyarDifferential Revision: D24900305fbshipit-source-id: b00a90ab85badea7d18ae007cc68d0bcd58ab15c,1,Move Method,,
789fc4c2926a8080f56460e8a957ce8dc133de2d,2023-03-05T06:33:32Z,https://github.com/pytorch/pytorch/commit/789fc4c2926a8080f56460e8a957ce8dc133de2d,[dtensor] refactor shape/offset calculation (#95923)  Shape offset calculation is commonly used and extract them into a separate util  Pull Request resolved: https://github.com/pytorch/pytorch/pull/95923 Approved by: https://github.com/fduwjj,1,Move Method,Rename Method,Rename Module
86ddfc7f68fa598bdc392e7eb90b66c412a7ffad,2023-05-08T15:24:02Z,https://github.com/pytorch/pytorch/commit/86ddfc7f68fa598bdc392e7eb90b66c412a7ffad,[inductor] Move cpp wrapper trigger logic to inner_compile (#100611)  Summary: This enables cpp wrapper for backward as well.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/100611 Approved by: https://github.com/jansel,1,Move Method,,
88735f2cc9fae995ab3bd4baf881919f6cdfe653,2020-12-02T20:21:22Z,https://github.com/pytorch/pytorch/commit/88735f2cc9fae995ab3bd4baf881919f6cdfe653,[package] move importer logic into import pickler (#48632)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/48632Test Plan: Imported from OSSReviewed By: suoDifferential Revision: D25236017Pulled By: zdevitofbshipit-source-id: 57fd80d36ddf390ae35c58adf6dddbf15a1347c1,1,Move Method,Rename Variable,
c63e38add5d0baa345cc363460dc0d0e18c87903,2022-07-15T17:06:53Z,https://github.com/scikit-learn/scikit-learn/commit/c63e38add5d0baa345cc363460dc0d0e18c87903,MNT Move base._pprint into model_selection._split (#23883),1,Move Method,,
d3e99a81099951850b789bc6dae10fcc5c56aaf2,2022-03-16T10:09:14Z,https://github.com/scikit-learn/scikit-learn/commit/d3e99a81099951850b789bc6dae10fcc5c56aaf2,MNT Some clean-up in the random_projection module (#22761),1,Move Method,,
826032f917dce2ca917388964f3c2ca62b6ee2c2,2021-12-21T17:37:33Z,https://github.com/scikit-learn/scikit-learn/commit/826032f917dce2ca917388964f3c2ca62b6ee2c2,MAINT refactor ARFF parser (#22026),1,Move Method,,
1296fc09a91b18fabe3e5b54bd57043681261c83,2020-07-17T00:36:37Z,https://github.com/scikit-learn/scikit-learn/commit/1296fc09a91b18fabe3e5b54bd57043681261c83,MNT Refactor center initialization in KMeans (#17928)  * refactor center init in KMeans  * address comments,1,Move Method,,
94a5d93eccfe3c72d9a75f18604a50669605bd6a,2020-07-08T14:22:04Z,https://github.com/scikit-learn/scikit-learn/commit/94a5d93eccfe3c72d9a75f18604a50669605bd6a,TST parametrize and clean-up tests GBDT (#17860),1,Move Method,,
88ce8cd77e7aae1726364d92690025f0027c844c,2020-03-27T19:12:14Z,https://github.com/scikit-learn/scikit-learn/commit/88ce8cd77e7aae1726364d92690025f0027c844c,MNT remove coupling between pipeline methods (#16777),1,Move Method,Rename Variable,
bb719e188c549b699bd14f189fbd6068c4e53edd,2018-07-09T23:52:25Z,https://github.com/scikit-learn/scikit-learn/commit/bb719e188c549b699bd14f189fbd6068c4e53edd,Move _transform_selected helper to base.py,1,Move Method,,
0cf41c8f3d08bc5fdc6b56507ad7138c4bdec5eb,2015-03-24T06:59:05Z,https://github.com/scikit-learn/scikit-learn/commit/0cf41c8f3d08bc5fdc6b56507ad7138c4bdec5eb,Moved optimize test to a new file  simplified code  Used fhess_p  Added RandomState  Added tol=1e-10 to newton_cg  Added RandomState with seed 0,1,Move Method,,
f86622d9cb1a03e8e1f650f840e735998e4e2034,2014-12-09T15:22:10Z,https://github.com/scikit-learn/scikit-learn/commit/f86622d9cb1a03e8e1f650f840e735998e4e2034,MAINT: Moved compute_label test to common tests,1,Move Method,,
9622e858b3bf9fd7a32bbf8f9f1ca2647b0043e1,2014-10-21T07:21:30Z,https://github.com/scikit-learn/scikit-learn/commit/9622e858b3bf9fd7a32bbf8f9f1ca2647b0043e1,MAINT: Move _get_median into sparsefuncs to avoid circular imports,1,Move Method,,
9db5ba15eb94a8faa16616a490167d00fbd78a75,2014-09-06T09:50:57Z,https://github.com/scikit-learn/scikit-learn/commit/9db5ba15eb94a8faa16616a490167d00fbd78a75,ENH: Refactoring in theil_sen  - Moved _get_n_jobs to utils.get_n_jobs - Reworked unittest of _get_n_jobs as doctest - Made unittest of theil_sen a bit nicer,1,Move Method,,
81f82682d6045a377e6ddc7e6242f1975b1b3459,2014-08-04T22:24:07Z,https://github.com/scikit-learn/scikit-learn/commit/81f82682d6045a377e6ddc7e6242f1975b1b3459,Move test_sparse_class_distribution to utils/multiclass from utils/sparsefuncs,1,Move Method,,
24bd8f903057bd7cb46a7b9edd8ef2ead006ebd1,2014-07-22T13:03:49Z,https://github.com/scikit-learn/scikit-learn/commit/24bd8f903057bd7cb46a7b9edd8ef2ead006ebd1,Merge pull request #3472 from arjoly/fix-metrics-division  MAINT move log_loss and hinge_loss to the classification metrics,1,Move Method,,
85c9c84bc7cc0a981962f4a6136ac6a8bea03cbe,2014-07-22T12:27:42Z,https://github.com/scikit-learn/scikit-learn/commit/85c9c84bc7cc0a981962f4a6136ac6a8bea03cbe,MAINT move log_loss and hinge_loss to the classification metrics,1,Move Method,,
718f6ad19f90794e62f56d980c6e730a854e56d7,2014-07-18T12:34:51Z,https://github.com/scikit-learn/scikit-learn/commit/718f6ad19f90794e62f56d980c6e730a854e56d7,split test_common.py into checks and test file. move dataset generation into estimator_checks,1,Move Method,,
09e6e351c586a14b1496ded04fb3c4213131c7b8,2014-05-22T11:43:57Z,https://github.com/scikit-learn/scikit-learn/commit/09e6e351c586a14b1496ded04fb3c4213131c7b8,"Refactoring check_increasing, ensuring that increasing_ is only set on fit/fit_transform, and fixing rho \in {-1, +1}",1,Move Method,,
20c45ae3d8c8c48349b64c5786041db13a86878d,2014-03-20T22:21:00Z,https://github.com/scikit-learn/scikit-learn/commit/20c45ae3d8c8c48349b64c5786041db13a86878d,TST move Mac OS checking utility to sklearn.utils.testing,1,Move Method,,
5d8b429f17e0aab6742417a672501b59300e8d23,2014-01-16T03:43:15Z,https://github.com/scikit-learn/scikit-learn/commit/5d8b429f17e0aab6742417a672501b59300e8d23,Refactor cv code,1,Move Method,,
c74b1f8c1e95b2682065cd1216450d37555133a0,2013-10-20T13:57:55Z,https://github.com/scikit-learn/scikit-learn/commit/c74b1f8c1e95b2682065cd1216450d37555133a0,Move RANSAC implementation to linea_model subpackage,1,Move Method,,
e3211e1c203c8343429273691ae3538b939e078f,2013-10-10T02:57:48Z,https://github.com/scikit-learn/scikit-learn/commit/e3211e1c203c8343429273691ae3538b939e078f,Cosmit: move log_loss.,1,Move Method,,
cc7407654bae56c55710084ed32b06390566f20c,2013-09-11T11:51:12Z,https://github.com/scikit-learn/scikit-learn/commit/cc7407654bae56c55710084ed32b06390566f20c,ENH: move _partition_estimators to ensemble.base,1,Move Method,,
1627a9231187877394bcc28743263f96c45516f4,2013-08-13T15:29:58Z,https://github.com/scikit-learn/scikit-learn/commit/1627a9231187877394bcc28743263f96c45516f4,COSMIT refactor Hungarian algorithm,1,Move Method,,
d8f90d137d943803fe082cb2a46f245ec9158c40,2013-07-26T15:16:27Z,https://github.com/scikit-learn/scikit-learn/commit/d8f90d137d943803fe082cb2a46f245ec9158c40,"use column_or_1d, move it to utils",1,Move Method,,
395b23177450d4a0d8375cf7fe9e97763f6b1872,2013-07-25T17:19:19Z,https://github.com/scikit-learn/scikit-learn/commit/395b23177450d4a0d8375cf7fe9e97763f6b1872,moved and renamed _make_nonnegative() and _safe_min(),1,Move Method,Rename Method,
c38caacb3d4307d6ddd19b03cea2315fd4f07f53,2013-07-25T12:24:57Z,https://github.com/scikit-learn/scikit-learn/commit/c38caacb3d4307d6ddd19b03cea2315fd4f07f53,Refactored verbose output in GBRT - output much more nice Added tests for verbose output in GBRT cosmit: use str.format instead of % updated whats new with GBRT changes,1,Move Method,,
ca40d2fa404436de1a03de4096a2affdd9c9ae7f,2013-07-22T14:28:15Z,https://github.com/scikit-learn/scikit-learn/commit/ca40d2fa404436de1a03de4096a2affdd9c9ae7f,"COSMIT refactor forests, part 2  Decouple RandomTreesEmbedding from ForestRegressor.",1,Move Method,,
1bd7c8d41ebc7d4f6d306edd713f4b07d7ff5159,2013-07-22T10:20:02Z,https://github.com/scikit-learn/scikit-learn/commit/1bd7c8d41ebc7d4f6d306edd713f4b07d7ff5159,WIP: refactor some code in forest.fit,1,Move Method,,
de560bfcfb31983f353b69ad79a5921e66b616a8,2013-06-04T09:45:07Z,https://github.com/scikit-learn/scikit-learn/commit/de560bfcfb31983f353b69ad79a5921e66b616a8,Move balance_weights out of preprocessing.  See #1763.,1,Move Method,,
fcad90d91c8cbf29e0476f4f385bcf45759eaf8e,2013-03-05T17:53:09Z,https://github.com/scikit-learn/scikit-learn/commit/fcad90d91c8cbf29e0476f4f385bcf45759eaf8e,Merge pull request #1740 from tjanez/move_roc_curve_test  COSMIT Moved the test_roc_curve_one_label test where other ROC curve tests are,1,Move Method,,
5a8114dac34b0ead7a39d4b661cffe9a93580bd7,2013-03-05T15:03:45Z,https://github.com/scikit-learn/scikit-learn/commit/5a8114dac34b0ead7a39d4b661cffe9a93580bd7,COSMIT Moved the test_roc_curve_one_label test where other ROC curve tests are.,1,Move Method,,
39b3d41ca690e6b04789d69439f7ca452d286c5c,2013-01-20T12:04:46Z,https://github.com/scikit-learn/scikit-learn/commit/39b3d41ca690e6b04789d69439f7ca452d286c5c,ENH: output processing speed in MB/s for vectorizer example  Moving common text feature extraction methods in a new base class  Hashing vectorizer work in progress,1,Move Method,,
986fdfa5d7f89966e21d614c5cd370c14c755af3,2013-01-05T14:04:35Z,https://github.com/scikit-learn/scikit-learn/commit/986fdfa5d7f89966e21d614c5cd370c14c755af3,More clean up of test_pairwise.py.,1,Move Method,,
1c1538af8765aaf5b4703c28264daacde343452f,2013-01-03T12:28:10Z,https://github.com/scikit-learn/scikit-learn/commit/1c1538af8765aaf5b4703c28264daacde343452f,"ENH move utility function into dedicated file, not __init__.py",1,Move Method,,
127c44b73049754d92ddcef2033815fbb81f4d95,2013-01-03T12:21:50Z,https://github.com/scikit-learn/scikit-learn/commit/127c44b73049754d92ddcef2033815fbb81f4d95,ENH refactoring class weights for SVM and SGD,1,Move Method,,
af3345cbc31d7583389c7e60cce7e007483cd0c2,2012-11-20T17:47:46Z,https://github.com/scikit-learn/scikit-learn/commit/af3345cbc31d7583389c7e60cce7e007483cd0c2,remove partial dependence (moved to own module),1,Move Method,,
2cae34b059b0b343f78979e20a558a273e8c25aa,2012-09-28T17:16:05Z,https://github.com/scikit-learn/scikit-learn/commit/2cae34b059b0b343f78979e20a558a273e8c25aa,Move solver option to constructor.,1,Move Method,,
913e2224a4d37e70094cd51ebad54f32d96a0acb,2012-08-02T16:43:17Z,https://github.com/scikit-learn/scikit-learn/commit/913e2224a4d37e70094cd51ebad54f32d96a0acb,COSMIT minor refactoring of SGD,1,Move Method,,
934d373490eaebadaf667733a574cb932270b697,2012-03-19T14:15:21Z,https://github.com/scikit-learn/scikit-learn/commit/934d373490eaebadaf667733a574cb932270b697,ENH: Moved _build_tree into Tree,1,Move Method,,
ff09f4877c002a4c82fe5e271aee3f19ad324828,2012-03-19T13:39:09Z,https://github.com/scikit-learn/scikit-learn/commit/ff09f4877c002a4c82fe5e271aee3f19ad324828,ENH: move _compute_feature_importance into Tree,1,Move Method,,
02d238fbbeb70e067154f9ceb5c32e26005956af,2012-03-04T19:06:19Z,https://github.com/scikit-learn/scikit-learn/commit/02d238fbbeb70e067154f9ceb5c32e26005956af,Merge remote-tracking branch 'upstream/master' into text-feature-extraction-simplification,1,Move Method,,
eb248b7bea6aa16e96366649acf054a7d5fbbcb0,2011-12-19T19:15:21Z,https://github.com/scikit-learn/scikit-learn/commit/eb248b7bea6aa16e96366649acf054a7d5fbbcb0,Move validation utils to their own submodule,1,Move Method,,
70316d3f81ebe2d2b3b32c4bce5dc98bc1e44c6d,2011-10-07T12:33:26Z,https://github.com/scikit-learn/scikit-learn/commit/5891d987d4a78f3b3d91a36647ce93ebc491b0ba,"Refactor ensemble learning code  * Take estimator instances, not classes, as arguments * Don't expose complete list-like API; if we switch to arrays later   on, append will be O(n) * Fit parameters moved to __init__ parameters where possible per   discussion on the ML before 0.9 release * Allocate estimators all at once in __init__ * Remove superfluous predict_single and add atleast_2d in predict * Other, minor stuff",1,Move Method,,
4ef3db8f05c16e036ec9ee9c9ca1f5c8857f4403,2011-09-28T14:07:12Z,https://github.com/scikit-learn/scikit-learn/commit/4ef3db8f05c16e036ec9ee9c9ca1f5c8857f4403,refactor common code of NB estimators into BaseNB class  Still TODO: bring them closer to linear models by setting coef_ and intercept_ in GaussianNB.,1,Move Method,,
625b35846a254a717228b88e6e539937dfc249f3,2011-09-12T15:00:49Z,https://github.com/scikit-learn/scikit-learn/commit/625b35846a254a717228b88e6e539937dfc249f3,"Incorporated suggested changes to Graphviz exporter  Renamed Visitor to Exporter Moved all write functions into the exporter Removed Leaf class (only use Node class, so that samples and error are shown) Assign nodes a repeatable unique id Replaced .png files with .svg files",1,Move Method,,
dfbc00dd1d657973284e8ab2aec4056bb284dde0,2011-09-12T01:35:49Z,https://github.com/scikit-learn/scikit-learn/commit/dfbc00dd1d657973284e8ab2aec4056bb284dde0,pep8 + move weighted_mode to utils,1,Move Method,,
9a5c0b92fe00509f687978909747a98ff672b42a,2011-08-24T13:10:21Z,https://github.com/scikit-learn/scikit-learn/commit/9a5c0b92fe00509f687978909747a98ff672b42a,Moved dict_learning stuff out of sparse_pca.py,1,Move Method,,
eb92e5273ad897f287b21076655d5debe815532f,2011-07-15T17:17:51Z,https://github.com/scikit-learn/scikit-learn/commit/eb92e5273ad897f287b21076655d5debe815532f,"ENH: l1_distance: gaussian_process -> metrics  Move l1_distance computation from gaussian_process to metrics. I did not move the cross computation because its signature is a bit weird, but this is probably future work to be done.",1,Move Method,,
ead245d2d09647dedb7720031ee9b47f1d1434ce,2011-06-25T21:31:00Z,https://github.com/scikit-learn/scikit-learn/commit/ead245d2d09647dedb7720031ee9b47f1d1434ce,Refactoring in ridge.py  Expose low-level routine used to compute the ridge solution. Also some minor cleanup.,1,Move Method,,
1c7fd2f8e8348bb2f9c1310666203b3542db9d92,2011-05-26T16:01:08Z,https://github.com/scikit-learn/scikit-learn/commit/1c7fd2f8e8348bb2f9c1310666203b3542db9d92,ERF: Move testing utilities to make them accessible from doctests,1,Move Method,,
b9a4154f14503cf2d4d4da4fb6aaa1b85c6064f3,2011-04-01T12:51:34Z,https://github.com/scikit-learn/scikit-learn/commit/b9a4154f14503cf2d4d4da4fb6aaa1b85c6064f3,Refactoring of the covariance estimators modules.  We now have the inheritance scheme: Covariance <-- ShrunkCovariance <-- LedoitWolf since LedoitWolf is a particular case of shrinkage.  Should we put LedoitWolf class within the shrunk_covariance.py file?,1,Move Method,,
dd998ffc0f7daea9817cf02b1ad6611a622c3a6d,2010-03-12T14:18:13Z,https://github.com/scikit-learn/scikit-learn/commit/dd998ffc0f7daea9817cf02b1ad6611a622c3a6d,Move Bayesian Ridge Regression to module linreg.  Also fixed some tests.  From: Fabian Pedregosa <fabian.pedregosa@inria.fr>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@522 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8,1,Move Method,,
2694fe4bb678bc011a400c9a0d704bb6fc88dd15,2010-03-03T15:29:49Z,https://github.com/scikit-learn/scikit-learn/commit/2694fe4bb678bc011a400c9a0d704bb6fc88dd15,Put fast_logdet into utils.  Also clean some code in bayes.py  From: Fabian Pedregosa <fabian.pedregosa@inria.fr>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@459 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8,1,Move Method,,
1689aea73346816b936b84932e12b774974e61a6,2023-07-26T17:30:38Z,https://github.com/huggingface/transformers/commit/1689aea73346816b936b84932e12b774974e61a6,Move center_crop to BaseImageProcessor (#25122),1,Move Method,,
1486d2aec2c667aa2beeed5eaac6625c87577093,2023-07-26T14:09:17Z,https://github.com/huggingface/transformers/commit/1486d2aec2c667aa2beeed5eaac6625c87577093,Move common image processing methods to BaseImageProcessor (#25089)  Move out common methods,1,Move Method,,
b6295b26c500024ec733e18730463a5e94a7b716,2023-06-22T18:28:25Z,https://github.com/huggingface/transformers/commit/b6295b26c500024ec733e18730463a5e94a7b716,"Refactor hyperparameter search backends (#24384)  * Refactor hyperparameter search backends  * Simpler refactoring without abstract base class  * black  * review comments: specify name in class use methods instead of callable class attributes name constant better  * review comments: safer bool checking, log multiple available backends  * test ALL_HYPERPARAMETER_SEARCH_BACKENDS vs HPSearchBackend in unit test, not module. format with black.  * copyright",1,Move Method,,
6c2ad00c4678d56aad4f34ee8d05e699f2ef10c5,2023-03-14T09:03:02Z,https://github.com/huggingface/transformers/commit/6c2ad00c4678d56aad4f34ee8d05e699f2ef10c5,Move `is_pipeline_test_to_skip` to specific model test classes (#21999)  * Move `is_pipeline_test_to_skip` to specific model test classes  ---------  Co-authored-by: ydshieh <ydshieh@users.noreply.github.com>,1,Move Method,,
13254591054630b08d1a1338aa5ca9674d2513ed,2023-03-02T17:12:19Z,https://github.com/huggingface/transformers/commit/13254591054630b08d1a1338aa5ca9674d2513ed,Refactor whisper asr pipeline to include language too. (#21427)  * [WIP] whisper refacto to support language output.  * Handling merges.  * A bit more cleanup and comments.  * Many improvements.  Lots of details everywhere.  * Cleanup old code and tests.  * Handle lone timestamp tokens (just recover when something bad happens).  * Adding return_language example.  * No ffmpeg.  * Hmm.  * Some corrections.  * Both fast and slow.  * New black.  * Update src/transformers/models/whisper/tokenization_whisper.py  Co-authored-by: Arthur <48595927+ArthurZucker@users.noreply.github.com>  * Update src/transformers/models/whisper/tokenization_whisper.py  Co-authored-by: Arthur <48595927+ArthurZucker@users.noreply.github.com>  * Remove print.  * Undoing tests modifications.  * Smaller test modifications.  * Rename.  * Remove maxDiff.  ---------  Co-authored-by: Arthur <48595927+ArthurZucker@users.noreply.github.com>,1,Move Method,,
6e93d947929ce64e651e6cef0c44ceb8b71f97e0,2022-06-10T06:12:17Z,https://github.com/huggingface/transformers/commit/6e93d947929ce64e651e6cef0c44ceb8b71f97e0,"Move Clip image utils to image_utils.py (#17628)  * move clip image utils to image_utils.py  * dont default to square images  * fix typo, revert change to test file  * edit convert_rgb comments",1,Move Method,,
a315988baeddd64da3eb4f030ca804ef92a73d1f,2022-04-12T16:38:50Z,https://github.com/huggingface/transformers/commit/a315988baeddd64da3eb4f030ca804ef92a73d1f,"Moved functions to pytorch_utils.py (#16625)  * Moved functions to pytorch_utils.py  * isort formatting  * Reverted tf changes  * isort, make fix-copies  * documentation fix  * Fixed Conv1D import  * Reverted research examples file  * backward compatibility for pytorch_utils  * missing import  * isort fix",1,Move Method,,
cfd2eaa8cf82da8581825c6592b66d2789c5bc53,2021-04-20T13:07:44Z,https://github.com/huggingface/transformers/commit/cfd2eaa8cf82da8581825c6592b66d2789c5bc53,"[GPTNeo] create local attention mask ones (#11335)  * create local attention mask ones  * remove old method, address patricks comment",1,Move Method,,
bdbb2c756b87aea8e03107add321432f4815b107,2021-02-24T16:32:52Z,https://github.com/huggingface/transformers/commit/bdbb2c756b87aea8e03107add321432f4815b107,[trainer] move secondary methods into a separate file (#10363)  * move secondary methods into a separate file  * cleanup  * style,1,Move Method,,
5bf9afbf351f9419505eb1c9e0c5ab78883c3caf,2020-06-04T04:57:01Z,https://github.com/huggingface/transformers/commit/5bf9afbf351f9419505eb1c9e0c5ab78883c3caf,Introduce a new tensor type for return_tensors on tokenizer for NumPy (#4585)  * Refactor tensor creation in tokenizers.  * Make sure to convert string to TensorType  * Refactor convert_to_tensors_  * Introduce numpy tensor creation  * Format  * Add unittest for TensorType creation from str  * sorting imports  * Added unittests for numpy tensor conversion.  * Do not use in-place version for squeeze as numpy doesn't provide such feature.  * Added extra parameter prepend_batch_axis: bool on prepare_for_model.  * Ensure test_np_encode_plus_sent_to_model is not executed if encoder/decoder model.  * style.  * numpy tests require_torch for now while flax not merged.  * Hopefully will make flake8 happy.  * One more time :notes:,1,Move Method,Rename Method,
f7eba090077a443d4a2fd1cd341c822a8fb4dcbc,2019-12-10T01:37:55Z,https://github.com/huggingface/transformers/commit/f7eba090077a443d4a2fd1cd341c822a8fb4dcbc,clean for release,1,Move Method,,
6c742af2358ced0976dd0e5ad36bfc3d6b615b86,2020-04-14T19:04:19Z,https://github.com/pytorch/pytorch/commit/6c742af2358ced0976dd0e5ad36bfc3d6b615b86,Remove attributes and method of submodules in frozen module (#34787)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/34787This is a follow up patch of freezing of TorchScript modules. This patchenables removal of constant attributes and unused method in submodules.The clean up logic is generalized to handle  attributes that share their classtype.Test Plan: Imported from OSSDifferential Revision: D21004990Pulled By: bzinodevfbshipit-source-id: 84778aa9ae1a96d23db29c051031f9995ed3ac90,1,Move Dead Code,,
c4aab507627a773b83c1428f381d019f5b7c5b40,2021-01-13T21:33:28Z,https://github.com/tensorflow/tensorflow/commit/c4aab507627a773b83c1428f381d019f5b7c5b40,Move the LossReduction class from tf to Keras.PiperOrigin-RevId: 351654535Change-Id: I405d4f79568c05ddeaa3755c3171960db633e6de,1,Move Class,,
6c9d159c0acf54fa59a57ae0371b4c777b726d8f,2020-12-03T19:19:30Z,https://github.com/tensorflow/tensorflow/commit/6c9d159c0acf54fa59a57ae0371b4c777b726d8f,"Split hdf5_format_test to save_test and save_weights_test.hdf5_format_test tests both h5 and SavedModel formats. Splitting it into 2 files helps the test organization.(because save_test already exists, the whole model saving tests had to be copied over manually. No changes have been made to the copied tests)PiperOrigin-RevId: 345493852Change-Id: I5893c027ba85ffc5931dd0963a7068a71fc82a5c",1,Move Class,,
1492da4bae85410a9ce5b896b871de2fb930ba06,2020-10-15T19:00:55Z,https://github.com/tensorflow/tensorflow/commit/1492da4bae85410a9ce5b896b871de2fb930ba06,"[XLA:Python] Split xla_client_test.py into backend dependent and independent tests.Remove some Python 2 compatibility code.Refactoring only, no functional changes intended.PiperOrigin-RevId: 337354186Change-Id: Ia8abe2fa51f4d8819b70e4d172f21ec2e8c0c36f",1,Move Class,Move Method,
d9ad5ce61b2bf1b716667d6319704329c246a424,2020-10-13T17:04:13Z,https://github.com/tensorflow/tensorflow/commit/d9ad5ce61b2bf1b716667d6319704329c246a424,Split strategy_common_test into two pieces as this test is currently timing out.PiperOrigin-RevId: 336899619Change-Id: Ic9edad4ecec00aa20d0a0183fd7a23ff5ade5b71,1,Move Class,,
2c1693cfcf9d0fa376adc93ff940181c4afd3ef2,2020-09-23T18:15:20Z,https://github.com/tensorflow/tensorflow/commit/2c1693cfcf9d0fa376adc93ff940181c4afd3ef2,[tf.data service] Refactor to simplify tf.data service tests.This CL creates a TestCluster class to manage the tf.data service cluster during testing.PiperOrigin-RevId: 333331557Change-Id: Icbbaa2a325b33b086baafb49766d43c30a5c76f9,1,Move Class,,
7813d494170d9d2a8c1ae7418f8cb4c7643c7f5d,2020-09-18T19:51:09Z,https://github.com/tensorflow/tensorflow/commit/7813d494170d9d2a8c1ae7418f8cb4c7643c7f5d,"Remove _auto_cast_variable_read_dtype from Graph.This change removes a dependency from Keras to a private API of TensorFlow. In particular, this removes the _auto_cast_variable_read_dtype property of the Graph and adds a thread-local variable in Keras that plays the same role.This also causes a behavior change. Now, calling `MirroredStrategy.run` or `ReplicaContext.merge_call` within `Layer.call` will reset the value of the autocast dtype to None because these methods use threads. This means layers which call `Strategy.run` may not work correctly with mixed precision unless they start manually casting variables. In practice, I do not think this is an issue, as I don't think any layer calls `Strategy.run` or `ReplicaContext.merge_call`.Another behavior change is that switching a graph in `Layer.run` will no longer reset the value of autocast dtype to None.PiperOrigin-RevId: 332508065Change-Id: I3fb081a4e5f8e8ba275c20c304980c14ad522032",1,Move Class,,
4e73f5f852941754f1f4a2880bf92d5d2b26e51b,2020-07-04T18:02:28Z,https://github.com/tensorflow/tensorflow/commit/4e73f5f852941754f1f4a2880bf92d5d2b26e51b,Remove unit tests from values_test that test functions in distribute_utils.PiperOrigin-RevId: 319609162Change-Id: I8b81cc472742470c6b7705e562a8188760f560ad,1,Move Class,,
f2306d9f25e0f3987391d42add002613ac7cff79,2020-06-10T16:17:33Z,https://github.com/tensorflow/tensorflow/commit/f2306d9f25e0f3987391d42add002613ac7cff79,Move keras related saved_model test to keras integration test and unit test.The memory test couldn't be convert to integration test since the anntation for eager garbage collection is not publicly visible.PiperOrigin-RevId: 315702765Change-Id: I4c8d54b074364d3884af64a2b4d00ad615ef319d,1,Move Class,,
0d7dbab9df897bd6991cc6ec9aa08a531a2c4416,2020-06-09T21:19:35Z,https://github.com/tensorflow/tensorflow/commit/0d7dbab9df897bd6991cc6ec9aa08a531a2c4416,Move the keras related load test to be keras integration test.PiperOrigin-RevId: 315558519Change-Id: Idb5c4cc42185549803069a63d480e839514de090,1,Move Class,,
efa880137ed3e00d7b1178abc95ec58f2108749a,2020-05-29T20:47:23Z,https://github.com/tensorflow/tensorflow/commit/efa880137ed3e00d7b1178abc95ec58f2108749a,Move linspace tests to their own file.PiperOrigin-RevId: 313843608Change-Id: Ifdae2ac60a721795151124a6a2ee643cb0e527ec,1,Move Class,,
e164659e5b607f2e7fc54fbc090894c78745d544,2020-05-21T18:04:45Z,https://github.com/tensorflow/tensorflow/commit/e164659e5b607f2e7fc54fbc090894c78745d544,Move the feature_column.LinearModel to estimator which is the only caller for it.PiperOrigin-RevId: 312702513Change-Id: Iac4cb6970ddb0e46fbdf1f043c4d11bf6ebc4429,1,Move Class,,
0992a65a5d016febeddd2e094c854a3806f19165,2020-05-20T18:30:15Z,https://github.com/tensorflow/tensorflow/commit/0992a65a5d016febeddd2e094c854a3806f19165,Move the _BaseFeatureLayer back to Keras.All its subclasses are in keras/feature_columnPiperOrigin-RevId: 312521092Change-Id: Icba59f4be0299487df5e2fd86ab697ab9e7317b3,1,Move Class,,
2046f7c450b8215f33b4ebfca094b637e36e6a7f,2020-05-13T21:56:38Z,https://github.com/tensorflow/tensorflow/commit/2046f7c450b8215f33b4ebfca094b637e36e6a7f,Move TPUClusterResolver into tpu subdirectory.PiperOrigin-RevId: 311410592Change-Id: I7c4ca01621ae27cd4c36ff996cf90237328d75e4,1,Move Class,,
7d704e32464c25e910a8ce51d643336b7d8f8bd6,2020-05-13T20:47:01Z,https://github.com/tensorflow/tensorflow/commit/7d704e32464c25e910a8ce51d643336b7d8f8bd6,Move tf.keras.layers.featureDenseFeature back to Keras package.PiperOrigin-RevId: 311396758Change-Id: I253d89a5f23dce3ed06db665640c0c2ec3902cf9,1,Move Class,,
2d452266176737db8c4dedb7a9e6521c2beb1d49,2020-05-12T23:52:16Z,https://github.com/tensorflow/tensorflow/commit/2d452266176737db8c4dedb7a9e6521c2beb1d49,Move tf.keras.layers.featureDenseFeature back to Keras package.PiperOrigin-RevId: 311229082Change-Id: I3317086f3b6c53da0f6d0cc4f5558afcd74b264b,1,Move Class,,
c53eca0d6a7be90fbdec0fac776050bb7297aee4,2020-05-01T16:41:40Z,https://github.com/tensorflow/tensorflow/commit/c53eca0d6a7be90fbdec0fac776050bb7297aee4,Move tf.keras.experimental.SequenceFeatures to keras package.PiperOrigin-RevId: 309421612Change-Id: I55e17386071dad91cce2e2500f30fc9e3c3cf657,1,Move Class,,
bb126a32c85fffc84a94b6b52827225ebffadbc0,2020-04-22T19:58:15Z,https://github.com/tensorflow/tensorflow/commit/bb126a32c85fffc84a94b6b52827225ebffadbc0,Move TensorLike under types.internal and rename it NativeObject to distinguish from types which actually behave like tensors.PiperOrigin-RevId: 307878924Change-Id: Ia1ba2d5df2f57540fa8063a0feaf54ed1e256077,1,Move Class,Rename Class,
5d08924cdacee4320835995517243209a874246a,2020-04-08T18:15:42Z,https://github.com/tensorflow/tensorflow/commit/5d08924cdacee4320835995517243209a874246a,Move eager benchmark test to Keras/tests.PiperOrigin-RevId: 305515417Change-Id: I20e0e566599c5cd4c712bc7b21a75fd27ae295d2,1,Move Class,,
97d5010a8fab6c9125516f2eb404a0c4543c955a,2020-04-08T17:27:04Z,https://github.com/tensorflow/tensorflow/commit/97d5010a8fab6c9125516f2eb404a0c4543c955a,Move keras related eager memory test to kerasPiperOrigin-RevId: 305504849Change-Id: If783553d443ad4c900eebbb72970ea582cf801a5,1,Move Class,,
03ee7f43e86f5515100ccda51ca2c7761adb4bd5,2020-04-06T23:04:52Z,https://github.com/tensorflow/tensorflow/commit/03ee7f43e86f5515100ccda51ca2c7761adb4bd5,Move keras related legacy RNN test to integration test.Tests are run under compat.v1 and graph model.PiperOrigin-RevId: 305138425Change-Id: I45054928f2aab86792f908752fe76fe057398b44,1,Move Class,,
305a6e725171d3fcc3c1b8e4e8a446bf7f013166,2020-04-04T17:54:03Z,https://github.com/tensorflow/tensorflow/commit/305a6e725171d3fcc3c1b8e4e8a446bf7f013166,Move TF function test that is keras related to integration test.PiperOrigin-RevId: 304803957Change-Id: Ia190726a64701dca4d8dfe9aabb5f7f80faf78e6,1,Move Class,,
0c82821c55939f9c8364ae75c15f1a09ab310b6c,2020-03-10T17:47:19Z,https://github.com/tensorflow/tensorflow/commit/0c82821c55939f9c8364ae75c15f1a09ab310b6c,Move tests for RaggedTensor.__getitem__ into a separate file (ragged_getitem_test.py).  Also use parameterized.parameters in testWithStridedSlices to allow better test shard balancing.PiperOrigin-RevId: 300127399Change-Id: I2c9e7ec30eefb807ce445b94261dcc02608cf10c,1,Move Class,,
ca0bd89c9a00ae933617ecc98eedee105a29afb9,2020-02-19T18:15:08Z,https://github.com/tensorflow/tensorflow/commit/ca0bd89c9a00ae933617ecc98eedee105a29afb9,Move the _TFBufferWrapper helper to a common place instead of in the tpu codebase.PiperOrigin-RevId: 295996954Change-Id: I2557fddd7cdc858ce661dd5a8c7bcd9996d519c6,1,Move Class,,
a7f1d52b0396acc53e2ba27fe5499f614884d871,2020-02-12T23:01:43Z,https://github.com/tensorflow/tensorflow/commit/a7f1d52b0396acc53e2ba27fe5499f614884d871,Split distribute/custom_training_loop_test into three parts as it is timing out on our kokoro TPU continuous tests.PiperOrigin-RevId: 294765478Change-Id: I574ca0433ade67673e1b5ea731db94e40e28ae5f,1,Move Class,,
f7c8d32d3291db99d0a284444f154f0fdc8db5d8,2020-02-10T22:38:27Z,https://github.com/tensorflow/tensorflow/commit/f7c8d32d3291db99d0a284444f154f0fdc8db5d8,Change TrtConversionParams to a namedtuple subclass.This was recently changed from a namedtuple to a class to be able to export it with tf_export. But it's cleaner to keep it as a namedtuple.PiperOrigin-RevId: 294306452Change-Id: I3f3ecb308d64a85424db24184506375417026aee,1,Move Class,,
94e7575690c761fa10367e0d9ce7e44f2ffdcd4f,2020-02-08T16:47:31Z,https://github.com/tensorflow/tensorflow/commit/94e7575690c761fa10367e0d9ce7e44f2ffdcd4f,Splitting crossing and hashing into separate modules.PiperOrigin-RevId: 293998910Change-Id: I5bb67a28afebc913a785d5002617725133c01933,1,Move Class,,
d38a8fe01b2e265b1f6196e1b4c2ea39d56ce32a,2019-07-16T22:37:32Z,https://github.com/tensorflow/tensorflow/commit/d38a8fe01b2e265b1f6196e1b4c2ea39d56ce32a,Take eager tensor caches outside of EagerContextThis CL should have no behavior changes. It moves the tensor cachesthat were fields of eager Context into a global map indexed by context id.This CL is needed so that eager Context does not have a referencesto EagerTensors. Future changes will add a reference from EagerTensor toeager Context. This will mimick the ownership structure of corresponding C++objects and ensure that Python will delete the context only after allthe tensors have been deleted. The latter will allow us to simplify EagerContextdestruction and remove ref counting from it.PiperOrigin-RevId: 258454245,1,Move Class,,
42b8511f632033111179fd3d77e9d91d7a0c4503,2019-07-13T01:14:31Z,https://github.com/tensorflow/tensorflow/commit/42b8511f632033111179fd3d77e9d91d7a0c4503,Move combinations.py closer to TF's test_util.py.Customizations are split into tf.distribute.*-specific and general TF.PiperOrigin-RevId: 257903643,1,Move Class,,
840f32a26f50b945d6601f3a50afde914e94bf6a,2019-07-10T21:00:24Z,https://github.com/tensorflow/tensorflow/commit/840f32a26f50b945d6601f3a50afde914e94bf6a,Split out multiprocessing specific test to a different file so that we candisable the test on windows.PiperOrigin-RevId: 257476078,1,Move Class,,
13591c2d69f518b170ee8cf42aaca59bfe0c9f45,2019-06-28T15:54:09Z,https://github.com/tensorflow/tensorflow/commit/13591c2d69f518b170ee8cf42aaca59bfe0c9f45,Split base_preprocessing_layer_v1 into its own module.PiperOrigin-RevId: 255608982,1,Move Class,,
f6a3077b39508afd72b942fd35858d763df6a3ea,2019-06-18T13:10:46Z,https://github.com/tensorflow/tensorflow/commit/f6a3077b39508afd72b942fd35858d763df6a3ea,Refactor integration_tests/saved_model_test.PiperOrigin-RevId: 253775838,1,Move Class,,
f4bb606fc1d7f145be07bff5a925790b690e4d0f,2019-06-07T23:11:37Z,https://github.com/tensorflow/tensorflow/commit/f4bb606fc1d7f145be07bff5a925790b690e4d0f,Move `Node` class into a separate file.PiperOrigin-RevId: 252138807,1,Move Class,,
88ed9779719b8b2136a596c7b4dda875568894a3,2019-06-03T17:53:11Z,https://github.com/tensorflow/tensorflow/commit/88ed9779719b8b2136a596c7b4dda875568894a3,Move IndexedSlices to its own python modulePiperOrigin-RevId: 251265677,1,Move Class,,
c362fa7e80917ab9d05de489da5722339abdae83,2019-05-29T22:03:20Z,https://github.com/tensorflow/tensorflow/commit/c362fa7e80917ab9d05de489da5722339abdae83,Refactor training_distributed to reduce the duplication.PiperOrigin-RevId: 250574286,1,Move Class,,
302acb768a8f00605f84430fabd28b6daa2c4c77,2019-03-26T05:18:40Z,https://github.com/tensorflow/tensorflow/commit/302acb768a8f00605f84430fabd28b6daa2c4c77,Move xla.compile and friends to tensorflow/python/compiler/xla and export them as tf symbols.PiperOrigin-RevId: 240282770,1,Move Class,,
02b669895933d6e098f8ba1ce7ced675c818d163,2019-03-22T15:54:03Z,https://github.com/tensorflow/tensorflow/commit/02b669895933d6e098f8ba1ce7ced675c818d163,Refactors functions into util.py file.PiperOrigin-RevId: 239803035,1,Move Class,,
30f441132612187c12337c97887532e86d037586,2019-02-12T08:38:37Z,https://github.com/tensorflow/tensorflow/commit/30f441132612187c12337c97887532e86d037586,Move custom layer into its own file.PiperOrigin-RevId: 233556594,1,Move Class,,
4604d1e52351ebc47a535ab82393e9bd0744ce73,2019-02-08T06:16:23Z,https://github.com/tensorflow/tensorflow/commit/4604d1e52351ebc47a535ab82393e9bd0744ce73,Move V2 loss reduction to the keras module as the distribute lib dependency on it has been removed.PiperOrigin-RevId: 233004569,1,Move Class,,
6f650f54e4c16be4fe94bc9e2172077481b224ac,2019-02-02T01:39:03Z,https://github.com/tensorflow/tensorflow/commit/6f650f54e4c16be4fe94bc9e2172077481b224ac,Move CollectiveAllReduceStrategy to core.PiperOrigin-RevId: 232067817,1,Move Class,,
da47d5a9a6cb6b10b166d4f3169e50bdafec2683,2019-01-15T17:47:53Z,https://github.com/tensorflow/tensorflow/commit/da47d5a9a6cb6b10b166d4f3169e50bdafec2683,"Refactoring: store structured inputs on FuncGraph, same as structured outputs.PiperOrigin-RevId: 229387670",1,Move Class,,
30afb286a47474dc68b61e572028e3b96b43af6a,2019-01-11T06:23:11Z,https://github.com/tensorflow/tensorflow/commit/30afb286a47474dc68b61e572028e3b96b43af6a,Split off SeparableConv and ConvTranspose tests and parameterize many test so they can be properly sharded.PiperOrigin-RevId: 228832550,1,Move Class,,
4df903f8fff67700567abb68ae46c4cddab67cee,2019-01-10T22:51:46Z,https://github.com/tensorflow/tensorflow/commit/4df903f8fff67700567abb68ae46c4cddab67cee,Splitting metrics_test file - moving confusion matrix related metric tests into a separate file.PiperOrigin-RevId: 228781953,1,Move Class,,
a15adadb7cc945b6a142d2454a02d98c44d1325b,2018-12-21T22:09:56Z,https://github.com/tensorflow/tensorflow/commit/a15adadb7cc945b6a142d2454a02d98c44d1325b,Test case cleanup.PiperOrigin-RevId: 226540622,1,Move Class,,
a11de92aa0cc81835096b2ed323872b456feddfe,2018-12-20T02:10:41Z,https://github.com/tensorflow/tensorflow/commit/a11de92aa0cc81835096b2ed323872b456feddfe,Cleanup the v1 only test cases for RNN layers. Move them to test under 3 keras modes.PiperOrigin-RevId: 226265610,1,Move Class,,
e3f1e41ac6e5dc529b6d40730a0e0298223b3cc8,2018-12-13T17:06:55Z,https://github.com/tensorflow/tensorflow/commit/e3f1e41ac6e5dc529b6d40730a0e0298223b3cc8,Refactoring metrics tests.PiperOrigin-RevId: 225380695,1,Move Class,,
8420f5741558c79fa71b442bcc613800c3b3dfa6,2018-12-04T19:26:58Z,https://github.com/tensorflow/tensorflow/commit/8420f5741558c79fa71b442bcc613800c3b3dfa6,Refactor generator and eager training loops.PiperOrigin-RevId: 224014115,1,Move Class,,
8650885a7a1e037919d8870b77a24e2e33b80a0c,2018-11-30T21:49:36Z,https://github.com/tensorflow/tensorflow/commit/8650885a7a1e037919d8870b77a24e2e33b80a0c,"Move some testing utils from estimator_training_test to multi_worker_test_base, preparing for independent-worker mode in keras_multi_worker_testPiperOrigin-RevId: 223569411",1,Move Class,,
a26f3b05986eaec30fa3d9547decbaa9607291dd,2018-11-29T21:30:32Z,https://github.com/tensorflow/tensorflow/commit/a26f3b05986eaec30fa3d9547decbaa9607291dd,Moves ClusterResolvers into tensorflow.python.distribute in preparation for TensorFlow 2.0PiperOrigin-RevId: 223401165,1,Move Class,,
3ffbbfb5a9e4cf0ae777453f0c70bc95c1e17d4e,2018-11-21T03:45:36Z,https://github.com/tensorflow/tensorflow/commit/3ffbbfb5a9e4cf0ae777453f0c70bc95c1e17d4e,Move input spec checking logic to a separate file (part of a multi-step refactoring of base_layer.py to achieve better readability).PiperOrigin-RevId: 222344969,1,Move Class,,
670eff0b0f60b9fde8231e927807677a80016904,2018-10-25T10:48:34Z,https://github.com/tensorflow/tensorflow/commit/670eff0b0f60b9fde8231e927807677a80016904,Extract UnconnectedGradients from gradients_impl to simplify dependenciesPiperOrigin-RevId: 218661408,1,Move Class,,
cff5372f377a8b5ba21fc133e52f4b6d00d6e653,2018-10-19T22:32:55Z,https://github.com/tensorflow/tensorflow/commit/cff5372f377a8b5ba21fc133e52f4b6d00d6e653,"Split up function.py into multiple files.This change adds func_graph.py and auto_control_deps.py. This ispurely copy/pasting code from function.py and function_test.py tothese new files, plus changing imports and minor lint fixes.PiperOrigin-RevId: 217942335",1,Move Class,,
a13c744ca6c7574630af6801f3ed1a2452724675,2018-10-13T04:25:46Z,https://github.com/tensorflow/tensorflow/commit/a13c744ca6c7574630af6801f3ed1a2452724675,Move stateless ops out of contrib,1,Move Class,,
4136bd49d92c80de3c6ae03ffdb2524b36e96fa8,2018-09-08T16:22:58Z,https://github.com/tensorflow/tensorflow/commit/4136bd49d92c80de3c6ae03ffdb2524b36e96fa8,[tf.data] Refactoring of optimization tests.PiperOrigin-RevId: 212119773,1,Move Class,,
99fe2f603466a03897fd653f9fdf583b78b9d5b0,2018-09-05T22:13:16Z,https://github.com/tensorflow/tensorflow/commit/99fe2f603466a03897fd653f9fdf583b78b9d5b0,"Fold CapturingGraph into FuncGraph.There's no need for the two separate classes anymore. This also cleans up some other parts of the interface:* Removes the clear_resource_control_flow_state, which isn't used anywhere* Makes capture_value a private method of FuncGraph (_capture_helper)* Makes create_substitute_placeholder privatePiperOrigin-RevId: 211707906",1,Move Class,,
6b318b9e4495aaff3601acb1c0f8750070c6b4a9,2018-08-22T20:30:24Z,https://github.com/tensorflow/tensorflow/commit/6b318b9e4495aaff3601acb1c0f8750070c6b4a9,[tf.data] Cosmetic changes to tf.data optimizers:- Use graph_utils::GetInputNode in optimizers- Moved python optimization tests into their own files from optimize_dataset_op_testPiperOrigin-RevId: 209819734,1,Move Class,,
586d2d510eb5722464911a38b4f22b4b344d8689,2018-06-18T20:55:36Z,https://github.com/tensorflow/tensorflow/commit/586d2d510eb5722464911a38b4f22b4b344d8689,"Broad refactoring (part 3): reorganize the code so that the dependency graph is cleaner and better separates AutoGraph logic from the general purpose SCT code (concentrated in pyct).The new module structure is described in CONTRIBUTING.md.Summary of changes: * the new lang and core modules now replace their old counterparts * CONTRIBUTING.md now has a short paragraph on developer info * the lang APIs are exposed into the main autograph interface * the old implementations for converter_test_base.py, config.py, directives.py, naming.py, special_functions.py and their tests are now removed * all converters now inherit converter.Base instead of transformer.Base * all converter tests now inherit converter_testing.TestCase instead of converter_test_base.TestCase * converter interfaces now all share a common signature: <converter>.transform(node, context) * the decorator module now actually imports dependencies requires for existing decorators, which was previously just a TODO * decorator_test now runs an additional test that was previously disabled * the implementation of conversion.node_to_graph is now simpler and more consistent; ConversionMap is removed * type_info.py now creates a separate ""definition"" annotation for all symbols * transformer.py no longer has any mention to AutoGraph specific implementations * other no-op code simplifications, doc and comment updatesPiperOrigin-RevId: 201053048",1,Move Class,,
fd839c3980d4fb40bbe92fb8fa3105e2330334fc,2018-05-24T00:32:54Z,https://github.com/tensorflow/tensorflow/commit/fd839c3980d4fb40bbe92fb8fa3105e2330334fc,[tf.data] Split out the `tf.contrib.data.sample_from_datasets()` tests.These were previously broken and disabled in CI builds; this change also fixesthem up.PiperOrigin-RevId: 197818554,1,Move Class,,
79ccb99e9396a7b480615c9ee4b924e851f67163,2018-05-01T01:51:48Z,https://github.com/tensorflow/tensorflow/commit/79ccb99e9396a7b480615c9ee4b924e851f67163,Move LinearOperatorKronecker and LinearOperatorBlockDiag to core.PiperOrigin-RevId: 194881237,1,Move Class,,
236120d32d1c720ff72f617792d268ec2c82d9e6,2018-04-26T23:40:16Z,https://github.com/tensorflow/tensorflow/commit/236120d32d1c720ff72f617792d268ec2c82d9e6,"Split out SaveableObjects into their own filePulls a couple build rules out of tensorflow/python:training. I'd like to use a SaveableObject in :checkpointable (for saving some Python state by default), which means the file with SaveableObject has to be essientially dependency-free.PiperOrigin-RevId: 194473987",1,Move Class,,
bac72dc5a59b844d908d3badf77d62a8a93e2c3a,2018-03-14T00:11:56Z,https://github.com/tensorflow/tensorflow/commit/bac72dc5a59b844d908d3badf77d62a8a93e2c3a,tfdbg: split session_debug_grpc_test* so that the test sizes are medium for both the existing session_debug_grpc_test  and the new grpc_large_data_testAlso in this CL* Consolidate the functions for creating no-grappler-rewrite ConfigProtos  in one place: in session_debug_testlib.pyPiperOrigin-RevId: 188955135,1,Move Class,,
ca8cb9e928b622d202008c12046a4fb0b7ba9c09,2018-02-24T01:32:14Z,https://github.com/tensorflow/tensorflow/commit/ca8cb9e928b622d202008c12046a4fb0b7ba9c09,"Refactor Keras engine by splitting it into short, specialized files.The purpose of this change is to make the codebase more maintainable and readable.Before:engine/topology.pymodels.pyAfter:engine/base_layer.pyengine/input_layer.pyengine/network.pyengine/sequential.pyengine/saving.pyThis is a large change but it only moves code around with no change in logic or API.New files are all under 1000 lines of logic (network.py is 1500 lines, but under 1000 if you remove imports and docstrings), and often under 500.PiperOrigin-RevId: 186847895",1,Move Class,,
5049da67cd28ef3d78a1734532bd3b4708f1fa56,2017-11-01T20:08:40Z,https://github.com/tensorflow/tensorflow/commit/5049da67cd28ef3d78a1734532bd3b4708f1fa56,Refactor to BasicLSTM like,1,Move Class,,
391b4a0ec1a2a7a3ef33acbf3aa41590ddc62999,2017-11-01T20:05:16Z,https://github.com/tensorflow/tensorflow/commit/391b4a0ec1a2a7a3ef33acbf3aa41590ddc62999,Refactor to BasicLSTM like,1,Move Class,,
23418e4317b9e2c4a5148368daec873592a0de9e,2017-10-10T21:16:21Z,https://github.com/tensorflow/tensorflow/commit/23418e4317b9e2c4a5148368daec873592a0de9e,Move LinearOperator to tf.linalg (with backwards compatibility support in contrib.linalg.)PiperOrigin-RevId: 171732711,1,Move Class,,
b31c03565e18fef7ab4539032dd5c69a94487a05,2017-10-05T19:55:19Z,https://github.com/tensorflow/tensorflow/commit/b31c03565e18fef7ab4539032dd5c69a94487a05,Move profiler hook from contrib to core.PiperOrigin-RevId: 171194291,1,Move Class,,
fa0a40a51f6f9cce48342d40c19e184470148242,2017-09-06T15:46:57Z,https://github.com/tensorflow/tensorflow/commit/fa0a40a51f6f9cce48342d40c19e184470148242,"tfdbg: Refactor graph-processing code out of debug_data.pyThe basic idea is to separate the code in debug_data.py that handles graph structures into its own module (debug_graphs.py). This tackles an existing TODO item to simplify the code debug_data.DebugDumpDir.In a later CL, code will be added to debug_graphs.DebugGraph to allow reconstruction of the original GraphDef, i.e., the GraphDef without the Copy* and Debug* nodes inserted by tfdbg. This will be useful for, among other things, the TensorBoard Debugger Plugin.PiperOrigin-RevId: 167726113",1,Move Class,,
656ed3d824b42e4f01ed0194d197b06a98850db5,2017-08-11T22:34:36Z,https://github.com/tensorflow/tensorflow/commit/656ed3d824b42e4f01ed0194d197b06a98850db5,Move core.Tensor into framework/ops.py.PiperOrigin-RevId: 165034131,1,Move Class,,
35253fa89c5f8af25e3d84f76980729569091a6c,2017-05-17T00:49:16Z,https://github.com/tensorflow/tensorflow/commit/35253fa89c5f8af25e3d84f76980729569091a6c,"Refactor Keras layers to rely on core TF layers, specifically:- dropout- conv layers- pooling layers- batchnormAlso add to core layers an automated layer input spec check system, allowing to easily specify constraints on inputs acceptable by layers, and raise helpful error messages in case of incompatibility.PiperOrigin-RevId: 156256513",1,Move Class,,
4791259788372cef78919d8a6ee64970872e500f,2017-03-02T00:26:05Z,https://github.com/tensorflow/tensorflow/commit/4791259788372cef78919d8a6ee64970872e500f,Move estimator.predictChange: 148945600,1,Move Class,,
57151fe77addf768e0cf6555f0570c52a6356e89,2017-02-27T20:15:38Z,https://github.com/tensorflow/tensorflow/commit/57151fe77addf768e0cf6555f0570c52a6356e89,"Move cluster initialization to happen during training using training hooksinstead of depending on variable initialization logic. This avoids deadlocks that canhappen if QueueRunners are used to generate data. Deadlocks would happen sinceinitialization would wait for QueueRunner to generate data, but QueueRunnerswere not started till variable initialization was complete.Also some refactoring of the code to move Hooks and model function out of the Estimator class.Change: 148678573",1,Move Class,,
84867aa7353bda7335dd9976fe3ec3d7063255bd,2017-01-25T00:03:32Z,https://github.com/tensorflow/tensorflow/commit/84867aa7353bda7335dd9976fe3ec3d7063255bd,"[distributions] Move conditioning behavior into subclasses ConditionalDistribution, ConditionalBijector, ConditionalTransformedDistribution.Change: 145480520",1,Move Class,,
bc2e763b2cb359e49abf9bd0e8415765766e730a,2017-01-17T21:30:01Z,https://github.com/tensorflow/tensorflow/commit/bc2e763b2cb359e49abf9bd0e8415765766e730a,"Moved FeedFnHook into basic_session_run_hooks.Make LoggingTensorHook to print tensors in the order they were given [if list].Added formatter option, to support custom string formatting.Added numpy printing options configuration to tweak precision and summarization.Change: 144748847",1,Move Class,,
d5c9d24f0f734d59c75b5b16a7b7550aee1f224f,2016-12-01T00:47:20Z,https://github.com/tensorflow/tensorflow/commit/d5c9d24f0f734d59c75b5b16a7b7550aee1f224f,Move the util classes out of sdca_ops.py.Change: 140670395,1,Move Class,,
927c9f57358f596de1c93d364312c496135497db,2016-10-24T17:46:19Z,https://github.com/tensorflow/tensorflow/commit/927c9f57358f596de1c93d364312c496135497db,"Refactor TensorForestEstimator to implement Trainable and Evaluable, and use Estimator under the hood instead of inheriting from BaseEstimator.Specify names of weights and key features so they can be extracted in model_fn, which helps with exporting a model.Change: 137051793",1,Move Class,,
cbf1ca9b4a146e7a0434771396f18476dd38af81,2016-10-06T23:02:13Z,https://github.com/tensorflow/tensorflow/commit/cbf1ca9b4a146e7a0434771396f18476dd38af81,"Refactor and reorganize SummaryWriter code.- Split SummaryWriter implementation into two pieces:*** SummaryToEventTransformer, which implements the functional API that transforms summaries and other data into Event protocol buffers*** EventFileWriter, which takes Event protocol buffers and writes them to diskAs the summary-transformer logic in SummaryWriter grows more complicated, this decomposition makes it much easier to test. Also, it will faciltiate adding other event-writing backends in the future.- Create LegacySummaryWriter, which is the composition of those two pieces and has an API that is identical to the current tf.train.SummaryWriter- Move the SummaryWriter code into python/summary and out of python/training- Reimport the code to training/summary_io, so that no one downstream notices any changes.Change: 135417373",1,Move Class,,
5025e7607e8a0e4a9379b70c562cb8eced650c57,2016-10-06T17:23:33Z,https://github.com/tensorflow/tensorflow/commit/5025e7607e8a0e4a9379b70c562cb8eced650c57,Move Matthieu's MonitoredTrainingSession to tf.train.Change: 135373918,1,Move Class,,
a90dabcfa81c16386a10920c2c56f0ab6bd73258,2016-08-08T16:39:21Z,https://github.com/tensorflow/tensorflow/commit/a90dabcfa81c16386a10920c2c56f0ab6bd73258,Removed deprecated monitors out of MonitoredSession.Change: 129638617,1,Move Class,,
ecc874be2739b9c901f0e452065f2a5719524605,2016-07-13T23:23:30Z,https://github.com/tensorflow/tensorflow/commit/ecc874be2739b9c901f0e452065f2a5719524605,Move SDCAOptimizer from contrib/learn to contrib/linear_optimizerChange: 127373128,1,Move Class,,
d41da157414d8252bab96d43757cf2b2852cf319,2015-11-23T05:58:08Z,https://github.com/tensorflow/tensorflow/commit/d41da157414d8252bab96d43757cf2b2852cf319,Moved out DataFeeder class into it's own file. Added a placeholder for StreamingDataFeeder.,1,Move Class,,
919a2f4acd939bb62a87c25dbe7ad1fffefdccb7,2015-11-19T03:38:55Z,https://github.com/tensorflow/tensorflow/commit/919a2f4acd939bb62a87c25dbe7ad1fffefdccb7,Moved out models into separate module. Added special handling in DataFeeder if batch size is equal to dataset size,1,Move Class,,
7c4ca54b99ba9c4f2c9d55b5127a180763986c09,2023-04-22T09:41:03Z,https://github.com/keras-team/keras/commit/7c4ca54b99ba9c4f2c9d55b5127a180763986c09,Move CosineSimilarity class to up top.,1,Move Class,,
0becb1fc8a018236fc7b493969cd1d92a7dc1ae4,2021-01-13T21:34:49Z,https://github.com/keras-team/keras/commit/0becb1fc8a018236fc7b493969cd1d92a7dc1ae4,Move the LossReduction class from tf to Keras.  PiperOrigin-RevId: 351654535,1,Move Class,Expression,
675a4cb9fb3122a20fdd9e04582d81e53e064ed0,2019-11-08T22:32:05Z,https://github.com/pytorch/pytorch/commit/675a4cb9fb3122a20fdd9e04582d81e53e064ed0,Extracted quantize/dequantize out of linear.Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/29173Test Plan: Imported from OSSDifferential Revision: D18318561Pulled By: z-a-ffbshipit-source-id: 89317bb5f56e31221ed9ed02bf727ce39f44ebf8,1,Move Class,,
86fc417147e4f8545d53bfe6ae8f0d2a22e7f678,2019-07-10T21:58:10Z,https://github.com/pytorch/pytorch/commit/86fc417147e4f8545d53bfe6ae8f0d2a22e7f678,Move Quantization Models to common_quantization (#22706)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/22706Moved the models used for quantization test from the test_quantization.py file to common_quantization.pyReviewed By: jerryzh168Differential Revision: D16189865fbshipit-source-id: 409b43454b6b3fe278ac16b1affb9085d6ed6835,1,Move Class,,
c2098487e8005837c1c4c5ed76df7df4cac796f2,2021-06-14T22:05:55Z,https://github.com/pytorch/pytorch/commit/c2098487e8005837c1c4c5ed76df7df4cac796f2,[c10d] Move pg wrapper tests to their own file. (#59840)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/59840  moving these tests to their own standalone file. No meaningful code changes. ghstack-source-id: 131359162  Test Plan: CI  Reviewed By: cbalioglu  Differential Revision: D29012664  fbshipit-source-id: 348870016509a6ed7e69240fa82bccef4a12d674,1,Move Class,,
cdb46f4c6e836ffe559781a40846c2f3b50b9e9c,2021-09-02T11:34:35Z,https://github.com/pytorch/pytorch/commit/cdb46f4c6e836ffe559781a40846c2f3b50b9e9c,extract TestAutogradComplex into its own test file (#63400)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/63400  This is the first step to break up test_autograd.py for #63205.  Test Plan: Imported from OSS  Reviewed By: albanD  Differential Revision: D30541499  Pulled By: dagitses  fbshipit-source-id: 8d9d32007938b9eade0e88f95a6a3190e7e2ef01,1,Move Class,,
d6dec1a5cf8a34583f22257a5fe4aacdecc266bb,2023-02-07T09:12:02Z,https://github.com/pytorch/pytorch/commit/d6dec1a5cf8a34583f22257a5fe4aacdecc266bb,"Refactor sharding data pipe into a seperate file (#94095)  Move `ShardingFilterIterDataPipe` into a dedicated file.  Also, propose to have a dedicated parent class (`_ShardingIterDataPipe`) for sharding data pipe, as this seems more like a ""system/engine-level"" datapipe that gives strong hints to RS on how to execute, and needs first-class citizen treatment in RS (compared with other ""user-level"" datapipe that are mostly composable `Callable[[Iterable], Iterable]`.  So we don't need to based on whether `is_shardable` and `apply_sharding` are presented in DataPipe in `graph_settings.py`. But open to other discussions.  Open question: Should [ShardingRoundRobinDispatcherIterDataPipe](https://github.com/pytorch/data/blob/01fc76200354501b057bb439b43a1f05f609dd0a/torchdata/datapipes/iter/util/sharding.py#L16-L17) also be considered as a `_ShardingIterDataPipe`? (e.g. this sharding is executed by replicating (the metadata), while `ShardingRoundRobinDispatcherIterDataPipe` hints too expensive to replicate so requires round robin data exchange/dispatch).  Differential Revision: D43014692  Pull Request resolved: https://github.com/pytorch/pytorch/pull/94095 Approved by: https://github.com/ejguan, https://github.com/NivekT",1,Move Class,,
e146ed21fb76bcb7f34240b1004e201057330093,2021-05-27T06:02:11Z,https://github.com/pytorch/pytorch/commit/e146ed21fb76bcb7f34240b1004e201057330093,[quant][refactor tests] Move TestModelNumerics to a separate file (#59000)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/59000  These tests span both QAT and PTQ APIs so factor them out  Test Plan: python test/test_quantization.py TestModelNumericsEager  Imported from OSS  Reviewed By: HDCharles  Differential Revision: D28713910  fbshipit-source-id: b2ad27cf59abb7cc0c4e4da705f8c9220410f8ad,1,Move Class,,
a8ae33ce27717ac7604aa6e0f898052a13a0b842,2019-08-29T16:50:57Z,https://github.com/pytorch/pytorch/commit/a8ae33ce27717ac7604aa6e0f898052a13a0b842,Move autograd function for CrossMapLRN2d from being backend specific to modules/_functions. (#25339)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/25339This is to get rid of backend-specific dispatch in modules; this autograd function is no longer backend specific sodoesn't need to be in a backend specific location.Test Plan: Imported from OSSDifferential Revision: D17101576Pulled By: gchananfbshipit-source-id: f4f0bd3ecc2d4dbd8cdfedbaabcadb8c603d2507,1,Move Class,,
0b71e7e1fd1d06b5015902936b75f6f720566931,2019-11-25T22:53:11Z,https://github.com/pytorch/pytorch/commit/0b71e7e1fd1d06b5015902936b75f6f720566931,"Refactor QAT Conv module for better extensibility (#30362)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/30362Right now the qat modules(qat.ConvBn2d, qat.ConvBnReLU2d, qat.Conv2d)are not convinent to support other dimensions of Conv, this PR refactorsthese modules so that we can support Conv1d/Conv3d betterTest Plan:python test/test_quantization.pyImported from OSSDifferential Revision: D18691152fbshipit-source-id: 5b561e6b054eadd31b98cabdf1ac67a61ee9b805",1,Move Class,Rename Method,
2dc293335870a0038ac1c842468c37d90212f0f4,2020-03-24T20:57:37Z,https://github.com/pytorch/pytorch/commit/2dc293335870a0038ac1c842468c37d90212f0f4,Move NewModuleTest and NewCriterionTest from test_nn.py to common_nn.py (#35189)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/35189Test Plan: Imported from OSSDifferential Revision: D20588197Pulled By: yf225fbshipit-source-id: 5a28159b653895678c250cbc0c1ddd51bc7a3123,1,Move Class,,
1eb134e1c64816335f5404d77229bcbe6ec0ec01,2021-12-31T09:02:23Z,https://github.com/scikit-learn/scikit-learn/commit/1eb134e1c64816335f5404d77229bcbe6ec0ec01,MNT move bunch to its own file (#22084),1,Move Class,,
6b332d9969be7bb57aef1488bae89ece75fd05ad,2021-10-08T15:57:32Z,https://github.com/scikit-learn/scikit-learn/commit/6b332d9969be7bb57aef1488bae89ece75fd05ad,MNT Move `DistanceMetric` under `metrics`  (#21177),1,Move Class,,
ca9618c0e228b67293c422e99a0f133c3384f7b2,2021-03-18T13:58:51Z,https://github.com/scikit-learn/scikit-learn/commit/ca9618c0e228b67293c422e99a0f133c3384f7b2,MNT move PolynomialFeatures from _data.py to _polynomial.py (#19611)  Co-authored-by: Roman Yurchak <rth.yurchak@gmail.com>,1,Move Class,,
61ae8d56c4af2495aa685518bcab357191a52f19,2015-10-19T20:35:36Z,https://github.com/scikit-learn/scikit-learn/commit/61ae8d56c4af2495aa685518bcab357191a52f19,MAINT move deprecated into deprecation.py,1,Move Class,,
9cb320dd6d4aaf5768949589eb57d1d6922a5b7f,2013-07-26T15:08:59Z,https://github.com/scikit-learn/scikit-learn/commit/9cb320dd6d4aaf5768949589eb57d1d6922a5b7f,Imp move OneHotEncoder to preprocessing/data.py,1,Move Class,,
34037306ab90ff16e1f8a81d826c08769be233d6,2012-11-08T06:21:19Z,https://github.com/scikit-learn/scikit-learn/commit/34037306ab90ff16e1f8a81d826c08769be233d6,Remove transform from PassiveAggressive*.  It really only makes sense if the estimator supports L1-penalty.,1,Move Class,,
7c8f435469c359b1ded20453ace03235f3180773,2012-08-01T13:25:36Z,https://github.com/scikit-learn/scikit-learn/commit/7c8f435469c359b1ded20453ace03235f3180773,COSMIT move BaseSGD to its only place of usage,1,Move Class,,
a59575409d232ec9b787e974bceddf8f7bd5f19d,2011-12-29T19:21:12Z,https://github.com/scikit-learn/scikit-learn/commit/a59575409d232ec9b787e974bceddf8f7bd5f19d,MISC: move SelectorMixin outside of __init__.py,1,Move Class,,
794605a90074ce041c6384b0a4a343ad8a49c858,2011-06-10T12:46:40Z,https://github.com/scikit-learn/scikit-learn/commit/794605a90074ce041c6384b0a4a343ad8a49c858,Refactor MultinomialNB and BernoulliNB: introduce BaseDiscreteNB  Maybe GaussianNB should share some of the code as well (?),1,Move Class,,
e0a1b362571c6c6ff47b75b2b815517bd2cfae1d,2011-05-26T14:36:07Z,https://github.com/scikit-learn/scikit-learn/commit/e0a1b362571c6c6ff47b75b2b815517bd2cfae1d,ERF: refactor object mocking urllib2 for general use (to be used in doctests),1,Move Class,,
6d212527494971179402c294231b39d3684ade31,2011-04-24T22:27:23Z,https://github.com/scikit-learn/scikit-learn/commit/6d212527494971179402c294231b39d3684ade31,Splitting test_mixture,1,Move Class,,
d5c62cf83082264ea395e0575631c9a8fad76bf9,2010-10-21T03:22:51Z,https://github.com/scikit-learn/scikit-learn/commit/d5c62cf83082264ea395e0575631c9a8fad76bf9,Move sparse code to sparse module.,1,Move Class,,
bcdb2a1d930680ca36402cce6d85da145743a464,2010-09-09T08:20:43Z,https://github.com/scikit-learn/scikit-learn/commit/bcdb2a1d930680ca36402cce6d85da145743a464,splitting ledoit_wolf.py in two files,1,Move Class,,
486dc51757ad504106341613384c21a73566600e,2010-03-12T15:02:21Z,https://github.com/scikit-learn/scikit-learn/commit/486dc51757ad504106341613384c21a73566600e,Move remaining code in bayes to linreg.  From: Fabian Pedregosa <fabian.pedregosa@inria.fr>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@523 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8,1,Move Class,,
372f50030bd422309d7b859d730842d7755d3371,2023-06-15T11:30:24Z,https://github.com/huggingface/transformers/commit/372f50030bd422309d7b859d730842d7755d3371,Split common test from core tests (#24284),1,Move Class,,
990936a8689e4a129690ca31177d342f7dabbadb,2022-09-29T00:09:29Z,https://github.com/huggingface/transformers/commit/990936a8689e4a129690ca31177d342f7dabbadb,Move AutoClasses under Main Classes (#19163)  * move autoclasses to main classes  * keep auto.mdx in model_doc,1,Move Class,,
640318befa1a4f2850f7cdea6fceecb47898807d,2021-06-02T16:56:00Z,https://github.com/huggingface/transformers/commit/640318befa1a4f2850f7cdea6fceecb47898807d,[deepspeed] Move code and doc into standalone files (#11984)  * move code and docs  * style  * moved  * restore,1,Move Class,,
0397619ac65f0756a0c6bf4eee959eae2f106bc3,2020-10-22T20:13:49Z,https://github.com/huggingface/transformers/commit/0397619ac65f0756a0c6bf4eee959eae2f106bc3,Move NoLayerEmbedTokens (#7945)  * Move NoLayerEmbedTokens  * TFWrappedEmbeddings  * Add comment,1,Move Class,,
7edb51f3a516ca533797fb2bb2f2b7ce86e0df70,2019-12-03T22:07:25Z,https://github.com/huggingface/transformers/commit/7edb51f3a516ca533797fb2bb2f2b7ce86e0df70,[pplm] split classif head into its own file,1,Move Class,,
1b92564330aa2f40b065a0b9a2a94a28a595bbc6,2019-11-26T18:08:12Z,https://github.com/huggingface/transformers/commit/1b92564330aa2f40b065a0b9a2a94a28a595bbc6,Reorganize and cleanup,1,Move Class,,
c5407f343f428957e44b0898a9d3f7347c10b63f,2019-06-18T12:29:03Z,https://github.com/huggingface/transformers/commit/c5407f343f428957e44b0898a9d3f7347c10b63f,split squad example in two,1,Move Class,,
a5ec992b1fb7e52b12c9cfa220defaa9a5b0628e,2017-01-11T22:05:19Z,https://github.com/keras-team/keras/commit/a5ec992b1fb7e52b12c9cfa220defaa9a5b0628e,Remove dependency on np.inf,1,Introduce Special Case,,
32be731194a2ff3f82a0689bb758fbdd44e10a69,2016-11-01T23:52:25Z,https://github.com/keras-team/keras/commit/32be731194a2ff3f82a0689bb758fbdd44e10a69,Some backend refactoring,1,Introduce Special Case,,
8f6562697ad7b38f1961d0323831f885e686e2a6,2021-02-13T11:00:16Z,https://github.com/tensorflow/tensorflow/commit/8f6562697ad7b38f1961d0323831f885e686e2a6,refactor test_cases loop with combinations,1,Inline Variable,,
e3b2f635b956ea184634892759c1bc314e9c7461,2020-10-20T23:01:20Z,https://github.com/tensorflow/tensorflow/commit/e3b2f635b956ea184634892759c1bc314e9c7461,Refactor keras dependency to a common utility.PiperOrigin-RevId: 338155812Change-Id: Ibbd933514dbb76032a7c982a9233e183d311ab37,1,Inline Variable,,
00b44494f75b78afc37a0082f8fdff255886e9cf,2020-08-12T20:43:27Z,https://github.com/tensorflow/tensorflow/commit/00b44494f75b78afc37a0082f8fdff255886e9cf,clean up,1,Inline Variable,,
be8d4be4f4e75c5d720aa4b4c9da025d5d54c1be,2020-06-22T21:38:16Z,https://github.com/tensorflow/tensorflow/commit/be8d4be4f4e75c5d720aa4b4c9da025d5d54c1be,"remove use_pfor, use tf.concat",1,Inline Variable,,
358e3373058de91e6a3e512e347746c35f3aa7f0,2020-02-27T19:29:48Z,https://github.com/tensorflow/tensorflow/commit/358e3373058de91e6a3e512e347746c35f3aa7f0,Replace len(shape) with shape.rank since length of an unknown rankTensorShape is undefined.PiperOrigin-RevId: 297646567Change-Id: I3d830ab61e9872e40f195d166554fc3e74662f5d,1,Inline Variable,,
88ba8fdd9de97fb80f2061b4c7541b3feb68d8a1,2020-01-03T22:17:08Z,https://github.com/tensorflow/tensorflow/commit/88ba8fdd9de97fb80f2061b4c7541b3feb68d8a1,Refactor ParallelInterleaveTest to be parameterized,1,Inline Variable,,
0bd3a75b2e7c1eb0689712a6e5fff7b0091ddf17,2019-02-05T20:12:03Z,https://github.com/tensorflow/tensorflow/commit/0bd3a75b2e7c1eb0689712a6e5fff7b0091ddf17,"Simplify dataset shuffling logic in Keras' model.fit(), andmake it sensitive to the user's batch size.PiperOrigin-RevId: 232533325",1,Inline Variable,,
3ba26026545be700c4aed9bc609b25fad9c1531e,2019-01-08T17:25:59Z,https://github.com/tensorflow/tensorflow/commit/3ba26026545be700c4aed9bc609b25fad9c1531e,"Removed ResourceVariable._cached_shape_as_list_shape_as_list is no longer on the hotpath of EagerLinearRegressionBenchmark,the change does not seem to affect throughput estimates. Note that bothestimates have high variance.Before:    entry {      name: ""EagerLinearRegressionBenchmark.eager_train_cpu""      iters: 2000      wall_time: 1.24479007721      extras {        key: ""examples_per_sec""        value {          double_value: 102828.583183        }      }    }After:    entry {      name: ""EagerLinearRegressionBenchmark.eager_train_cpu""      iters: 2000      wall_time: 1.25307798386      extras {        key: ""examples_per_sec""        value {          double_value: 102148.470924        }      }    }PiperOrigin-RevId: 228343127",1,Inline Variable,,
e8c65fa77fb7473d95988fa23e51c906a428b27a,2018-12-12T00:45:06Z,https://github.com/tensorflow/tensorflow/commit/e8c65fa77fb7473d95988fa23e51c906a428b27a,"Small refactor to improve the readability of the Model class for those who use the code as documentation.General idea: most important methods come first, private utilities are moved to the bottom of the class.Also use a single method for `_standardize_user_data` (previously split into 2 methods that did not reflecttwo separate sets of actions).PiperOrigin-RevId: 225094903",1,Inline Variable,,
263c094c1d4f9509c4428e97fdd83957d8225c25,2018-05-08T04:58:27Z,https://github.com/tensorflow/tensorflow/commit/263c094c1d4f9509c4428e97fdd83957d8225c25,eliminate result variable in _should_add_regularizer to make code clean,1,Inline Variable,,
946584497b34f443c158f82374b86bc404e44458,2018-04-18T01:43:24Z,https://github.com/tensorflow/tensorflow/commit/946584497b34f443c158f82374b86bc404e44458,Remove unneeded assignmentSigned-off-by: Yong Tang <yong.tang.github@outlook.com>,1,Inline Variable,,
8744d2954a755a64e115e2c2dc81e9f79e19f17a,2018-04-17T20:25:51Z,https://github.com/tensorflow/tensorflow/commit/8744d2954a755a64e115e2c2dc81e9f79e19f17a,Remove range_builder,1,Inline Variable,,
130539dd89914bdb63250a91fe94a7ddf1fdadbc,2018-03-06T23:20:58Z,https://github.com/tensorflow/tensorflow/commit/130539dd89914bdb63250a91fe94a7ddf1fdadbc,Remove clipping on BoundedTensorSpec range.PiperOrigin-RevId: 188089885,1,Inline Variable,,
297d03703f400878a353918c5e1ae55ea927f6a9,2018-02-09T19:28:21Z,https://github.com/tensorflow/tensorflow/commit/297d03703f400878a353918c5e1ae55ea927f6a9,"Simplify and extend the management of input-conditional losses and updates.Instead of keeping track of dependencies manually, we rely on the TF graph structure to find dependencies. The resulting implementation is cleaner and more robust.This does not change any existing behavior. It extends the current behavior by allowing `get_updates_for(inputs)` and `get_losses_for(inputs)` to be called from *any* tensors upstream of the layer, not just the immediate layer's inputs.PiperOrigin-RevId: 185168680",1,Inline Variable,,
840c30b0f38bcf0d94fe86e50a619465f935adda,2018-02-07T16:48:05Z,https://github.com/tensorflow/tensorflow/commit/840c30b0f38bcf0d94fe86e50a619465f935adda,Refactor score definition in GMM operations. This is simplified to be the per-sample likelihood of the data.PiperOrigin-RevId: 184843634,1,Inline Variable,,
f8f9163449c3b1ec60db7d05d68f652a0ca9257a,2018-01-31T03:06:48Z,https://github.com/tensorflow/tensorflow/commit/f8f9163449c3b1ec60db7d05d68f652a0ca9257a,Simplify loader_impl.py logic around main Op Tensor.,1,Inline Variable,,
2679dcfbaa491c764caa9e2d69b071dbc1b7978b,2017-09-21T17:00:54Z,https://github.com/tensorflow/tensorflow/commit/2679dcfbaa491c764caa9e2d69b071dbc1b7978b,Simplify tf.contrib.distributions.fill_triangular indexing calculation and add more comments explaining some of the magic.PiperOrigin-RevId: 169557899,1,Inline Variable,,
e8a91fdaf055a3566c4c75f700aa09bbc4c91779,2017-08-28T14:28:10Z,https://github.com/tensorflow/tensorflow/commit/e8a91fdaf055a3566c4c75f700aa09bbc4c91779,Simplify _should_unpack_args(),1,Inline Variable,,
5f1a6a4e388869573bed17eb041011d11e811c8e,2015-12-06T04:45:13Z,https://github.com/tensorflow/tensorflow/commit/5f1a6a4e388869573bed17eb041011d11e811c8e,Remove unnecessarily assigned variable for summary writer,1,Inline Variable,,
aac5b539ac92fb6c91851e67441bbb9bd4f3cf59,2017-07-23T20:45:40Z,https://github.com/keras-team/keras/commit/aac5b539ac92fb6c91851e67441bbb9bd4f3cf59,Simplify static shape management in TF backend.,1,Inline Variable,,
33a1c30cb117c2e39126e49b5ec4a2b9b7a64b0d,2019-08-07T23:25:04Z,https://github.com/pytorch/pytorch/commit/33a1c30cb117c2e39126e49b5ec4a2b9b7a64b0d,cleanup torch/nn/functional.py (#23977)Summary:Cleanup torch/nn/functional now that JIT:- Handles multiple returns- Typechecks exits (exceptions)- assertions refine typesPull Request resolved: https://github.com/pytorch/pytorch/pull/23977Differential Revision: D16697750Pulled By: eellisonfbshipit-source-id: 1f777d6b9ead1105de50120fffd46d523e1e6797,1,Inline Variable,,
013c7f5ba4f56b2ac5e47e05bb27dada273142ab,2023-04-05T23:10:46Z,https://github.com/pytorch/pytorch/commit/013c7f5ba4f56b2ac5e47e05bb27dada273142ab,"[inductor] Move `tl.broadcast` call out codegen.common (#98304)  This makes only a cosmetic change to the generated code, but means triton's broadcasting logic doesn't leak out into the CSE class.  Before: ```python     tmp5_load = tl.load(in_ptr1 + (0))     tmp5 = tl.broadcast_to(tmp5_load, [XBLOCK]) ```  After: ```python     tmp5 = tl.load(in_ptr1 + (0))     tmp6 = tl.broadcast_to(tmp5, [XBLOCK]) ```  Pull Request resolved: https://github.com/pytorch/pytorch/pull/98304 Approved by: https://github.com/ngimel",1,Inline Variable,Expression,
7ac98c93961faae6e193e2c85fe59e6967cd903e,2020-04-30T02:39:19Z,https://github.com/pytorch/pytorch/commit/7ac98c93961faae6e193e2c85fe59e6967cd903e,"graph mode: refactor quantized hardswish API for easier graph handling (#37523)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/37523Makes the quantized hardswish function API more suited to graph modehandling, which will come in the next PR.Test Plan:CIImported from OSSDifferential Revision: D21310364fbshipit-source-id: 0d438dce5b87481d558c07bcccd9fe717200b4dc",1,Inline Variable,,
876b9591dc82c1534dbdf33f4fa646358e557341,2020-06-05T02:48:17Z,https://github.com/pytorch/pytorch/commit/876b9591dc82c1534dbdf33f4fa646358e557341,"Refactor unittests for activation functions relu, elu, and sigmoid (#39190)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/39190The tests covered previously by test_qrelu, test_qrelu6, test_qsigmoid, and test_qhardsigmoid are now merged into one test to ensure conciseness and reduce redundancy.The refactoring aims to provide the basis for a more generalizable framework to test quantized activation functions and more in the future.Test Plan:1. On a devserver, build PyTorch from source by running the command ""buck build mode/dev //caffe2:torch"" 2. Run the merged unit test throught the command""buck test mode/dev //caffe2/test:quantization -- test_qrelu""""buck test mode/dev //caffe2/test:quantization -- test_qrelu6""""buck test mode/dev //caffe2/test:quantization -- test_qsigmoid""""buck test mode/dev //caffe2/test:quantization -- test_qhardsigmoid""Reviewed By: z-a-fDifferential Revision: D21755690fbshipit-source-id: ef62b2a50ee1c3b8607746f47fb587561e75ff25",1,Inline Variable,,
88b1fa6f0ede7e53e00a78b563a062e2c74e14b1,2020-07-09T04:00:27Z,https://github.com/scikit-learn/scikit-learn/commit/88b1fa6f0ede7e53e00a78b563a062e2c74e14b1,MNT Small refactor for cross_validate (#17867),1,Inline Variable,,
528533dab7bbf0a6ba6b646bae486b8639321da9,2016-03-21T05:16:04Z,https://github.com/scikit-learn/scikit-learn/commit/528533dab7bbf0a6ba6b646bae486b8639321da9,MAINT: Simplify n_features_to_select in RFECV,1,Inline Variable,,
f4fa7823083ffea96ae7ff2e2ec736aa5a13c109,2015-08-14T16:46:56Z,https://github.com/scikit-learn/scikit-learn/commit/f4fa7823083ffea96ae7ff2e2ec736aa5a13c109,Merge pull request #5111 from chyikwei/remove-unnecessary-variable  Remove dirichlet_component_ variable in LatentDirichletAllocation  Fixes #5101.,1,Inline Variable,,
26e47d7ab98ab0c2dd26189fadce4cdef48a7449,2015-08-14T01:57:14Z,https://github.com/scikit-learn/scikit-learn/commit/26e47d7ab98ab0c2dd26189fadce4cdef48a7449,remove dirichlet_component_ variable,1,Inline Variable,,
bd9d16b5eee87d8f98f9caea429b1d6f23aaae3a,2015-02-01T17:48:05Z,https://github.com/scikit-learn/scikit-learn/commit/bd9d16b5eee87d8f98f9caea429b1d6f23aaae3a,Simplify the code by using len,1,Inline Variable,,
4d8cbba40911507dd92a1c816fd844c697e3bf59,2014-12-24T09:43:04Z,https://github.com/scikit-learn/scikit-learn/commit/4d8cbba40911507dd92a1c816fd844c697e3bf59,STY remove unnecessary variable/operation,1,Inline Variable,,
9cfb50636828a0e538752863b90410935fa0a5ae,2014-12-23T12:16:44Z,https://github.com/scikit-learn/scikit-learn/commit/9cfb50636828a0e538752863b90410935fa0a5ae,STY remove unnecessary variable/operation,1,Inline Variable,,
c2d59d2f65532778e9d8d0df9754ca7cbaebc90b,2014-07-14T18:47:17Z,https://github.com/scikit-learn/scikit-learn/commit/c2d59d2f65532778e9d8d0df9754ca7cbaebc90b,simplify tests,1,Inline Variable,,
a48c51b6e08b217d650c17ffcc4d37938614359c,2014-03-11T17:39:17Z,https://github.com/scikit-learn/scikit-learn/commit/a48c51b6e08b217d650c17ffcc4d37938614359c,"Removed unnecessary variable n_dim in utils.check_arrays, removed unnecessary parens in same place",1,Inline Variable,,
af4b94070100048e9d719e491eac563b7667d9b9,2013-09-30T07:06:00Z,https://github.com/scikit-learn/scikit-learn/commit/af4b94070100048e9d719e491eac563b7667d9b9,ENH : simplify input checking in GP,1,Inline Variable,,
b20accb9dd7b8ee9acf443118c0e62a07de1b826,2013-06-14T08:43:19Z,https://github.com/scikit-learn/scikit-learn/commit/b20accb9dd7b8ee9acf443118c0e62a07de1b826,cosmit : inline extract_instance,1,Inline Variable,,
91111d801ce47ae4e70893dee9e9e7a39019ebe4,2013-05-17T15:21:10Z,https://github.com/scikit-learn/scikit-learn/commit/91111d801ce47ae4e70893dee9e9e7a39019ebe4,COSMIT refactor AdaBoost code,1,Inline Variable,,
72c360ceb4843b8e79272bf46d3623de7b86d330,2012-10-28T09:04:38Z,https://github.com/scikit-learn/scikit-learn/commit/72c360ceb4843b8e79272bf46d3623de7b86d330,"ENH simplify circles dataset generator, make classes balanced.",1,Inline Variable,,
56c6bfb61d009a3c324ccca24febf2d90cd9e33b,2012-08-26T03:25:52Z,https://github.com/scikit-learn/scikit-learn/commit/56c6bfb61d009a3c324ccca24febf2d90cd9e33b,Simplify LabelEncoder.transform.,1,Inline Variable,,
c8dde782ad97b39d5b77ddbdf4b5bc86954d18fb,2012-08-17T15:31:53Z,https://github.com/scikit-learn/scikit-learn/commit/c8dde782ad97b39d5b77ddbdf4b5bc86954d18fb,Remove needless loop in inverse_transform.,1,Inline Variable,,
f6bd86e29070c2e420bf25a58fee5cd6e51d1e77,2012-07-21T10:57:49Z,https://github.com/scikit-learn/scikit-learn/commit/f6bd86e29070c2e420bf25a58fee5cd6e51d1e77,COSMIT cleanup tests with pyflakes,1,Inline Variable,,
c2eeca76ae78d404cf678890e77224c303d39202,2012-04-14T21:03:53Z,https://github.com/scikit-learn/scikit-learn/commit/c2eeca76ae78d404cf678890e77224c303d39202,COSMIT refactor SVMlight loader,1,Inline Variable,,
6cb7d84814e1c25fe3920e46eda68822851aec42,2012-03-21T21:14:54Z,https://github.com/scikit-learn/scikit-learn/commit/6cb7d84814e1c25fe3920e46eda68822851aec42,cosmit: comments + rm unnecessary variables,1,Inline Variable,,
6a9a449a0b2db098879c13b6a736fbcbba40f790,2012-01-09T23:07:24Z,https://github.com/scikit-learn/scikit-learn/commit/6a9a449a0b2db098879c13b6a736fbcbba40f790,removed properties from dpgmm,1,Inline Variable,,
564134ed898e0104c7dccb68d933de658c8ab01c,2011-08-30T14:30:54Z,https://github.com/scikit-learn/scikit-learn/commit/564134ed898e0104c7dccb68d933de658c8ab01c,"Refactor roc_curve method. The new implementation, even if it looks very naive, reduces the computation time of fpr/tpr vectors. roc_curve computation time depends now only on the length of y_score. For comparison, here are the results between the old and the new implementation for the following vectors:  - 10^6 length vector  (y_score has 1000 unique values):     - old impl.: 28.29 seconds     - new impl.: 3.14 seconds  - 10^6 length vector (y_score has 10000 unique values):     - old impl.: 267.61 seconds     - new impl.: 3.64 seconds",1,Inline Variable,,
7a87962e72292aac0d1943a10f714de19f230952,2011-07-08T11:07:26Z,https://github.com/scikit-learn/scikit-learn/commit/7a87962e72292aac0d1943a10f714de19f230952,simplify sparse pca,1,Inline Variable,,
e4dee4f4f1be13776718de94cf06ee6ef690e826,2011-05-23T18:58:02Z,https://github.com/scikit-learn/scikit-learn/commit/e4dee4f4f1be13776718de94cf06ee6ef690e826,ERF: Simplify conversion of mldata.org data set name to filename,1,Inline Variable,,
a8fe71bfeee2169185e5eac4cce8a0f3ccbf5ff6,2011-04-17T22:02:12Z,https://github.com/scikit-learn/scikit-learn/commit/a8fe71bfeee2169185e5eac4cce8a0f3ccbf5ff6,cleaned up tests,1,Inline Variable,,
9995c11b22b3cc9f374e5d75fc567a7f1ed809c1,2010-10-31T20:52:26Z,https://github.com/scikit-learn/scikit-learn/commit/9995c11b22b3cc9f374e5d75fc567a7f1ed809c1,factorizing code to make it easier to do the multiclass refactoring in one place,1,Inline Variable,,
7bcd7fc32c55804886e11526cfebc97eee644899,2010-01-05T13:51:37Z,https://github.com/scikit-learn/scikit-learn/commit/7bcd7fc32c55804886e11526cfebc97eee644899,"Updates/refactorings for mlp and srn, addition of rbf.  From: fred.mailhot <fred.mailhot@cb17146a-f446-4be1-a4f7-bd7c5bb65646>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@32 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8",1,Inline Variable,,
4e244b8817356d8a090b80185e8e98a865871e91,2023-05-16T19:14:11Z,https://github.com/huggingface/transformers/commit/4e244b8817356d8a090b80185e8e98a865871e91,Replace appends with list comprehension. (#23359)  It's more idiomatic and significantly more efficient because 1) it avoids repeated `append` call that Python has to resolve on each iteration 2) can preallocate the size of the final list avoiding resizing,1,Inline Variable,,
3b309818e794cf6ff7fa79f34ea3e7b2386156da,2023-01-04T17:05:36Z,https://github.com/huggingface/transformers/commit/3b309818e794cf6ff7fa79f34ea3e7b2386156da,Refactor the function get_results (#20999),1,Inline Variable,,
96d833b211a35bc48c3f9174042a796bb110a66b,2022-07-04T16:26:19Z,https://github.com/huggingface/transformers/commit/96d833b211a35bc48c3f9174042a796bb110a66b,"Return scalar losses instead of per-sample means (#18013)  * Return scalar losses instead of per-sample means  * Make loss shape (1,) instead of scalar  * Allow scalar losses in test_loss_computation  * Allow scalar losses in test_loss_computation  * Allow scalar losses in test_loss_computation  * Remove XLA loss function for RAG",1,Inline Variable,,
0d2bffad31e88fe72ec12eb20f5dc8996cbc6497,2021-07-07T15:17:30Z,https://github.com/huggingface/transformers/commit/0d2bffad31e88fe72ec12eb20f5dc8996cbc6497,"Remove tf.roll wherever not needed (#12512)  It was used in shift_right. After this change TF code is more similar to Pytorch implementations Also, TF graphs are optimized (one node less)",1,Inline Variable,,
443f67e887a030d8254eba126e5f2cdb8b70eb63,2020-12-02T18:19:50Z,https://github.com/huggingface/transformers/commit/443f67e887a030d8254eba126e5f2cdb8b70eb63,[PyTorch] Refactor Resize Token Embeddings (#8880)  * fix resize tokens  * correct mobile_bert  * move embedding fix into modeling_utils.py  * refactor  * fix lm head resize  * refactor  * break lines to make sylvain happy  * add news tests  * fix typo  * improve test  * skip bart-like for now  * check if base_model = get(...) is necessary  * clean files  * improve test  * fix tests  * revert style templates  * Update templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/modeling_{{cookiecutter.lowercase_modelname}}.py,1,Inline Variable,,
27b402cab0a27f2a57067ce8aa6b3e35fc48612e,2020-11-05T20:10:43Z,https://github.com/huggingface/transformers/commit/27b402cab0a27f2a57067ce8aa6b3e35fc48612e,Output global_attentions in Longformer models (#7562)  * Output global_attentions in Longformer models  * make style  * small refactoring  * fix tests  * make fix-copies  * add for tf as well  * remove comments in test  * make fix-copies  * make style  * add docs  * make docstring pretty  Co-authored-by: patrickvonplaten <patrick.v.platen@gmail.com>,1,Inline Variable,,
f39217a5ec96132ffd106d5018d4f724cdc76733,2020-05-01T02:30:15Z,https://github.com/huggingface/transformers/commit/f39217a5ec96132ffd106d5018d4f724cdc76733,[tests] Light cleanup of tempfile in tests/,1,Inline Variable,,
0bc19e77d27db1d0f2e6cc6504576b3729dde4ab,2022-11-30T21:09:14Z,https://github.com/pytorch/pytorch/commit/0bc19e77d27db1d0f2e6cc6504576b3729dde4ab,[quant][be] Simplify `insert_observers_for_model` in fx/prepare.py (#89887)  Summary: att  Test Plan: python test/test_quantization.py TestQuantizeFx  Reviewers:  Subscribers:  Tasks:  Tags:  Pull Request resolved: https://github.com/pytorch/pytorch/pull/89887 Approved by: https://github.com/andrewor14,1,Inline Statement,,
0c6f409cdad073e8c64ef11b72c41d89ab7ee167,2023-05-20T03:43:33Z,https://github.com/pytorch/pytorch/commit/0c6f409cdad073e8c64ef11b72c41d89ab7ee167,[inductor] Refactor RNG operators (#100064)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/100064 Approved by: https://github.com/ngimel,1,Inline Statement,,
11b722c063f030c42d79678a8351dd1ab4f86951,2021-07-02T03:41:55Z,https://github.com/pytorch/pytorch/commit/11b722c063f030c42d79678a8351dd1ab4f86951,[DDP] Refactor hook running logic (#61018)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/61018  Extract logic of hook running to a function `run_reduction_hook` that takes in a `GradBucket` and runs the hook/allreduce. This is mainly to prepare for join to support comm. hook in follow up diffs. ghstack-source-id: 132924220  Test Plan: CI  Reviewed By: SciPioneer  Differential Revision: D29477143  fbshipit-source-id: 87e8e563e71821fd462d6b259c98a6a0afbcd7b4,1,Inline Statement,,
c75210face79759ebc81c8eac131082fe27139df,2021-10-06T09:22:26Z,https://github.com/pytorch/pytorch/commit/c75210face79759ebc81c8eac131082fe27139df,"[PyTorch Edge][type] Move TypeParser class definition to header file (#65976)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/65976  More TypeParser class to header file so it can be called from somewhere else. For example, the getContainedTypes() api in this stack can be moved to other files. ghstack-source-id: 139826943  Test Plan: CI  Reviewed By: iseeyuan  Differential Revision: D31294254  fbshipit-source-id: 1c532fd69c7f6b44ad2332055d24c95a0fac1846",1,Inline Statement,,
c06d3d133469eb8adab5ee89a30dd8659865d303,2022-01-31T22:40:51Z,https://github.com/keras-team/keras/commit/c06d3d133469eb8adab5ee89a30dd8659865d303,Reorganize `advanced_activations.py` into smaller logically organized files hosted under an `activation` directory.  PiperOrigin-RevId: 425465077,1,Inline Module,,
b4dca51d0558e788f62a96d1009a07f773a202f4,2022-01-31T00:23:46Z,https://github.com/keras-team/keras/commit/b4dca51d0558e788f62a96d1009a07f773a202f4,Refactor disparate metrics-related files into a single metrics folder.  Further work may be needed to split up the long file with individual metric definitions. However having a single file per metric may be too granular. TBD.  PiperOrigin-RevId: 425248502,1,Inline Module,,
8015f697d0109ccd6021fe1b8f2bf5b133b259b9,2022-01-28T23:37:25Z,https://github.com/keras-team/keras/commit/8015f697d0109ccd6021fe1b8f2bf5b133b259b9,Refactor `local.py` into smaller logically organized files hosted under a `locally_connected` directory.  PiperOrigin-RevId: 424972748,1,Inline Module,,
e57d0af272f6d6ee2e63c0eed5fdefae869436ad,2022-01-27T00:52:53Z,https://github.com/keras-team/keras/commit/e57d0af272f6d6ee2e63c0eed5fdefae869436ad,Reorganize regularization layers into smaller logically organized files hosted under a `regularization` directory.  PiperOrigin-RevId: 424473851,1,Inline Module,,
85ccb4e108551b7444213276ffb4c4c09f22f886,2022-01-25T21:19:10Z,https://github.com/keras-team/keras/commit/85ccb4e108551b7444213276ffb4c4c09f22f886,Refactor `merge.py` into smaller logically organized files hosted under a `merging` directory.  PiperOrigin-RevId: 424162837,1,Inline Module,,
e8cdedbf695718e2afc7ab040c00e19f6d7feb25,2022-01-21T05:37:18Z,https://github.com/keras-team/keras/commit/e8cdedbf695718e2afc7ab040c00e19f6d7feb25,Refactor `pooling.py` into smaller logically organized files hosted under a `pooling` directory.  PiperOrigin-RevId: 423231364,1,Inline Module,,
88f10c04703c360c696095a091a81a125c10b54d,2022-01-18T19:22:26Z,https://github.com/keras-team/keras/commit/88f10c04703c360c696095a091a81a125c10b54d,Refactor `convolutional.py` into smaller logically organized files hosted under directories named `convolutional` and `reshaping`.  PiperOrigin-RevId: 422604120,1,Inline Module,,
c0155a39d9a9d77895e9876a2c2544b7e43685dc,2021-10-21T19:41:01Z,https://github.com/keras-team/keras/commit/c0155a39d9a9d77895e9876a2c2544b7e43685dc,"Split tracking.py into autotrackable.py, resource.py, and asset.py.  This is a pure refactor, no functional changes are intended.  This is for the preparation of moving the implementation of restored objects out of load.py, in order to make loading more generic (as designed in the SavedModel Layering API).  PiperOrigin-RevId: 404856967",1,Inline Module,,
948df87f1669e203e16e39daeaca52e2ea3253ad,2021-07-13T17:22:28Z,https://github.com/keras-team/keras/commit/948df87f1669e203e16e39daeaca52e2ea3253ad,Refactor `core.py` into smaller logically organized files hosted under a `core` directory.  PiperOrigin-RevId: 384494141,1,Inline Module,,
beb579d52f85e263ab96192220a2afc63f26a2c3,2021-07-08T22:46:13Z,https://github.com/keras-team/keras/commit/beb579d52f85e263ab96192220a2afc63f26a2c3,Refactor `core.py` into smaller logically organized files hosted under a `core` directory.  PiperOrigin-RevId: 383730642,1,Inline Module,,
77237ea09a4c9c735f9f23dcd99493d3c1cc706d,2021-07-08T21:50:57Z,https://github.com/keras-team/keras/commit/77237ea09a4c9c735f9f23dcd99493d3c1cc706d,Refactor `core.py` into smaller logically organized files hosted under a `core` directory.  PiperOrigin-RevId: 383720074,1,Inline Module,,
f199d00ea5bb2230230a34193fbce7ecb5a4d4d2,2018-12-18T15:47:46Z,https://github.com/keras-team/keras/commit/f199d00ea5bb2230230a34193fbce7ecb5a4d4d2,"Splitting the test_model_method which had more than 400 LOC. (#11398)  ### Summary  Test functions should be small and target as few functionalities as possible. This `test_model_method` is very big and makes it hard to find out how to work with it or add new test.   ### Related Issues  ### PR Overview  `test_model_methods` became `test_model_methods`, `test_fit_generator` and `test_fit_generator_shape` with two helper functions, `get_model` and `TrackerCallback`.  - [ ] This PR requires new unit tests [y/n] (make sure tests are included) - [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date) - [x] This PR is backwards compatible [y/n] - [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)",1,Inline Module,,
af85b95bb8b0c82aabe0df0ab24420e31fb057a2,2018-09-30T18:35:23Z,https://github.com/keras-team/keras/commit/af85b95bb8b0c82aabe0df0ab24420e31fb057a2,"add more variable initializers to numpy backend (#11261)  * add variable initializers ( ones, zeros, ones_like, zeros_like ). consolidate tests of all variable initializers + add new tests.  * split up the unit tests  * spelling error  * undo formating changes",1,Inline Module,,
c9cb6087394656247b13dbcb447135dfcb91685c,2018-06-02T06:53:49Z,https://github.com/keras-team/keras/commit/c9cb6087394656247b13dbcb447135dfcb91685c,Split `applications` and `preprocessing` modules. (#10339)  * Split `applications` and `preprocessing` modules.  * Fix dependencies.,1,Inline Module,,
bde45eff87ef40ce02da98c56a2ad59ae9170d4d,2016-03-08T01:48:54Z,https://github.com/keras-team/keras/commit/bde45eff87ef40ce02da98c56a2ad59ae9170d4d,"Split model tests, fix create_output graph bug",1,Inline Module,,
039d15bb55b03984c6515f1ada736bd02edd1347,2015-12-12T19:21:15Z,https://github.com/keras-team/keras/commit/039d15bb55b03984c6515f1ada736bd02edd1347,Split unit and integration tests:  - separate job on travis for IT tests  - refactor and document IT tests (test_tasks.py)  - char generation test with stacked LSTM,1,Inline Module,,
18642e664a67ecd59f7db70e78088e4b4425dcec,2021-06-03T06:52:39Z,https://github.com/pytorch/pytorch/commit/18642e664a67ecd59f7db70e78088e4b4425dcec,[quant][graphmode][fx][refactor] Split quantize.py to prepare.py and convert.py (#59353)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/59353  Next: remove Quantizer class  Test Plan: Imported from OSS  Reviewed By: raghuramank100  Differential Revision: D28856277  fbshipit-source-id: 25f5502be387dbe9706780f667501b46b82789a5,1,Inline Module,,
60e8c766b5cea8667a64c190b108b958cba04b82,2023-02-03T03:07:15Z,https://github.com/pytorch/pytorch/commit/60e8c766b5cea8667a64c190b108b958cba04b82,Refactor dynamo training backends (#93409)  This splits training.py into many files and moves them from `dynamo.optimizations.training` to `dynamo.backends.*`.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/93409 Approved by: https://github.com/ezyang,1,Inline Module,,
82dba844bbbe2ee6a297c186989790002eb8429b,2023-03-07T22:05:27Z,https://github.com/pytorch/pytorch/commit/82dba844bbbe2ee6a297c186989790002eb8429b,[ONNX] Move symbolic export to separate file (#95650)  Move things around in the effort of preparing to refactor the code structure. Pull Request resolved: https://github.com/pytorch/pytorch/pull/95650 Approved by: https://github.com/titaiwangms,1,Inline Module,,
950e67fa438bef24a83415e6932968d2cd6e5e68,2021-05-26T14:49:59Z,https://github.com/pytorch/pytorch/commit/950e67fa438bef24a83415e6932968d2cd6e5e68,[quant][refactor tests] Move test_qat_module into test_quantize_eager_qat (#58928)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/58928  Test Plan: python test/test_quantization.py TestConvBNQATModule  Imported from OSS  Reviewed By: raghuramank100  Differential Revision: D28683925  fbshipit-source-id: 59d240d521c8067a344c9bdf4bec94e82f52e76f,1,Inline Module,,
c3072fd5d21eb1788c7928b640b1e4ae1fb903e3,2016-06-25T20:54:49Z,https://github.com/pytorch/pytorch/commit/c3072fd5d21eb1788c7928b640b1e4ae1fb903e3,Refactor cwrap,1,Inline Module,,
c55f6973e42b8951d7c547d0ad47b02ad7142df5,2023-01-18T07:16:23Z,https://github.com/pytorch/pytorch/commit/c55f6973e42b8951d7c547d0ad47b02ad7142df5,"[dtensor][3/N] move OpSchema and types to a separate file (#90732)  This PR moves OpSchema and types to a separate file to resolve circular dependency better, this is part of refactor on dispatching logic to enable more complicated features Pull Request resolved: https://github.com/pytorch/pytorch/pull/90732 Approved by: https://github.com/XilunWu",1,Inline Module,,
cc07825a21f2abef3d05bf696578a4754d2cfdca,2021-05-26T14:48:28Z,https://github.com/pytorch/pytorch/commit/cc07825a21f2abef3d05bf696578a4754d2cfdca,"[quant][refactor tests] Split test_quantize into test_quantize_eager_ptq, test_quantize_eager_qat and test_fusion (#58927)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/58927  Part of larger re-factor of quantization tests to make it clearer as to which test belongs where.  proposed folder structure ``` test/quantization          - bc/             - test_backward_compatibility.py          - core/             - test_quantized_kernels.py             - test_quantized_workflow_ops.py             - test_quantized_tensor.py             - test_workflow_module.py          - eager/             - test_quantize_eager_ptq.py             - test_quantize_eager_qat.py             - test_fusion.py          - equalization/             - test_equalize_eager.py             - test_bias_correction_eager.py          - fx/            - test_quantize_fx.py          - jit/             - test_quantize_jit.py             - test_fusion_passes.py          - numeric_suite/             - test_numeric_suite_fx.py             - test_numeric_suite_eager.py ```  Test Plan: python test/test_quantization.py  Imported from OSS  Reviewed By: raghuramank100  Differential Revision: D28683926  fbshipit-source-id: f84a4271c77c418ce9751196241933ea8cc14913",1,Inline Module,,
d8532e3524abdc5ea00f8b1fd43e743f5e99f80f,2021-10-12T04:52:24Z,https://github.com/pytorch/pytorch/commit/d8532e3524abdc5ea00f8b1fd43e743f5e99f80f,[PyTorch] Split c10 Type.cpp into two files to allow targets to include one of them (#66445)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/66445  `Type.cpp` implements `demangle()` function based on the macro `HAS_DEMANGLE`. This diff splits it into two `.cpps` so that we can add either one into the build target. This change follows the patternof `flags_use_no_gflags.cpp` and `flags_use_gflags.cpp`.  Test Plan: Rely on CI  Reviewed By: iseeyuan  Differential Revision: D31551432  fbshipit-source-id: f8b11783e513fa812228ec873459ad3043ff9147,1,Inline Module,,
f65945200985cb863d6cd4a654b323bcb8e0a93e,2023-01-20T02:02:59Z,https://github.com/pytorch/pytorch/commit/f65945200985cb863d6cd4a654b323bcb8e0a93e,[FSDP][1/N] Split `fully_shard` unit tests (#92296)  This PR splits `test_fully_shard.py` into `fully_shard/test_fully_shard<...>.py`. This should help improve readability and avoid some future rebase conflicts.  The only other real change is resolving a `TODO` for using `run_subtests` in the model checkpointing unit tests. Pull Request resolved: https://github.com/pytorch/pytorch/pull/92296 Approved by: https://github.com/mrshenli,1,Inline Module,,
f8a4b1a2663ed3f214f3e58cd5dda246f7647775,2017-12-27T23:59:41Z,https://github.com/pytorch/pytorch/commit/f8a4b1a2663ed3f214f3e58cd5dda246f7647775,Split off load_derivatives and gen_autograd_functions from gen_variable_type (#4370),1,Inline Module,,
c58b80eb60443f97161ff674670166346a586b05,2021-02-16T14:42:43Z,https://github.com/tensorflow/tensorflow/commit/c58b80eb60443f97161ff674670166346a586b05,remove redundant test in random_seed_test,1,Inline Method,,
3cd22f746ac108e4cd6f289e90f1347239674392,2020-08-05T18:13:03Z,https://github.com/tensorflow/tensorflow/commit/3cd22f746ac108e4cd6f289e90f1347239674392,Refactored tf.data.Dataset.from_generator,1,Inline Method,,
4e554aecc8c8c0ef32a05871bcc3c2f45be599d0,2020-01-22T18:04:44Z,https://github.com/tensorflow/tensorflow/commit/4e554aecc8c8c0ef32a05871bcc3c2f45be599d0,Move test case to backend_test.py (based on review feedback)Signed-off-by: Yong Tang <yong.tang.github@outlook.com>,1,Inline Method,,
bca5e7385f5eaf59caf9ccf2d093435a0f820c15,2019-07-23T22:07:01Z,https://github.com/tensorflow/tensorflow/commit/bca5e7385f5eaf59caf9ccf2d093435a0f820c15,"Inlined tensor_shape.{scalar,vector,matrix}Explicit constructor call is no less clear and match what we export viathe public API.The functions will be removed once all the internal users are migrated.PiperOrigin-RevId: 259620054",1,Inline Method,,
30129ffa1ac1902ea1db51d2722918e37fd5915f,2019-05-23T19:07:18Z,https://github.com/tensorflow/tensorflow/commit/30129ffa1ac1902ea1db51d2722918e37fd5915f,Simplify the resource dumping logic by using eager (op by op mode) to executethe dumping op.PiperOrigin-RevId: 249689630,1,Inline Method,,
289745a6606bb35655d4d3927fa34b254095ef44,2019-03-27T10:12:00Z,https://github.com/tensorflow/tensorflow/commit/289745a6606bb35655d4d3927fa34b254095ef44,Replaced get_shape() to shape.This is the recommended method.,1,Inline Method,,
1718297b28b870a6685ce55ad8e415dccc05c094,2019-03-27T10:10:30Z,https://github.com/tensorflow/tensorflow/commit/1718297b28b870a6685ce55ad8e415dccc05c094,Replaced get_shape() to shape.This is the recommended method.,1,Inline Method,,
3a31d9fc8dfd903c49175e846f147fd9d4328dfc,2019-03-27T10:09:33Z,https://github.com/tensorflow/tensorflow/commit/3a31d9fc8dfd903c49175e846f147fd9d4328dfc,Replaced get_shape() to shape.This is the recommended method.,1,Inline Method,,
68ab60fcb54bcb4ff53ac206feb33e567e432690,2019-03-27T10:08:42Z,https://github.com/tensorflow/tensorflow/commit/68ab60fcb54bcb4ff53ac206feb33e567e432690,Replaced get_shape() to shape.This is the recommended method.,1,Inline Method,,
388c918beea410128311e28a8943c3d900ba8bf9,2019-03-27T10:07:32Z,https://github.com/tensorflow/tensorflow/commit/388c918beea410128311e28a8943c3d900ba8bf9,Replaced get_shape() to shape.This is the recommended method.,1,Inline Method,,
7b2b2489d2fe2a29db5b50379b0c01a2be67cf41,2019-03-27T10:05:28Z,https://github.com/tensorflow/tensorflow/commit/7b2b2489d2fe2a29db5b50379b0c01a2be67cf41,Replaced get_shape() to shape.This is the recommended method.,1,Inline Method,,
59c6372d8a57e9b1397db801de017885e4115a3a,2019-03-27T10:04:15Z,https://github.com/tensorflow/tensorflow/commit/59c6372d8a57e9b1397db801de017885e4115a3a,Replaced get_shape() to shape().This is the recommended method.,1,Inline Method,,
b445b1c6f3f2ae73fa6e6fd05a0d0746a406af31,2019-03-17T02:38:39Z,https://github.com/tensorflow/tensorflow/commit/b445b1c6f3f2ae73fa6e6fd05a0d0746a406af31,Replaced get_shape() to shape.This is the recommended method.,1,Inline Method,,
b11b8e6f97b5c1d79cedbeb0e88f4b47175bf7a8,2019-03-17T02:37:32Z,https://github.com/tensorflow/tensorflow/commit/b11b8e6f97b5c1d79cedbeb0e88f4b47175bf7a8,Replaced get_shape() to shape.This is the recommended method.,1,Inline Method,,
573e070ce20c5376415d54b96870595da7a7823b,2019-03-17T02:36:04Z,https://github.com/tensorflow/tensorflow/commit/573e070ce20c5376415d54b96870595da7a7823b,Replaced get_shape() to shape.This is the recommended method.,1,Inline Method,,
92aecf83841a5155346cd12b1a8a8ae01ab4905a,2019-03-17T02:34:38Z,https://github.com/tensorflow/tensorflow/commit/92aecf83841a5155346cd12b1a8a8ae01ab4905a,Replaced get_shape() to shape.This is the recommended method.,1,Inline Method,,
014a9da3afe4af3c8e5927a0d1464d267cbd390d,2019-03-17T02:33:36Z,https://github.com/tensorflow/tensorflow/commit/014a9da3afe4af3c8e5927a0d1464d267cbd390d,Replaced get_shape() to shape.This is the recommended method.,1,Inline Method,,
ddbdacce492472b98909e53e05f45b3b91e8f03b,2019-03-17T02:32:35Z,https://github.com/tensorflow/tensorflow/commit/ddbdacce492472b98909e53e05f45b3b91e8f03b,Replaced get_shape() to shape.This is the recommended method.,1,Inline Method,,
1196482ce402847358a54e0f1564e0f1a720cda8,2019-03-17T02:31:36Z,https://github.com/tensorflow/tensorflow/commit/1196482ce402847358a54e0f1564e0f1a720cda8,Replaced get_shape() to shape.This is the recommended method.,1,Inline Method,,
2cb159fbd16a19e703af5425bd0b8a89d4577e48,2019-03-17T02:30:37Z,https://github.com/tensorflow/tensorflow/commit/2cb159fbd16a19e703af5425bd0b8a89d4577e48,Replaced get_shape() to shape.This is the recommended method.,1,Inline Method,,
bf07bede894416e72298f99ba64a8d7bf2f46633,2019-03-17T02:29:35Z,https://github.com/tensorflow/tensorflow/commit/bf07bede894416e72298f99ba64a8d7bf2f46633,Replaced get_shape() to shape.This is the recommended method.,1,Inline Method,,
99b873e0dad85004130a900708908f9866b42ef3,2019-03-17T02:28:16Z,https://github.com/tensorflow/tensorflow/commit/99b873e0dad85004130a900708908f9866b42ef3,Replaced get_shape() to shape.This is the recommended method.,1,Inline Method,,
e0d0bc8e7bf9b2d335a99236a61c2675e9deaf0e,2019-03-17T02:26:58Z,https://github.com/tensorflow/tensorflow/commit/e0d0bc8e7bf9b2d335a99236a61c2675e9deaf0e,Replaced get_shape() to shape.This is the recommended method.,1,Inline Method,,
5ff59a37dae23c822202e5f3c55b05c87160fc42,2019-03-17T02:25:44Z,https://github.com/tensorflow/tensorflow/commit/5ff59a37dae23c822202e5f3c55b05c87160fc42,Replaced get_shape() to shape.This is the recommended method.,1,Inline Method,,
9ae235661585c1294d0408f01608bf697d4fbd83,2019-03-17T02:24:37Z,https://github.com/tensorflow/tensorflow/commit/9ae235661585c1294d0408f01608bf697d4fbd83,Replaced get_shape() to shape.This is the recommended method.,1,Inline Method,,
0b1dfaaad1c2ce5496a6290fcfeb29a4b2f7a713,2019-03-17T02:22:46Z,https://github.com/tensorflow/tensorflow/commit/0b1dfaaad1c2ce5496a6290fcfeb29a4b2f7a713,Replaced get_shape() to shape.This is the recommended method.,1,Inline Method,,
991741fe3440e1be9a1766ef4141ecccf01d4883,2019-03-17T02:21:37Z,https://github.com/tensorflow/tensorflow/commit/991741fe3440e1be9a1766ef4141ecccf01d4883,Replaced get_shape() to shape.This is the recommended method.,1,Inline Method,,
76279ff70441ece3f8de7edd35c0f74bef5adf76,2019-03-17T02:20:29Z,https://github.com/tensorflow/tensorflow/commit/76279ff70441ece3f8de7edd35c0f74bef5adf76,Replaced get_shape() to shape.This is the recommended method.,1,Inline Method,,
dea69732461a536e6ee6295a3c4ee54988bacf97,2019-03-17T02:18:49Z,https://github.com/tensorflow/tensorflow/commit/dea69732461a536e6ee6295a3c4ee54988bacf97,Replaced get_shape() to shape.This is the recommended method.,1,Inline Method,,
f87174c50001d53e096ee47ee3e9520ceff166a1,2019-03-17T02:17:03Z,https://github.com/tensorflow/tensorflow/commit/f87174c50001d53e096ee47ee3e9520ceff166a1,Replaced get_shape() to shape.This is the recommended method.,1,Inline Method,,
ad5c47fe1f62599b26687911ea9749006aa51ebb,2019-03-13T08:55:19Z,https://github.com/tensorflow/tensorflow/commit/ad5c47fe1f62599b26687911ea9749006aa51ebb,Replaced get_shape() with shape.This is the recommended method to use.,1,Inline Method,,
414b73d3cc319f44de9f5b038742d7364c9c98d8,2019-03-13T08:53:53Z,https://github.com/tensorflow/tensorflow/commit/414b73d3cc319f44de9f5b038742d7364c9c98d8,Replaced get_shape() with shape.This is the recommended method to use.,1,Inline Method,,
3f9c3d05329aec8af0330db66b0481d53658ee2a,2019-03-13T08:52:07Z,https://github.com/tensorflow/tensorflow/commit/3f9c3d05329aec8af0330db66b0481d53658ee2a,Replaced get_shape() with shape.This is the recommended method to use.,1,Inline Method,,
e19ae2228c99a8d394a0c7111555ed7650b812fd,2019-03-13T08:50:20Z,https://github.com/tensorflow/tensorflow/commit/e19ae2228c99a8d394a0c7111555ed7650b812fd,Replaced get_shape() with shape.This is the recommended method to use.,1,Inline Method,,
359876ee27b4efe9e20fce91c2f10e30c8e8c6c1,2019-03-13T08:48:53Z,https://github.com/tensorflow/tensorflow/commit/359876ee27b4efe9e20fce91c2f10e30c8e8c6c1,Replaced get_shape() with shape.This is the recommended method to use.,1,Inline Method,,
0837fa288e8331e928c651ba582edd0150daf07d,2019-03-13T08:47:10Z,https://github.com/tensorflow/tensorflow/commit/0837fa288e8331e928c651ba582edd0150daf07d,Replaced get_shape() with shape.This is the recommended method to use.,1,Inline Method,,
bd6e2c5a426ee61ddc2e469f61c80081ad41db70,2019-03-13T08:45:38Z,https://github.com/tensorflow/tensorflow/commit/bd6e2c5a426ee61ddc2e469f61c80081ad41db70,Replaced get_shape() with shape.This is the recommended method to use.,1,Inline Method,,
425b9023c3e808782b82815c39ac6432ab932928,2019-03-13T08:43:14Z,https://github.com/tensorflow/tensorflow/commit/425b9023c3e808782b82815c39ac6432ab932928,Replaced get_shape() with shape.This is the recommended method to use.,1,Inline Method,,
ef5d41d827b4130cc3cedf08454e54ce1340f6eb,2019-01-16T18:11:41Z,https://github.com/tensorflow/tensorflow/commit/ef5d41d827b4130cc3cedf08454e54ce1340f6eb,"Refactoring: Get signature directly from concrete function.We can do this now, because signature is stored on the function, and it will clean the list_all_concrete_functions return value.PiperOrigin-RevId: 229578645",1,Inline Method,,
d8ba8138a221dce01fef830f6cb58b1a008bbbc5,2018-11-12T11:23:07Z,https://github.com/tensorflow/tensorflow/commit/d8ba8138a221dce01fef830f6cb58b1a008bbbc5,"Moved the workaround for circular import into assert_no_garbage_createdCurrently, there is a circular dependency between  eager/tape.py  framework/ops.py  training/distribution_strategy_context.pywhich is resolved by adding lazy loaders in each of these modules.However, lazy loading causes spurious allocations during eager testruns and consecutively fails tests decorated with@assert_no_garbage_collected.The workaround could be removed once the lazy loading is removed.PiperOrigin-RevId: 221065109",1,Inline Method,,
4325fcc4b8291df72687f3ab83808ed1b3142c90,2018-08-06T18:39:18Z,https://github.com/tensorflow/tensorflow/commit/4325fcc4b8291df72687f3ab83808ed1b3142c90,"This removes the output & mask caching done by graph networks in graph mode.The primary function of the caching was to avoid recomputing the forward pass graph of the Model when querying its output mask. As a result, we change the way output masks are obtained in order to avoid redundant computations, by setting a tensor's mask as metadata on the tensor object (in graph mode) and relying on that metadata where applicable.PiperOrigin-RevId: 207580457",1,Inline Method,,
3d4cddf87d544f4f5868497caf5c6ab3e25aea2b,2018-04-16T20:54:03Z,https://github.com/tensorflow/tensorflow/commit/3d4cddf87d544f4f5868497caf5c6ab3e25aea2b,Simplify the recursion when processing unpackings.PiperOrigin-RevId: 193094078,1,Inline Method,,
457eaab8d9a3a08de57b5b2f11bf36a5030c2304,2018-04-16T20:04:23Z,https://github.com/tensorflow/tensorflow/commit/457eaab8d9a3a08de57b5b2f11bf36a5030c2304,Simplify the implementation of break_statements.pyPiperOrigin-RevId: 193086371,1,Inline Method,,
949dd29d3a8bdc21328c9e94721b344310686eab,2018-01-25T18:36:25Z,https://github.com/tensorflow/tensorflow/commit/949dd29d3a8bdc21328c9e94721b344310686eab,"Simplify the template mechanism by specifying templates using multi-line strings instead of functions. This loses the syntax verification on templates, but it avoids the clutter of lint overrides and the duplication of parameter names, so things are more readable.Addresses #16318PiperOrigin-RevId: 183260854",1,Inline Method,,
b15e04609c197259bf82769d49c882aaef07965f,2018-01-16T19:35:51Z,https://github.com/tensorflow/tensorflow/commit/b15e04609c197259bf82769d49c882aaef07965f,"Remove private Operation._input_dtypes alias.This isn't necessary for anything, but it limits the surface area ofprivate API abuse.PiperOrigin-RevId: 182086883",1,Inline Method,,
62ed39337eeb7d11a503454840d83af191f9b0ad,2017-12-06T20:12:34Z,https://github.com/tensorflow/tensorflow/commit/62ed39337eeb7d11a503454840d83af191f9b0ad,Style cleanups in `tf.contrib.distributions.bijectors.SoftmaxCentered`.PiperOrigin-RevId: 178133366,1,Inline Method,,
d38e0c4fc0805e80fad4c63b69e4efab9c0f8609,2022-09-12T22:17:37Z,https://github.com/keras-team/keras/commit/d38e0c4fc0805e80fad4c63b69e4efab9c0f8609,Simplify object retrieval logic.  PiperOrigin-RevId: 473856979,1,Inline Method,,
9bcb02b246b2cb5e0a3ccd5b22c5d15c35174d7d,2021-07-13T05:21:12Z,https://github.com/keras-team/keras/commit/9bcb02b246b2cb5e0a3ccd5b22c5d15c35174d7d,nested func -> partial,1,Inline Method,,
172397ebf45d58ba256c10004c6fce8b40df286b,2017-04-11T18:32:11Z,https://github.com/keras-team/keras/commit/172397ebf45d58ba256c10004c6fce8b40df286b,Simplify param counting in model summary.,1,Inline Method,,
d56b634f711802ae88c277926b6634465f346275,2022-03-09T18:36:19Z,https://github.com/keras-team/keras/commit/d56b634f711802ae88c277926b6634465f346275,"Remove the @tf.function for the dtensor run_with_layout().  This was creating one tf.function per initializer, and causing function retracing. We only need this currently for Identity initializer, since tf.function will convert the tf.MatrixDiag to tf.constant.  PiperOrigin-RevId: 433516308",1,Inline Method,,
0046092178c67422d9e34b55d76c8545116fe19f,2019-10-07T20:50:23Z,https://github.com/pytorch/pytorch/commit/0046092178c67422d9e34b55d76c8545116fe19f,Reduce special casing around 'training' (#27109)Summary:Most of this was old cruft left over from special handling of `training` before we had a `bool` type. This makes all modules have a `training` attribute that is true by default and removes all other special handling.Fixes #26884](https://our.intern.facebook.com/intern/diff/17728129/)Pull Request resolved: https://github.com/pytorch/pytorch/pull/27109Pulled By: driazatiDifferential Revision: D17728129fbshipit-source-id: 8ddc9fbb07a953dd05529538bfdd01ed88b5cb57,1,Inline Method,API Refactoring,
192c4111a3befbfd4648099844fb934ca53e99f4,2020-09-11T20:02:49Z,https://github.com/pytorch/pytorch/commit/192c4111a3befbfd4648099844fb934ca53e99f4,Simplify target handling in nn gradcheck. (#44507)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/44507Test Plan: Imported from OSSReviewed By: albanDDifferential Revision: D23635799Pulled By: gchananfbshipit-source-id: 75090d6a48771e5c92e737a0829fbfa949f7c8a7,1,Inline Method,,
4316bf98f5a45063e37eef9f7a267b29dc35587b,2020-11-19T05:55:00Z,https://github.com/pytorch/pytorch/commit/4316bf98f5a45063e37eef9f7a267b29dc35587b,[FX] Refactor unique name handling (#48205)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/48205Test Plan: Imported from OSSReviewed By: zdevitoDifferential Revision: D25068934Pulled By: jamesr66afbshipit-source-id: 04e02bbfd2cc9a8c3b963d9afdf40bac065c319b,1,Inline Method,,
11d1cd899ac8fd004bf0f948498b00efd6ac6079,2023-05-25T00:00:06Z,https://github.com/pytorch/pytorch/commit/11d1cd899ac8fd004bf0f948498b00efd6ac6079,Replace require_backend with require_backend_is_available (#101891)  [BE] `require_backend_is_available` offers the a more thorough check as `require_backend` but both are often used together. This remove `require_backend` and centralizes on the `require_backend_is_available` decorator Pull Request resolved: https://github.com/pytorch/pytorch/pull/101891 Approved by: https://github.com/awgu,1,Inline Method,,
397793d61c0ed011ae81d39b21d5df6c9bcf0f81,2017-10-31T23:32:22Z,https://github.com/pytorch/pytorch/commit/397793d61c0ed011ae81d39b21d5df6c9bcf0f81,simplify beam search codeSummary: This cleans up the _hack_get_slice_end() using the Conditional operator.Reviewed By: jmp84Differential Revision: D6177797fbshipit-source-id: 5ce0b76b8472123415bba39488aa2c69aad96111,1,Inline Method,,
44e73db3c2f649f09d7d4c70d2ca88e0b429fb83,2023-03-29T13:57:16Z,https://github.com/pytorch/pytorch/commit/44e73db3c2f649f09d7d4c70d2ca88e0b429fb83,"[2/n] Consolidate `replicate` and `DDP`: split `forward` function (#96658)  Split `forward` function into `pre_forward` and `post_forward`, so that they can be reused in the composable API of `replicate`.  Differential Revision: [D44377456](https://our.internmc.facebook.com/intern/diff/D44377456) Pull Request resolved: https://github.com/pytorch/pytorch/pull/96658 Approved by: https://github.com/rohan-varma",1,Inline Method,,
094a077af5578277a5d703e6aa238b96efa81707,2016-01-21T19:27:16Z,https://github.com/scikit-learn/scikit-learn/commit/094a077af5578277a5d703e6aa238b96efa81707,MAINT: Small refactoring in mutual_info_.py,1,Inline Method,,
c7ce0ab6618e8f3debb648612bdddc28d6db7756,2016-01-15T21:17:42Z,https://github.com/scikit-learn/scikit-learn/commit/c7ce0ab6618e8f3debb648612bdddc28d6db7756,MAINT: Refactor and speed up silhoutte_score,1,Inline Method,,
d3dec9496321e904dfd31c87ce2ce1dca3dd16e9,2015-08-28T04:16:23Z,https://github.com/scikit-learn/scikit-learn/commit/d3dec9496321e904dfd31c87ce2ce1dca3dd16e9,comparison test of Lasso and LassoLars under positive restriction refactored and commented,1,Inline Method,,
0f11698eaa3ad7430fdfb42597bfa300bc8c89bb,2013-07-24T15:27:22Z,https://github.com/scikit-learn/scikit-learn/commit/0f11698eaa3ad7430fdfb42597bfa300bc8c89bb,COSMIT refactoring rbm,1,Inline Method,,
f77930199f2b84cf811a21d3ed094b34f1c30267,2012-08-17T16:28:39Z,https://github.com/scikit-learn/scikit-learn/commit/f77930199f2b84cf811a21d3ed094b34f1c30267,Simplify LabelEncoder.fit_transform.,1,Inline Method,,
246903dca960da8d8b8cdc4499cb7d89e3e16aae,2011-10-03T12:22:47Z,https://github.com/scikit-learn/scikit-learn/commit/246903dca960da8d8b8cdc4499cb7d89e3e16aae,"CountVectorizer.fit_transformer refactoring, part N  Here's the changes I promised in the previous commit, but forgot to git add:  Optimized CountVectorizer.fit_transform by using Counter.update instead of __iadd__ (+=). Counter replacement more closely follows collection.Counter behavior.  Also condensed the CountVectorizer.transform code further.",1,Inline Method,,
365ce02ab9a42eea6075345b2b0222783ead125c,2010-03-05T15:18:41Z,https://github.com/scikit-learn/scikit-learn/commit/365ce02ab9a42eea6075345b2b0222783ead125c,Refactor plot_svm examples.  Do not use functions in examples (flat is better than nested)  From: Fabian Pedregosa <fabian.pedregosa@inria.fr>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@502 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8,1,Inline Method,,
3e4c9e5c64bdeb3558cf6efe4f1e60e3399f4a10,2022-12-07T14:35:37Z,https://github.com/huggingface/transformers/commit/3e4c9e5c64bdeb3558cf6efe4f1e60e3399f4a10,[`ViTHybrid`] + [`BiT`] cleaner `__init__` (#20649)  * cleaner `__init__`  * add docstring for `backbone_config`,1,Inline Method,,
4bb07647504a277398856e828fa48ddbec97678e,2022-11-17T14:59:22Z,https://github.com/huggingface/transformers/commit/4bb07647504a277398856e828fa48ddbec97678e,refactor test (#20300)  - simplifies the devce checking test,1,Inline Method,,
62d98c67d91ae5bb5cc00e2faaad90d546456ee1,2020-08-11T21:54:40Z,https://github.com/tensorflow/tensorflow/commit/62d98c67d91ae5bb5cc00e2faaad90d546456ee1,removed additional test class,1,Inline Class,,
6f6d4af798cd77d0299f3880a1343558ccb03bcf,2016-12-16T22:23:52Z,https://github.com/tensorflow/tensorflow/commit/6f6d4af798cd77d0299f3880a1343558ccb03bcf,Refactor LogisticRegressor from inheritance into a factory method.Change: 142298395,1,Inline Class,,
31521d500ca42dc17f0fea9d7328723d88d1e5e2,2016-02-05T04:07:38Z,https://github.com/tensorflow/tensorflow/commit/31521d500ca42dc17f0fea9d7328723d88d1e5e2,* Refactored batch_normalize,1,Inline Class,,
986b8772cf86329408a78ce098157ac8b25f033c,2015-12-26T23:15:11Z,https://github.com/tensorflow/tensorflow/commit/986b8772cf86329408a78ce098157ac8b25f033c,"Moved WordVocabulary as a separate into CategoricalVocabulary, separated tests",1,Inline Class,,
c9addefa289ca397598fde4b0bc697eb22119e5e,2015-06-27T20:30:01Z,https://github.com/keras-team/keras/commit/c9addefa289ca397598fde4b0bc697eb22119e5e,Simplify regularizers,1,Inline Class,,
0e8e739a9f63527547aae25eb80dd5c155c7e122,2021-01-28T10:37:05Z,https://github.com/pytorch/pytorch/commit/0e8e739a9f63527547aae25eb80dd5c155c7e122,Move AcceleratedGraphModule out of graph_manipulation. (#51220)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/51220testing with OS this time...Reviewed By: jfix71Differential Revision: D26105140fbshipit-source-id: b4b7a8f0f4cc8f96f9f8b270277a71061d5e5e84,1,Inline Class,,
cae52b403606f3255cd9f813019a6a97d252b1c5,2020-09-03T15:13:00Z,https://github.com/pytorch/pytorch/commit/cae52b403606f3255cd9f813019a6a97d252b1c5,Merge CriterionTest into NewCriterionTest. (#44055)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/44055There is no functional change here.  Another patch will rename NewCriterionTest to CriterionTest.Test Plan: Imported from OSSReviewed By: zou3519Differential Revision: D23482572Pulled By: gchananfbshipit-source-id: de364579067e2cc9de7df6767491f8fa3a685de2,1,Inline Class,,
48fe5d462285d003429143b23d40dddd6c9d0bc0,2017-11-02T19:17:36Z,https://github.com/pytorch/pytorch/commit/48fe5d462285d003429143b23d40dddd6c9d0bc0,Move select and permute to ATen/C++ (#3421)Move select and permute to ATen/C++,1,Inline Class,,
4966268a1d62125ea8ac46d56d83a7aafa5f85dc,2019-08-22T01:10:53Z,https://github.com/pytorch/pytorch/commit/4966268a1d62125ea8ac46d56d83a7aafa5f85dc,Move CPU-only jobs to xenialSummary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/24506Test Plan: Imported from OSSDifferential Revision: D16862005Pulled By: jamesr66afbshipit-source-id: cc4b3eee7f442a63ddc68667ac42404fe0b49d6c,1,Inline Class,,
a39726f0f4f51014b25516d3ea65f8710f8d2d74,2020-12-02T18:12:44Z,https://github.com/tensorflow/tensorflow/commit/a39726f0f4f51014b25516d3ea65f8710f8d2d74,Move tf.Keras object identifiers into constants.py.PiperOrigin-RevId: 345257730Change-Id: I0961d32f28300fe06cac6fa16928fec119baf779,1,Extract Variable,Move Variable,
a29ed76bc2c119bbae735ede6082202d51b67683,2020-09-09T17:26:16Z,https://github.com/tensorflow/tensorflow/commit/a29ed76bc2c119bbae735ede6082202d51b67683,refactored tests,1,Extract Variable,,
a236b79295c930b48bfd5171d9b2658851f48b6e,2020-07-23T02:51:29Z,https://github.com/tensorflow/tensorflow/commit/a236b79295c930b48bfd5171d9b2658851f48b6e,refactored test cases and added details,1,Extract Variable,,
e4d6335bcb7a73cd8967c2c12339380aa1ae284f,2020-06-23T17:21:31Z,https://github.com/tensorflow/tensorflow/commit/e4d6335bcb7a73cd8967c2c12339380aa1ae284f,"Refactor DecodeImageOp for the purpose of removing redundant data parsing and format checks from python wrapper and having them take place only in kernels. Remove security concerns. This change:- Creates new op kernel (`DecodeImageV2Op`) that can decode all four image formats (jpg, png, gif, bmp). `DecodeImage` is the op name. `DecodeBmpOp` is moved into `DecodeImageV2Op`. (Now we have `gen_image_ops.decode_image` as opposed to previous `decode_image` which was a pure python implementation.)- Updates GIF decoder to take in `expand_animation` flag for decoding just one frame.- Removes data parsing and format checking logic from python layer entirely.- Updates magic bytes for detecting image formats.- Replicates portions of `convert_image_dtype` functionality in kernel (for optionally converting uint8/uint16 -> float32).PiperOrigin-RevId: 317891936Change-Id: I84f18e053f6dad845d9f2a61e1119f4de131c85d",1,Extract Variable,,
d318b778e90fef1b90ef9bfee7cfc37f3c2e9cfd,2020-06-09T15:38:56Z,https://github.com/tensorflow/tensorflow/commit/d318b778e90fef1b90ef9bfee7cfc37f3c2e9cfd,[tfdbg2] Refactor and simplify code in dumping_callback.py- There is some duplication in the code that creates DebugIdentityV2  ops for tfdbg2. This CL removes some of the duplication.PiperOrigin-RevId: 315490159Change-Id: Ic8d7003aeb8552d43ddbd5a6731e550ddd7d2f90,1,Extract Variable,,
40e160df02156d9b76456e922e7e9bcca8847795,2020-04-19T12:03:42Z,https://github.com/tensorflow/tensorflow/commit/40e160df02156d9b76456e922e7e9bcca8847795,refactoring: deduplication,1,Extract Variable,,
15f2821f8727e7305dd223976ff2fe4239df0392,2020-04-07T05:55:53Z,https://github.com/tensorflow/tensorflow/commit/15f2821f8727e7305dd223976ff2fe4239df0392,refactoring: 'if' syntax deduplication,1,Extract Variable,,
140687f2982395111a27b7f3cd84b791fbe26e0f,2019-12-17T22:15:47Z,https://github.com/tensorflow/tensorflow/commit/140687f2982395111a27b7f3cd84b791fbe26e0f,"Remove circular dependency between pyct and utils. This was undetected for a while, but an upcoming change detects it.PiperOrigin-RevId: 286057471Change-Id: Ib8c8f5fe30af1c49d798515c0b3ddfb155a1e2f2",1,Extract Variable,,
7b85c1ae985a368d2b29114fa028627bcf3096ba,2019-12-13T17:18:52Z,https://github.com/tensorflow/tensorflow/commit/7b85c1ae985a368d2b29114fa028627bcf3096ba,Refactor on default setting to rename 'tf' to 'tf.compat.v2' or notPiperOrigin-RevId: 285412445Change-Id: I14b424ed9f8b6237a1e27245608e1dadd307684c,1,Extract Variable,,
30b99dd053aad083927faecc5a6eaca398e55410,2019-12-05T00:52:47Z,https://github.com/tensorflow/tensorflow/commit/30b99dd053aad083927faecc5a6eaca398e55410,Refactor the keras optimizer gradient apply function to reuse a context call and skip name scopes in eager mode where they have no effect. This reduces the Python overhead of applying gradient updates in eager mode.PiperOrigin-RevId: 283867294Change-Id: I8d61428b79d377c3f0ff724a56aaffdb795865ba,1,Extract Variable,,
539a627e16df48424bef85fba341689c18ad95a6,2019-09-05T22:33:07Z,https://github.com/tensorflow/tensorflow/commit/539a627e16df48424bef85fba341689c18ad95a6,"Refactor parsing_ops.py to reduce code duplication.Created a new `_ParseOpParams` class that is used to store the raw `gen_parsing_ops` parameters that correspond to a list of feature configuration objects (such as VarLenFeature).  This reduces code duplication by centralizing validation (previously it was performed in each op), and simplifies argument passing (we can pass the raw parameters as a single object, instead of using 8 separate parameters).PiperOrigin-RevId: 267470190",1,Extract Variable,,
b0cd40d7c7fd3828ae15bbbcf8b5f1f272ebf5c2,2019-07-22T19:24:09Z,https://github.com/tensorflow/tensorflow/commit/b0cd40d7c7fd3828ae15bbbcf8b5f1f272ebf5c2,"Internal cleanup: avoid discarding the result of NodeTransformer visitor, for consistency. This is a no-op, because generic_visit doesn't ever replace the node, so the CL is purely for consistency.PiperOrigin-RevId: 259380818",1,Extract Variable,,
24f6c4d45af85b44c166b3eaf28732c059b26d8a,2019-04-03T21:22:30Z,https://github.com/tensorflow/tensorflow/commit/24f6c4d45af85b44c166b3eaf28732c059b26d8a,Change metadata point for GCE to canonical http://metadata.google.internalPiperOrigin-RevId: 241804920,1,Extract Variable,,
47cf89738d3dd09dd4c0ff24df3c5c433c544d0d,2019-01-17T23:30:05Z,https://github.com/tensorflow/tensorflow/commit/47cf89738d3dd09dd4c0ff24df3c5c433c544d0d,[TF:XLA] Extract max_num_elements from empty_tensor_list.PiperOrigin-RevId: 229829562,1,Extract Variable,,
51fd9d70b8ef3c11b89e5009357cfbe3abb72473,2018-03-08T13:12:20Z,https://github.com/tensorflow/tensorflow/commit/51fd9d70b8ef3c11b89e5009357cfbe3abb72473,Extract the iterated expression of a for loop into a variable to avoid repeated staging.PiperOrigin-RevId: 188316160,1,Extract Variable,,
138ce5760011b862375fb2ac750de4493a7c1919,2018-01-02T20:28:57Z,https://github.com/tensorflow/tensorflow/commit/138ce5760011b862375fb2ac750de4493a7c1919,Internal cleanup.PiperOrigin-RevId: 180578376,1,Extract Variable,,
d77add1baa914faca60c0b5b06e97efbf075d009,2017-12-22T22:49:14Z,https://github.com/tensorflow/tensorflow/commit/d77add1baa914faca60c0b5b06e97efbf075d009,Extracts the tpu_job_name from TF_CONFIG if set.PiperOrigin-RevId: 179966184,1,Extract Variable,,
b211be166c20a23249dd65a5b47ae3f688d68794,2017-09-19T21:07:52Z,https://github.com/tensorflow/tensorflow/commit/b211be166c20a23249dd65a5b47ae3f688d68794,TFE: Simplify code example in backprop.pyPiperOrigin-RevId: 169297126,1,Extract Variable,,
e405b0f6b17768e5e3c687377acc54faa5065b8e,2017-05-30T22:20:53Z,https://github.com/tensorflow/tensorflow/commit/e405b0f6b17768e5e3c687377acc54faa5065b8e,"Refactoring of layer name autogeneration, to remove a graph serialization warning.PiperOrigin-RevId: 157520123",1,Extract Variable,Rename Variable,
b2e0dda6c6f92e4b14e567a508e1a5b5d475decc,2017-04-06T19:12:18Z,https://github.com/tensorflow/tensorflow/commit/b2e0dda6c6f92e4b14e567a508e1a5b5d475decc,Replace a gather op for shapes by a stack op so dilated convolutions can beplaced on GPU even with strict placing (before the gather went to CPU).Change: 152411159,1,Extract Variable,,
9f743e87769634577d81031a1e709ee5cd95e513,2017-02-03T18:49:56Z,https://github.com/tensorflow/tensorflow/commit/9f743e87769634577d81031a1e709ee5cd95e513,"Initial refactor for RichTextLinesThe goal here is to, eventually, entirely avoid referring to font_attr_segment indicesanywhere outside the RichLine class.Change: 146491606",1,Extract Variable,,
a66671c8ec219371c2d84ad57b99385fd7b82df4,2017-02-03T18:49:56Z,https://github.com/tensorflow/tensorflow/commit/a66671c8ec219371c2d84ad57b99385fd7b82df4,"Initial refactor for RichTextLinesThe goal here is to, eventually, entirely avoid referring to font_attr_segment indicesanywhere outside the RichLine class.Change: 146491606",1,Extract Variable,,
2275fe9693250bf87182e5c88f127e39c405dd55,2017-02-02T03:32:39Z,https://github.com/tensorflow/tensorflow/commit/2275fe9693250bf87182e5c88f127e39c405dd55,Split test_log_output flag into two flags: test_log_output_dir andtest_log_output_filename. This lets us create test_log_output_filenameautomatically if it is not passed in.Change: 146320874,1,Extract Variable,,
b0bbb8fc18c9116b8d2a7c0fa6c0daa48db0027f,2016-11-15T17:33:37Z,https://github.com/tensorflow/tensorflow/commit/b0bbb8fc18c9116b8d2a7c0fa6c0daa48db0027f,Refactor DNNClassifier to use head.Change: 139210204,1,Extract Variable,,
54ab19d23562c26e88a493e190deb1494d8550bf,2016-11-03T18:56:51Z,https://github.com/tensorflow/tensorflow/commit/54ab19d23562c26e88a493e190deb1494d8550bf,Remove duplicate PredictionKeys.Change: 138099098,1,Extract Variable,,
4d5b97a37b80940463111fdd5259576c69eca079,2016-10-22T06:04:12Z,https://github.com/tensorflow/tensorflow/commit/4d5b97a37b80940463111fdd5259576c69eca079,Change quantize_graph to use two steps - RequantizationRange and Requantize -in place of QuantizeDownAndShrinkRange.  This will alow replacingRequantizationRange with constants.Also remove restriction on requested_output_max that was not present inQuantizeDownAndShrinkRange.Change: 136906788,1,Extract Variable,,
230568c53a63032e6bc74d88418899da41616bd2,2016-01-16T14:37:27Z,https://github.com/tensorflow/tensorflow/commit/230568c53a63032e6bc74d88418899da41616bd2,* minor refactoring,1,Extract Variable,,
6a05407841c717e53c361c2d2f29968a71e52c4e,2023-07-03T05:52:26Z,https://github.com/keras-team/keras/commit/6a05407841c717e53c361c2d2f29968a71e52c4e,"refactor:  _log_epoch_metrics()  In this refactored version, I have changed the code to consolidate two loops into one loop for the same method, improving efficiency and readability.",1,Extract Variable,,
ae7cee57b1c82ab26b1b1aec2a28f9f0d5ede00d,2022-12-05T23:30:23Z,https://github.com/keras-team/keras/commit/ae7cee57b1c82ab26b1b1aec2a28f9f0d5ede00d,Improve readability of sample code in Sequence class by reusing the computation of the lower and upper bounds for the given batch.  PiperOrigin-RevId: 493129794,1,Extract Variable,,
12bbd222729f75a60b8692598f9ca45ae769230c,2022-09-12T23:19:58Z,https://github.com/keras-team/keras/commit/12bbd222729f75a60b8692598f9ca45ae769230c,Minor saving logic touchups.  PiperOrigin-RevId: 473871888,1,Extract Variable,,
48247a7752e3160062bc9d08fa1cb8affad02e63,2022-01-07T01:34:29Z,https://github.com/keras-team/keras/commit/48247a7752e3160062bc9d08fa1cb8affad02e63,Put absl logging control flag in a separate file. Open the APIs for control the logging in Keras.  PiperOrigin-RevId: 420178505,1,Extract Variable,,
d8c81998185b67e409fd0d31a07bbe9d1d61122f,2021-09-19T05:37:12Z,https://github.com/keras-team/keras/commit/d8c81998185b67e409fd0d31a07bbe9d1d61122f,Replace validation_fn and fn_alt with allow_zero,1,Extract Variable,,
b75b2f7dcf5d3c83e33b8b2bc86f1d2543263a59,2019-10-08T09:56:20Z,https://github.com/keras-team/keras/commit/b75b2f7dcf5d3c83e33b8b2bc86f1d2543263a59,Small refactors on the keras.utils module (#13388)  * Use .format calls for string interpolation on utils  * Use generators over listcomps whenever possible to save memory,1,Extract Variable,,
2afe0b0054694045aff3dd7e263b5c44f04c323a,2017-08-13T01:01:19Z,https://github.com/keras-team/keras/commit/2afe0b0054694045aff3dd7e263b5c44f04c323a,Improve TB UX by grouping `compile` logic into name scopes. (#7584)  * Move constraint management to be based on variable attributes (like TF).  * Add correctness tests for constraint support in all optimizers.  * Add `constraint` in `variable` docstring.  * Skip TF opt test if backend isn’t TF  * Fix Theano backend support.  * Improve TensorBoard UX by grouping `compile` logic into name scopes.  * Improve name scoping in optimizers.  * Fix issue with saving duplicate variable names in optimizers for Theano/CNTK  * Name update,1,Extract Variable,,
98af4eb39faa55a6f0d89e6fe375da9b985e34a4,2017-03-12T09:55:40Z,https://github.com/keras-team/keras/commit/98af4eb39faa55a6f0d89e6fe375da9b985e34a4,Slight refactoring,1,Extract Variable,,
ed4a95bdada471ef42f80d539a453d81826f78c0,2016-04-06T18:46:18Z,https://github.com/keras-team/keras/commit/ed4a95bdada471ef42f80d539a453d81826f78c0,Slight cleanup of build_map_of_graph,1,Extract Variable,,
be24159959672c32abb31697e721d96ae6ffaf97,2016-02-28T05:46:20Z,https://github.com/keras-team/keras/commit/be24159959672c32abb31697e721d96ae6ffaf97,Refactoring of sklearn,1,Extract Variable,,
9e001ee70cd274fbea1491658a3d35a8dbc264a9,2015-08-24T19:27:52Z,https://github.com/keras-team/keras/commit/9e001ee70cd274fbea1491658a3d35a8dbc264a9,Make the logic more understandable via DRY,1,Extract Variable,,
91ccb284abcd83a091dc5f2549f6b24df849a2b5,2019-02-24T23:49:58Z,https://github.com/keras-team/keras/commit/91ccb284abcd83a091dc5f2549f6b24df849a2b5,Use local RandomState instead of seeding the global RNG (#12259)  * Use local RandomState instead of seeding the global RNG  * Create a unit test module for datasets and move tests there  * Move initializer test to the proper file,1,Extract Variable,,
a8385c3835a417dc85f8bc862ef87d9c35dc9017,2022-02-03T19:54:30Z,https://github.com/keras-team/keras/commit/a8385c3835a417dc85f8bc862ef87d9c35dc9017,change CatAcc to call sparseCatAcc,1,Extract Variable,,
ccc9357778bf3ee6d1ae7c7b77e744586a4401d8,2022-02-03T19:53:38Z,https://github.com/keras-team/keras/commit/ccc9357778bf3ee6d1ae7c7b77e744586a4401d8,change topKCat to call sparseTopKCat,1,Extract Variable,,
1c21cd2213f167888fc4bc57685c8d7c86a37031,2023-03-31T15:54:19Z,https://github.com/pytorch/pytorch/commit/1c21cd2213f167888fc4bc57685c8d7c86a37031,"[quant][pt2e][refactor] Add input_output_share_observers to node.meta[""target_dtype_info""] (#97949)  Summary: The goal for this PR is to unify the flow of information to reduce fragmentation of implementations between fx graph mode quantization and quantize_pt2e, since quantize_pt2e will be using node.meta to store this information, we'd like to make sure fx graph mode quantization get this information from the same place  Test Plan: python test/test_quantization.py TestQuantizeFx  Reviewers:  Subscribers:  Tasks:  Tags: Pull Request resolved: https://github.com/pytorch/pytorch/pull/97949 Approved by: https://github.com/andrewor14",1,Extract Variable,,
2d8deffc1e651c25a445dfe3a64ab00f3ab40c62,2023-05-01T11:12:38Z,https://github.com/pytorch/pytorch/commit/2d8deffc1e651c25a445dfe3a64ab00f3ab40c62,"Refactor repro/minifier into CLI; add analyze (#100226)  This is a two part PR; I can split it if you really want me to.  The first part is a refactor of the after aot repro/minifier scripts to come with a command line interface. I maintain exact BC with the previous interface (so, e.g., you still get a repro.py and a run_minifier.py that do the same thing as before), but each of these scripts also take command line arguments now which you can use to customize what actually happens. Check `run_repro` for full documentation on the arguments.  The second part of this is an implementation of `analyze` subcommand on the new CLI for any repro.  <img width=""1277"" alt=""image"" src=""https://user-images.githubusercontent.com/13564/235045677-8545aab7-5e83-4813-bbec-47783dc60122.png"">  This facility is oriented towards accuracy debugging. It does several things:  1. It will run your model twice and check for nondeterminism in inductor/float64, *even* on intermediate inputs (our benchmarking nondeterminism test only checks for nondeterminism on the final output). This makes localizing which operator is nondeterministic easy. 2. It will run your compiled model side-by-side with eager and float64 variants, and then report when things diverge too far from RMSE delta from float64.  Importantly, it does all this without requiring every intermediate to be held in memory (which will cause an OOM on large repros, such as the one I tested this on.)  Some other minor improvements:  * MinifierTestBase now has an easy to comment out spot that you can use to retain the temporary directory; good for debugging * We print ""running minifier"" and ""running repro"" in MinifierTestBase to make it easier to orient where logs are coming from * same takes a `log_error` optional argument which you can use to reroute the error logs when things mismatch * counters[""inductor""][""intermediate_hooks""] tracks the number of intermediate hooks we've codegen'ed; good for populate the tqdm interface * torch.fx.interpreter gets an official `boxed_run` interface which uses the boxed arguments calling convention and doesn't retain inputs unnecessarily long * torch.utils._content_store gets compute_tensor_metadata/read_tensor_metadata helper functions for computing tensor information without serializing it  Signed-off-by: Edward Z. Yang <ezyang@meta.com>  Pull Request resolved: https://github.com/pytorch/pytorch/pull/100226 Approved by: https://github.com/bertmaher, https://github.com/bdhirsh, https://github.com/anijain2305",1,Extract Variable,,
59c1b5025f64f9a8ce87fc96b738fbbbb1191d91,2023-02-07T08:23:56Z,https://github.com/pytorch/pytorch/commit/59c1b5025f64f9a8ce87fc96b738fbbbb1191d91,"[quant][fx][pt2e] Refactor prepare so it's aligned better with the new API plan in pt2e (#94011)  Summary: There are three things that happens in the current prepare code, (1). user express their intention of how they want the model to be quantized with QConfigMapping, we translate that to node.meta[""target_dtype_info""] (2). we validate the setting against BackendConfig (3). insert observers based on the validated node.meta[""target_dtype_info""]  previously (2) and (3) are mixed together, this PR tries to move (2) closer to (1), with one edge case left, this refactor moves us closer to our target design for quantization in pytorch 2.0 export path  this is a follow up PR for https://github.com/pytorch/pytorch/pull/92641  Test Plan: python test/test_quantization.py TestQuantizeFx python test/test_quantization.py TestQuantizeFxOps python test/test_quantization.py TestQuantizeFxModels  Reviewers:  Subscribers:  Tasks:  Tags: Pull Request resolved: https://github.com/pytorch/pytorch/pull/94011 Approved by: https://github.com/vkuzo",1,Extract Variable,,
9217bde807115bf8e161dc54faeed0851a247780,2018-12-19T20:26:44Z,https://github.com/pytorch/pytorch/commit/9217bde807115bf8e161dc54faeed0851a247780,"Refactor dataloader.py (#15331)Summary:Same as #14668, and was approved there.ailzhang , please apply this patch to Horizon's `data_streamer.py`: https://gist.github.com/SsnL/020fdb3d6b7016d81b6ba1d04cc41459 Thank you!Below is the original description at #14668:As I am working on tasks in https://github.com/pytorch/pytorch/issues/13023, I realized how unreadable the code is because all functions to be run in multiprocessing must be at top global level. Adding more functionalities to `dataloader.py` will only make things worse.So in this PR, I refactor `dataloader.py` and move much of it into `data._utils`. E.g., the `_worker_loop` and related methods are now in `data._utils.worker`, signal handling code in `data._utils.signal_handling`, collating code in `data._utils.collate`, etc. This split, IMHO, makes code much clearer. I will base my future changes to DataLoader on top of this.No functionality is changed, except that  I added `torch._six.queue`.Pull Request resolved: https://github.com/pytorch/pytorch/pull/15331Reviewed By: yf225Differential Revision: D13503120Pulled By: ailzhangfbshipit-source-id: 94df16b4d80ad1102c437cde0d5a2e62cffe1f8e",1,Extract Variable,,
93de80203d79615d406e741357172fef11cee29b,2021-04-26T23:58:35Z,https://github.com/pytorch/pytorch/commit/93de80203d79615d406e741357172fef11cee29b,"ns for fx: move node I/O dtype mapping to be local instead of global (#56296)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/56296To support shadows of custom functions, we need to allow user tospecify I/O type of the custom functions.This PR is a cleanup in preparation for making the above happen.We make the I/O dtype mappings be generated by a function insteadof a global variable. In the next PR, we will add a hook so usercan modify these mappings.Test Plan:```python test/test_quantization.py TestFXNumericSuiteCoreAPIs```Imported from OSSReviewed By: jerryzh168Differential Revision: D27831996fbshipit-source-id: 782f5e77de0eef3899b9b7def0fdabd8dcafef12",1,Extract Variable,,
eaeea62ee4288a235484b4c0939d641e4763b060,2023-06-02T13:36:50Z,https://github.com/pytorch/pytorch/commit/eaeea62ee4288a235484b4c0939d641e4763b060,"Make TestPythonRegistration clean up after itself (#102292)  We did this for TestCustomOp, now we are applying the same thing to TestPythonRegistration.  This PR: - changes TestPythonRegistration to register new ops under a single namespace (self.test_ns) - clean up the namespace by deleting it from torch.ops after each test is done running.  This avoids a problem where if an op is re-defined, torch.ops.myns.op crashes because we do some caching. The workaround in many of these tests have been to just create an op with a different name, but this PR makes it so that we don't need to do this.  Test Plan: - existing tests Pull Request resolved: https://github.com/pytorch/pytorch/pull/102292 Approved by: https://github.com/ezyang, https://github.com/bdhirsh",1,Extract Variable,,
0a0ff8312466531762d659b67e4ebc873d9565d3,2019-05-31T03:45:13Z,https://github.com/pytorch/pytorch/commit/0a0ff8312466531762d659b67e4ebc873d9565d3,replace `num_bits` with `quant_min` and `quant_max` (#21097)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/21097attDifferential Revision: D15547166fbshipit-source-id: 60bc7f7d82c424558b67881627fb74f1eff515af,1,Extract Variable,,
41f7a9dac057126d545bcd4fa4439f63db0cce1d,2021-07-24T01:28:08Z,https://github.com/pytorch/pytorch/commit/41f7a9dac057126d545bcd4fa4439f63db0cce1d,"[profiler][refactor] Avoid using legacy event in profiler (#61721)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/61721  Remove dependency on LegacyEvent from the profiler  Test Plan: python test/test_profiler.py -v  Imported from OSS  Reviewed By: kimishpatel, gdankel  Differential Revision: D29716769  fbshipit-source-id: 2c2b48f2ee096adcbde09821e0cc7c0fcb94d19f",1,Extract Variable,Rename Method,
5f14ef8cc167e8d4b12aa8a65b09e84c1b963a7a,2019-05-17T19:56:03Z,https://github.com/pytorch/pytorch/commit/5f14ef8cc167e8d4b12aa8a65b09e84c1b963a7a,Split out gpu/cpu targets based on gpu_library_targets (#20633)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/20633Merge the c2_gpu and is_amd_build logic in targets files.Reviewed By: dzhulgakovDifferential Revision: D15176621fbshipit-source-id: 9185b394ffcb305fd8d94dc7c7c92780bf10a511,1,Extract Variable,,
6100c0ea14306f409bc6d7ba46b149c64a2417b3,2018-09-20T21:35:02Z,https://github.com/pytorch/pytorch/commit/6100c0ea14306f409bc6d7ba46b149c64a2417b3,"Introduce ExtensionVersioner for C++ extensions (#11725)Summary:Python never closes shared library it `dlopen`s. This means that calling `load` or `load_inline` (i.e. building a JIT C++ extension) with the same C++ extension name twice in the same Python process will never re-load the library, even if the compiled source code and the underlying shared library have changed. The only way to circumvent this is to create a new library and load it under a new module name.I fix this, of course, by introducing a layer of indirection. Loading a JIT C++ extension now goes through an `ExtensionVersioner`, which hashes the contents of the source files as well as build flags, and if this hash changed, bumps an internal version stored for each module name. A bump in the version will result in the ninja file being edited and a new shared library and effectively a new C++ extension to be compiled. For this the version name is appended as `_v<version>` to the extension name for all versions greater zero.One caveat is that if you were to update your code many times and always re-load it in the same process, you may end up with quite a lot of shared library objects in your extension's folder under `/tmp`. I imagine this isn't too bad, since extensions are typically small and there isn't really a good way for us to garbage collect old libraries, since we don't know what still has handles to them.Fixes https://github.com/pytorch/pytorch/issues/11398 CC The controller you requested could not be found.ezyang gchanan soumith fmassaPull Request resolved: https://github.com/pytorch/pytorch/pull/11725Differential Revision: D9948244Pulled By: goldsboroughfbshipit-source-id: 695bbdc1f1597c5e4306a45cd8ba46f15c941383",1,Extract Variable,Rename Variable,Rename Method
6c833efd65599acfe61f2709c0ee5ce750ae0ee3,2021-01-04T19:51:28Z,https://github.com/pytorch/pytorch/commit/6c833efd65599acfe61f2709c0ee5ce750ae0ee3,"Move default or no default logic into native.argument (#49489)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/49489Previously, it was done at a use site, but that meant other usesites don't get the right logic.  Pushing it in makes sure everyonegets it.I also fixed one case of confusion where defn() was used to define a decl().If you want to define a declaration with no defaults, say no_default().decl()which is more direct and will give us code reviewers a clue if you shouldhave pushed this logic in.Signed-off-by: Edward Z. Yang <ezyang@fb.com>Test Plan: Imported from OSSReviewed By: smessmerDifferential Revision: D25595407Pulled By: ezyangfbshipit-source-id: 89c664f0ed4d95699794a0d3123d54d0f7e4cba4",1,Extract Variable,Expression,
bbce4184bebc1843a1af0ca4d31e8d1dfa452766,2023-01-17T04:05:43Z,https://github.com/pytorch/pytorch/commit/bbce4184bebc1843a1af0ca4d31e8d1dfa452766,Refactor inductor to use standard BACKENDS dict (#92187)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/92187 Approved by: https://github.com/desertfire,1,Extract Variable,Extract Method,
ca89e7942a038a4b545539ca676ab24ff860aa7c,2023-04-19T20:40:09Z,https://github.com/pytorch/pytorch/commit/ca89e7942a038a4b545539ca676ab24ff860aa7c,[SPMD][Easy] switch to tree_map_only to simplify code (#99547)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/99547 Approved by: https://github.com/fegin,1,Extract Variable,Expression,
d1cbee7b2b1da94ff1a0fa880bd0173de27fb89f,2021-08-16T13:42:56Z,https://github.com/pytorch/pytorch/commit/d1cbee7b2b1da94ff1a0fa880bd0173de27fb89f,Refactor BucketBatch (#63185)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/63185  Test Plan: Imported from OSS  Reviewed By: bdhirsh  Differential Revision: D30288893  Pulled By: ejguan  fbshipit-source-id: b88b792d12a83c99d8ea9e516e3b4c54a82100f6,1,Extract Variable,Rename Variable,
e856a45283c6a215c78597d05f6e8dfeb0030c49,2021-07-24T01:39:45Z,https://github.com/pytorch/pytorch/commit/e856a45283c6a215c78597d05f6e8dfeb0030c49,"[Model Averaging] Refactor averagers to accept parameters instead of a module (#62105)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/62105  This is for the preparation of wrapping the averager as an optimizer, which can only accept parameters rather than a module.  Proposal: https://github.com/pytorch/pytorch/issues/59699 ghstack-source-id: 134213572  Test Plan: buck test mode/dev-nosan caffe2/test/distributed:distributed_nccl_fork -- test_periodic_model_averager  buck test mode/dev-nosan caffe2/test/distributed:distributed_nccl_fork -- test_average_parameters  Reviewed By: rohan-varma  Differential Revision: D29883693  fbshipit-source-id: 474ba924a0b05068b12f163fb74582bccf314964",1,Extract Variable,Rename Variable,
5fd66bc55f03740f395971abf1189b11594252b1,2022-08-19T15:52:14Z,https://github.com/scikit-learn/scikit-learn/commit/5fd66bc55f03740f395971abf1189b11594252b1,CI Remove pandas FutureWarning in scipy-dev build (#24206),1,Extract Variable,,
87bcb9768209bf0c0681e0ded7853fecbcea4f31,2022-05-25T17:48:42Z,https://github.com/scikit-learn/scikit-learn/commit/87bcb9768209bf0c0681e0ded7853fecbcea4f31,MNT Small refactor of `_bagging.py` (#23460)  Co-authored-by: MDouriez <marie.douriez@gmail.com>,1,Extract Variable,,
4685cf624582cbc9a35d646f239347e54db798dc,2022-05-13T20:16:08Z,https://github.com/scikit-learn/scikit-learn/commit/4685cf624582cbc9a35d646f239347e54db798dc,MAINT Minor refactor of `_assert_all_finite` logic (#23347)  * Streamlined logic  * Reverted back to safe_accumulator for StandardScalar performance  Co-authored-by: Guillaume Lemaitre <g.lemaitre58@gmail.com>,1,Extract Variable,,
0d3713ec00c84d88286f6131ae0399c59aa1ab4d,2020-06-29T18:08:48Z,https://github.com/scikit-learn/scikit-learn/commit/0d3713ec00c84d88286f6131ae0399c59aa1ab4d,TST Refactor the test of oob score of forest predictors (#17770),1,Extract Variable,,
f71de6fd264ba350e69737973e4eadebbe900469,2018-09-12T04:48:11Z,https://github.com/scikit-learn/scikit-learn/commit/f71de6fd264ba350e69737973e4eadebbe900469,MNT Unify and refactor strategy error (#12050),1,Extract Variable,,
77b8e554c7b1de182f422785e664164b7b7641e3,2018-08-30T00:09:51Z,https://github.com/scikit-learn/scikit-learn/commit/77b8e554c7b1de182f422785e664164b7b7641e3,COSMIT Mimimal refactoring of gradient_boosting.py (#11921),1,Extract Variable,,
91c2386e89a98022e4aa3de3a665b974c25bd29d,2014-12-22T22:23:44Z,https://github.com/scikit-learn/scikit-learn/commit/91c2386e89a98022e4aa3de3a665b974c25bd29d,STY cleaning some LSHForest query code,1,Extract Variable,,
31d9b12a4a0d26f1c17e2d771cb0030519afcfab,2014-08-04T15:35:05Z,https://github.com/scikit-learn/scikit-learn/commit/31d9b12a4a0d26f1c17e2d771cb0030519afcfab,"Make cosmetic revisions to random_choice_csc  Drop the passing of deault parmaters in calls to sample_without_replacement and random.choice, calculate nnz in a more concise 2 line sequence",1,Extract Variable,,
37e7c0a1cf49b4bf56040614bffa23d5e9673ce3,2014-01-16T03:43:15Z,https://github.com/scikit-learn/scikit-learn/commit/37e7c0a1cf49b4bf56040614bffa23d5e9673ce3,Refactor RFE and add _check_scorable,1,Extract Variable,,
e95533d1725e4d3b2126a317f285dc02347ea19a,2013-10-03T14:48:00Z,https://github.com/scikit-learn/scikit-learn/commit/e95533d1725e4d3b2126a317f285dc02347ea19a,cleanup changes,1,Extract Variable,,
547c8f582f61c08d332fa6e48fecb8da5b233472,2013-07-04T10:39:23Z,https://github.com/scikit-learn/scikit-learn/commit/547c8f582f61c08d332fa6e48fecb8da5b233472,Simplify ridge solvers (ongoing work).,1,Extract Variable,,
cb701b0267480318a0baf1893df57c26e649e96f,2013-05-12T07:41:32Z,https://github.com/scikit-learn/scikit-learn/commit/cb701b0267480318a0baf1893df57c26e649e96f,MAINT: refactored metrics.auc to use np.trapz,1,Extract Variable,,
0984cf6ff963ff278d6f16428761124df01c51eb,2012-06-22T15:16:42Z,https://github.com/scikit-learn/scikit-learn/commit/0984cf6ff963ff278d6f16428761124df01c51eb,"For the sake of clarity, creates new temporary arrays instead of copying the same one several times.\n Modified error message for negative valued arrays.",1,Extract Variable,,
42e691b44e6e818e4ec1e9f87363436e3ed55d20,2012-03-26T08:36:26Z,https://github.com/scikit-learn/scikit-learn/commit/42e691b44e6e818e4ec1e9f87363436e3ed55d20,Broadcasting used to remove a loop,1,Extract Variable,,
278fe52ba251333e55fea0e3127acdf529ab3920,2012-01-16T22:34:03Z,https://github.com/scikit-learn/scikit-learn/commit/278fe52ba251333e55fea0e3127acdf529ab3920,COSMIT refactor liblinear bindings  Move knowledge of the CSR matrix format down the chain.,1,Extract Variable,,
826df8d1797fd6e2b87a56f09bb9a5501f705336,2011-12-07T19:07:32Z,https://github.com/scikit-learn/scikit-learn/commit/826df8d1797fd6e2b87a56f09bb9a5501f705336,clean up test,1,Extract Variable,,
643e559f32f12ffadaf849f28ea72947e7f38291,2011-09-14T15:36:04Z,https://github.com/scikit-learn/scikit-learn/commit/643e559f32f12ffadaf849f28ea72947e7f38291,Merge pull request #350 from tinyclues/master  Refactor and speed up of metrics.roc_curve method,1,Extract Variable,,
a1fa061e922b32dab821011375779d19c944a646,2011-08-08T11:00:12Z,https://github.com/scikit-learn/scikit-learn/commit/a1fa061e922b32dab821011375779d19c944a646,ENH: PatchExtractor transform,1,Extract Variable,,
767de181faac929880fd86377cbe0781158a60ad,2011-07-10T13:16:24Z,https://github.com/scikit-learn/scikit-learn/commit/767de181faac929880fd86377cbe0781158a60ad,ENH: PatchExtractor transform,1,Extract Variable,,
7685c9ea5cc5fdc69ed17bff4a96a6be07891c6b,2010-10-26T19:25:04Z,https://github.com/scikit-learn/scikit-learn/commit/7685c9ea5cc5fdc69ed17bff4a96a6be07891c6b,"ENH: more cosmit, docstring, test cleanup for the metrics module",1,Extract Variable,,
4a96ecf5e1723df0cb9a47a34e27dca3aa7c9cc3,2010-05-07T09:25:31Z,https://github.com/scikit-learn/scikit-learn/commit/4a96ecf5e1723df0cb9a47a34e27dca3aa7c9cc3,"Refactor lasso coordinate descent code.  The code of coordinate descent was optimized algorithmically reducing the number of matrix operations and eliminating callbacks. The resulting code is thus simpler but less flexible in theory, although in my oppinion this feature was not really used.  In my computer this gives a 150x speed improvement on the example plot_lasso_coordinate_descent_path.py.  Further improvements should be done, notably those that exploit sparsity. This is planned but not done in this commit.  Other changes:    * squash enet_cd_fast.pyx and lasso_cd_fast.pyx into cd_fast.pyx.   * remove python code that duplicates functionality of cython code.   * Refactor test for this module, as they where mostly based on the     callback code.   * Modify plot_lasso_coordinate_descent_path.py to compute only the     lasso path.   * throw a warning if dual gap > tolerance.",1,Extract Variable,,
88e9d3a4eb0a3113a729095e78f0158293f07978,2010-05-06T14:29:25Z,https://github.com/scikit-learn/scikit-learn/commit/88e9d3a4eb0a3113a729095e78f0158293f07978,"Refactor lasso coordinate descent code.  The code of coordinate descent was optimized algorithmically reducing the number of matrix operations and eliminating callbacks. The resulting code is thus simpler but less flexible in theory, although in my oppinion this feature was not really used.  In my computer this gives a 150x speed improvement on the example plot_lasso_coordinate_descent_path.py.  Further improvements should be done, notably those that exploit sparsity. This is planned but not done in this commit.  Other changes:    * squash enet_cd_fast.pyx and lasso_cd_fast.pyx into cd_fast.pyx.   * remove python code that duplicates functionality of cython code.   * Refactor test for this module, as they where mostly based on the     callback code.   * Modify plot_lasso_coordinate_descent_path.py to compute only the     lasso path.   * throw a warning if dual gap > tolerance.",1,Extract Variable,,
ec364fe93246d2f79ac19ae5c6f8943e9e74b967,2010-05-06T08:55:24Z,https://github.com/scikit-learn/scikit-learn/commit/ec364fe93246d2f79ac19ae5c6f8943e9e74b967,"Refactor lasso coordinate descent code.  The code of coordinate descent was optimized algorithmically reducing the number of matrix operations and eliminating callbacks. The resulting code is thus simpler but less flexible in theory, although in my oppinion this feature was not really used.  In my computer this gives a 150x speed improvement on the example plot_lasso_coordinate_descent_path.py.  Further improvements should be done, notably those that exploit sparsity. This is planned but not done in this commit.  Other changes:    * squash enet_cd_fast.pyx and lasso_cd_fast.pyx into cd_fast.pyx.   * remove python code that duplicates functionality of cython code.   * Refactor test for this module, as they where mostly based on the     callback code.   * Modify plot_lasso_coordinate_descent_path.py to compute only the     lasso path.   * throw a warning if dual gap > tolerance.",1,Extract Variable,,
a2514e3f034814395989470a566b5ccd6af20caa,2010-01-05T17:19:18Z,https://github.com/scikit-learn/scikit-learn/commit/a2514e3f034814395989470a566b5ccd6af20caa,Refactoring kernels to work better in sparse and dense cases.  Lots of other updates.  From: fullung <fullung@cb17146a-f446-4be1-a4f7-bd7c5bb65646>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@206 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8,1,Extract Variable,,
d68d6665f94f86cbd9d5f512c9d2942528661cad,2023-05-31T13:42:30Z,https://github.com/huggingface/transformers/commit/d68d6665f94f86cbd9d5f512c9d2942528661cad,Support shared tensors (#23871)  * Suport shared storage  * Really be sure we have the same storage  * Make style  * - Refactor storage identifier mechanism  - Group everything into a single for loop  * Make style  * PR  * make style  * Update src/transformers/pytorch_utils.py  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  ---------  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>,1,Extract Variable,,
5b85add7d5434b220fed7e0630fe7ac355fb857c,2023-03-13T19:51:40Z,https://github.com/huggingface/transformers/commit/5b85add7d5434b220fed7e0630fe7ac355fb857c,[trainer] fix bug in grad accum with multiple epochs (#22098)  * [trainer] fix bug in grad accum  * comment out debug  * fix one-off  * rename counter,1,Extract Variable,,
51c3f42d8e51f1edfd5f5e04e6ee275ec870edf3,2023-02-10T14:44:14Z,https://github.com/huggingface/transformers/commit/51c3f42d8e51f1edfd5f5e04e6ee275ec870edf3,Replace inefficient torch.sqrt taking scalar input with numpy.sqrt (#21496)  * fix rsqrt  * fix typo,1,Extract Variable,,
3e39fd09a9c4d78bc2088777d3255789cf2acac8,2022-11-08T08:59:03Z,https://github.com/huggingface/transformers/commit/3e39fd09a9c4d78bc2088777d3255789cf2acac8,[Audio Processor] Only pass sr to feat extractor (#20022)  * [Audio Processor] Only pass sr to feat extractor  * move out of if/else  * copy to other processors,1,Extract Variable,,
69e16abf98c94b8a6d2cf7d60ca36f13e4fbee58,2021-11-22T21:17:26Z,https://github.com/huggingface/transformers/commit/69e16abf98c94b8a6d2cf7d60ca36f13e4fbee58,Switch from using sum for flattening lists of lists in group_texts (#14472)  * remove sum for list flattening  * change to chain(*)  * make chain object a list  * delete empty lines  per sgugger's suggestions  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  Co-authored-by: Nicholas Broad <nicholas@nmbroad.com> Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>,1,Extract Variable,,
fb2b89840bf2ab9f74702bf83af8ddf92b61efb3,2021-03-23T16:41:41Z,https://github.com/huggingface/transformers/commit/fb2b89840bf2ab9f74702bf83af8ddf92b61efb3,[file_utils] import refactor (#10859)  * import refactor  * fix the fallback,1,Extract Variable,,
dee876cefffa769491a008670b35b5ac3192e929,2021-02-17T23:52:36Z,https://github.com/huggingface/transformers/commit/dee876cefffa769491a008670b35b5ac3192e929,"[trainer] refactor place_model_on_device logic, add deepspeed (#10243)  * refactor place_model_on_device logic, add deepspeed  * doc  * style",1,Extract Variable,,
ece6c514586cf925f1d12cf9c7d472aa6f85a9e0,2021-02-08T15:08:16Z,https://github.com/huggingface/transformers/commit/ece6c514586cf925f1d12cf9c7d472aa6f85a9e0,[s2s examples] Replace -100 token ids with the tokenizer pad_id for compute_metrics (#10046)  * replace -100 token ids with the tokenizer pad_id for compute_metrics  * fixed typo for label_ids,1,Extract Variable,,
9fd11bf1a889d140d6c81435e2927a718ec52b0f,2020-09-09T08:56:40Z,https://github.com/huggingface/transformers/commit/9fd11bf1a889d140d6c81435e2927a718ec52b0f,replace torch.triu with onnx compatible code (#6929),1,Extract Variable,,
0416d437fb020b1c5dcf8268ee6cabb735b6c968,2020-03-06T21:01:46Z,https://github.com/huggingface/transformers/commit/0416d437fb020b1c5dcf8268ee6cabb735b6c968,Merge pull request #3148 from patrickvonplaten/refactoring_beam_search_for_tf_2  refactored beam search according to torch implementation,1,Extract Variable,,
9362eb4a07a26c72fc7f2a3e3f94d828cb4947d3,2020-03-05T23:46:29Z,https://github.com/huggingface/transformers/commit/9362eb4a07a26c72fc7f2a3e3f94d828cb4947d3,refactored beam search according to torch implementation,1,Extract Variable,,
bbabbc1613da0ac7e659e085c1ba7b1d65606f72,2020-03-05T21:12:56Z,https://github.com/huggingface/transformers/commit/bbabbc1613da0ac7e659e085c1ba7b1d65606f72,Merge pull request #3135 from patrickvonplaten/refactor_beam_search_generate  Refactoring and bug fixing beam search generate,1,Extract Variable,,
c47394b0c9ce5ef360bee9efd07779afe06f48a8,2020-03-05T12:12:50Z,https://github.com/huggingface/transformers/commit/c47394b0c9ce5ef360bee9efd07779afe06f48a8,refactoring and bug fixing beam search generate,1,Extract Variable,,
cbcb83f21d83d357f2a806bfa2bb191a3b787ed3,2020-02-04T21:38:52Z,https://github.com/huggingface/transformers/commit/cbcb83f21d83d357f2a806bfa2bb191a3b787ed3,minor cleanup of test_attention_outputs,1,Extract Variable,,
e3be9bbcad50e9993ec61fc90979cf9d115d1087,2019-10-16T21:42:43Z,https://github.com/tensorflow/tensorflow/commit/e3be9bbcad50e9993ec61fc90979cf9d115d1087,Refactor generate_examples_lib.py to split each op to separate files.PiperOrigin-RevId: 275117423Change-Id: I4ee19a6c388187fa231373eeaa4b14339e328680,1,Extract Module,,
3be3aea56e19e2bcb440ccd736ee86b4e3d6c197,2019-03-12T19:21:31Z,https://github.com/tensorflow/tensorflow/commit/3be3aea56e19e2bcb440ccd736ee86b4e3d6c197,Split the LSTM/GRU implementation for 2.0 into separate module and rename them.PiperOrigin-RevId: 238070364,1,Extract Module,,
4c08b96795a1b3367ebbb676c00201318122ecd0,2019-01-31T22:03:27Z,https://github.com/tensorflow/tensorflow/commit/4c08b96795a1b3367ebbb676c00201318122ecd0,Split-up gradients_impl into gradients_utilThis allows use of many of the underlying utilities without having toimport all the gradients.PiperOrigin-RevId: 231849392,1,Extract Module,,
3029a930c4f6e2ca3eadfb75bf25068645e055aa,2018-06-18T22:36:47Z,https://github.com/tensorflow/tensorflow/commit/3029a930c4f6e2ca3eadfb75bf25068645e055aa,Extract tf_record_test.py from reader_ops_test.pyPiperOrigin-RevId: 201071448,1,Extract Module,,
4944c2708090c761af5b970666301a35ae04b2d9,2018-06-15T14:13:49Z,https://github.com/tensorflow/tensorflow/commit/4944c2708090c761af5b970666301a35ae04b2d9,Broad refactoring (part 1): Introduce a module dedicated to symbols that are user-visible and which represent idioms not found in plain Python.This CL only adds the module - a future CL will replace existing implementations with these.PiperOrigin-RevId: 200712144,1,Extract Module,,
787381ca528ff737d614c96ef4c3603a76405061,2017-06-01T00:37:51Z,https://github.com/tensorflow/tensorflow/commit/787381ca528ff737d614c96ef4c3603a76405061,"Split up session_test.py -> session_clusterspec_prop_test.pysession_test.py has gotten very large. Additionally, recently it has becomeflaky. In order to both (1) improve overall code health, and (2) to facilitateroot-causing the test flakiness, this CL begins to split apart session_testinto focused subsets.I've suffixed the scoping of the session_test in order to preserve filesystemsort-order grouping.PiperOrigin-RevId: 157658981",1,Extract Module,,
7ed44f4c92c1553c0cefb607ce8a17b7d85f326f,2017-05-31T23:30:17Z,https://github.com/tensorflow/tensorflow/commit/7ed44f4c92c1553c0cefb607ce8a17b7d85f326f,"Split up session_test.py -> session_partial_run_test.pysession_test.py has gotten very large. Additionally, recently it has becomeflaky. In order to both (1) improve overall code health, and (2) to facilitateroot-causing the test flakiness, this CL begins to split apart session_testinto focused subsets.I've suffixed the scoping of the session_test in order to preserve filesystemsort-order grouping.PiperOrigin-RevId: 157651813",1,Extract Module,,
d310de4fac93c42caf7135038429362161045c6b,2017-05-31T22:05:07Z,https://github.com/tensorflow/tensorflow/commit/d310de4fac93c42caf7135038429362161045c6b,"Split up session_test.py -> session_list_devices_test.pysession_test.py has gotten very large. Additionally, recently it has becomeflaky. In order to both (1) improve overall code health, and (2) to facilitateroot-causing the test flakiness, this CL begins to split apart session_testinto focused subsets.I've suffixed the scoping of the session_test in order to preserve filesystemsort-order grouping.PiperOrigin-RevId: 157640788",1,Extract Module,,
b0f76d112be9190ac03f5b6083afb12aa6bdbc35,2017-02-11T23:46:54Z,https://github.com/tensorflow/tensorflow/commit/b0f76d112be9190ac03f5b6083afb12aa6bdbc35,Move various MVNs into distinct files.Change: 147257664,1,Extract Module,,
aa734b58be4043b5045e941f315e8d0fd62bd54e,2016-08-03T17:31:31Z,https://github.com/tensorflow/tensorflow/commit/aa734b58be4043b5045e941f315e8d0fd62bd54e,Splits sampling_ops_test.py to pull out the threading-related test.Change: 129229732,1,Extract Module,,
d107fecfb47d32777708025449fc6a2527ea1fcf,2016-05-12T16:17:16Z,https://github.com/tensorflow/tensorflow/commit/d107fecfb47d32777708025449fc6a2527ea1fcf,Split nn_test into more manageable pieces.Change: 122163424,1,Extract Module,,
41ae5285c076c39d151206a06d6f3204b177a369,2016-04-12T05:13:16Z,https://github.com/tensorflow/tensorflow/commit/41ae5285c076c39d151206a06d6f3204b177a369,Moved mnist reading from input_data in tutorial to learn/datasets (#1864)* Moved mnist reading from input_data in tutorial to learn/datasets,1,Extract Module,,
60765a4b210fc54ec32a7729f8532a60c5217544,2016-02-05T00:12:08Z,https://github.com/tensorflow/tensorflow/commit/60765a4b210fc54ec32a7729f8532a60c5217544,"Move the bulk of the TensorBoard server setup logic into its own file.This will make it easier to write TensorBoard integration tests that test theentire server by spinning up a server instance, pointing it at a log directory,and making HTTP requests.Change: 113899708",1,Extract Module,,
eba5976642dceb35f7e6038d49e63233e62b1cb3,2015-12-21T04:17:20Z,https://github.com/tensorflow/tensorflow/commit/eba5976642dceb35f7e6038d49e63233e62b1cb3,"Moved all estimators from __init__ into estimators/ folder and split into base, linear and dnn files",1,Extract Module,,
3bc3770c3a46fac19345d133dc4152626b5b9c30,2015-11-23T05:36:50Z,https://github.com/tensorflow/tensorflow/commit/3bc3770c3a46fac19345d133dc4152626b5b9c30,Split Ops file into separate files to be able to scale number of ops without hassle.,1,Extract Module,,
2060e0a9dd197f8116635dc7517dde5191c0b1a0,2020-01-28T22:57:46Z,https://github.com/pytorch/pytorch/commit/2060e0a9dd197f8116635dc7517dde5191c0b1a0,Split serialization tests to their own file (#32241)Summary:Stacked PRs * #32244 - Make zip serialization the default * **#32241 - Split serialization tests to their own file**This makes them all easier to run as a batch. This PR is just a code move / fixing up imports. There are still some serialization tests in `test_torch.py` as part of `TestDeviceType`.](https://our.intern.facebook.com/intern/diff/19415826/)Pull Request resolved: https://github.com/pytorch/pytorch/pull/32241Pulled By: driazatiDifferential Revision: D19415826fbshipit-source-id: a3f6cfe1626ff2f9b9631c409bf525bd32e4639b,1,Extract Module,,
240d62fbaa0110f565b4702809014982b82c86e4,2019-06-06T15:11:17Z,https://github.com/pytorch/pytorch/commit/240d62fbaa0110f565b4702809014982b82c86e4,Move redundant code that checks NumPy during build to a helper module and add an option to disable building with NumPySummary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/21417Reviewed By: ezyangDifferential Revision: D15694357Pulled By: fmassafbshipit-source-id: bc1bda23349ba4531f19619fa4adecb846225c20,1,Extract Module,,
27d789500bc953e453908d2189f7fe59d3e49fd9,2020-06-18T00:24:52Z,https://github.com/pytorch/pytorch/commit/27d789500bc953e453908d2189f7fe59d3e49fd9,"[test] split tracer related tests out of test_jit (#40142)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/40142test_jit is becoming huge again, which makes editor hard to load andwrite new tests, this split out the tracer related tests.Test Plan: Imported from OSSReviewed By: ailzhangDifferential Revision: D22085035Pulled By: wanchaolfbshipit-source-id: 696bee84985ecfbfeac8e2ee5c27f1bdda8de394",1,Extract Module,,
2e25fb5d55ae22a0eb8b8ba9c833eaf5edfebcca,2023-04-19T16:00:19Z,https://github.com/pytorch/pytorch/commit/2e25fb5d55ae22a0eb8b8ba9c833eaf5edfebcca,Refactor debug_utils into after_aot and after_dynamo modules (#99450)  There are no code changes but I did take the opportunity to reorder and group the functions once they were placed in their respective modules.  Signed-off-by: Edward Z. Yang <ezyang@meta.com>  Pull Request resolved: https://github.com/pytorch/pytorch/pull/99450 Approved by: https://github.com/anijain2305,1,Extract Module,,
2efa7e04c24f50ddcfe2ff83e7dc7a65a925675f,2020-05-14T00:34:34Z,https://github.com/pytorch/pytorch/commit/2efa7e04c24f50ddcfe2ff83e7dc7a65a925675f,[jit] move torchbind tests to separate file (#37473)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/37473Test Plan: Imported from OSSDifferential Revision: D21297541Pulled By: suofbshipit-source-id: 65c48094b1f26fbbf251021957257ce04279922b,1,Extract Module,,
304c02ee44b6f6c2d2ef17ed4fd9c741a0ccef18,2021-07-14T20:19:13Z,https://github.com/pytorch/pytorch/commit/304c02ee44b6f6c2d2ef17ed4fd9c741a0ccef18,refactor ps benchmark (#60784)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/60784  This pr refactors the ps benchmark for modular trainers.  Test Plan: Imported from OSS  Reviewed By: zou3519  Differential Revision: D29697291  Pulled By: gcramer23  fbshipit-source-id: 64579a1f5326d3cd9f32936dcf53bc243d54b71d,1,Extract Module,,
36acad58b662d207127b2e165f21a89549618f60,2023-04-19T23:49:33Z,https://github.com/pytorch/pytorch/commit/36acad58b662d207127b2e165f21a89549618f60,"[quant][pt2e][refactor] Move the annotation for observer sharing ops into separate util (#99384)  Summary: In order to keep quantizer simple, we want to move the annotation code for operators like flatten, hardtanh etc. to a separate utility function that is called after the quantizer annotation is done, this makes these ops (operator list) not configurable by user, and also makes prepare_pt2e operator aware instead of operator agnostic, this design is not final, we may change it in the future if we find there are use cases that need these to be configurable or if we feel it is important for prepare_pt2e to stay agnostic to operator/operator patterns  Test Plan: python test/test_quantization.py TestQuantizePT2E.test_qnnpack_quantizer_obs_sharing_ops  Reviewers:  Subscribers:  Tasks:  Tags:  Differential Revision: [D45071006](https://our.internmc.facebook.com/intern/diff/D45071006) Pull Request resolved: https://github.com/pytorch/pytorch/pull/99384 Approved by: https://github.com/kimishpatel",1,Extract Module,,
37ab35c8fc3e6fa746118306ebda94417d7d6b80,2019-06-06T22:46:44Z,https://github.com/pytorch/pytorch/commit/37ab35c8fc3e6fa746118306ebda94417d7d6b80,"Move jit testing utils to their own file (#21491)Summary:This moves `JitTestCase` to its own file so that we can have other jittest files (ex. `test_jit_py3.py`)There aren't any code changes, just a move and cleaning up the importsPull Request resolved: https://github.com/pytorch/pytorch/pull/21491Pulled By: driazatiDifferential Revision: D15703060fbshipit-source-id: 6082e8b482100bb7b0cd9ae69738f1273e626171",1,Extract Module,,
4159191f0e17d172f59fa5d4a3b92b2785ef6878,2020-11-09T19:55:37Z,https://github.com/pytorch/pytorch/commit/4159191f0e17d172f59fa5d4a3b92b2785ef6878,[pytorch] split out trace type generator and migrate to new codegen model (#47438)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/47438Test Plan: Imported from OSSReviewed By: bhosmerDifferential Revision: D24808211Pulled By: ljk53fbshipit-source-id: 44dfadf550a255c05aa201e54b48101aaf722885,1,Extract Module,,
432df40d8389df76e26f70b3ae32852edc60aa27,2021-04-08T15:04:51Z,https://github.com/pytorch/pytorch/commit/432df40d8389df76e26f70b3ae32852edc60aa27,[Hackathon] Move python builtins to test_python_builtins.py (#55479)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/55479Test Plan: Imported from OSSReviewed By: pbelevichDifferential Revision: D27642098Pulled By: nikithamalgifbfbshipit-source-id: 8d92a7d0f6db63f3cc3f439cb75a8d809af9106d,1,Extract Module,,
4472ad3b2fe129414699f8a427c66c855d8a5144,2018-11-08T09:02:19Z,https://github.com/pytorch/pytorch/commit/4472ad3b2fe129414699f8a427c66c855d8a5144,Move functional _Reduction to its own module (#13401)Summary:To support `_Reduction` in the jit this PR moves it out to a new file so that it goes through the paths for python modules in the script compiler and converts `F.ctc_loss` to weak scriptDepends on #13484 for saving rng statePull Request resolved: https://github.com/pytorch/pytorch/pull/13401Differential Revision: D12868501Pulled By: driazatifbshipit-source-id: 23cec0fb135744578c73e31ac825e238db495d27,1,Extract Module,,
4dc8f3be8ca245f712e2464c0d56f4932567282b,2020-08-23T06:16:40Z,https://github.com/pytorch/pytorch/commit/4dc8f3be8ca245f712e2464c0d56f4932567282b,"Creates test_tensor_creation_ops.py test suite (#43104)Summary:As part of our continued refactoring of test_torch.py, this takes tests for tensor creation ops like torch.eye, torch.randint, and torch.ones_like and puts them in test_tensor_creation_ops.py. There hare three test classes in the new test suite: TestTensorCreation, TestRandomTensorCreation, TestLikeTensorCreation. TestViewOps and tests for construction of tensors from NumPy arrays have been left in test_torch.py. These might be refactored separately into test_view_ops.py and test_numpy_interop.py in the future.Most of the tests ported from test_torch.py were left as is or received a signature change to make them nominally ""device generic."" Future work will need to review test coverage and update the tests.Pull Request resolved: https://github.com/pytorch/pytorch/pull/43104Reviewed By: ngimelDifferential Revision: D23280358Pulled By: mruberryfbshipit-source-id: 469325dd1a734509dd478cc7fe0413e276ffb192",1,Extract Module,,
539ae451d22df71810e0a7f54c9c3a688df4e3fc,2017-10-03T21:15:07Z,https://github.com/pytorch/pytorch/commit/539ae451d22df71810e0a7f54c9c3a688df4e3fc,"Move random initialization functions from torch to torch.random.The motivation is that I wanted to add some more general purposeutility random functions, but not gunk up torch/__init__.py.Signed-off-by: Edward Z. Yang <ezyang@fb.com>",1,Extract Module,,
5447f5c0d72e0220e6b453c59d4be5b2d6d9904d,2017-06-05T22:48:17Z,https://github.com/pytorch/pytorch/commit/5447f5c0d72e0220e6b453c59d4be5b2d6d9904d,Move position weighted to separate layerReviewed By: kennyhorrorDifferential Revision: D5063086fbshipit-source-id: 212c08946728437bcc8b6049438ae82235137ec6,1,Extract Module,,
589a2024c8f6c7a986cab61a42452f2e8cc39f5e,2020-09-07T22:48:43Z,https://github.com/pytorch/pytorch/commit/589a2024c8f6c7a986cab61a42452f2e8cc39f5e,Benchmarks: re-enable profiling-te configuration (try 2). (#44270)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/44270The previous PR (#44212) was reverted since I didn't update the`upload_scribe.py` script and it was looking for 'executor_and_fuser'field in the json which now is replaced with two separate fields:'executor' and 'fuser'.Differential Revision: D23561500Test Plan: Imported from OSSReviewed By: ngimelPulled By: ZolotukhinMfbshipit-source-id: 7fe86d34afa488a0e43d5ea2aaa7bc382337f470,1,Extract Module,,
5e5ca0682bb9a4798820a7e177c7ffe091c7615c,2021-06-15T10:28:38Z,https://github.com/pytorch/pytorch/commit/5e5ca0682bb9a4798820a7e177c7ffe091c7615c,"Move CUDA-related stuff of TP agent to separate file (#59377)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/59377  This PR demonstrates that now the CUDA parts of the TensorPipe agent just ""plug on top"" of the CPU-only parts. Thus ideally the CPU-only parts could go in libtorch while the CUDA-only parts could go in libtorch_cuda. Unfortunately we can't do that just yet, because the TensorPipe agent depends on c10d (for its Store and its ProcessGroup), which lives in libtorch_python. ghstack-source-id: 131326168  Test Plan: CI  Reviewed By: cbalioglu  Differential Revision: D28796429  fbshipit-source-id: 41b2eb8400c0da282f3750a4eea21ad83ee4a175",1,Extract Module,,
5ec643494574a6422055db6c99cc3cd1ae841b70,2021-04-16T17:28:31Z,https://github.com/pytorch/pytorch/commit/5ec643494574a6422055db6c99cc3cd1ae841b70,"ns for fx: move op dtype category mapping to separate file (#55858)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/55858Moves the mappings of input and output dtypes of various opsinto its own file, and makes the variable names more clear. No logicchange.Test Plan:```python test/test_quantization.py TestFXNumericSuiteCoreAPIs```Imported from OSSReviewed By: raghuramank100Differential Revision: D27740662fbshipit-source-id: d384e7e542d9cc868d9cee9c53c2ac2f74a15a48",1,Extract Module,,
6007ad35299de9d4fc705d865d8ff8459452fbae,2021-07-26T15:25:10Z,https://github.com/pytorch/pytorch/commit/6007ad35299de9d4fc705d865d8ff8459452fbae,[Static Runtime] Refactor fb op tests to use testStaticRuntime (#62064)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/62064  `testStaticRuntime` was previously only available in `test_static_runtime.cc`. It has been moved to a common library `test_utils` to facilitate code re-use. This also lets us test dynamic shapes in `test_fb_operators`  Reviewed By: hlu1  Differential Revision: D29858928  fbshipit-source-id: 68a94760166ddb745972b0f1fc24bed594937d1c,1,Extract Module,,
6161730174eee8f8be8988ac4e76e34648b81bfb,2020-07-20T18:59:08Z,https://github.com/pytorch/pytorch/commit/6161730174eee8f8be8988ac4e76e34648b81bfb,[JIT] move remove mutation to its own test file (#41502)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/41502Test Plan: Imported from OSSReviewed By: KrovatkinDifferential Revision: D22629270Pulled By: eellisonfbshipit-source-id: fcec6ae4ff8f108164539d67427ef3d72fa07494,1,Extract Module,,
62cee0001ee03135436ca4b17451aff0b860bf4b,2020-07-09T17:08:10Z,https://github.com/pytorch/pytorch/commit/62cee0001ee03135436ca4b17451aff0b860bf4b,Move async + serialization implementation out of 'jit/__init__.py' (#41018)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/41018See https://github.com/pytorch/pytorch/pull/40807 for context.Test Plan: Imported from OSSReviewed By: ailzhangDifferential Revision: D22393869Pulled By: suofbshipit-source-id: a71cc571a423ccb81cd148444dc2a18d2ee43464,1,Extract Module,,
693ab77c007ce0cdeeef4b31eb3de364236878a6,2020-06-18T00:24:52Z,https://github.com/pytorch/pytorch/commit/693ab77c007ce0cdeeef4b31eb3de364236878a6,"[test] split onnx export test out of test_jit (#40143)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/40143as titled, to reduce size of test_jitTest Plan: Imported from OSSReviewed By: ailzhangDifferential Revision: D22085036Pulled By: wanchaolfbshipit-source-id: 424f189fd3849c111d06ebe2e341da50d98fe0ec",1,Extract Module,,
725d6cd8cec9f2d2c60b8b09bf6384b38612e85a,2019-08-02T16:15:03Z,https://github.com/pytorch/pytorch/commit/725d6cd8cec9f2d2c60b8b09bf6384b38612e85a,"Extract common classes and functions from test_c10d to common_distributed (#23660)Summary:MultiProcessTestCase will be useful for both c10d and rpc tests. So, this diff extracts that class and some common decorators to a separate file.Pull Request resolved: https://github.com/pytorch/pytorch/pull/23660Reviewed By: pieternDifferential Revision: D16602865Pulled By: mrshenlifbshipit-source-id: 85ad47dfb8ba187b7debeb3edeea5df08ef690c7",1,Extract Module,,
77ccb5c14d71ac887ad408c8ef4b52a5d4e41c79,2020-03-23T18:53:18Z,https://github.com/pytorch/pytorch/commit/77ccb5c14d71ac887ad408c8ef4b52a5d4e41c79,Move functional graph creation to testing utils (#34916)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/34916Test Plan: Imported from OSSDifferential Revision: D20539337Pulled By: eellisonfbshipit-source-id: 9b777e369facebbe68fe198ca3eec055cf9c5257,1,Extract Module,,
824641b083860df4d7ffef06a798ea2702bc4bde,2022-12-07T16:16:25Z,https://github.com/pytorch/pytorch/commit/824641b083860df4d7ffef06a798ea2702bc4bde,"[Quant][fx][bc-breaking] Make convert.py smaller (#90189)  Summary: This commit moves helper functions that are not core to the convert logic out of convert.py, which was more than 1000 lines. This helps with readability since a new developer won't have to scroll through hundreds of lines of util functions to understand the core logic. There should be no change in functionality in this commit.  BC-breaking notes: The following helper functions that were previously exposed under the `torch.ao.quantization.fx.convert` namespace are now made private. Many of these are moved to the new convert_utils.py ``` convert_custom_module convert_standalone_module convert_weighted_module get_module_path_and_prefix, has_none_qconfig, insert_dequantize_node, is_conversion_supported, maybe_recursive_remove_dequantize, replace_observer_or_dequant_stub_with_dequantize_node, restore_state, run_weight_observers, ```  Test Plan: python test/test_quantization.py TestQuantizeFx python test/test_quantization.py TestQuantizeFxOps  Reviewers: jerryzh168, vkuzo  Subscribers: jerryzh168, vkuzo Pull Request resolved: https://github.com/pytorch/pytorch/pull/90189 Approved by: https://github.com/jerryzh168",1,Extract Module,,
82d587f434a6112cce85b0a82de654fefc89e4bf,2021-05-27T06:01:08Z,https://github.com/pytorch/pytorch/commit/82d587f434a6112cce85b0a82de654fefc89e4bf,[quant][refactor tests] split test_workflow_module into test_workflow_ops and test_workflow_module (#58963)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/58963  some tests are used to check the op level numerics of the fake quantize operations  Test Plan: python test/test_quantization.py  Imported from OSS  Reviewed By: HDCharles  Differential Revision: D28696599  fbshipit-source-id: 98f9b0c993dd43050176125461ddd5288142989b,1,Extract Module,,
83437853adb3d52b444d6716bcb8237032c2cb49,2017-03-08T02:44:45Z,https://github.com/pytorch/pytorch/commit/83437853adb3d52b444d6716bcb8237032c2cb49,refactor and modulize optimizersSummary:The current optimizer code in c2/python has the following issues:(1) the optimizers in sgd.py cannot config per param-blob optimizer;(2) sgd.py is a bad file name. optimizer.py is a better name;(3) layer_model_helper.py has another set of optimizer code (which supports per param-blob optimizer)This diff did the following(1) create optimizer objects so that we can config per param-blob optimizer and that are also compatible to the existing optimizer code(2) the new optimizer code are much more modulized(3) move the optimizer code to file with better name (optimizer.py)(4) replace the optimizer imports in the existing codewill do in next diffs(1) optimizers with structured parameters for dper2(2) get rid of the optimizer code in layer_model_helper.pyReviewed By: salexspbDifferential Revision: D4609013fbshipit-source-id: 2e2d6dfa8685d10498f89069157453d9feca3f27,1,Extract Module,,
83ba71aa0e8ad1a9b47fd3a340a67597aa8540df,2021-06-15T10:27:40Z,https://github.com/pytorch/pytorch/commit/83ba71aa0e8ad1a9b47fd3a340a67597aa8540df,"Make CUDA serde support for TP agent pluggable (#59376)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/59376  This is an experiment. The end goal is to separate the CUDA-specific aspects of the TensorPipe agent so that they can be plugged ""on top"" of the CPU-only parts. This will then allow to move the TP agent to libtorch (because libtorch is split into a CPU and a CUDA part; now it's in libtorch_python), although unfortunately other conditions need to also be met for this to happen.  The only instance where we had CPU and CUDA logic within the same code, guarded by `#ifdef USE_CUDA`, is the serialization/deserialization code. I'm thus introducing a sort-of registry in order to ""decentralize it"". It's not a c10::Registry, because that's overkill (it uses an unordered_map, with strings as keys): here we can just use an array with integers as ""keys"". ghstack-source-id: 131326167  Test Plan: CI  Reviewed By: mrshenli  Differential Revision: D28796428  fbshipit-source-id: b52df832e0c0abf489a9e418353103496382ea41",1,Extract Module,,
8cd4dac78f32cb82e9a983e1d13006250ba78223,2021-03-18T22:39:18Z,https://github.com/pytorch/pytorch/commit/8cd4dac78f32cb82e9a983e1d13006250ba78223,"Move mypy wrapper to tools (#54268)Summary:This PR- moves `torch/testing/_internal/mypy_wrapper.py` (and its accompanying tests from `test/test_testing.py`) to `tools`,- removes the now-unused `test_run_mypy` from `test/test_type_hints.py`, and- replaces the hardcoded list of `mypy` configs (previously duplicated across `mypy_wrapper.py` and `.github/workflows/lint.yml`) with a simpler globPull Request resolved: https://github.com/pytorch/pytorch/pull/54268Test Plan:Should also be run in the ""Test tools"" GHA workflow in CI:```python tools/test/test_mypy_wrapper.py```Reviewed By: janeyx99Differential Revision: D27168095Pulled By: samestepfbshipit-source-id: a8dc18407b5e4c103ace23a636b0a8534951905a",1,Extract Module,,
91bf0a9f9d3ba3c8d7780ac47c2aa0eb96e95249,2019-06-22T05:45:21Z,https://github.com/pytorch/pytorch/commit/91bf0a9f9d3ba3c8d7780ac47c2aa0eb96e95249,Move quantized tensor tests in test_torch.py to test_quantized_tensor.py (#22089)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/22089attReviewed By: jianyuhDifferential Revision: D15950101fbshipit-source-id: 70acdeeef3a05201d72f986d5a0005832efd75ff,1,Extract Module,,
935fcc9580948b6b80b5d7931290a8afa985a492,2020-08-05T22:01:13Z,https://github.com/pytorch/pytorch/commit/935fcc9580948b6b80b5d7931290a8afa985a492,"[RPC tests] Merge process group tests into single entry point (#40818)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/40818Summary of the entire stack:--This diff is part of an attempt to refactor the RPC tests. They currently suffer from several problems:- Several ways to specify the agent to use: there exists one ""generic"" fixture that uses the global variable TEST_CONFIG to look up the agent name, and is used for process group and Thrift, and then there are separate fixtures for the flaky agent and the TensorPipe one.- These two ways lead to having two separate decorators (`requires_process_group_agent` and `@_skip_if_tensorpipe_agent`) which must both be specified, making it unclear what the effect of each of them is and what happens if only one is given.- Thrift must override the TEST_CONFIG global variable before any other import (in order for the `requires_process_group_agent` decorator to work correctly) and for that it must use a ""trap"" file, which makes it even harder to track which agent is being used, and which is specific to Buck, and thus cannot be used in OSS by other agents.- Even if the TensorPipe fixture doesn't use TEST_CONFIG, it still needs to set it to the right value for other parts of the code to work. (This is done in `dist_init`).- There are a few functions in dist_utils.py that return some properties of the agent (e.g., a regexp to match against the error it returns in case of shutdown). These functions are effectively chained if/elses on the various agents, which has the effect of ""leaking"" some part of the Thrift agent into OSS.- Each test suite (RPC, dist autograd/dist optimizer, their JIT versions, remote module, ...) must be run on each agent (or almost; the faulty one is an exception) in both fork and spawn mode. Each of these combinations is a separate file, which leads to a proliferation of scripts.- There is no ""master list"" of what combinations make sense and should be run. Therefore it has happened that when adding new tests or new agents we forgot to enroll them into the right tests. (TensorPipe is still missing a few tests, it turns out).- All of these tiny ""entry point"" files contain almost the same duplicated boilerplate. This makes it very easy to get the wrong content into one of them due to a bad copy-paste.This refactoring aims to address these problems by:- Avoiding global state, defaults/override, traps, if/elses, ... and have a single way to specify the agent, based on an abstract base class and several concrete subclasses which can be ""mixed in"" to any test suite.- Instead of enabling/disabling tests using decorators, the tests that are specific to a certain agent are now in a separate class (which is a subclass of the ""generic"" test suite) so that they are only picked up by the agent they apply to.- Instead of having one separate entry point script for each combination, it uses one entry point for each agent, and in that script it provides a list of all the test suites it wants to run on that agent. And it does that by trying to deduplicate the boilerplate as much as possible. (In fact, the various agent-suite combinations could be grouped in any way, not necessarily by agent as I did here).It provides further advantages:- It puts all the agents on equal standing, by not having any of them be the default, making it thus easier to migrate from process group to TensorPipe.- It will make it easier to add more versions of the TensorPipe tests (e.g., one that disables the same-machine backends in order to test the TCP-based ones) without a further duplication of entry points, of boilerplate, ...Summary of this commit--This diff does the changes described above for the process group agent. It defines a fixture for it (instead of using the generic fixture in its default behavior) and then merges all the entry points into a single script. Note that after this change there won't be anymore a ""vanilla"" RPC test: all test scripts now specify what agent they are using. This puts all agents on equal standing.ghstack-source-id: 109229474Test Plan: Sandcastle and CircleCIReviewed By: pritamdamania87Differential Revision: D22283182fbshipit-source-id: 7e3626bbbf37d88b892077a03725f0598576b370",1,Extract Module,,
99271ad411027e9cd0a29d90d221ddf8edccb21a,2019-10-19T00:44:55Z,https://github.com/pytorch/pytorch/commit/99271ad411027e9cd0a29d90d221ddf8edccb21a,Split out data_parallel tests from test_nn.py into a separate (#28297)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/28297Splitting data parallel tests out of test_nn.py since its easier tomanage and track these tests separately and failures can be routed toappropriate POCs.Test Plan: waitforbuildbotDifferential Revision: D18011663fbshipit-source-id: 17ebf7c04e7dc7ff4c8d38458daab5b911bed75d,1,Extract Module,,
a1ad28da102f54e297b2db3360c1c5ed54a1f5ae,2021-07-06T23:02:11Z,https://github.com/pytorch/pytorch/commit/a1ad28da102f54e297b2db3360c1c5ed54a1f5ae,"Refactor clang_tidy.py (#61119)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/61119  This change spilts the clang-tidy CI job into smaller steps and uses a refactored version of the clang_tidy.py script.  The new folder structure is as follows: ``` tools/linter/clang_tidy |_ __main__py |_ requirements.txt |_ run.py |_ setup.sh ```  `__main__.py`  This script will run `tools/linter/clang_tidy/setup.sh` if a `build` directory doesn't exist, mimicing what used to be done as a separate step in the CI job.  After that, it will invoke `clang-tidy` with default arguments being declared in the script itself (as opposed to declaring them in lint.yml).  The reasoning behind this approach is two-fold:  - Make it easier to run `clang-tidy` locally using this script - De-duplicate the option passing  `requirements.txt`  Contains a list of additional python dependencies needed by the `clang-tidy` script.  `setup.sh`  If a build directory doesn't exist, this command will run the necessary codegen and build commands for running `clang-tidy`  Example usage: ``` python3 tools/linter/clang_tidy --parallel ``` Notice that we don't have to put the `.py` at the end of `clang_tidy`.  Test Plan: Run the following command: ``` python3 tools/linter/clang_tidy --paths torch/csrc/fx --parallel ```  Reviewed By: walterddr, janeyx99  Differential Revision: D29568582  Pulled By: 1ntEgr8  fbshipit-source-id: cd6d11c5cb8ba9f1344a87c35647a1cd8dd45b04",1,Extract Module,,
aeb3e933515672a61cb21498fdbdef80a46ae0ee,2021-03-12T05:18:16Z,https://github.com/pytorch/pytorch/commit/aeb3e933515672a61cb21498fdbdef80a46ae0ee,Move view handling logic to gen_inplace_or_view_type.py (#53341)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/53341Test Plan: Imported from OSSReviewed By: nikithamalgifbDifferential Revision: D26973912Pulled By: ailzhangfbshipit-source-id: ea31bdef0beac6996d509f5d45ebefa3ea8e2b89,1,Extract Module,,
b2069e7d01814d776c417042e28133c6b0e5082f,2021-08-16T22:45:26Z,https://github.com/pytorch/pytorch/commit/b2069e7d01814d776c417042e28133c6b0e5082f,"Refactor NnapiCompilation registration into it's own file (#63183)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/63183  Move registration of NnapiCompilation into it's own file, so that `nnapi_bind.cpp` (which contains the implementation of NnapiCompilation) can be moved to `aten_cpu`, while maintaining the selectiveness for registration.  `nnapi_bind.cpp` is moved to `aten_cpu` in https://github.com/pytorch/pytorch/pull/62919. See the PR for more details on why it's needed.  ghstack-source-id: 135900318  Test Plan: Nnapi unit tests: `python test/test_nnapi.py`  Reviewed By: iseeyuan  Differential Revision: D30288708  fbshipit-source-id: 6ed5967fa6bd018075469d18e68f844d413cf265",1,Extract Module,,
c00d66f73c5e71594cb3eff82bdcaa86400e2964,2021-03-23T07:39:45Z,https://github.com/pytorch/pytorch/commit/c00d66f73c5e71594cb3eff82bdcaa86400e2964,"Move compute_native_function_declaration to its own dest module (#54419)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/54419I'm planning to break it into some helper functions, so let's put it in its own module first.Signed-off-by: Edward Z. Yang <ezyang@fb.com>Test Plan: Imported from OSSReviewed By: ailzhangDifferential Revision: D27235378Pulled By: ezyangfbshipit-source-id: c03c5440d2d753859e2c5ec2b2c8b1b82870f03a",1,Extract Module,,
c8209a73369edcda996299964ad8ef516ff9ebdf,2021-04-15T23:01:22Z,https://github.com/pytorch/pytorch/commit/c8209a73369edcda996299964ad8ef516ff9ebdf,"ns for fx: move pattern utils to separate file (#55805)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/55805No logic change, just moving util functions to separate file.Test Plan:```python test/test_quantization.py TestFXGraphMatcherpython test/test_quantization.py TestFXNumericSuiteCoreAPIs```Imported from OSSReviewed By: jerryzh168Differential Revision: D27719982fbshipit-source-id: c80d5397c1efeb9fc83eacaa532ecbde557cca3f",1,Extract Module,,
c998f3573c62c3cb92541ce522031fb5f274afa3,2021-04-09T01:38:56Z,https://github.com/pytorch/pytorch/commit/c998f3573c62c3cb92541ce522031fb5f274afa3,"[Hackathon]Move tests related to containers in typing to test_typing.py (#55504)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/55504Test Plan: Imported from OSSReviewed By: navahgar, pbelevichDifferential Revision: D27666760Pulled By: nikithamalgifbfbshipit-source-id: c1a7904f33855efa4f60f8f54c029a95a5fd529c",1,Extract Module,,
cc0701e5b36874387fbcca1ebb948af0874f3ca0,2023-03-21T03:11:39Z,https://github.com/pytorch/pytorch/commit/cc0701e5b36874387fbcca1ebb948af0874f3ca0,"[inductor] Move fx-fusion tests to a separate file (#97028)  They're sort of independent of the rest of inductor, and this makes them a bit easier to find and marginally faster to run.  Differential Revision: [D44168337](https://our.internmc.facebook.com/intern/diff/D44168337/)  **NOTE FOR REVIEWERS**: This PR has internal Meta-specific changes or comments, please review them on [Phabricator](https://our.internmc.facebook.com/intern/diff/D44168337/)!  Pull Request resolved: https://github.com/pytorch/pytorch/pull/97028 Approved by: https://github.com/jansel",1,Extract Module,,
d15b9d980c0cd504ce6e82db4e88f66cee7e0289,2020-09-01T23:36:15Z,https://github.com/pytorch/pytorch/commit/d15b9d980c0cd504ce6e82db4e88f66cee7e0289,[quant][graphmode][fx][refactor] Move patterns to separate files (#43891)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/43891Test Plan: Imported from OSSReviewed By: vkuzoDifferential Revision: D23429759fbshipit-source-id: f19add96beb7c8bac323ad78f74588ca1393040c,1,Extract Module,,
dcb8d0f08832d2fb8dff32b77618405e4f7cb19e,2017-10-06T16:12:50Z,https://github.com/pytorch/pytorch/commit/dcb8d0f08832d2fb8dff32b77618405e4f7cb19e,Refactor out python binding generation from gen_variable_type.py - Also includes some prep work for binding NN functions,1,Extract Module,,
f36497e6873dfd5fac5732ac04156887dfec8807,2019-10-22T00:12:15Z,https://github.com/pytorch/pytorch/commit/f36497e6873dfd5fac5732ac04156887dfec8807,split test_type_sharingSummary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/28037Test Plan: Imported from OSSDifferential Revision: D17954442Pulled By: suofbshipit-source-id: 6edee4d7dee0e52b58e71d3b520c0503fb7bd0ed,1,Extract Module,,
cc457ca30f64447bd991c06e46521c70526c50c6,2019-11-06T21:17:23Z,https://github.com/pytorch/pytorch/commit/cc457ca30f64447bd991c06e46521c70526c50c6,"split remaining ""easy"" tests (#29249)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/29249This splits out all the tests that are ""easy"", leaving `TestJit`,`TestScript`, the autogenerated tests, and a small docs test.Splitting those into reasonable chunks is more effort which is lessmechanical.Differential Revision: D18339007Test Plan: Imported from OSSPulled By: suofbshipit-source-id: 69164b9f9a2c379fe8923a846c98dd3c37ccb70e",1,Extract Module,,
2668ea8087d1c51e64229b369c63aff55135e67a,2020-12-08T23:33:13Z,https://github.com/pytorch/pytorch/commit/2668ea8087d1c51e64229b369c63aff55135e67a,fx quant: move qconfig utils to utils file (#48907)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/48907Improving readabilityTest Plan:CIImported from OSSReviewed By: jerryzh168Differential Revision: D25363078fbshipit-source-id: 6b0161db14ccf8c3b47edf4fc760ca9a399254b2,1,Extract Module,,
27a67d86993a546868f82026a2d39ca06ccbe735,2023-06-14T14:00:12Z,https://github.com/pytorch/pytorch/commit/27a67d86993a546868f82026a2d39ca06ccbe735,"Refactor and improve make_fx testing (#103196)  This is in preparation for the custom_op_compile_check utility, which will call the newly refactored function.  This PR: - splits off code into helper functions - adds clearer error messages - stops updating the inputs destructively (leading to slightly slower tests) Pull Request resolved: https://github.com/pytorch/pytorch/pull/103196 Approved by: https://github.com/bdhirsh, https://github.com/soulitzer",1,Extract Module,,
453ff9602949a2a08a82ef15163de509c5f701ac,2022-12-10T04:34:00Z,https://github.com/pytorch/pytorch/commit/453ff9602949a2a08a82ef15163de509c5f701ac,"[torchgen] Refactor types (#90589)  A retry of #89487. Accidentally closed.  ## Split `torchgen.api.types` into `types_base`, `types` and `signatures`.  In `types_base`: * Created base class `CType`. `BaseCType` and `ConstRefCType` etc are inheriting `CType`. * Only keep abstract type model definitions, such as `BaseCppType`.  In `types`: * Define `BaseCppType` with `at` and `c10` namespaces. * All the signatures using these types.  In `signatures`: * Define all the signatures.  In `__init__`: * `from ... import *`, suppress flake8 error.  Differential Revision: [D41455634](https://our.internmc.facebook.com/intern/diff/D41455634/)  **NOTE FOR REVIEWERS**: This PR has internal Meta-specific changes or comments, please review them on [Phabricator](https://our.internmc.facebook.com/intern/diff/D41455634/)! Pull Request resolved: https://github.com/pytorch/pytorch/pull/90589 Approved by: https://github.com/iseeyuan",1,Extract Module,,
4cce60751bf6555eeb757cc1314edde824c86d65,2023-03-30T17:55:34Z,https://github.com/pytorch/pytorch/commit/4cce60751bf6555eeb757cc1314edde824c86d65,"Move TestIndexingSimplification to its own file (#97941)  test_torchinductor has gotten too big (almost 10k lines), this stack is trying to split it into smaller pieces.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/97941 Approved by: https://github.com/ngimel",1,Extract Module,,
4f4e0db5bd99f784578ce25b126962ee2c0e90c1,2023-04-17T16:12:47Z,https://github.com/pytorch/pytorch/commit/4f4e0db5bd99f784578ce25b126962ee2c0e90c1,"[PT2E][Quant][BE] Split short term and long term tests in different files (#99065)  Just for better organization  Differential Revision: [D44918492](https://our.internmc.facebook.com/intern/diff/D44918492/)  **NOTE FOR REVIEWERS**: This PR has internal Meta-specific changes or comments, please review them on [Phabricator](https://our.internmc.facebook.com/intern/diff/D44918492/)! Pull Request resolved: https://github.com/pytorch/pytorch/pull/99065 Approved by: https://github.com/jerryzh168",1,Extract Module,,
50bc25baa0833019a2a3e8888c0df5dcbe39afa9,2023-02-11T02:54:49Z,https://github.com/pytorch/pytorch/commit/50bc25baa0833019a2a3e8888c0df5dcbe39afa9,Move ValueRanges into its own module (#94528)  I am going to use it in ShapeEnv shortly.  Signed-off-by: Edward Z. Yang <ezyang@meta.com>  Pull Request resolved: https://github.com/pytorch/pytorch/pull/94528 Approved by: https://github.com/eellison,1,Extract Module,Move Class,
567362cedbc12caf2b2f52631319020d51ac37ea,2023-02-20T00:01:48Z,https://github.com/pytorch/pytorch/commit/567362cedbc12caf2b2f52631319020d51ac37ea,[inductor] move dynamic shapes tests into a new file (#94971)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/94971 Approved by: https://github.com/ezyang,1,Extract Module,,
5ca4e95f6cbe86cc5e8378a9bf681265d1d8a9ba,2022-12-08T15:32:36Z,https://github.com/pytorch/pytorch/commit/5ca4e95f6cbe86cc5e8378a9bf681265d1d8a9ba,[Composable API] Move test models to common file (#90385)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/90385 Approved by: https://github.com/mrshenli,1,Extract Module,Move Class,
5f4fec74590bb4e6deb9946cbce793cfc261697e,2023-02-03T21:48:31Z,https://github.com/pytorch/pytorch/commit/5f4fec74590bb4e6deb9946cbce793cfc261697e,"Fix/refactor dynamo tvm backend (#93870)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/93870 Approved by: https://github.com/shingjan, https://github.com/desertfire",1,Extract Module,Move Method,
6e1e27fc4e36edc7d8dad602de7e8250ad16073b,2023-04-16T04:05:56Z,https://github.com/pytorch/pytorch/commit/6e1e27fc4e36edc7d8dad602de7e8250ad16073b,[inductor] Refactor pre-grad passes into inductor.fx_passes (#99130)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/99130 Approved by: https://github.com/ngimel,1,Extract Module,Move Method,
7c60d7a24db656f15ec2a25b26346225f6d54ed7,2023-04-01T00:47:42Z,https://github.com/pytorch/pytorch/commit/7c60d7a24db656f15ec2a25b26346225f6d54ed7,"Move CudaReproTests to its own file (#97942)  test_torchinductor has gotten too big (almost 10k lines), this stack is trying to split it into smaller pieces.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/97942 Approved by: https://github.com/ngimel",1,Extract Module,Move Method,
9be9592f28023eff3caf87e13c1a89901c1819cf,2023-03-31T23:15:39Z,https://github.com/pytorch/pytorch/commit/9be9592f28023eff3caf87e13c1a89901c1819cf,"[Dynamo] Code refactor: move context managers out of misc.py (#97958)  misc.py and test_misc.py is too big, moving context managers to context.py and test_context.py.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/97958 Approved by: https://github.com/ezyang, https://github.com/anijain2305, https://github.com/mlazos, https://github.com/voznesenskym",1,Extract Module,,
a5a10fe353bef5f9c79c5482ececc6ab1a21447e,2021-07-12T18:23:22Z,https://github.com/pytorch/pytorch/commit/a5a10fe353bef5f9c79c5482ececc6ab1a21447e,Move all downloading logic out of common_utils.py (#61479)  Summary: and into tools/ folder  Currently run_tests.py invokes tools/test_selections.py 1. download and analyze what test_file to run 2. download and parse S3 stats and pass the info to local files. 3. common_utils.py uses download S3 stats to determine what test cases to run.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/61479  Reviewed By: janeyx99  Differential Revision: D29661986  Pulled By: walterddr  fbshipit-source-id: bebd8c474bcc2444e135bfd2fa4bdd1eefafe595,1,Extract Module,Move Method,
a5ddecd00c4d0971e2ad8a40e7345d41cf6e1ca0,2019-03-30T01:10:36Z,https://github.com/pytorch/pytorch/commit/a5ddecd00c4d0971e2ad8a40e7345d41cf6e1ca0,Move fuser to test_jit_fuser (#18590)Summary:Start of breaking up test_jit.pyNew files will have the format test_jit_* so they are easily grepable but remain in the same directory so we don't have to go through multiple sources for imports.I am adding a test that's expected to fail to be sure it's running.Pull Request resolved: https://github.com/pytorch/pytorch/pull/18590Reviewed By: wanchaolDifferential Revision: D14677094Pulled By: eellisonfbshipit-source-id: 9782c6aa9525bb6f332fc75cfff004c83a417522,1,Extract Module,Move Class,
b0722451784c973d4a85f5d9dbc3c72fff2926e4,2023-02-01T05:02:11Z,https://github.com/pytorch/pytorch/commit/b0722451784c973d4a85f5d9dbc3c72fff2926e4,"[dtensor][4/N] refactor dispatching logic and add propagator (#90733)  This PR refactors the dispatching logic to make it more clean, and isolate the sharding propagation logic out to a separate class.  This is so that we can implement more complicated propagation features later.  Differential Revision: [D42876251](https://our.internmc.facebook.com/intern/diff/D42876251) Pull Request resolved: https://github.com/pytorch/pytorch/pull/90733 Approved by: https://github.com/XilunWu, https://github.com/fduwjj",1,Extract Module,Move Method,
35ed21ebb86f9b9c3e5a7e6a343dacdf1544efe6,2021-02-16T09:59:06Z,https://github.com/tensorflow/tensorflow/commit/35ed21ebb86f9b9c3e5a7e6a343dacdf1544efe6,refactor parameterized test cases,1,Extract Method,,
bbbdd5327df7beb6b61f737a753334a599285acb,2021-02-09T11:30:06Z,https://github.com/tensorflow/tensorflow/commit/bbbdd5327df7beb6b61f737a753334a599285acb,refactor eager and graph benchmark methods,1,Extract Method,,
053587a591793a6c218da21f55ab98553b258b4e,2021-01-13T06:49:10Z,https://github.com/tensorflow/tensorflow/commit/053587a591793a6c218da21f55ab98553b258b4e,"Replaces uses of op StatelessRandomGetKeyCounterAlg with StatelessRandomGetKeyCounter and StatelessRandomGetAlg, so that `seed` is no longer required by XLA to be a compile-time constant.Adds SetIsStateful to StatelessRandomGetKeyCounter and StatelessRandomGetAlg, so that they won't be constant-folded away.Re-introduces StatelessRandomNormalV2 in tf.random.stateless_normal, since the OOM problem has been fixed.PiperOrigin-RevId: 351518473Change-Id: I40f075ba615a76286a49bec2eed4d8c0e2cbeed9",1,Extract Method,,
46e9ee6a5db47dc4de526d04d2904e8a1e4ba80f,2021-01-07T22:56:39Z,https://github.com/tensorflow/tensorflow/commit/46e9ee6a5db47dc4de526d04d2904e8a1e4ba80f,split the combinations into different tests,1,Extract Method,,
c1efa5341c713b21acefb2536e59ccae232ab066,2020-12-30T05:18:26Z,https://github.com/tensorflow/tensorflow/commit/c1efa5341c713b21acefb2536e59ccae232ab066,Eager execution coverage for extract_volume_patches_grad_test.py. Removed  run_deprecated_v1 decorators. (Part 2)PiperOrigin-RevId: 349508066Change-Id: I9b7bb2595679ed1a42bb3bf34e6583dc52f1dfbd,1,Extract Method,,
38213428929862120bdb32b963a600792ec6feb2,2020-12-30T04:44:36Z,https://github.com/tensorflow/tensorflow/commit/38213428929862120bdb32b963a600792ec6feb2,Eager execution coverage for extract_image_patches_grad_test.py. Removed  run_deprecated_v1 decorators.PiperOrigin-RevId: 349505498Change-Id: I4a43b1be685d1fef4a9e7ed91e265617c7187feb,1,Extract Method,,
d3bba8c715ba5d4ca15308ec72780115eeddbc79,2020-12-30T04:43:28Z,https://github.com/tensorflow/tensorflow/commit/d3bba8c715ba5d4ca15308ec72780115eeddbc79,Eager execution coverage for image_grad_test.py. Removed  run_deprecated_v1 decorators. (Part 2)PiperOrigin-RevId: 349505411Change-Id: Ifeaf7b77d0150339d88eda47984752bb7e3efa98,1,Extract Method,,
b8fcda3cd1fe0a69b0957b75dbd7738c598d1749,2020-10-26T21:38:11Z,https://github.com/tensorflow/tensorflow/commit/b8fcda3cd1fe0a69b0957b75dbd7738c598d1749,Fork is_composite_or_commposite_value into Keras to split a dependency on private symbolsPiperOrigin-RevId: 339120462Change-Id: I8c48668daf0daf330b4d34bc58b4a20f1a9de67c,1,Extract Method,,
861f63a327690047df1b6c40ebd18be01e4f6b0a,2020-10-19T05:28:42Z,https://github.com/tensorflow/tensorflow/commit/861f63a327690047df1b6c40ebd18be01e4f6b0a,Have AutoCastVariable.dtype refer to the variable dtype.This allows us the flexibility to later remove AutoCastVariable and instead have a mechanism so that individual ops will cast variables (and potentially other tensors) to the correct dtype. See the last paragraph of the this section of the mixed precision RFC (https://github.com/tensorflow/community/blob/85635744559cdfe27ff92bf11adbd17c6f88ae73/rfcs/20200929-keras-mixed-precision.md#op-based-autocasting-api) for an example of how this could be done.PiperOrigin-RevId: 337793570Change-Id: I8e56f7d276117a9a81070ab0984369e8a4490eea,1,Extract Method,,
46b6d3707f97b9ef95a7d6d6bd75a93fda4ab8ea,2020-08-28T14:02:24Z,https://github.com/tensorflow/tensorflow/commit/46b6d3707f97b9ef95a7d6d6bd75a93fda4ab8ea,Split some of the code in _apply_op_helper out into helper functions.PiperOrigin-RevId: 328931451Change-Id: I33eed3decaa6f21485d42eaf4ba036e9da81cd06,1,Extract Method,,
b58e25577f9cbccba31ce1ba3fd1877e307571b0,2020-08-21T00:57:57Z,https://github.com/tensorflow/tensorflow/commit/b58e25577f9cbccba31ce1ba3fd1877e307571b0,Split _cache_key,1,Extract Method,,
cee5f17479966a40125a842fba3bfdd050faf079,2020-08-12T00:17:20Z,https://github.com/tensorflow/tensorflow/commit/cee5f17479966a40125a842fba3bfdd050faf079,[tf.data] Split RangeBenchmark into two different benchmark methodsPiperOrigin-RevId: 326135090Change-Id: I5e7735468f953e5155fcbbb2c61a6084332096c0,1,Extract Method,,
52e516c3d1b07baa1251c2c8ae09ad6fddab5b78,2020-07-22T01:08:51Z,https://github.com/tensorflow/tensorflow/commit/52e516c3d1b07baa1251c2c8ae09ad6fddab5b78,"Split test into two, as otherwise the same dtype will be reused in internal testsand cause testing to fail.Signed-off-by: Yong Tang <yong.tang.github@outlook.com>",1,Extract Method,,
3d585c30a3faa4ca299f5e3a72a5777169cfa7ad,2020-07-23T18:05:33Z,https://github.com/tensorflow/tensorflow/commit/3d585c30a3faa4ca299f5e3a72a5777169cfa7ad,refactored int tests,1,Extract Method,,
7074d7326ccb26404685fc84bb2d5ea66489bb1a,2020-07-23T15:52:37Z,https://github.com/tensorflow/tensorflow/commit/7074d7326ccb26404685fc84bb2d5ea66489bb1a,refactored tests and added unsupported type test,1,Extract Method,,
fa10b3fafcf3831004d67d5b9dbdc8090243e9b6,2020-07-14T05:52:25Z,https://github.com/tensorflow/tensorflow/commit/fa10b3fafcf3831004d67d5b9dbdc8090243e9b6,Refactor flatbuffer_utils functions that parse model files.PiperOrigin-RevId: 321101293Change-Id: I51430786d0403a9a6735b1c8e4cee3f9596d4f00,1,Extract Method,,
e0a29900c5d8986b127941743082d46c28dad79b,2020-06-03T06:24:36Z,https://github.com/tensorflow/tensorflow/commit/e0a29900c5d8986b127941743082d46c28dad79b,refactor: change check_penalty_number from instance method to function,1,Extract Method,,
bc49458b14127fedeb1e1fdf73cf86a1406eb8d8,2020-06-02T07:03:54Z,https://github.com/tensorflow/tensorflow/commit/bc49458b14127fedeb1e1fdf73cf86a1406eb8d8,"Move the recovering tensor shape logic of DistributedIterator get_next_as_optional earlier, so it covers more use cases.PiperOrigin-RevId: 314277550Change-Id: I2c8f3afcc791b02310b5242251f335d9da7cd5bf",1,Extract Method,,
38e7a4457d8afd1a9960e079c6857ca32a73c2ef,2020-06-01T17:51:58Z,https://github.com/tensorflow/tensorflow/commit/38e7a4457d8afd1a9960e079c6857ca32a73c2ef,"Consolidate all the quantization configurations and validationsThis patch makes the following changes to the tflite converter:- All the quantization related converter and quantizer configurations are  consolidated in the QuantizationMode class- Converter v1 and v2 shared the same interface to set the quantization flags- The restriction ""couldn't use int8 inference type when representative data is  specified"" is removed since the we workflow should be able to partially  quantize the model by the converter and then post-training quantization by  the quantizer (MLIR-based).PiperOrigin-RevId: 314160448Change-Id: Ic212cddd89cfdd33048592d2aaf8e9b2f9f8999f",1,Extract Method,,
09e67c47ee7ce8139093f9a455b7c7a94877193d,2020-04-22T17:25:47Z,https://github.com/tensorflow/tensorflow/commit/09e67c47ee7ce8139093f9a455b7c7a94877193d,Create `text_dataset_from_directory` utility and refactor shared code between `text_dataset_from_directory` and `image_dataset_from_directory`.PiperOrigin-RevId: 307844332Change-Id: I4b5f094dfa98a71d5ffa59c3134794bce765a575,1,Extract Method,,
2a6eb169c847abc8c06e7207df3a87eb70962871,2020-04-21T21:06:10Z,https://github.com/tensorflow/tensorflow/commit/2a6eb169c847abc8c06e7207df3a87eb70962871,Refactor DistributedVariable update logicThe change separates _update_cross_replica and _update_replica.Subclasses(SyncOnReadVariable and MirroredVariable) can then overrideaccordingly. _update() serves as an entry point and dispatch to theaforementioned two methods accordingly. Common logic can be added to _update().This is part of the work to make assign() return a variable.PiperOrigin-RevId: 307676699Change-Id: If23372f784dd874d951a4fe5cbb1bfedb057d69d,1,Extract Method,,
716bcea5a24f87f66419b07fcc1bd36c12f82fc2,2020-04-13T02:40:08Z,https://github.com/tensorflow/tensorflow/commit/716bcea5a24f87f66419b07fcc1bd36c12f82fc2,Move keras model related template test case to keras model test.PiperOrigin-RevId: 306166092Change-Id: I798e1039c43795c781f7125e4f6b61f9641cc587,1,Extract Method,,
859c4c21c0e813fc1f08efb5a5f7d0f6a659effb,2020-04-11T16:39:39Z,https://github.com/tensorflow/tensorflow/commit/859c4c21c0e813fc1f08efb5a5f7d0f6a659effb,Internal clean-up: move signature handling code that's specific to WrapFunction into WrapFunction subclass.PiperOrigin-RevId: 306041412Change-Id: I672c54772689e7bd67dc25d8059d6cf2de8fd3e6,1,Extract Method,,
7903be44d3ab1b08579f8aa719d52d18e621dcef,2020-04-08T22:59:45Z,https://github.com/tensorflow/tensorflow/commit/7903be44d3ab1b08579f8aa719d52d18e621dcef,moved duplicate code to helper function. Removed unnecessary else statement.,1,Extract Method,,
dc90dde87528ea974f42a223b57ab2166e78dbb8,2020-02-13T23:45:04Z,https://github.com/tensorflow/tensorflow/commit/dc90dde87528ea974f42a223b57ab2166e78dbb8,"[XLA:Python] Expose an API to start the TensorFlow profiler via xla_client.profiler.start_server(port)In addition, expose a variant of the TraceMe class. Unlike the implementation in TensorFlow, implement the context manager directly using pybind11.In passing, refactor code to build the ops module into a separate function.PiperOrigin-RevId: 295018106Change-Id: Ic9f344418c9c29903f104b5e191ce6b097a0a3a9",1,Extract Method,,
f960bdb26b5a8af22c7bdef7b9eedb82197a2080,2020-01-11T01:21:28Z,https://github.com/tensorflow/tensorflow/commit/f960bdb26b5a8af22c7bdef7b9eedb82197a2080,"Pull the custom for loop operator for distributed dataset inside the autograph operators. This is a temporary, medium-term refactoring. The existing structure will be restored once a stable contract for custom operators is established.This is in preparation for an internal interface change that breaks compatibility with py2. Since autograph already has a mechanism for branching away py2-compatible implementations, it's easy to move this operator in there, and limit the amount of patching.PiperOrigin-RevId: 289194635Change-Id: I0fe5723148516acee5bbab71c4d2543a977a3749",1,Extract Method,,
1e05422089bfec08e20ccbebf6053e93623d5089,2020-01-10T02:22:16Z,https://github.com/tensorflow/tensorflow/commit/1e05422089bfec08e20ccbebf6053e93623d5089,"Pull the custom for loop operator for distributed dataset inside the autograph operators. This is a temporary, medium-term refactoring. The existing structure will be restored once a stable contract for custom operators is established.This is in preparation for an internal interface change that breaks compatibility with py2. Since autograph already has a mechanism for branching away py2-compatible implementations, it's easy to move this operator in there, and limit the amount of patching.PiperOrigin-RevId: 289013513Change-Id: I1f1a92fc96621f3eec97569bef48279644ffa544",1,Extract Method,,
1bcbacd3dff6aa28e27a9c10e5aeeb2138c38f57,2019-12-05T17:47:03Z,https://github.com/tensorflow/tensorflow/commit/1bcbacd3dff6aa28e27a9c10e5aeeb2138c38f57,[tf.data] Refactoring optimization test methods.This CL breaks down large tests that iterate over different test cases into smaller ones -- one per test case.PiperOrigin-RevId: 283993741Change-Id: I0e67958279d924d0b139164108e971bf39de96ca,1,Extract Method,,
77b19fb814d53607fc7c66f3731559cdf71dc210,2019-11-09T02:47:13Z,https://github.com/tensorflow/tensorflow/commit/77b19fb814d53607fc7c66f3731559cdf71dc210,Refactor MultiProcessRunner:  * break run function into smaller functions  * create a python thread/process-like API  * remove some seldom used featuresPiperOrigin-RevId: 279433471Change-Id: Ibb7febc2347f45872d1455e000ddcfb9541eee23,1,Extract Method,,
df22a29b757bf6682ca5ec9418aa74d7f83dab23,2019-08-21T20:39:41Z,https://github.com/tensorflow/tensorflow/commit/df22a29b757bf6682ca5ec9418aa74d7f83dab23,"Refactor the keras TensorLikeDataAdapter (numpy array, EagerTensor, etc) to use tf.shuffle rather than np.shuffle. This allows us to use more of tf.data's pipelining machinery which both improves multi-epoch performance and decreases memory consumption.PiperOrigin-RevId: 264681581",1,Extract Method,,
bd33b057087e7124bf34555d53986328c5b5782d,2019-07-29T18:49:27Z,https://github.com/tensorflow/tensorflow/commit/bd33b057087e7124bf34555d53986328c5b5782d,"Refactor the training._standardize_user_data().Split out the on-fly build and on-fly compile into separate methods, toreduce the overall size of training._standardize_user_data().The same method might also be used for training v2 in future.PiperOrigin-RevId: 260547059",1,Extract Method,,
5fed792127f6b9ad34a7be5f6a2b17ce90c50edd,2019-06-28T22:42:52Z,https://github.com/tensorflow/tensorflow/commit/5fed792127f6b9ad34a7be5f6a2b17ce90c50edd,Split TransposeTest into two so Grappler layout optimizer can be run moreaggressively without breaking it.PiperOrigin-RevId: 255681948,1,Extract Method,,
3438a4c411d16e4aa9d889a7c050b2142522079c,2019-06-28T13:27:50Z,https://github.com/tensorflow/tensorflow/commit/3438a4c411d16e4aa9d889a7c050b2142522079c,Extracted conversion function caching into tensor_conversion_registryThis change also fixes a race condition in the cache population logicwhich could result in cache being populated more than once for a particulartype.PiperOrigin-RevId: 255590346,1,Extract Method,,
d640fd47a1ad332b94ff287c8795fa541bd28cd5,2019-05-07T19:58:40Z,https://github.com/tensorflow/tensorflow/commit/d640fd47a1ad332b94ff287c8795fa541bd28cd5,Minor refactor to make __call__ more readable.PiperOrigin-RevId: 247074218,1,Extract Method,,
93520d5c4e62396ea5a124544d654613d5ae11f4,2019-03-27T00:26:08Z,https://github.com/tensorflow/tensorflow/commit/93520d5c4e62396ea5a124544d654613d5ae11f4,Internal cleanup for tracking attributes in keras.layer.PiperOrigin-RevId: 240462586,1,Extract Method,,
5c57cdc12b6de258cad268072a32e706ccc11e11,2019-02-13T21:00:33Z,https://github.com/tensorflow/tensorflow/commit/5c57cdc12b6de258cad268072a32e706ccc11e11,Refactor (Extract methods) and improve model.compile() readability.PiperOrigin-RevId: 233812403,1,Extract Method,,
bae887e18dada914c3719bc1dacbb3a4c09eb60d,2019-02-12T21:36:28Z,https://github.com/tensorflow/tensorflow/commit/bae887e18dada914c3719bc1dacbb3a4c09eb60d,Move dispatch logic out of the module,1,Extract Method,,
930108569819c13e12c8c6919596d2899c410911,2019-02-05T17:17:53Z,https://github.com/tensorflow/tensorflow/commit/930108569819c13e12c8c6919596d2899c410911,"Refactor code for listing checkpointable functions of an object.The main goal is to move the logic of ""dir+getattr"" from all checkpointableobjects to just ""AutoCheckpointable"". Similar to how checkpointable basedoes not enforcesThe refactoring also provides an internal mechanism for a class to provideits own listing of functions if needed and makes obsolete the need to registera getter and an attribute extractor.PiperOrigin-RevId: 232499034",1,Extract Method,,
f3de78482f7dc95383ee40e548aac0e729fabbe6,2019-02-01T23:44:47Z,https://github.com/tensorflow/tensorflow/commit/f3de78482f7dc95383ee40e548aac0e729fabbe6,Refactor some code to allow for distributed model caching in the future.PiperOrigin-RevId: 232051357,1,Extract Method,,
7c929bf6ef15d47f208743ac9ea5bbafdd981173,2019-01-24T23:45:54Z,https://github.com/tensorflow/tensorflow/commit/7c929bf6ef15d47f208743ac9ea5bbafdd981173,Refactor out moment-testing and make more numpy friendly.PiperOrigin-RevId: 230804842,1,Extract Method,,
d319d8d716b58d71ee0794025a7679e47ed79622,2019-01-18T23:11:35Z,https://github.com/tensorflow/tensorflow/commit/d319d8d716b58d71ee0794025a7679e47ed79622,Differentiate calls to colocate_with from private vs public API.colocate_with has been deprecated from public API. There are still TF internal uses of colocate_with but previously calls to private and public were treated the same and resulted in deprecation warnings for internal uses.PiperOrigin-RevId: 230002109,1,Extract Method,,
bcf94f9cf2a4cfe8d2b7a76a1fe1be553a591edd,2019-01-11T01:04:59Z,https://github.com/tensorflow/tensorflow/commit/bcf94f9cf2a4cfe8d2b7a76a1fe1be553a591edd,Minor refactor of _WhileBodyGradFuncGraph._capture_helper.It was getting kind of long. This also makes minor stylistic changes to the moved code.PiperOrigin-RevId: 228804655,1,Extract Method,,
4b2b456ea4353864478e608a587ea9b5f7eb696c,2019-01-09T23:00:20Z,https://github.com/tensorflow/tensorflow/commit/4b2b456ea4353864478e608a587ea9b5f7eb696c,Remove a deprecation warning from tf.saved_model.savePiperOrigin-RevId: 228594973,1,Extract Method,,
c503c6254608a622b06340f1f7ddd8f31565ab5e,2019-01-08T12:37:51Z,https://github.com/tensorflow/tensorflow/commit/c503c6254608a622b06340f1f7ddd8f31565ab5e,Small clean up in in saved_model/load_test.pyTemporary `function` in checkpointable under test is not needed in most examplesas `cycle` is passing signatures explicitly.PiperOrigin-RevId: 228309220,1,Extract Method,,
8fb8174483cf17d99223ac8c7114eb164a6459dc,2018-12-27T17:11:14Z,https://github.com/tensorflow/tensorflow/commit/8fb8174483cf17d99223ac8c7114eb164a6459dc,Refactoring the keras correctness test to take more models.This CL adds a CNN model (w.o. batch norm).PiperOrigin-RevId: 227033892,1,Extract Method,,
15fa7c49e27963df5304d7f827e6c4459079cc18,2018-12-18T09:55:09Z,https://github.com/tensorflow/tensorflow/commit/15fa7c49e27963df5304d7f827e6c4459079cc18,Extract function spec information that is needed for canonicalization.This will allow serialization of all the information we need for canonicalization.PiperOrigin-RevId: 225960841,1,Extract Method,,
06303a8ea057dbfcc639303557a7ab87362e6c09,2018-12-17T10:28:33Z,https://github.com/tensorflow/tensorflow/commit/06303a8ea057dbfcc639303557a7ab87362e6c09,"Refactoring to make the polymorphic code easier to read.Changes:1. Remove ""self._created_variables = []"" as this shouldn't matter.2. Remove self._concrete_stateful_fn -> this is used only for the first time we call __call__.3. Make _initialize not return canonicalized arguments, instead create a function for it.PiperOrigin-RevId: 225794015",1,Extract Method,,
3dfe44784dcfdc8cca87e59ce8eb1a47b9d95bfd,2018-12-11T23:12:10Z,https://github.com/tensorflow/tensorflow/commit/3dfe44784dcfdc8cca87e59ce8eb1a47b9d95bfd,"Small refactor of `thresholds` default value and validation steps. The number of thresholds is used instead of the user specified type of the `thresholds` kwarg to determine the output of the result method:`thresholds` is a scalar or single element list/tuple -> return scalar`thresholds` is a multi element list/tuple -> return listThis is functionally equivalent to the previous code except for cases where the user passes in a single element list for the thresholds kwarg. In the previous code, this would cause the result method to return a list whereas now it returns a scalar.PiperOrigin-RevId: 225079221",1,Extract Method,,
a1f87073027572737b275401202726f736350206,2018-11-29T21:19:39Z,https://github.com/tensorflow/tensorflow/commit/a1f87073027572737b275401202726f736350206,Extracted ~logically independent bits from `_VarStore._get_partitioned_variables`PiperOrigin-RevId: 223399274,1,Extract Method,,
0d40f081369150bdab2ca49fe173d2a19717c0f7,2018-11-28T20:16:50Z,https://github.com/tensorflow/tensorflow/commit/0d40f081369150bdab2ca49fe173d2a19717c0f7,"Simplify semantics of `build`:`build(input_shape)` is a method that implementers of subclasses of Layer or Model can override if they need a state-creation step in-between layer instantiation and layer call. This is typically used to create the weights of Layer subclasses.If you do not override it, it is never called by the framework (i.e. default implementations of `build` are *never called* unless you explicitly call `model.build()` yourself, therefore they never introduce surprising issues).In addition, you can call `model.build(input_shape)` on a Model instance in a standalone way, as a substitute for calling the model on some data to create its weights. This may raise an exception if the request is impossible (then you have to call the model on some data yourself in order to build it).The change also fixes two related issues:- enable `build` to be called on Model subclasses with a signature containing keyword arguments with default values (e.g. `call(self, inputs, training=False, mask=None)`.- enable a Model subclass to be nested in a Sequential model without having to implement `compute_output_shape` on the Model subclass.PiperOrigin-RevId: 223213320",1,Extract Method,,
0d2e879a162a6c92d5602a7a88ea4e92fd104ee2,2018-11-26T16:55:52Z,https://github.com/tensorflow/tensorflow/commit/0d2e879a162a6c92d5602a7a88ea4e92fd104ee2,Refactor shared cond_v2 and _IfGrad logic into _build_cond helper method.PiperOrigin-RevId: 222832725,1,Extract Method,,
1d3d92dfdecd38daf068583b39aef7811a604601,2018-11-16T14:39:12Z,https://github.com/tensorflow/tensorflow/commit/1d3d92dfdecd38daf068583b39aef7811a604601,No-op refactor and comment fix.PiperOrigin-RevId: 221786311,1,Extract Method,,
fa0661ee7daa284f5fe71ceac778642bcc375c4f,2018-11-06T06:47:05Z,https://github.com/tensorflow/tensorflow/commit/fa0661ee7daa284f5fe71ceac778642bcc375c4f,Move to using num_replicas_in_sync instead of num_replicas.PiperOrigin-RevId: 220229772,1,Extract Method,Rename Variable,
b306ad9846238b7a396694c07510a1fc161627b2,2018-10-17T00:57:09Z,https://github.com/tensorflow/tensorflow/commit/b306ad9846238b7a396694c07510a1fc161627b2,"Extract nested functions functions in anf_test.py that include `exec` to toplevel, for a baroque compatibility reason.PiperOrigin-RevId: 217420773",1,Extract Method,,
9eba75e54e87aa00efae482c69797794d7020950,2018-09-14T23:08:40Z,https://github.com/tensorflow/tensorflow/commit/9eba75e54e87aa00efae482c69797794d7020950,Refactored some of the metrics code in compile function for better readability.- Logic change: Moved getting metric name and function out of the training/eval loops in eager mode- Moved setting metric attributes on the model out the function which calls metric functions.PiperOrigin-RevId: 213060143,1,Extract Method,,
0c71f791bf353e84e9a46487c81914d250470210,2018-08-15T16:49:41Z,https://github.com/tensorflow/tensorflow/commit/0c71f791bf353e84e9a46487c81914d250470210,Split unit test case for further parallelize.PiperOrigin-RevId: 208834783,1,Extract Method,,
d17db4b011d3c04cf7ff8caf4578032b4c0fc622,2017-10-25T16:03:21Z,https://github.com/tensorflow/tensorflow/commit/d17db4b011d3c04cf7ff8caf4578032b4c0fc622,Split Evaluator.evaluate_on_dataset() into two methods to separategraph construction from running in sessions. Otherwise it is very hard toavoid adding to the graph every time you do an eval.Also:* Stop making init_variables() conditional on whether the variables have  already been initialized.* Use new feature of group() to accept lists.PiperOrigin-RevId: 173404673,1,Extract Method,,
de1b4a8a75ae3a50f4fa7480efb1177d79abf553,2017-10-24T21:00:10Z,https://github.com/tensorflow/tensorflow/commit/de1b4a8a75ae3a50f4fa7480efb1177d79abf553,Refactor K-FAC FisherEstimatorPiperOrigin-RevId: 173307212,1,Extract Method,,
86908c30c4c0adf92fa14ed6f1d92616177c1b89,2017-10-20T18:13:45Z,https://github.com/tensorflow/tensorflow/commit/86908c30c4c0adf92fa14ed6f1d92616177c1b89,Step 1: Large refactoring toward wrapping input_fn and TPU infeed into tf.while_loopPiperOrigin-RevId: 172907182,1,Extract Method,,
ade8e9f29d4b1374d41fcc5ca9109bd05df765d1,2017-09-30T03:06:59Z,https://github.com/tensorflow/tensorflow/commit/ade8e9f29d4b1374d41fcc5ca9109bd05df765d1,Extracted time_series_regression_head (#13275)* Extracted time_series_regression_head* Addressed comments and fix ci build* Fixed BUILD file and tests* Remove whitelisted timeseries head lint error,1,Extract Method,,
a78545d56067b2abcfd78ac631d1eb23398686b9,2017-07-28T21:09:23Z,https://github.com/tensorflow/tensorflow/commit/a78545d56067b2abcfd78ac631d1eb23398686b9,tfdbg: clean up SessionRunHook codeRemove the multiple inheritance in LocalCLIDebugHook and DumpingDebugHookPiperOrigin-RevId: 163516434,1,Extract Method,,
d82f8f818cec7a1099a7e680a30ba8f5f8ed2589,2017-03-30T18:41:56Z,https://github.com/tensorflow/tensorflow/commit/d82f8f818cec7a1099a7e680a30ba8f5f8ed2589,Refactor TF-Slim ResNet blocks to use a dictionary for arguments to supportuser-defined blocks with custom parameters.Change: 151728925,1,Extract Method,,
580c7502f68dd84cf74c34b9d454a37def81d286,2017-03-09T17:07:24Z,https://github.com/tensorflow/tensorflow/commit/580c7502f68dd84cf74c34b9d454a37def81d286,internal change.Change: 149658231,1,Extract Method,,
0ea7b2bcc2f553b06859b7cbf6962dfc340c868d,2017-02-21T23:54:35Z,https://github.com/tensorflow/tensorflow/commit/0ea7b2bcc2f553b06859b7cbf6962dfc340c868d,Move Global step creator utilities from contrib to training_util.Change: 148156049,1,Extract Method,,
ab336a6a7d56a712364897f8bd4b30b7b7a4b186,2017-02-14T17:14:26Z,https://github.com/tensorflow/tensorflow/commit/ab336a6a7d56a712364897f8bd4b30b7b7a4b186,Refactor head implementations to reduce code duplication and eliminate deep inheritance.Change: 147480076,1,Extract Method,,
b7859e1940c433a38841919661e2156cb57d0946,2017-01-27T18:59:46Z,https://github.com/tensorflow/tensorflow/commit/b7859e1940c433a38841919661e2156cb57d0946,Remove some vestigial code from TensorBoard.Change: 145813521,1,Extract Method,,
c38776d63b087caad3539bd88e43cde1bdacc479,2016-12-16T02:16:05Z,https://github.com/tensorflow/tensorflow/commit/c38776d63b087caad3539bd88e43cde1bdacc479,Refactor to use the same code for handling control dependency inside cond.Change: 142214059,1,Extract Method,,
7ed1fb97cd9c6c8606264123d6c0222a852a98c9,2016-11-17T23:12:47Z,https://github.com/tensorflow/tensorflow/commit/7ed1fb97cd9c6c8606264123d6c0222a852a98c9,"Extract epoch via its limit_epochs variable, rather than as a passedparameter.Change: 139513507",1,Extract Method,,
07562bebcfad034fbbb659d6b671ba1d3e603dd7,2016-08-27T22:31:30Z,https://github.com/tensorflow/tensorflow/commit/07562bebcfad034fbbb659d6b671ba1d3e603dd7,Refactor tf.learn export functions to make them use the same input_fn signature as train/evaluate. Deprecate the old export signature.Split queue_parsed_features() out of read_keyed_batch_features().Change: 131501231,1,Extract Method,,
b922cde9075527b450d88c53d27ffee5176e069b,2016-06-24T20:04:33Z,https://github.com/tensorflow/tensorflow/commit/b922cde9075527b450d88c53d27ffee5176e069b,"RealValuedColumn.to_weighted_sum didn't use variable scopes, so it was impossible to reuse the values in a graph. This is inconsistent with the rest of layers.It also manually performed a matrix multiply and this was replaced with a more standard formulation.Change: 125808727",1,Extract Method,,
5a77d20459d4cb4267ab6ca22ad92222b0ac9510,2023-04-05T17:44:54Z,https://github.com/keras-team/keras/commit/5a77d20459d4cb4267ab6ca22ad92222b0ac9510,Move dtype setting logic to the Policy class to make dtype policy awareness more self-contained.  PiperOrigin-RevId: 522094585,1,Extract Method,,
b63f572cdb0c7b6b498607de3084ca0b847aaa9f,2023-01-25T07:17:41Z,https://github.com/keras-team/keras/commit/b63f572cdb0c7b6b498607de3084ca0b847aaa9f,"formatted, changed == to self.assertEqual, reworked test case, changed self._trainable to kwargs.get('trainable', layer.trainable)",1,Extract Method,,
a404a31621cc5a61d21304ed49b474e0c47779be,2022-04-06T16:37:27Z,https://github.com/keras-team/keras/commit/a404a31621cc5a61d21304ed49b474e0c47779be,Return KerasTensor.type_spec instead of construct a new TensorSpec in get_tensor_spec.  PiperOrigin-RevId: 439862461,1,Extract Method,,
98105b739a163a1911735b9e63c12bebba576349,2022-02-24T23:27:53Z,https://github.com/keras-team/keras/commit/98105b739a163a1911735b9e63c12bebba576349,Refactor the RandomTranslation with the new BaseImageAugmentationLayer API.  PiperOrigin-RevId: 430807261,1,Extract Method,,
33f395aeceaad95910ce6f0931621bb82d3e967c,2022-02-16T00:30:57Z,https://github.com/keras-team/keras/commit/33f395aeceaad95910ce6f0931621bb82d3e967c,making util methods for all the categorical accuracies,1,Extract Method,,
119cd4655d01570a70c70879dff4461ea46161bf,2022-02-15T22:04:26Z,https://github.com/keras-team/keras/commit/119cd4655d01570a70c70879dff4461ea46161bf,Added util metric method for binary_matches. Decoupled from public metric binarry_acc,1,Extract Method,,
2780ab0c9712b41c34693758141f30ae3d3c2e7f,2018-09-05T22:57:14Z,https://github.com/keras-team/keras/commit/2780ab0c9712b41c34693758141f30ae3d3c2e7f,Refactor Enqueuers  (#11079)  * Refactor data_utils  * Fix for python 2  * Fix for python 2  * Fix super  * Better ux  * Make pool init private,1,Extract Method,,
1068e173eafd15e5aa9f40b9f73590a7f5be4a84,2018-08-05T23:48:16Z,https://github.com/keras-team/keras/commit/1068e173eafd15e5aa9f40b9f73590a7f5be4a84,Created a function to_data_format to abstract the shape and data_format handling. (#10781)  * Created a function to_data_format to abstract the shape and data_format handling.  * Moved to_data_format to generic_utils.py.  * Changed the to_data_format signature.,1,Extract Method,,
dd07a4c41efed22afb5780cd584555cbff141c74,2018-07-26T13:02:36Z,https://github.com/keras-team/keras/commit/dd07a4c41efed22afb5780cd584555cbff141c74,Refactoring: Simplified some code by using the `to_list` function. (#10678)  ### Summary We have the method `to_list` in keras. Let's use it to make the codebase simpler! ### Related Issues  ### PR Overview  - [ ] This PR requires new unit tests [y/n] (make sure tests are included) - [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date) - [x] This PR is backwards compatible [y/n] - [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet),1,Extract Method,,
5103fd8134ccf2ef6ed114d525d8b07d148716d3,2018-07-14T18:18:11Z,https://github.com/keras-team/keras/commit/5103fd8134ccf2ef6ed114d525d8b07d148716d3,Refactoring the `layer_test` function. (#10660),1,Extract Method,,
3a431ea52d090fb3ef8a1e0e5d7f796d9a42e097,2018-01-11T06:29:42Z,https://github.com/keras-team/keras/commit/3a431ea52d090fb3ef8a1e0e5d7f796d9a42e097,Refactor workarounds in application tests (#9032)  * Refactor workarounds in application tests  * Remove `set_image_data_format`,1,Extract Method,,
dec0c7b7aeddab2b31b55ccb015d7e0735206d59,2017-12-02T21:01:45Z,https://github.com/keras-team/keras/commit/dec0c7b7aeddab2b31b55ccb015d7e0735206d59,"Refactor RNN dropout to be self-contained in RNN cells (#8660)  * Refactor RNN dropout to be self-contained in RNN cells, which is cleaner and fixes a couple of outstanding bugs. Side effect: disables RNN dropout for Theano.  * Fix failing test.",1,Extract Method,,
785384016277ae624fe1f5ff0876ed95c2936ef7,2017-11-25T21:24:07Z,https://github.com/keras-team/keras/commit/785384016277ae624fe1f5ff0876ed95c2936ef7,"Refactor preprocess_input so I can use it in the functional API (#8520)  * Revise preprocess_input to enable it to be used in the functional API  * Global imagenet_mean variables, lazily instantion; Add test  * Use K.floatx() instead of np.float32; plus minor refactoring  * Rename global variables of imagenet mean for less confusion; Add 4D case for channel last; Casting on the fly  * Update  * Use bias_add for symbolic tensors  * Lint  * Refactor, removing redundant code; explicitly pass data_format to bias_add  * Move data_format setting and checking from private functions to public function",1,Extract Method,,
e092fa8b5776ee8c7bc80227d046036de900412c,2017-02-20T01:13:31Z,https://github.com/keras-team/keras/commit/e092fa8b5776ee8c7bc80227d046036de900412c,Refactor print_summary.,1,Extract Method,,
54fc6465377da71da506827df086374b3f95cc42,2016-09-20T15:43:42Z,https://github.com/keras-team/keras/commit/54fc6465377da71da506827df086374b3f95cc42,Split multitest in test_recurrent (#3818),1,Extract Method,,
44d558ad7f13251650f40475eef6652df59e4b09,2016-02-22T18:21:07Z,https://github.com/keras-team/keras/commit/44d558ad7f13251650f40475eef6652df59e4b09,"Refactor implementation of __call__.  This refactor allows the inherited method to work properly for Sequential and Graph (with single input) containers in addition to normal layers, so there's no need to override the method. Previously, __call__ did not work correctly for Graph containers.  Implement Graph.__call__ for multiple inputs  Add option (re-)initialize weights in set_previous  This allows us to use set_previous in places where we previously manually adjusted the previous layer, which means that layers that have non-standard set_previous implementations (like Graph) work properly when they are, for example, the first layer in a Sequential model.  This commit also adds a clear_previous method.  Add input_shape property to Graph container",1,Extract Method,,
2b51317be82d4420169d2cc79dc4443028417911,2016-11-04T03:28:04Z,https://github.com/keras-team/keras/commit/2b51317be82d4420169d2cc79dc4443028417911,"Refactor F-score into precision and recall metrics (#4276)  * Refactor f-score into precision and recall metrics  * Docstring consistency  * Add docstring for fmeasure  * Added precision, recall, f-measure tests",1,Extract Method,,
3184efd620840fb6032526df32a09185b7ae18e2,2018-09-17T22:13:01Z,https://github.com/keras-team/keras/commit/3184efd620840fb6032526df32a09185b7ae18e2,Splitted the convolutional recurrent tests. (#11154)  * Splitted the onvolutional recurrent tests.  * Added the keras_test,1,Extract Method,Move Variable,
b057eff257dd49d8d6f931cbf72600ca2df06e2a,2021-12-07T18:23:17Z,https://github.com/keras-team/keras/commit/b057eff257dd49d8d6f931cbf72600ca2df06e2a,Extract optimizer iteration variable logic for subclass to override.  PiperOrigin-RevId: 414763454,1,Extract Method,Move Statement,
5b6243485acc20cc36f2db4f258512c332d691ec,2018-09-14T14:19:10Z,https://github.com/keras-team/keras/commit/5b6243485acc20cc36f2db4f258512c332d691ec,Breaking down the attention API PR: part 2 (#11140)  ### Summary  This refactoring will allow the simplification of some code in #8296  ### Related Issues  ### PR Overview  - [ ] This PR requires new unit tests [y/n] (make sure tests are included) - [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date) - [x] This PR is backwards compatible [y/n] - [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet),1,Extract Method,,
f11b422541cb68857d6f62ab667d7778f3f3e3a2,2017-10-23T19:30:45Z,https://github.com/keras-team/keras/commit/f11b422541cb68857d6f62ab667d7778f3f3e3a2,Simplify and fix count_params() (#8206)  * Simplify and fix count_params()  * Replace non-ascii ' with an ascii one,1,Extract Method,,
004f3d71aaec0ed2ddbb52c887d04a403186ebd4,2023-04-26T18:26:46Z,https://github.com/pytorch/pytorch/commit/004f3d71aaec0ed2ddbb52c887d04a403186ebd4,[export] Move verifier over to export from torch/fx (#100019)  Fixes #ISSUE_NUMBER  Pull Request resolved: https://github.com/pytorch/pytorch/pull/100019 Approved by: https://github.com/tugsbayasgalan,1,Extract Method,,
04e55d69f94f0e74bfb2bb0e64e13dbfbf5761d5,2020-08-04T01:46:11Z,https://github.com/pytorch/pytorch/commit/04e55d69f94f0e74bfb2bb0e64e13dbfbf5761d5,[ONNX] Enable scripting tests and update jit passes (#41413)Summary:This PR initiates the process of updating the torchsciprt backend interface used by ONNX exporter.- Replace jit lower graph pass by freeze module pass- Enable ScriptModule tests for ONNX operator tests (ORT backend) and model tests by default.Pull Request resolved: https://github.com/pytorch/pytorch/pull/41413Reviewed By: VitalyFedyuninDifferential Revision: D22845258Pulled By: bzinodevfbshipit-source-id: d57fd4086f27bd0c3bf5f70af7fd0daa39a2814a,1,Extract Method,,
06ab3f962fd2c8a3042126fa5a711e84d973603a,2016-09-21T02:37:20Z,https://github.com/pytorch/pytorch/commit/06ab3f962fd2c8a3042126fa5a711e84d973603a,Refactor _C extension to export some utilities,1,Extract Method,,
08561cad1014d6fec184c32529e0ec3b0a9916fd,2021-04-12T18:32:02Z,https://github.com/pytorch/pytorch/commit/08561cad1014d6fec184c32529e0ec3b0a9916fd,[OpInfo] move matmul to OpInfo (#55543)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/55543Reviewed By: samestepDifferential Revision: D27708944Pulled By: walterddrfbshipit-source-id: c200ded15082eaeed7ba3077a0c8629fed0db505,1,Extract Method,,
08caf1550249db707225b35d741cb8dd0dddd5db,2020-09-26T00:02:16Z,https://github.com/pytorch/pytorch/commit/08caf1550249db707225b35d741cb8dd0dddd5db,[optimizer] refactor Adam to use functional API (#44791)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/44791Test Plan: Imported from OSSReviewed By: ailzhangDifferential Revision: D23935257Pulled By: wanchaolfbshipit-source-id: 6f6e22a9287f5515d2e4e6abd4dee2fe7e17b945,1,Extract Method,,
0af0cba2b735cdb648be8939c4301977e278018c,2017-05-19T19:46:18Z,https://github.com/pytorch/pytorch/commit/0af0cba2b735cdb648be8939c4301977e278018c,"Refactor data_parallel_model initial sync and checkpointingSummary:Major improvements. Before we only synced ""params"" and ""computed params"" of model after initialization and after loading a checkpoint. But actually we want to sync all blobs that are generated in the param_init_net. For example the _momentum blobs were missed by the previous implementation and had to be manually included in checkpoint finalization.I also added GetCheckpointParams() to data_parallel_model because it is now fully general. Also added a unit test.Reviewed By: andrewwdyeDifferential Revision: D5093689fbshipit-source-id: 8154ded0c73cd6a0f54ee024dc5f2c6826ed7e42",1,Extract Method,,
0b000952c12b8e73bef6f668a6f10e1f19b222ba,2017-08-02T23:55:05Z,https://github.com/pytorch/pytorch/commit/0b000952c12b8e73bef6f668a6f10e1f19b222ba,Split batchnorm eval test into cpu and cuda functions. (#2273),1,Extract Method,,
1089ff404ce7460b08e393a2249f71c9e1b2c494,2020-08-25T16:58:02Z,https://github.com/pytorch/pytorch/commit/1089ff404ce7460b08e393a2249f71c9e1b2c494,Refactored the duplicate code into a function in _ConvNd (#43525)Summary:Fixes #{issue number}Pull Request resolved: https://github.com/pytorch/pytorch/pull/43525Reviewed By: ngimelDifferential Revision: D23306593Pulled By: jerryzh168fbshipit-source-id: 3427cd2b9132a203858477b6c858d59b00e1282e,1,Extract Method,,
14ea4bf0d1dcf3a98436b0743b64eee92a963ac0,2018-10-25T20:57:40Z,https://github.com/pytorch/pytorch/commit/14ea4bf0d1dcf3a98436b0743b64eee92a963ac0,Make 7 nn modules into weak modules (#12966)Summary:Depends on #12682 ([stacked diff](https://github.com/driazati/pytorch/compare/weak_mod...driazati:mod_conv1))* Adds tests for weak module conversion that creates a `ScriptModule` that uses the weak module and checks its graph* Adds `torch._jit_internal.weak_module` tags to modules that already work  * `Sigmoid`  * `Tanh`  * `Hardshrink`  * `PReLU`  * `Softsign`  * `Tanhshrink`  * `PairwiseDistance`Pull Request resolved: https://github.com/pytorch/pytorch/pull/12966Differential Revision: D10559557Pulled By: driazatifbshipit-source-id: dc4bea3aa744b3c44d4fa7dceefd97e951f824d0,1,Extract Method,,
16c72a5a6b7085a9651e7bef7e98c80b2d5547e9,2020-11-08T09:03:59Z,https://github.com/pytorch/pytorch/commit/16c72a5a6b7085a9651e7bef7e98c80b2d5547e9,[pytorch] continue to rewrite gen_python_functions.py with typed models (#46978)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/46978Refactored and added type annotations to the most part of the file.Some top-level codegen functions are called by other codegen scripts.Will migrate them in subsequent PRs.Test Plan: Imported from OSSReviewed By: ezyangDifferential Revision: D24589210Pulled By: ljk53fbshipit-source-id: e0c7e5b3672b41983f321400c2e2330d1462e76e,1,Extract Method,,
1915ae9510725bf053f08ca5ed31b44fc8abac00,2020-11-13T19:14:05Z,https://github.com/pytorch/pytorch/commit/1915ae9510725bf053f08ca5ed31b44fc8abac00,[quant][graphmode][fx][refactor] is_output_quantized (#47879)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/47879Test Plan: Imported from OSSReviewed By: vkuzoDifferential Revision: D24928796fbshipit-source-id: 55c49243b6a0b4811953cf72af57e5f56be8c419,1,Extract Method,,
1ab6ac4682553b45e9d83d8a87b7bd5d4c76eea4,2022-12-21T21:38:14Z,https://github.com/pytorch/pytorch/commit/1ab6ac4682553b45e9d83d8a87b7bd5d4c76eea4,"[FSDP][optim_state_dict][6/N] Refactor the optim_state_dict APIs to support hooks (#90798)  **What does this PR do?**  This PR splits the FSDP optim_state_dict APIs into common implementation parts that are shared for different frontend APIs (we have many now and will consolidate them gradually). This PR also add `_optim_state_dict_post_hook` and `_load_optim_state_dict_pre_hook` for the integration with `NamedOptimzer`.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/90798 Approved by: https://github.com/rohan-varma, https://github.com/awgu",1,Extract Method,,
1ac663d9f1d2733c75880b4f8fade78fce12cffa,2023-05-19T17:24:35Z,https://github.com/pytorch/pytorch/commit/1ac663d9f1d2733c75880b4f8fade78fce12cffa,"`collect_env`: parse HIP version exception free (#101844)  Should prevent broken collect_env reporting as shown in https://github.com/pytorch/vision/issues/7561#issue-1698000841  <!-- copilot:poem --> ### <samp>🤖 Generated by Copilot at 5204e0f</samp>  > _`get_version_or_na`_ > _Helper function refactors_ > _Code like autumn leaves_  Pull Request resolved: https://github.com/pytorch/pytorch/pull/101844 Approved by: https://github.com/kit1980, https://github.com/ZainRizvi",1,Extract Method,,
1afdcbfbb34c7885b5cf82e0de52d6a123e71bfa,2020-11-13T05:37:00Z,https://github.com/pytorch/pytorch/commit/1afdcbfbb34c7885b5cf82e0de52d6a123e71bfa,[quant][graphmode][fx][refactor] insert_observer_for_output_of_the_node (#47784)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/47784Test Plan:python test/test_quantization.py TestQuantizeFxImported from OSSReviewed By: vkuzoDifferential Revision: D24900301fbshipit-source-id: abaeae1b5747e517adeb0d50cec5998a8a3fc24d,1,Extract Method,,
1b20eeb13866657439ea6747e6de8d1b523a4290,2021-05-03T03:10:58Z,https://github.com/pytorch/pytorch/commit/1b20eeb13866657439ea6747e6de8d1b523a4290,fx quant: move output obs logic to QuantizeHandler (#57377)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/57377Moves the logic which determines1. whether a pattern instance's output should be observed2. whether a pattern instance's output should be marked as observed based on its inputs3. whether to ovverride the activation specified in the qconfigfrom `quantize.py` to `quantization_patterns.py`.  This makesthe code easier to read and reduces the coupling between `Quantizer`and `QuantizeHandler` instances.Note: there are some further cleanups which would be good after this one- leaving those for future PRs.Test Plan:```python test/test_quantization.py TestQuantizeFxOps```Imported from OSSReviewed By: jerryzh168Differential Revision: D28126896fbshipit-source-id: 94c80a9c7307452783348d65b402acc84983e3f6,1,Extract Method,,
1f2b6d632a95d4aa06b12e1b75168075d4d6bd11,2020-01-06T18:56:16Z,https://github.com/pytorch/pytorch/commit/1f2b6d632a95d4aa06b12e1b75168075d4d6bd11,Refactor tests in pytorch's test/dist_autograd_test.py file (#31803)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/31803Refactored the following fairly similar functions:  1. `test_context_cleanup_tensor_with_grad`  2. `test_context_cleanup_tensor_no_grad`  3. `test_context_cleanup_no_tensors`by creating a helper function `context_cleanup_test_helper` that can be invoked with the appropriate arguments.Test Plan: Verified by running tests.Differential Revision: D19269246fbshipit-source-id: bfb42b078ad56b97ceeecf0d68b4169768c2c453,1,Extract Method,,
2293a6b95ea35e2ff308a82409ccf3eacc62ab43,2023-01-15T23:02:29Z,https://github.com/pytorch/pytorch/commit/2293a6b95ea35e2ff308a82409ccf3eacc62ab43,[BE] Refactor get_workflow_job_id (#92191)  A noop change that refactors existing codebase and prints a bit more verbose error message when request fails.  Get rid of `requests` as it inevitable results in flakiness  TODO: Remove in a few days after PR is landed https://github.com/pytorch/pytorch/blob/4af5939d7ac70cba7f130ab74705080cbda68d7b/.github/actions/get-workflow-job-id/action.yml#L29 Pull Request resolved: https://github.com/pytorch/pytorch/pull/92191 Approved by: https://github.com/kit1980,1,Extract Method,,
246701df816fbc31319438d031233b3e4b01365e,2017-10-20T15:19:43Z,https://github.com/pytorch/pytorch/commit/246701df816fbc31319438d031233b3e4b01365e,Separate out native processing into procecss_native; remove (TH)Type specific logic.,1,Extract Method,,
2ff748a680b818b6591b3e79410c62c45b196b98,2020-11-18T15:43:15Z,https://github.com/pytorch/pytorch/commit/2ff748a680b818b6591b3e79410c62c45b196b98,Move kthvalue scalar test to separate method for XLA (#48042)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/48042Moving scalar test to a separate method so the XLA team can continue to test for the other cases without failing. Requested here https://github.com/pytorch/xla/issues/2620#issuecomment-725696108Test Plan: Imported from OSSReviewed By: zhangguanheng66Differential Revision: D25055677Pulled By: heitorschuerofffbshipit-source-id: 5da66bac78ea197821fee0b9b8a213ff2dc19c67,1,Extract Method,,
3588688adecef0409b06c76749d06a219fa0cfc3,2023-04-27T03:16:03Z,https://github.com/pytorch/pytorch/commit/3588688adecef0409b06c76749d06a219fa0cfc3,"inductor: simplify the test_mkldnn_pattern_matcher.py code (#100057)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/100057 Approved by: https://github.com/jgong5, https://github.com/desertfire",1,Extract Method,,
36a95625daf002bddeb8347d3a353becd4be2f84,2023-04-17T16:17:36Z,https://github.com/pytorch/pytorch/commit/36a95625daf002bddeb8347d3a353becd4be2f84,[PT2E][Quant][BE] Refactor observer code (#99066)  Combine per channel and per tensor observer code  Differential Revision: [D44918494](https://our.internmc.facebook.com/intern/diff/D44918494/) Pull Request resolved: https://github.com/pytorch/pytorch/pull/99066 Approved by: https://github.com/jerryzh168,1,Extract Method,,
3826f7e8e09c48949fa523653a8beb6d6c43ecd0,2021-06-01T20:01:54Z,https://github.com/pytorch/pytorch/commit/3826f7e8e09c48949fa523653a8beb6d6c43ecd0,[quant][graphmode][fx][refactor] Remove quantized_graph from Quantizer (#59031)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/59031  Trying to remove Quantizer class and split prepare and convert code  Test Plan: python test/test_quantization.py TestQuantizeFx python test/test_quantization.py TestQuantizeFxOps  Imported from OSS  Reviewed By: vkuzo  Differential Revision: D28724871  fbshipit-source-id: dad0332ba271c4cfb6ec1e8f2036443149b5bea4,1,Extract Method,,
38da54e9c9471565812d2be123ee4e9fd6bfdbc0,2023-03-27T11:14:15Z,https://github.com/pytorch/pytorch/commit/38da54e9c9471565812d2be123ee4e9fd6bfdbc0,"Split rnn primitive for inference and training (#96736)  ## Description Currently, both inference and training will use `forward_training` in rnn primitive, which will bring performance downgrade for inference (The performance drop is from rnn primitive and unnecessary creation of `pd` and `workspace`). This PR is to split them into `forward_inference` and `forward_training` seperately.  ## Performance With this fix PR, in RNN-T inference, the throughput reduction is 167 ms, which increases `3.7%` of E2E time.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/96736 Approved by: https://github.com/jgong5",1,Extract Method,,
3a4344a7179e2f70eb59c3ea75659f905a676772,2021-04-22T22:12:01Z,https://github.com/pytorch/pytorch/commit/3a4344a7179e2f70eb59c3ea75659f905a676772,Create helper function for RPC profiling in _invoke_rpc and remote (#56643)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/56643Refactor enabling rpc profiling logic in `_invoke_rpc` and `remote()` into `_rpc_profiling()` helper function.Reviewed By: rohan-varmaDifferential Revision: D27922286fbshipit-source-id: 27cfe662a401756f0ee8a3cd45978d933377f78f,1,Extract Method,,
3cd9c7a16d8b19c28d12bf5b56a8a7c20405476a,2023-03-15T16:34:04Z,https://github.com/pytorch/pytorch/commit/3cd9c7a16d8b19c28d12bf5b56a8a7c20405476a,"[aot autograd] refactor to make functionalization self-contained (#96341)  This refactor should make it easier to add an export hook into aot autograd.  (1) I killed `create_forward_or_joint_functionalized()` (and the functions that it called, like `forward_or_joint()`) which used to handle autograd + functionalization all-in-one-go for the joint case, and was also used in the inference case.  I added a few separate helper functions:  `create_functionalized_graph()`: this takes a flat fn, and returns a functionalized fx graph. It is mostly just a thin wrapper around functionalization + make_fx(), but also has some extra logic to manually append `copy_()` ops to the end of the graph.  `fn_no_extra_mutations()`: this creates the fn that we want to trace in the inference code path. It takes in a function that it then calls, and returns the outputs + any (updated) mutated inputs.  `joint_fn_no_external_mutations()`: this creates the fn that we want to trace in the joint code path. It takes in a function, and traces out its joint. It also does the work of cloning inputs that are mutated and require gradients, returning mutated inputs as outputs, and returning intermediate bases as outputs  We should be able to add an export hook by basically adding a similar version of `joint_fn_no_external_mutations` but with a lot more restrictions (guaranteed to have no tangents, not synthetic bases, etc), and calling `create_functionalized_graph()` on it.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/96341 Approved by: https://github.com/ezyang",1,Extract Method,,
3d521e8b4088e659adca099d4c4e4ff4f8df1816,2021-06-01T21:52:22Z,https://github.com/pytorch/pytorch/commit/3d521e8b4088e659adca099d4c4e4ff4f8df1816,[quant][graphmode][fx][refactor] Remove prepare_custom_config from Quantizer class (#59034)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/59034  To remove Quantizer class and split prepare and convert functions to different files  Test Plan: python test/test_quantization.py TestQuantizeFx python test/test_quantization.py TestQuantizeFxOps  Imported from OSS  Reviewed By: vkuzo  Differential Revision: D28724873  fbshipit-source-id: 870e0822843ad1d035f41eaa015bdde9ccf6ec23,1,Extract Method,,
3e8ebb17aa694786a131da601559cef9e190b417,2021-04-10T00:55:30Z,https://github.com/pytorch/pytorch/commit/3e8ebb17aa694786a131da601559cef9e190b417,[reland][quant][graphmode][fx][refactor] Factor out insert_observers_for_model to a separate function (#54733) (#55307)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/55307Test Plan: Imported from OSSReviewed By: vkuzoDifferential Revision: D27567475fbshipit-source-id: 74b7db63f7e1e795e7ac7ed6027cf786d922e7bf,1,Extract Method,,
43327cc197d0415ef86d5de7fa45ba5ac384a59e,2021-08-03T15:43:14Z,https://github.com/pytorch/pytorch/commit/43327cc197d0415ef86d5de7fa45ba5ac384a59e,Refactor commonalities between two approaches (#62624)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/62624  Test Plan: Imported from OSS  Reviewed By: mrshenli  Differential Revision: D30058543  Pulled By: andwgu  fbshipit-source-id: 73c794062b75e011868fae264f592549eed67482,1,Extract Method,,
446488960aa4f2d54fadd4d24f6bcc973e1729f5,2019-12-09T23:09:59Z,https://github.com/pytorch/pytorch/commit/446488960aa4f2d54fadd4d24f6bcc973e1729f5,"polish up overloads on free functions (#30356)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/30356This finishes up the `torch.jit.overload` api for free-functions.- defaults now required on the implementation function itself- fully follows [overload spec](https://mypy.readthedocs.io/en/latest/more_types.html#function-overloading) such that the following is supported```overloaddef mouse_event(x1: int, y1: int) -> ClickEvent: ...def mouse_event(x1: int,                y1: int,                x2: Optional[int] = None,                y2: Optional[int] = None): ...```Note: `jit.overload` isn't supported yet for UDT, but is support for modules. This PR doesn't make the same changes for modules, if reviewers think I should include them then I could do so in a follow up PR or wait to land this. Since that's still an internal api I think it's fine, and the changes here would allow us to expose `torch.jit.overload` on free functions.Test Plan: Imported from OSSDifferential Revision: D18864774Pulled By: eellisonfbshipit-source-id: 6c566738bd6f0551a000a9ea8d56e403636b7856",1,Extract Method,,
457fac0a33a6b6789631e8de4235cf153c7b2a2b,2021-04-14T15:59:38Z,https://github.com/pytorch/pytorch/commit/457fac0a33a6b6789631e8de4235cf153c7b2a2b,"ns for fx: move more weight matching logic to weight_utils.py (#55288)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/55288No logic change, just moving util-like code to the utils file.Test Plan:```python test/test_quantization.py TestFXNumericSuiteCoreAPIs```Imported from OSSReviewed By: hx89Differential Revision: D27575423fbshipit-source-id: cd5188a0940bb664be7d0275faa7df8ea18401a8",1,Extract Method,,
47ac468504a7e7c6b7e9d5d3d2f0737ddea399ed,2017-11-14T19:28:05Z,https://github.com/pytorch/pytorch/commit/47ac468504a7e7c6b7e9d5d3d2f0737ddea399ed,Remove dilations for pooling in onnx export and other small fixes (#3698)* fix optimization pass issues* remove pool dilations,1,Extract Method,,
481a334b7a5cf55bcdbb5836b7f58e150792d04d,2023-02-02T15:10:14Z,https://github.com/pytorch/pytorch/commit/481a334b7a5cf55bcdbb5836b7f58e150792d04d,"[FSDP][3/N] Refactor `summon_full_params` unit tests (#92298)  **Overview** - This PR refactors the `summon_full_params()` unit tests to prepare for `unshard_params()` by consolidating redundant tests and improving others. - This PR enables `CPUOffload(offload_params=True)` + `NO_SHARD` + `writeback=True`. - This PR provides an improved error message when calling `summon_full_params()` from an invalid context (i.e. from forward, backward, or in `summon_full_params()`).  **Details** <details> <summary>Existing Unit Tests</summary>  `test_summon_full_param_writeback()` with `world_size=1` `test_summon_full_param_writeback()` with `world_size=2` - Tests that `writeback=True` persists write and that `writeback=False` does not persist write when modifying a root FSDP instance's `flat_param` (`modify_outer=True`) or a non-root FSDP instance's `flat_param` (`modify_outer=False`); additionally configures with `mixed_precision` and `use_orig_params` - `CPUOffload(offload_params=True)` + `world_size=1` is not tested because it is not supported. - The write inside `summon_full_params()` is on the `flat_param` itself, which is not the expected usage.  `test_summon_full_param_shard_value()` - Tests that reconstructing the `flat_param` (by re-flattening and chunking parameters) inside `summon_full_params()` gives the same as the originally constructed `flat_param` when using a single FSDP instance - This test seems to exercise the FSDP sharding algorithm, not the specification of `summon_full_params()`. The only relevant part being implicitly tested is that `model.parameters()` order is preserved. - This test assumes the current FSDP sharding algorithm.  `test_summon_full_param_recursive()` - Tests that `recurse=True` recursively applies to all FSDP instances and that `recurse=False` does not - This test assumes the current FSDP sharding algorithm.  `test_cannot_summon_full_params_from_forward()` `test_cannot_summon_full_params_from_backward()` - Tests that calling `summon_full_params()` from inside the forward or backward raises an error - The error message leaks `FlatParamHandle` to the user. I provided a better error in this PR.  `test_summon_full_params_respects_reshard_after_forward()` - Tests that calling `summon_full_params()` after forward preserves whether the padded unsharded `flat_param` data is freed or not (like `reshard_after_forward`) - This test depends on FSDP internals (`flat_param._full_param_padded.storage().size()`).  `test_summon_single_param()` - Tests that writing to padding with `writeback=True` does not persist those writes (doing so by using a singleton `(1, 1)` parameter that gets flattened and padded to `(2,)`) - This test name is misleading.  `test_summon_full_params_equivalence()` - Tests `writeback`, `rank0_only`, and `offload_to_cpu` with `writeback=not rank0_only`, using `CPUOffload(offload_params=True)` and including a `torch.cuda._sleep(int(1e6))` _after_ the write in `summon_full_params()` - The PR introducing this test said that the `torch.cuda._sleep(int(1e6))` exercised the stream synchronization in `summon_full_params()`--namely that the current stream waits for the all-gather stream after all-gathering the parameters. I did not follow conceptually how that works since the `torch.cuda._sleep()` call happens after both the all-gather and write and is in the default stream, which seems to be after the relevant ops. If we clarify this, I can re-incorporate this into the unit tests. Doing so is not a high priority since `summon_full_params()` unshards in the default stream now and does not require stream synchronization. - This unit test has overlap with `test_summon_full_param_writeback()` and can be coalesced.  `test_summon_from_non_fsdp()` - Tests calling `summon_full_params()` with default args on a non-FSDP root module exposes the original parameters correctly - This test actually covers much of the specification since checking for original parameter equivalence includes shape, value, device, etc. checking.  `test_reshard_outside_forward_backward_iteration()` - Tests that calling `summon_full_params()` after forward preserves whether the padded unsharded `flat_param` data is freed or not (like `reshard_after_forward`) and that calling `summon_full_params()` after backward preserves that the padded unsharded `flat_param` data are freed; additionally configures `mixed_precision` - This test strictly dominates `test_summon_full_params_respects_reshard_after_forward()` in strictness since it includes the check after backward as well.  `test_params_are_unflattenned()`  - Tests that original parameters are exposed with the unflattened shape factoring in `rank0_only` (e.g. including that nonzero ranks reshard early when `rank0_only=True`) and that with `offload_to_cpu=True`, the `flat_param`s are moved back to GPU after exiting the context; additionally configures `mixed_precision`  `test_params_count_and_value()` - Tests that original parameters are all exposed and with the correct values factoring in `rank0_only` (e.g. including that nonzero ranks do not expose the original parameters when `rank0_only=True`) and that with `offload_to_cpu=True`, the `flat_param`s are moved back to GPU after exiting the context; additionally configures `mixed_precision`  `test_raises_rank0_with_writeback()` - Tests that `rank0_only` + `writeback=True` raises an error  `test_named_parameters_buffers()` - Tests that `named_parameters()` and `named_buffers()` return clean names (without FSDP prefixes) inside `summon_full_params()`  `test_with_grads_core()` - Tests `with_grads=True` by comparing against DDP  `test_with_grads_none_grads()` - Tests `with_grads=True` when ranks' `FlatParameter`s have `None` gradient  </details>  <details> <summary>New Unit Tests</summary>  `test_unshard_params_writeback_no_shard()` (with `world_size=1`) `test_unshard_params_writeback()` (with `world_size=2`) - Tests the `writeback` argument (using the default value for all others)  `test_unshard_params_param_data_no_shard()` (with `world_size=1`) `test_unshard_params_param_data()` (with `world_size=2`) - Tests that parameters are exposed correctly for `recurse=True` and all other argument configs for a non-FSDP root module  `test_unshard_singleton_param_writeback()` - Tests `writeback=True` for a singleton parameter, which includes testing that writing to padding does not persist  `test_unshard_params_respects_reshard()` - Tests that unsharding parameters respects the expected reshard behavior between forward and backward as well as after backward  `test_unshard_params_recurse()` - Tests the `recurse` argument (using default for all others)  `test_offload_to_cpu_no_shard_raises()` - Tests that `offload_to_cpu=True` with `NO_SHARD` raises an error  </details>  <details> <summary>Summary of Unit Test Changes</summary>  - `test_summon_full_param_writeback` -> `test_unshard_params_writeback()` - `test_summon_full_params_equivalence()`, `test_params_are_unflattenned()`, `test_params_count_and_value()` -> `test_unshard_params_param_data()` - `test_summon_full_params_respects_reshard_after_forward()`, `test_reshard_outside_forward_backward_iteration()` -> `test_unshard_params_respects_reshard()` - `test_summon_full_param_recursive()` -> `test_unshard_params_recurse()` - `test_named_parameters_and_buffers()` unchanged - `test_with_grads_core()` unchanged - `test_with_grads_none_grads()` unchanged - `test_cannot_summon_full_params_from_forward()`, `test_cannot_summon_full_params_from_backward()` -> `test_unshard_params_from_forward_raises()`, `test_unshard_params_from_backward_raises()` - `test_raises_rank0_with_writeback()` -> `test_rank0_only_with_writeback_raises()` - `test_offload_to_cpu_no_shard_raises()` new - `test_summon_full_param_shard_value()` removed  </details>  Pull Request resolved: https://github.com/pytorch/pytorch/pull/92298 Approved by: https://github.com/rohan-varma",1,Extract Method,,
49754f44ee242cd3ee4abfd8b49b41cc376770db,2023-06-12T19:36:24Z,https://github.com/pytorch/pytorch/commit/49754f44ee242cd3ee4abfd8b49b41cc376770db,"Rewrite size/stride/numel TensorVariable handling (#103438)  The main concept behind this refactor is this: if we know that a size/stride/etc is constant, do NOT trace it into the graph, EXCEPT for any preexisting special cases that applied for static shapes. The refactor unfolds like this:  1. Delete the `dynamic_shapes` branches in torch/_dynamo/variables/builder.py which accept int/float/bool outputs. This is over-aggressive and we don't want to allow this (because if the operator returns a constant, we shouldn't have called wrap_fx_proxy in the first place.) This causes a bunch of failures because we are blindly feeding the result of size() call to wrap_fx_proxy when dynamic shapes is enabled. 2. Modify TensorVariable.call_method in torch/_dynamo/variables/tensor.py to avoid sending constant ints to wrap_fx_proxy. After normal specialization (which should be deleted, see https://github.com/pytorch/pytorch/pull/103434) we consult the fake tensor to see if the values in question have free variables or not. If they don't we short circuit tracing into graph. We only trace into graph if the operation in question is truly symbolic. Note that there is a near miss here: it's OK to trace x.size() call entirely into the graph, even if it doesn't have all dynamic shapes, because operator.getitem with int output is special cased in builder.py. This is a preexisting special case and I don't try to get rid of it. 3. It turns out that the change here also breaks torch_np compatibility layer. So I completely rewrite getattr handling in torch/_dynamo/variables/tensor.py to follow the same pattern (only trace into graph if truly dynamic).  There's some minor housekeeping in torch/fx/experimental/symbolic_shapes.py and some test files.  Signed-off-by: Edward Z. Yang <ezyang@meta.com>  Pull Request resolved: https://github.com/pytorch/pytorch/pull/103438 Approved by: https://github.com/larryliu0820",1,Extract Method,,
499696182677053f1527d07b128bd1509748afcb,2020-05-06T19:59:44Z,https://github.com/pytorch/pytorch/commit/499696182677053f1527d07b128bd1509748afcb,"In interpolate, only call _interp_output_size in one place (#37168)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/37168It looks like this was made a separate function because of the `dim` argument,but that argument is always equal to `input.dim() - 2`.  Remove the argumentand consolidate all call sites into one.  This also means that this will becalled on paths that previously didn't call it, but all those cases throwexceptions anyway.ghstack-source-id: 102773596Test Plan: Existing tests for interpolate.Reviewed By: kimishpatelDifferential Revision: D21209993fbshipit-source-id: 2c274a3a6900ebfdb8d60b311a4c3bd956fa7c37",1,Extract Method,Inline Method,
4e1060c609c094fd5f58041ebed803f74410ee36,2023-03-14T18:26:05Z,https://github.com/pytorch/pytorch/commit/4e1060c609c094fd5f58041ebed803f74410ee36,"[memory profiling] add a facility to gather combined C++/Python/TorchScript stack traces. (#95541)      This refactors the stack trace facility specific to memory profiling     in python+cuda to make a generic facility to generate combined stack     traces.      The generic facility (combined_traceback.h) does not require     python to be around to work, but will return python stacks if it is     present.      This facility is then used to add support for stack trace gathering in memory profiling that     happens directly from C++.      It is also used to expose a python API for gathering and symbolizing     combineds stacks.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/95541 Approved by: https://github.com/ezyang",1,Extract Method,,
4f468646d98f18a6418156b41183c5717d7c2f0e,2023-05-30T21:37:59Z,https://github.com/pytorch/pytorch/commit/4f468646d98f18a6418156b41183c5717d7c2f0e,[PT2][Quant][BE] refactor tets cose to reduce duplication and standardize (#102497)  Summary: This refactor introduces an internal function which selectively tests againt fx quant as well. Notably this does increase  test times so wo need to figure out how to resolve that.  Test Plan: test_quantization_pt2e  Reviewed By: jerryzh168  Differential Revision: D46154323  Pull Request resolved: https://github.com/pytorch/pytorch/pull/102497 Approved by: https://github.com/jerryzh168,1,Extract Method,,
5423c2f0e292bb09e44d33141de2ac51578f8ba0,2022-12-05T18:35:30Z,https://github.com/pytorch/pytorch/commit/5423c2f0e292bb09e44d33141de2ac51578f8ba0,Light refactor to how we get shape_env for graph lowering (#90139)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/90139 Approved by: https://github.com/ezyang,1,Extract Method,,
544cd8e1340da91b7bedaa7a4b755f3ac0122e7e,2023-04-16T00:07:21Z,https://github.com/pytorch/pytorch/commit/544cd8e1340da91b7bedaa7a4b755f3ac0122e7e,[SPMD] Refactor DSize to DSymInt to enable sym_numel (#99206)  This commit uses `aten.arange.default` and `aten.arange.start` to test `aten.sym_numel`.  Differential Revision: [](https://our.internmc.facebook.com/intern/diff/)  Differential Revision: [D45028715](https://our.internmc.facebook.com/intern/diff/D45028715) Pull Request resolved: https://github.com/pytorch/pytorch/pull/99206 Approved by: https://github.com/yifuwang,1,Extract Method,,
545abc292b4693fa4f308e535fddf9c90e3b1d01,2023-03-22T21:41:52Z,https://github.com/pytorch/pytorch/commit/545abc292b4693fa4f308e535fddf9c90e3b1d01,"[aot autograd] refactor to make functionalization self-contained (#96341)  This refactor should make it easier to add an export hook into aot autograd.  (1) I killed `create_forward_or_joint_functionalized()` (and the functions that it called, like `forward_or_joint()`) which used to handle autograd + functionalization all-in-one-go for the joint case, and was also used in the inference case.  I added a few separate helper functions:  `create_functionalized_graph()`: this takes a flat fn, and returns a functionalized fx graph. It is mostly just a thin wrapper around functionalization + make_fx(), but also has some extra logic to manually append `copy_()` ops to the end of the graph.  `fn_no_extra_mutations()`: this creates the fn that we want to trace in the inference code path. It takes in a function that it then calls, and returns the outputs + any (updated) mutated inputs.  `joint_fn_no_external_mutations()`: this creates the fn that we want to trace in the joint code path. It takes in a function, and traces out its joint. It also does the work of cloning inputs that are mutated and require gradients, returning mutated inputs as outputs, and returning intermediate bases as outputs  We should be able to add an export hook by basically adding a similar version of `joint_fn_no_external_mutations` but with a lot more restrictions (guaranteed to have no tangents, not synthetic bases, etc), and calling `create_functionalized_graph()` on it.  Differential Revision: [D44204090](https://our.internmc.facebook.com/intern/diff/D44204090) Pull Request resolved: https://github.com/pytorch/pytorch/pull/96341 Approved by: https://github.com/ezyang",1,Extract Method,,
553e4ec20df5e7e3fd23439fc1ecd4097a4bacc9,2017-06-26T16:11:16Z,https://github.com/pytorch/pytorch/commit/553e4ec20df5e7e3fd23439fc1ecd4097a4bacc9,"Refactor conv_test - no cuDNN+dilation+NHWCSummary:Place all the cuDNN version checks in a helper function. Easier to usein future tests and update for newer versions of cuDNN in one place.Fixes this error in `test_convolution_gradients`:```RuntimeError: [enforce fail at conv_op_cudnn.cc:519] status == CUDNN_STATUS_SUCCESS. 9 vs 0. , Error at: /data/caffe2/caffe2/operators/conv_op_cudnn.cc:519: CUDNN_STATUS_NOT_SUPPORTED Error from operator:input: ""X"" input: ""w"" output: ""Y"" name: """" type: ""Conv"" arg { name: ""stride"" i: 1 } arg { name: ""pad"" i: 0 } arg { name: ""order"" s: ""NHWC"" } arg { name: ""dilation"" i: 2 } arg { name: ""kernel"" i: 1 } device_option { device_type: 1 } engine: ""CUDNN""```Closes https://github.com/caffe2/caffe2/pull/839Reviewed By: salexspbDifferential Revision: D5292123Pulled By: akyrolafbshipit-source-id: 513cc742be73c29ffe24e9e964845a217405a73d",1,Extract Method,,
5739f777750da1093843a9abb4953d3c02917aee,2021-09-22T21:12:51Z,https://github.com/pytorch/pytorch/commit/5739f777750da1093843a9abb4953d3c02917aee,"[DDP] Refactor and remove sync_params (#64514)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/64514  sync_params is a misnomer since we don't actually synchroniz parameters. While removing this I realized `self._check_and_sync_module_buffers` does almost everything we need it to, so just refactored that and made DDP forward call into it. ghstack-source-id: 138684982  Test Plan: CI  Reviewed By: zhaojuanmao  Differential Revision: D30751231  fbshipit-source-id: add7c684f5c6c71dad9e9597c7759849fa74f47a",1,Extract Method,,
5ea418bf6319508e5204d2ae26f4f9cfb0cf5ebc,2022-12-16T21:27:27Z,https://github.com/pytorch/pytorch/commit/5ea418bf6319508e5204d2ae26f4f9cfb0cf5ebc,"[FSDP][3/N] Move `fsdp_modules(root_only=True)` -> `_get_fsdp_root_states()` (#90862)  - This PR introduces `_get_fsdp_root_states(state: _FSDPState, module: nn.Module)` to return all states that are FSDP root in the module tree rooted at `module`.    - This requires passing in both `state` and `module` because it must call `_lazy_init()` to check for root-ness, which requires that signature. - This PR moves the one internal usage of `FullyShardedDataParallel.fsdp_modules(root_only=True)` to use `_get_fsdp_root_states()`. Pull Request resolved: https://github.com/pytorch/pytorch/pull/90862 Approved by: https://github.com/rohan-varma",1,Extract Method,,
5ee230face2d7e26752a77c79949fc955269c521,2023-02-13T21:43:00Z,https://github.com/pytorch/pytorch/commit/5ee230face2d7e26752a77c79949fc955269c521,"[FSDP][1/N] Refactor module materialization (#94196)  **Overview** This refactors module materialization (i.e. meta device or `torchdistX` deferred initialization) to compute the parameter and buffer names as needed instead of pre-computing them. These are needed to reacquire references to the states (e.g. `module.get_parameter(param_name)`) after materialization since the materialization may create new variables.  This refactor simplifies `_get_fully_sharded_module_to_states()` (the core function for ""pseudo auto wrapping"") to better enable lowest common ancestor (LCA) module computation for shared parameters, for which tracking parameter and buffer names may complicate the already non-obvious implementation.  **Discussion** The tradeoff is a worst case quadratic traversal over modules if materializing all of them. However, since (1) the number of modules is relatively small, (2) the computation per module in the quadratic traversal is negligible, (3) this runs only once per training session, and (4) module materialization targets truly large models, I think this tradeoff is tolerable.  **For Reviewers** - `_init_param_handle_from_module()` initializes _one_ `FlatParamHandle` from a fully sharded module and represents the module wrapper code path. For this code path, there is no need to reacquire references to the parameters/buffers for now since the managed parameters are only computed after materialization. This works because the managed parameters have a simple definition: any parameter in the local root module's tree excluding those already marked as flattened by FSDP. Similarly, FSDP marks buffers to indicate that they have already been processed (synced if `sync_module_states`). - `_init_param_handles_from_module()` initializes _all_ `FlatParamHandle`s from a fully sharded module and represents the composable code path. For this code path, we must reacquire references to parameters/buffers because each logical wrapping is specified as a list of parameters/buffers to group together by those variables and because materialization may create new variables.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/94196 Approved by: https://github.com/rohan-varma",1,Extract Method,,
6492b7d22eaacdade4fd2967f22c115d8966c333,2023-06-02T17:14:56Z,https://github.com/pytorch/pytorch/commit/6492b7d22eaacdade4fd2967f22c115d8966c333,[PT2][Quant][BE] Refactor qnnpack_quantizer.py (#102701)  This diff refactors annotate functions so as to couple annotate functions with corresponding quantization configs that they support. This will help in dynamic quantization which is only supported for linear layers  Differential Revision: [D46235071](https://our.internmc.facebook.com/intern/diff/D46235071/) Pull Request resolved: https://github.com/pytorch/pytorch/pull/102701 Approved by: https://github.com/jerryzh168,1,Extract Method,,
6624a73837bee5b59f01bdd4d2f0d5619bd3ab1f,2023-02-27T02:50:58Z,https://github.com/pytorch/pytorch/commit/6624a73837bee5b59f01bdd4d2f0d5619bd3ab1f,"Move istype and object identity tests into a dispatching dictionary. (#95476)  The idea is to make it a little more obvious which branch you're going to go down in a subset of cases, and make it easier to detect if you've accidentally shadowed one condition with another (the reason I wrote this in the first place.) The type dictionary also makes it harder for people to accidentally use isinstance when they should have used istype.  Signed-off-by: Edward Z. Yang <ezyang@meta.com>  Pull Request resolved: https://github.com/pytorch/pytorch/pull/95476 Approved by: https://github.com/jansel",1,Extract Method,,
67c2f0ead969a8ace48ed354c6e937fae0087043,2017-10-20T15:19:43Z,https://github.com/pytorch/pytorch/commit/67c2f0ead969a8ace48ed354c6e937fae0087043,Separate out native processing into procecss_native; remove (TH)Type specific logic.,1,Extract Method,,
69d62373aab8e828e741e6132a77da3533c2295b,2023-02-25T02:23:40Z,https://github.com/pytorch/pytorch/commit/69d62373aab8e828e741e6132a77da3533c2295b,"Move multi-line wrap functions to helper (#95472)  My intention is to collapse all of the istype() and isinstance() and object identity tests into a more structured form involving a dict lookup. To do this conveniently, I need every continuation to be expressible in a single expression. Thus, all multi-line wrap methods are moved. This is code motion only, no logic changes.  Signed-off-by: Edward Z. Yang <ezyang@meta.com>  Pull Request resolved: https://github.com/pytorch/pytorch/pull/95472 Approved by: https://github.com/Skylion007",1,Extract Method,,
6d72c829855607953ac001a21e34692f278f6439,2017-12-15T18:50:32Z,https://github.com/pytorch/pytorch/commit/6d72c829855607953ac001a21e34692f278f6439,"Trace ATen native functions as themselves, not their implementations. (#4127)* Trace ATen non-primitive functions as themselves, not their implementations.Previously, if I invoked an ATen non-primitive function foo, which in turncalled subfoo, I would always see 'subfoo' in the trace (e.g., tracing'inlines' all of these operations.)  Such inlining is bad for ONNX(and can be bad for optimization) as it prevents high-leveloptimizations from taking advantage of the structure.  It mightbe right to inline, but give the optimizer a chance to work beforeinlining happens!The implementation here is surprisingly simple, because it usesthe ""DCE trick"".  Essentially, it doesn't matter if the constituentcalls perform tracing, because you can always trace it again, andoverride the trace nodes associated with the returned variables.The original trace becomes dead and can be DCE'd.While implementing this, I also refactored how 'isTracing' and'trace_outputs' works:- isTracing was previously a single function with overloads for  both Tensor and Variable arguments.  Unfortunately, such overloads  are not safe, because of how C++ implicit conversions work.  You  would think that C++ should never confuse an overload for  Variable with ArrayRef<Tensor>, but this is exactly what can  happen: Tensor is convertible to both Variable and ArrayRef<Tensor>,  thus it's ambiguous and C++ doesn't like it.  The last time I ran  into this problem, I applied initializer lists to everything and  called it a day.  A more robust fix is to separate out the  Variable and Tensor overloads, which I have done in this patch.- trace_outputs was fed as an initializer list, which doesn't work  when you have heterogenous inputs.  So instead we first feed  everything through 'flatten', which has overloads for each of the  argument patterns in ATen, which then goes on to the recordTrace  (which takes an ArrayRef).  This is *no less efficient*, because  we were allocating a vector anyway (to do the conversion from  vector of Tensor to vector of Variable).This fixes mean that 'index' can properly be traced... although theJIT still does not support it.  A failing test case has been added tothis effect.Some knock-on effects:- The fuser now knows about chunk as well as split.  They're pretty  similar so there is no problem.- There is a new 'canonicalize' pass in the JIT which renumbers a graph  so that all structurally equivalent graphs render the same.- We run DCE before the fuser tests, to make sure dead nodes don't  block fusion.- There are new ONNX exports for the newly introduced higher level ATen  operations.  This includes type_as (no-op case only), chunk, select.Zach didn't like the extra use of 'native' in the new codegen, sowe've introduced a new concept, 'abstract'.  An abstract functionis one that is implemented in derived types (e.g., CPUDoubleType),where as a concrete one is implemented in the base type (Type).Signed-off-by: Edward Z. Yang <ezyang@fb.com>",1,Extract Method,,
6e61629f103eef07d2c16a055dd4f906b7a3a99a,2023-02-26T22:39:04Z,https://github.com/pytorch/pytorch/commit/6e61629f103eef07d2c16a055dd4f906b7a3a99a,"[inductor] Refactors/improvements to max-autotune (#95554)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/95554 Approved by: https://github.com/ngimel, https://github.com/nmacchioni",1,Extract Method,,
72b0447f8d22413a388e794e122e3056bffbb735,2020-06-04T08:49:27Z,https://github.com/pytorch/pytorch/commit/72b0447f8d22413a388e794e122e3056bffbb735,"[pytorch] move tracing logic to a separate dispatch backend (#38467)Summary:This PR moves tracing logic out of the generated VariableType kernels, to associate it with a new dedicated dispatch key Tracer.It also toggles the dispatch key set at various places to keep the semantics unchanged - see the inline [Tracing Mode Switches] note.Sample generated code:```Tensor & __ilshift___Tensor(Tensor & self, const Tensor & other) {  #if !defined(PYTORCH_DISABLE_TRACING)  torch::jit::Node* node = nullptr;  std::shared_ptr<jit::tracer::TracingState> tracer_state;  if (jit::tracer::isTracing()) {    tracer_state = jit::tracer::getTracingState();    at::Symbol op_name;    op_name = jit::Symbol::fromQualString(""aten::__ilshift__"");    node = tracer_state->graph->create(op_name, /*num_outputs=*/0);    jit::tracer::recordSourceLocation(node);    jit::tracer::addInputs(node, ""self"", self);    jit::tracer::addInputs(node, ""other"", other);    tracer_state->graph->insertNode(node);    jit::tracer::setTracingState(nullptr);  }  #endif  static auto op = c10::Dispatcher::singleton().findSchemaOrThrow(""aten::__ilshift__"", ""Tensor"");  c10::Dispatcher::singleton().redispatch<Tensor &, Tensor &, const Tensor &>(op, c10::DispatchKey::Tracer, self, other);  #if !defined(PYTORCH_DISABLE_TRACING)  if (tracer_state) {    jit::tracer::setTracingState(std::move(tracer_state));    jit::tracer::addOutput(node, self);  }  #endif  return self;}```Pull Request resolved: https://github.com/pytorch/pytorch/pull/38467ghstack-source-id: 105215150Test Plan: CIDifferential Revision: D21570684fbshipit-source-id: 1a96761830307f9a934f38bfb9fe8b5b1763e0e0",1,Extract Method,,
743c385543502ae3fb18146c26e873ae9bbb67cc,2023-01-03T22:10:15Z,https://github.com/pytorch/pytorch/commit/743c385543502ae3fb18146c26e873ae9bbb67cc,refactor show_traces in memory_tracker (#90145)  refactor show_tracers in memory_tracker to make it plot multiple figures and also can load serialized stats and then plot figures Pull Request resolved: https://github.com/pytorch/pytorch/pull/90145 Approved by: https://github.com/rohan-varma,1,Extract Method,,
75469725650e8215198d676db199e843e526191f,2023-04-19T19:29:07Z,https://github.com/pytorch/pytorch/commit/75469725650e8215198d676db199e843e526191f,"[BE] Refactoring test execution and improving comments (#99467)  Sharing code between the code that handles test results in parallel vs serial mode.  Note that the original version of this code had an inconsistency between the two versions where it would execute `print_to_stderr(err_message)` on every test that ran in parallel, but for serial tests it would only invoke `print_to_stderr(err_message)` if `continue_on_error` was also specified.  By sharing code, this PR changes that behavior to be consistent between the two modes.  Also adding some comments.  <!-- copilot:poem --> ### <samp>🤖 Generated by Copilot at 029342c</samp>  > _Sing, O Muse, of the skillful coder who refined_ > _The PyTorch testing script, `run_test.py`, and shined_ > _A light on its obscure logic, with docstrings and comments_ > _And made it run more smoothly, with better error contents_ Pull Request resolved: https://github.com/pytorch/pytorch/pull/99467 Approved by: https://github.com/huydhn, https://github.com/malfet",1,Extract Method,,
796be045bb8248770c81734fe5af98e7376f4191,2021-03-24T21:30:58Z,https://github.com/pytorch/pytorch/commit/796be045bb8248770c81734fe5af98e7376f4191,"Refactor gradcheck (#53857)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/53857This PR basically just factors a lot of the logic out from the main gradcheck function into their own individual functions. It aims to avoid any behavior change (but we may not have enough tests to actually verify this). Refactorings that lead to any behavior chang are done in the next PR in this stack.The rationale for this change is 1) to make the main gradcheck function cleaner to read, and 2) also allow us to reuse the same pieces when we add the fast gradcheck.Maybe this PR is also a good place to add some tests for gradcheck, i.e., make sure gradcheck fails when it should fail, as to make sure that we are indeed not changing any logic. This will also help us make sure our fast_gradcheck does all the necessary checks:So far existing tests are:- test_gradcheck_fail_when_no_differentiable_outputs_and_num_grad_not_zero` (test_autograd)- test_gradcheck_single_input (test_autograd)- test_gradcheck_sparse_input (test_autograd)- test_gradcheck_nondeterministic (test_autograd)- test_gradcheck (test_overrides)Full coverage would potentially require adding the following missing tests (for each test for both raise_exception=True/False) - Methodology for getting the list below is that for every type of error message we spit out, we make sure we can hit it:- complex:  - when numerical != analytical when tested with imag grad_out- check_inputs  - ~when inputs are not dense, but check_sparse_nnz is false~  - ~when none of the inputs require grad~  - ~(warning) when inputs are not double precision~  - ~when layout is not mkldnn(aka has strides) and input has a dimension with stride 0.~- check_no_differentiable_outputs:  - ~when none of the outputs are differentiable, but numerical gradient is not zero~- check_outputs:  - ~when sparse outputs (always raise)~  - ~when mkldnn outputs (always raise)~- test_batched_grad  - ~when encounter runtime error while computing batched grad (print big message)~  - when not allclose (print out big message)- test_backward_mul_by_grad_output  - ~when layout of grad_input is not the same as input~  - ~when grad_input is sparse and has incorrect sparse_dim/dense_dim~  - ~when backward not multiplied by grad_output (sparse/non-sparse case)~  - when grad is incorrect type/size- test_undefined_grad  - ~when encounter runtime error while running backward~  - when we complete backward but grad inputs (the output of .grad()) is not none- check_analytical_jacobian_attributes (for both complex/non complex)  - when grad input is incorrect dtype/sizeTest Plan: Imported from OSSReviewed By: heitorschueroffDifferential Revision: D27201571Pulled By: soulitzerfbshipit-source-id: 86670a91e65740d57dd6ada7c6b4512786d15962",1,Extract Method,,
7b2e8bec851f078b53e83f5fdf0e0386c2cafdd8,2020-10-19T20:53:09Z,https://github.com/pytorch/pytorch/commit/7b2e8bec851f078b53e83f5fdf0e0386c2cafdd8,"[fx] Refactor Tracer so that find_module and root args creation could be overridden by implementations (#46493)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/46493This will allow us to override tow following methods of Tracer:-- get_module_qualified_name: to find qualified name of a module. In default implementation, it looks for module in registered modules and from there it gets to the name, but in some scenarios, the module being called could not be the exact same module that was registered.-- create_args_for_root: This allows to create and pass custom structured input (like dictionary with specific keys) to the main module, rather than pure proxy objects. This will also allows us to let proxy objects only represent tensors when they are passed to modules.ghstack-source-id: 114609258Test Plan: Unit tests passedReviewed By: zdevito, bradleyhdDifferential Revision: D24269034fbshipit-source-id: d7b67f2349dd516b6f7678e41601d6899403d9de",1,Extract Method,,
7d7b7abb3baf44e37033ac2e1843ce6a07475ce1,2021-07-10T23:59:29Z,https://github.com/pytorch/pytorch/commit/7d7b7abb3baf44e37033ac2e1843ce6a07475ce1,[Static Runtime] Separate function for getting always_alive values (#61506)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/61506  Separate out the logic of GetAlwaysAliveValues from GetLivenessMap so to simplify the code structure. Also you don't need to run GetLivenessMap if optimize_memory is turned off.  Reviewed By: ajyu  Differential Revision: D29423534  fbshipit-source-id: dbdeeb10f7bcad86a24aa12f741f7c9ab946bb3b,1,Extract Method,,
7d84ca6e06556cda846416fdc643aa5ff1900fde,2019-06-03T21:57:43Z,https://github.com/pytorch/pytorch/commit/7d84ca6e06556cda846416fdc643aa5ff1900fde,clean code to unify the logic to use fp16 by the optimizer engine (#20915)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/20915Clean the unary processor code. Some question are added into the comments to seek suggestions.Reviewed By: pjh5Differential Revision: D15448502fbshipit-source-id: ef0c45718c1a06187e3fe2e4e59b7f20c641d9c5,1,Extract Method,,
82091d666c28a511fb27cf7ee30a3f5c97eb21df,2023-05-06T16:01:49Z,https://github.com/pytorch/pytorch/commit/0bf9722a3af5c00125ccb557a3618f11e5413236,"[ONNX] Refactor Input/Output Adapter (#100490)  This PR refactors how InputAdapter and OutputAdapter is used throughout the exporter.  During refactoring, API issues with passes (torch.onnx._internal.fx._pass.Transform) were identified and should be tackled on another API. In short, some passes can modify the input/output of the model and the input/output adapter must be in sync with such change, otherwise, the adapters will not reflect the actual model input/output. The first instance of this issue was with `ReplaceGetAttrWithPlaceholder` pass that adds new inputs to the model. In order to work this around, a new input adapt step to append new inputs (generated by the pass) was introduced. That resulted in the number of inputs of the ONNX model to mismatch the numer of inputs of the pytorch model, though.  Follow up on https://github.com/pytorch/pytorch/pull/98421 Pull Request resolved: https://github.com/pytorch/pytorch/pull/100490 Approved by: https://github.com/BowenBao",1,Extract Method,,
82dd69326bc95005236d223b064c1d4ff940b1f5,2019-06-21T16:42:16Z,https://github.com/pytorch/pytorch/commit/82dd69326bc95005236d223b064c1d4ff940b1f5,"Split nn.Module._save_to_state_dict to make it overridable (#21933)Summary:# MotivationWe allow to override JIT module serialization with `__getstate__/__setstate__` in order to cover cases where parameters are not serializable. Use cases include: MKLDNN integration: https://github.com/pytorch/pytorch/blob/a388c783505987363717bd4da0b166e8d1d7ccb9/torch/utils/mkldnn.py#L18-L26and also fbgemm prepacked format integration for quantized tensors.However many Eager scripts use `torch.save(module.state_dict())` form of serialization. There are several ways to make it work:* make packed_weight itself pickleable (e.g. by binding `__getstate__/__setstate__` on C++ UDT level)    * change: we’d need to allow module buffers to be of arbitrary, non-Tensor types    * pro: no change to state_dict behavior    * cons: might not be directly inspectable by user calling .state_dict(), especially if packed weights represent several tensors fused together* make packed_weight being proper Tensor layout    * pro: no change to state_dict or buffers behavior    * cons: adding new tensor layouts is pretty costly today    * cons: doesn’t work if multiple tensors are packed in one interleaved representation* *[this approach]* allow Modules to override state_dict and return regular tensors    * pro: most flexible and hackable    * pro: maintains semantic meaning of statedict as all data necessary to represent module’s state    * cons: complicates state_dict logic    * cons: potential code duplication between `__getstate__/__setstate__`Based on discussions with zdevito and gchanan we decided to pick latter approach. Rationale: this behavior is fully opt-in and will impact only modules that need it. For those modules the requirement listed above won't be true. But we do preserve requirement that all elements of state_dict are tensors. (https://fburl.com/qgybrug4 for internal discussion)In the future we might also implement one of the approaches above but those are more involved.Pull Request resolved: https://github.com/pytorch/pytorch/pull/21933Differential Revision: D15937678Pulled By: dzhulgakovfbshipit-source-id: 3cb5d1a8304d04def7aabc0969d0a2e7be182367",1,Extract Method,,
84af0c7acdac705e0465d4865cd37e6cfe2cd537,2021-03-13T21:34:22Z,https://github.com/pytorch/pytorch/commit/84af0c7acdac705e0465d4865cd37e6cfe2cd537,Refactor ForeachUtils.h (#51131)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/51131--------- Refactored `can_use_fast_route` logic in ForeachUtils.h.- Fixed related bugs in test_foreach.pyTest Plan: Imported from OSSReviewed By: zou3519Differential Revision: D26103904Pulled By: izdebyfbshipit-source-id: b3859b39adaab55c87dab6f7709d227adc0f6342,1,Extract Method,,
84b6c629d3ed0aff3dea7d3e0c2fdb50fc46d8ab,2021-05-22T01:23:40Z,https://github.com/pytorch/pytorch/commit/84b6c629d3ed0aff3dea7d3e0c2fdb50fc46d8ab,"[lint] Move shellcheck to its own step (#58623)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/58623  This splits out everything shellcheck related into its own job that generates and checks GHA workflows, then shellchecks those + jenkins scripts. This PR also integrates shellcheck into the changed-only stuff in `actions_local_runner.py` so that shellcheck won't do anything unless someone edits a shell script in their local checkout. This is the final piece to clean up the output of `make quicklint` and speeds it up by a good bit (before it was shellchecking everything which took a few seconds):  ``` $ make quicklint -j $(nproc) ?quick-checks: Ensure no unqualified noqa ?quick-checks: Ensure canonical include ?quick-checks: Ensure no unqualified type ignore ?quick-checks: Ensure no direct cub include ?quick-checks: Ensure no tabs ?quick-checks: Ensure no non-breaking spaces ?shellcheck: Regenerate workflows ?quick-checks: Ensure no versionless Python shebangs ?quick-checks: Ensure correct trailing newlines ?shellcheck: Assert that regenerating the workflows didn't change them ?mypy (skipped typestub generation) ?cmakelint: Run cmakelint ?quick-checks: Ensure no trailing spaces ?flake8 ?shellcheck: Extract scripts from GitHub Actions workflows ?shellcheck: Run Shellcheck real 0.92 user 6.12 sys 2.45 ```  Test Plan: Imported from OSS  Reviewed By: nikithamalgifb  Differential Revision: D28617293  Pulled By: driazati  fbshipit-source-id: af960ed441db797d07697bfb8292aff5010ca45b",1,Extract Method,,
878b0e35f7723a4638a9cd65f5b9601073e92958,2019-12-18T05:53:25Z,https://github.com/pytorch/pytorch/commit/878b0e35f7723a4638a9cd65f5b9601073e92958,"Simplify recursive script compilation flow. (#31019)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/31019No more `recurisve_script`, just direct calls to `create_script_module`.This reduces the number of pathways through the frontend, and theuniformity is useful for a future PR.Test Plan: Imported from OSSDifferential Revision: D18904113Pulled By: suofbshipit-source-id: 7de061dfef0cbdfc9376408fc6c1167b81803f01",1,Extract Method,,
89769d84ebbbbe1e623ddfb82f2e6946fc35af57,2022-11-30T20:29:41Z,https://github.com/pytorch/pytorch/commit/89769d84ebbbbe1e623ddfb82f2e6946fc35af57,"[FSDP][BE] Move dynamo annotation to separate file (#89890)  This PR makes two minor changes: It (1) moves the recently-added module annotation logic for dynamo support to a separate file `torch/distributed/fsdp/_dynamo_utils.py` and ~~(2) saves the annotated attribute names to global variables `FSDP_MANAGED_MODULE` and `FSDP_USE_ORIG_PARAMS`~~. Update: Since the distributed package may not be included in some builds, it is not safe to import from `torch.distributed...` to a file in `_dynamo/`. I will not include change (2) in this PR. The alternative is to define those globals (privately) in the dynamo file and import from there in the FSDP file. - The first change is mainly a personal choice, where I wanted to avoid the dynamo explanation from dominating the FSDP constructor space-wise. I added the `(see function for details)` to the inline comment to forward interested readers. - The second change follows the custom we have taken in the past for such attributes (e.g. `FSDP_FLATTENED`). My understanding (in the past as well as currently) is that this is a good practice.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/89890 Approved by: https://github.com/wconstab",1,Extract Method,,
8987726cc643044e1d554d5bac818cef0596306f,2021-08-16T01:08:12Z,https://github.com/pytorch/pytorch/commit/8987726cc643044e1d554d5bac818cef0596306f,Small refactor for OpInfo decorators (#62713)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/62713  Test Plan: Imported from OSS  Reviewed By: VitalyFedyunin  Differential Revision: D30327200  Pulled By: heitorschueroff  fbshipit-source-id: 1899293990c8c0a66da88646714b38f1aae9179d,1,Extract Method,,
8a2063e58a8a9438fa192b6b538ccda92cb7c88b,2021-07-22T04:59:57Z,https://github.com/pytorch/pytorch/commit/8a2063e58a8a9438fa192b6b538ccda92cb7c88b,"Foreach Test Refactor: Pointwise, Min/Max-imum (#61327)  Summary: - rewrite pointwise unittests using `ops` decorator - rewrite minimum&maximum unittests using `ops` decorator - enable minimum/maximum fastpath for BFloat16 - remove _test_data method  https://github.com/pytorch/pytorch/issues/58833  cc: ptrblck ngimel  Pull Request resolved: https://github.com/pytorch/pytorch/pull/61327  Reviewed By: albanD  Differential Revision: D29830209  Pulled By: ngimel  fbshipit-source-id: fa7805262b86c40fc32750b16629d80ad48ea4b5",1,Extract Method,,
8cdc4807cdda4c773097283de0d1c93fa4a550da,2020-05-15T00:05:51Z,https://github.com/pytorch/pytorch/commit/8cdc4807cdda4c773097283de0d1c93fa4a550da,[RELAND] .circleci: Improve docker image build workflow (#38484)Summary:closes https://github.com/pytorch/pytorch/issues/37855Relies on https://github.com/pytorch/pytorch/pull/38483Previous attempts to get this right:* https://github.com/pytorch/pytorch/pull/38335* https://github.com/pytorch/pytorch/pull/38279* https://github.com/pytorch/pytorch/pull/37976This reverts commit 80639604a82422e314890f154242202a43d264f9.Improves the docker image build workflow from many steps to basicallytransparent from a user's perspective.To update docker images now all one has to do is edit the.circleci/docker folder and it will update automatically and alsodynamically add the tags to the list of tags to keep from the garbagecollector.Adding a new image will currently stay the same but we can explore doingthat dynamically as well.How the build workflow works:  - Docker tags are determined by the hash defined from git for the    .circleci/docker sub-directory (extracted using git rev-parse)  - Images are only built if the computed hash is not found in ecr and    the hash is different than the previously computed hash. The    previously computed hash is found using the same process as before    but subbing out HEAD for the merge base between HEAD and the base    git revision  - That tag is then passed through the jobs using a shared workspace    which is added to downstream jobs using the circleci ${BASH_ENV}How the new garbage collection works:  - Tags to keep are generated by stepping through all of the commits in    in the .circleci/docker subdirectorySigned-off-by: Eli Uriegas <eliuriegas@fb.com>Pull Request resolved: https://github.com/pytorch/pytorch/pull/38484Differential Revision: D21585458Pulled By: seemetherefbshipit-source-id: 37792a1e0f5e5531438c4ae61507639c133aa76d,1,Extract Method,,
8ef13cf97637a6132c6d7f6e930f3fdcea0e8f94,2021-04-15T22:15:24Z,https://github.com/pytorch/pytorch/commit/8ef13cf97637a6132c6d7f6e930f3fdcea0e8f94,[optim] refactor rprop to use functional API (#55832)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/55832ghstack-source-id: 126325541Reviewed By: driazatiDifferential Revision: D27703877fbshipit-source-id: 34d4ce7b7d124c0cd75e2f6d0bc8f836713b7301,1,Extract Method,,
9354a68e7d8c4680a115b70b9b14565cd42cb03f,2021-05-17T19:25:35Z,https://github.com/pytorch/pytorch/commit/9354a68e7d8c4680a115b70b9b14565cd42cb03f,"[codegen] split out backend-specific information from NativeFunction in the model (#57361)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/57361  Data model change in the codegen, which splits backend-specific information out of `NativeFunction`  ### Overview Currently in the codegen, native_functions.yaml has backend-specific information about each operator that is encoded directly into the data model, in the `NativeFunction` object. That's reasonable, since the native_functions.yaml is the source of truth for information about an operator, and the data model encodes that information into types.  Now that external backends can use the codegen though, that information is technically incomplete/inaccurate. In another PR, I tried patching the information on the `NativeFunction` object with the additional external information, by updating the `dispatch` entry to contain the external backend kernel name and dispatch key.  Instead, this PR tries to split out that information. The `NativeFunction` class contains all information about an operator from native_functions.yaml that's backend-independent and is known never to change regardless of what extra information backends provide. We also build up a backend ""index"", which is basically a mapping from [backend] -> [backend-specific-metadata]. Reading in an external backend yaml just involves updating that index with the new backend.  There were a few places where `NativeFunction` used the dispatch table directly, that I encoded as properties directly on the NativeFunction object (e.g. `is_abstract`). They were mostly around whether or not the operator has a composite kernel, which isn't something that's going to change for any external backends.  This has a few advantages: - We can more easily re-use the existing logic in `native_function.py` and `register_dispatch_key.py` for both native and external backends, since they both involve a NativeFunction + a particular backend index - The data in the data model will be the same regardless of how the codegen is run. Running the codegen with a new external backend doesn't change the data inside of NativeFunction or an existing backend index. It just adds a new index for that backend. - There are several of codegen areas that don't care about backend-specific information: mostly the tracing and autograd codegen. We can reason about the codegen there more easily, knowing that backend-specific info is entirely uninvolved.  An alternative to this split would be to augment the NativeFunction objects with external backend information at the time that we create them. So the external codegen could read both native_functions.yaml and the external backend's yaml at the same time, and construct a NativeObject with a full dispatch table (including the XLA entry), and the correct setting of structured (taking into account both yamls). One disadvantage to this approach is that NativeFunction objects now contain different stuff depending on how you ran the codegen, and you have to make sure that any changes to the codegen can properly handle all the different variants.  ### Data Model Changes Removed 3 classes, which are used by the external codegen: - ExternalBackendFunction - ExternalBackendFunctionsGroup - ExternalBackendMetadata  And added two new ones: - BackendIndex - BackendMetadata  `BackendIndex` contains any info that's specific to that backend, plus a mapping from operator names to backend specific metadata about the operator. One example of backend-specific info that's not operator-dependent is the fact that XLA prefers to implement functional kernels instead of out kernels (and so when they eventually mark an op as structured, they're going to mark the functional op and not the out op).  `BackendMetadata` contains info specific to an (operator, backend) pair. Right now, that's just (a) the name of the kernel, and (b) whether or not that operator is structured.  ### Questions I wanted to get this PR up earlier so I could get feedback, but there are a few things I want to call out:  **Dealing with `structured`.** This PR separates out the notion of `structured` into two bits of information: - Does [operator] have a meta() function. This is backend-agnostic, and is represented by the `structured` property on `NativeFunction`, same as before. This is used, e.g., to decide what signatures to add to `MetaFunctions.h`. - Does [operator, backend] have an impl() function. This is backend dependent; even though technically all in-tree backends are forced to write impl() functions for an operator when we port the op to structured in native_functions.yaml, out-of-tree backends can decide to opt in independently. This is represented as a property on `BackendMetadata`. This is used in most other cases, e.g. in `RegisterDispatchKey` when we're deciding whether or not to gen a structured or unstructured wrapper.  I also baked `is_structured_dispatch_key` directly into each BackendIndex. So for operators marked ""structured"" in native_functions.yaml, their corresponding CPU/CUDA BackendIndex entries will be marked structured, and all others (except for potentially external backends) will not.  I ended up trying to deal with `structured` in this change since it's technically backend dependent (XLA can opt kernels into structured separately from in-tree ops), but that may have been too ambitious: it's technically not relevant until we actually add support for structured external kernels. If it's not clear that this is the right path for dealing with structured and we want to push that off, I'm fine with backing out the bits of this PR that make `structured` backend-dependent. I don't see anything *too* controversial related to structured in the change, but I tried to call out any areas in the comments  **Localizing the fact that external backends follow Dispatcher convention.** Another thing that's sort of backend specific that I didn't totally address in this PR is the fact the fact that in-tree backends follow the Native API while external backends follow the Dispatcher API. I painted over that in `native_functions.py` by adding a helper, `kernel_signature`, that takes in a native function and gives you the ""correct"" signature for the specified backend- NativeSignature for in-tree backends, and DispatcherSignature for out-of-tree backends. In order to make that fully useable though, we'll need `NativeSignature` and `DispatcherSignature` to have matching interfaces. I didn't bother with that in this PR, which is why `gen_external_aten_fallbacks.py` still has a bunch of direct references to the dispatcher API. Thinking of adding it in a later PR but wanted to see if anyone has other opinions.  Maybe `is_external()` shouldn't even be a property on the BackendMetadata, and anything the codegen does that requires asking for that information should just be better abstracted away.  **Thoughts on the `BackendIndex` / `BackendMetadata` breakdown.** One thing that's annoying right now is that to query for various pieces of metadata, you call helper functions like `backend_index.structured(f)`, which queries that particular backend and tells you if that specific NativeFunctionGroup is structured for that backend. It has to return an `Optional[bool]` though, since you have to handle the case where that operator doesn't have a kernel for that backend at all. So users of those helpers end up with a bunch of optionals that they need to unpack, even if they know at some point that the result isn't None. I think it would be easier instead to just store the NativeFunction object as a field directly on the BackendMetadata. Curious if there are any other opinions on a better way to model it though.  Test Plan: Imported from OSS  Reviewed By: navahgar  Differential Revision: D28474362  Pulled By: bdhirsh  fbshipit-source-id: 41a00821acf172467d764cb41e771e096542f661",1,Extract Method,,
937950e06473518e7a4852abc459039fe2686f20,2017-10-03T15:49:54Z,https://github.com/pytorch/pytorch/commit/937950e06473518e7a4852abc459039fe2686f20,"Move default arguments to function declaration * Make alpha, beta in addmm kwarg_only * Move kwarg_only arguments to the end * _out variants now have output arguments at the beginning",1,Extract Method,,
94b730681f749d2dd5c6bc8f52d993e9e1103397,2021-07-03T01:47:23Z,https://github.com/pytorch/pytorch/commit/94b730681f749d2dd5c6bc8f52d993e9e1103397,[DDP] Refactor uneven inputs to take GradBucket (#61019)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/61019  Changes uneven input logic of running allreduce to using `GradBucket` structure. This is to enable support for comm. hook with join in the next diff. ghstack-source-id: 132950107  Test Plan: ci  Reviewed By: SciPioneer  Differential Revision: D29480027  fbshipit-source-id: 7c42c53653052f71b86a75e14a5fc7ae656433f7,1,Extract Method,,
986e3c0a00677355c1edbd89a959264fa0aea1c4,2021-03-12T17:53:02Z,https://github.com/pytorch/pytorch/commit/986e3c0a00677355c1edbd89a959264fa0aea1c4,ns for fx: extract common code in tests to util functions (#53748)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/53748Extracts common testing patterns for FX numeric suite intoutil functions.  No logic change.Test Plan:```python test/test_quantization.py TestFXNumericSuiteCoreAPIspython test/test_quantization.py TestFXNumericSuiteCoreAPIsModels```Imported from OSSReviewed By: raghuramank100Differential Revision: D26967105fbshipit-source-id: 9f6cbe75bb6d2ede142929e0c9e40812006c159d,1,Extract Method,,
9f22805cc6312a98b2d4d2bb8f851b62e7307c5b,2019-06-26T14:57:49Z,https://github.com/pytorch/pytorch/commit/9f22805cc6312a98b2d4d2bb8f851b62e7307c5b,"Refactor function_wrapper.create_generic (#22077)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/22077ghimport-source-id: 39cf0a2e66e7fa2b6866af72782a22a4bd025e4cTest Plan:- Compared the build/aten/src folder before and after this changelocally and verified they are identical (`diff -r`).- Wait for CI + Also, [namedtensor ci]Imported from OSSDifferential Revision: D15941967Pulled By: zou3519fbshipit-source-id: d8607df78f48325fba37e0d00fce0ecfbb78cb36",1,Extract Method,,
a01e91e6b2ab28b000d66588b9d32a91f8fc4e62,2020-07-31T19:41:35Z,https://github.com/pytorch/pytorch/commit/a01e91e6b2ab28b000d66588b9d32a91f8fc4e62,"[pytorch] include all overloads for OSS custom buildSummary:For mobile custom build, we only generate code for ops that are used byspecific models to reduce binary size.There multiple places where we apply the op filtering:- generated_unboxing_wrappers_*.cpp- autograd/VariableType*.cpp- c10 op registration (in aten/gen.py)For c10 op registration, we filter by the main op name - all overloadsthat match the main op name part will be kept.For generated_unboxing_wrappers_*, we filter by the full op name - onlythose having exactly the same overload name will be kept.This PR changes generated_unboxing_wrappers_* and autograd/VariableType*.cppcodegen to also filter by the main op name.The reasons are:- keeping all overloads can have better backward compatibility;- generated_unboxing_wrappers_* are relatively small as it only contains  thin wrappers for root ops.- generated_unboxing_wrappers_* will be replaced by c10 op registration  soon anyway.- autograd/VariableType*.cpp are not included in OSS build.Why it offers better backward compatibility? #40737 is an example:It introduced a new `_convolution` overload and renamed the original oneto `_convolution.deprecated`. Before this PR, the model prepared by theold version PyTorch won't be able to run on the custom mobile buildgenerated on the PR because `_convolution.deprecated` won't be kept inthe custom build due to full op name matching policy. By relaxing it topartial matching policy, the mobile custom build CI on the PR can pass.Will test the size impact for FB production build before landing.Differential Revision: D22809564Test Plan: Imported from OSSReviewed By: iseeyuanPulled By: ljk53fbshipit-source-id: e2fc017da31f38b9430cc2113f33e6d21a0eaf0b",1,Extract Method,,
a0cf5566d88533c5caa7a490beb6eb0760eee9b4,2021-01-21T18:54:17Z,https://github.com/pytorch/pytorch/commit/a0cf5566d88533c5caa7a490beb6eb0760eee9b4,[optimizer] refactor SGD to use functional API (#45597)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/45597Test Plan: Imported from OSSReviewed By: izdebyDifferential Revision: D25932773Pulled By: wanchaolfbshipit-source-id: bc5f830d6812f847475b9bdcc67865d9968e3282,1,Extract Method,,
a2694699821be04e6a74760ba754911e714a5486,2023-03-15T13:45:43Z,https://github.com/pytorch/pytorch/commit/a2694699821be04e6a74760ba754911e714a5486,"aot autograd refactor: make all synthetic base logic layered in a single location (#96235)  This  refactor doesn't significantly change LoC in aot autograd, but I think this nets out to making it clearer (interested in peoples' thoughts).  The idea is that I tried to re-write the part of aot autograd that deals with synthetic bases in a layered way, similar to how Ed wrote the logic for dedup'ing inputs: it happens in one place, and all of the downstream transformation in aot autograd don't have to worry about it.  Specifically, I added a new function `aot_wrapper_synthetic_base`, similar to the existing `aot_wrapper_dedupe`.  The benefit: none of the other code in aot autograd needs to think about synthetic bases (previously, synthetic base code was intertwined in several places).  The downsides: there are two.  (1) `aot_wrapper_synthetic_base()` needs to have its own epilogue. There is one particularly hairy case, where factoring the synthetic base logic to a single location was painful: If you have two inputs that alias each other, where one gets a data mutation, and the other gets a metadata mutation.  Ordinarily, metadata mutations are handled by the runtime epilogue, in `create_runtime_wrapper`. However, now that things are factored this way, the runtime wrapper operates only on synthetic bases instead of operating on the original inputs. For data mutations, it is fine to apply the data mutation to the synthetic base instead of the original input alias. But for metadata mutations, we **need** to apply the metadata mutation directly to the original inputs.  The way that I handled this was by tracking which inputs slot into this specific case (part of a synthetic base, and get metadata mutations), and updateing the flat_fn() that we pass downstream to return these updated inputs as extra outputs. From the perspective of downstream logic, these are real user outputs, that it can treat like any other user outputs. `aot_wrapper_synthetic_base` will know to grab these extra outputs and use them to apply the metadata mutations.  This was pretty annoying, but has the benefit that all of that logic is encapsulated entirely in `aot_wrapper_synthetic_base()`.  (2) input mutations are now performed on the synthetic base instead of the individual aliases.  You can see the original code comment [here](https://github.com/pytorch/pytorch/blob/b0b5f3c6c681896febbd9ff7ad7649b13def345d/torch/_functorch/aot_autograd.py#L1131) for details. We used to do the optimized thing in this case, and now we do the less optimized thing (copying the entire synthetic base, instead of the potentially smaller alias).  To be fair, we had no data showing that this optimization was showing improvements on any models in practice. I also think that the main reason anyone would ever run across this problem is because of a graph break - so if you care about perf, you probably want to avoid the extra graph breaks to begin with. I haven't added any warnings for this, but we probably could depending on what people think.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/96235 Approved by: https://github.com/ezyang",1,Extract Method,,
a55b7e2a6d8bb1fe84589ededc300f2056f7b498,2020-08-14T03:42:28Z,https://github.com/pytorch/pytorch/commit/a55b7e2a6d8bb1fe84589ededc300f2056f7b498,"[reland][quant][fix] Remove activation_post_process in qat modules (#42343) (#43015)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/43015Currently activation_post_process are inserted by default in qat modules, which is notfriendly to automatic quantization tools, this PR removes them.Test Plan:Imported from OSSImported from OSSReviewed By: vkuzoDifferential Revision: D23105059fbshipit-source-id: 3439ac39e718ffb0390468163bcbffd384802b57",1,Extract Method,,
a9983ac09c9772fa426224b080090083b4c9607b,2021-08-27T16:38:27Z,https://github.com/pytorch/pytorch/commit/a9983ac09c9772fa426224b080090083b4c9607b,"Refactor structured set_output in Register{DispatchKey}.cpp (#62188)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/62188  These parts of the `set_output` code are identical for all operators in the kernel registration files. So, this moves them from being copied into every class to two helper functions at the top of the file.  Test Plan: Imported from OSS  Reviewed By: soulitzer  Differential Revision: D29962045  Pulled By: albanD  fbshipit-source-id: 753b8aac755f3c91b77ffa2c30a89ac91a84b7c4",1,Extract Method,,
ad5be26b2fee9303a93ec921be450a40504969ed,2020-11-12T19:06:50Z,https://github.com/pytorch/pytorch/commit/ad5be26b2fee9303a93ec921be450a40504969ed,"Small changes/cleanup (#46950)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/46950Make sure that we're fusing in a fuse tests, and refactor to more concise API to check if fusions have happened.Test Plan: Imported from OSSReviewed By: ansleyDifferential Revision: D24805250Pulled By: eellisonfbshipit-source-id: f898008a64b74e761bb5fe85f91b3cdf2dbdf878",1,Extract Method,,
b628eb524be9261acf198a59dff89e462550fe4a,2023-05-25T23:52:35Z,https://github.com/pytorch/pytorch/commit/b628eb524be9261acf198a59dff89e462550fe4a,simplify BinaryDivFloorKernel.cu code (#102168)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/102168 Approved by: https://github.com/ngimel,1,Extract Method,,
bb245b6444d3c5b9f586d93121730390985a0bae,2021-04-15T22:15:24Z,https://github.com/pytorch/pytorch/commit/bb245b6444d3c5b9f586d93121730390985a0bae,[optim] refactor adamax to use functional API (#55830)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/55830ghstack-source-id: 126325537Reviewed By: driazatiDifferential Revision: D26561017fbshipit-source-id: 41273d200e546d4ac08d39b57865d63c624f143a,1,Extract Method,,
bb48d90b00ed05025d14d44072997ba50c03bcd3,2023-02-09T01:20:17Z,https://github.com/pytorch/pytorch/commit/bb48d90b00ed05025d14d44072997ba50c03bcd3,[Executorch][Quant][BE] Refactor Choose_Qparams (#94338)  Summary: Refactor so that it can be decomposed  Test Plan: ci  Differential Revision: D42681268  Pull Request resolved: https://github.com/pytorch/pytorch/pull/94338 Approved by: https://github.com/jerryzh168,1,Extract Method,,
bbdadab306f52dc520cb9afc199186645b0f788e,2021-05-01T00:36:00Z,https://github.com/pytorch/pytorch/commit/bbdadab306f52dc520cb9afc199186645b0f788e,Refactor fast gradcheck (#55871)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/55871Test Plan: Imported from OSSReviewed By: albanDDifferential Revision: D28096549Pulled By: soulitzerfbshipit-source-id: ee8b71fbd03ee581e71cdfcfd5e2258adefe15a6,1,Extract Method,,
bc4ff7ba0506190524d598be1bbe8112f3e09935,2020-12-28T22:21:55Z,https://github.com/pytorch/pytorch/commit/bc4ff7ba0506190524d598be1bbe8112f3e09935,"fx quant: split linear test cases (#49740)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/497401. Separates the module and functional linear test cases.2. Combines the test case which tests for linear bias observation intothe main linear test case, as requested inhttps://github.com/pytorch/pytorch/pull/49628.Test Plan:```python test/test_quantization.py TestQuantizeFxOps.test_linear_modulepython test/test_quantization.py TestQuantizeFxOps.test_linear_functional```Imported from OSSReviewed By: jerryzh168Differential Revision: D25681272fbshipit-source-id: 0ed0ebd5afb8cdb938b530f7dbfbd79798eb9318",1,Extract Method,,
c0aa863c569aa853acbb9e89d2803d7fbffc5a34,2020-11-13T22:47:17Z,https://github.com/pytorch/pytorch/commit/c0aa863c569aa853acbb9e89d2803d7fbffc5a34,[quant][graphmode][fx][refactor] insert_quantize_node (#47880)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/47880Test Plan: Imported from OSSReviewed By: vkuzoDifferential Revision: D24928797fbshipit-source-id: 9a8b359cabfb800da86da114bf26bb5bd99d3fff,1,Extract Method,,
c25d0015f0b04ba3bb613ad61a9737ab9dcc80ef,2020-08-27T14:05:45Z,https://github.com/pytorch/pytorch/commit/c25d0015f0b04ba3bb613ad61a9737ab9dcc80ef,Autograd code clean up (#43167)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/43167Test Plan: Imported from OSSReviewed By: mruberryDifferential Revision: D23222358Pulled By: anjali411fbshipit-source-id: b738c63b294bcee7d680fa64c6300007d988d218,1,Extract Method,,
c3e3c5cc39165470ddab5afb6373399fdbd6598e,2019-03-27T18:14:32Z,https://github.com/pytorch/pytorch/commit/c3e3c5cc39165470ddab5afb6373399fdbd6598e,"Skip tests if C2/ONNX models cannot be read (#18494)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/18494Today we have some C2 end2end test run requiring reading model data from external filesystem (for example, Gluster and AWS). This could be a source for flaky test when the external filesystems are not reachable during the tests.In this diff, we add try/catch logic around where we download models and open model files from external system. In case such attempts fails, we will catch the excption and let the unittest skip the current test instead of failure.I also refactor the code a little bit by removing some duplicated logic on downloading and build the c2 model data. It has been duplicated in two classes and a few functions...Reviewed By: yinghaiDifferential Revision: D14442241fbshipit-source-id: da8bf56c8d096efa34ca2070de5cd10a18aad70c",1,Extract Method,,
c445f4ee939aad6d80bcdf5deb14e9259cf3994b,2021-04-01T01:48:58Z,https://github.com/pytorch/pytorch/commit/c445f4ee939aad6d80bcdf5deb14e9259cf3994b,[quant][graphmode][fx][refactor] Factor out insert_observers_for_model to a separate function (#54733)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/54733Test Plan: Imported from OSSReviewed By: vkuzoDifferential Revision: D27408378fbshipit-source-id: 9143f0a6f939fa80f1d1d6bae4b2d37aa21cb9b9,1,Extract Method,,
c4bec76bec0dc7fb677546f6d718be43429c170a,2021-04-27T23:26:26Z,https://github.com/pytorch/pytorch/commit/c4bec76bec0dc7fb677546f6d718be43429c170a,"ns for fx: move node I/O dtype mapping to be local instead of global (#57021)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/57021To support shadows of custom functions, we need to allow user tospecify I/O type of the custom functions.This PR is a cleanup in preparation for making the above happen.We make the I/O dtype mappings be generated by a function insteadof a global variable. In the next PR, we will add a hook so usercan modify these mappings.Test Plan:```python test/test_quantization.py TestFXNumericSuiteCoreAPIs```Reviewed By: jerryzh168Differential Revision: D28030094Pulled By: vkuzofbshipit-source-id: 3cbb617f034ef385c2875c4ec7fed13ca30bfc57",1,Extract Method,,
c4ecbcdcb317ffab2b4bba51915bad77b212b0b0,2020-11-13T04:42:07Z,https://github.com/pytorch/pytorch/commit/c4ecbcdcb317ffab2b4bba51915bad77b212b0b0,[quant][graphmode][fx][refactor] insert_observer_for_special_module (#47783)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/47783Test Plan:python test/test_quantization.py TestQuantizeFxImported from OSSReviewed By: vkuzoDifferential Revision: D24900304fbshipit-source-id: 11cc3dd4ea5e272209db9f3c419deadd40db5f42,1,Extract Method,,
c57541ce060e2043d0b30b3b382e2da7c1355695,2021-04-01T00:46:37Z,https://github.com/pytorch/pytorch/commit/c57541ce060e2043d0b30b3b382e2da7c1355695,"[quant][graphmode][fx] Separate handling Copy operator to a helper function (#54644)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/54644Previously we special case copy operator in normal insert observer code, this PR tries to split thespecial case logic to a separate function and keep the rest of the code clean.Test Plan: Imported from OSSReviewed By: vkuzoDifferential Revision: D27314678fbshipit-source-id: d36870ceb3717bc01eaeaa6f3f1532ad562cbaf1",1,Extract Method,,
cd8b82e5c6a69c94212a54baff73069a9eba2127,2023-05-08T13:27:39Z,https://github.com/pytorch/pytorch/commit/cd8b82e5c6a69c94212a54baff73069a9eba2127,bsr_dense_mm(): code refactoring (#100634)  Code unification/refactoring for better re-use. Intended for easier `sampled_addmm` implementation.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/100634 Approved by: https://github.com/cpuhrsch,1,Extract Method,,
ce1781d8db7ebe7d58f0a44160fa81b230aecdce,2021-01-21T18:54:17Z,https://github.com/pytorch/pytorch/commit/ce1781d8db7ebe7d58f0a44160fa81b230aecdce,[optimizer] refactor RMSProp to use functional API (#50410)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/50410Test Plan: Imported from OSSReviewed By: izdebyDifferential Revision: D25932779Pulled By: wanchaolfbshipit-source-id: b0d6007ea83d77e2d70d04681163ea7e4632c5cd,1,Extract Method,,
d6fb27ce72f357300abe65c2676f69a5848cb997,2021-01-21T18:54:17Z,https://github.com/pytorch/pytorch/commit/d6fb27ce72f357300abe65c2676f69a5848cb997,[optimizer] refactor Adadelta to use functional API (#50409)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/50409Test Plan: Imported from OSSReviewed By: izdebyDifferential Revision: D25932780Pulled By: wanchaolfbshipit-source-id: 2fc025f66a0e0863f21689892e19d8a5681f2f2f,1,Extract Method,,
da9af9868e0bd8cb516690bcce34e29ea414cf5e,2022-12-20T16:49:13Z,https://github.com/pytorch/pytorch/commit/da9af9868e0bd8cb516690bcce34e29ea414cf5e,"[FSDP][4/N] Refactor func to share state/init handle attrs (#90871)  For `limit_all_gathers`, if we do not enforce that they all have the same value, then the entire semantics guaranteed by the `bool` can be violated. It could be as if none of them set that value to be `True`.  For `use_orig_params`, optimizer state dict assumes that the value is the same for all FSDP instances.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/90871 Approved by: https://github.com/mrshenli",1,Extract Method,,
dd77d5a1d4cf175d46de4c3630d8c1ac36fdac67,2020-11-12T04:56:56Z,https://github.com/pytorch/pytorch/commit/dd77d5a1d4cf175d46de4c3630d8c1ac36fdac67,[quant][refactor] factor out get_combined_dict function (#47781)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/47781Test Plan: Imported from OSSReviewed By: supriyarDifferential Revision: D24900303fbshipit-source-id: 1a2cb0ec536384abcd140e0d073f0965ed2800cd,1,Extract Method,,
de43326cfc018d2d55306a452184b184b239fc93,2017-10-05T03:56:42Z,https://github.com/pytorch/pytorch/commit/de43326cfc018d2d55306a452184b184b239fc93,"Identify components after sparse layers' taggingSummary: Given a pair (init_net, train_net) where ops in sparse layers are tagged, this diff detects the components and rename the `node_name` (e.g. tag) to reflect the component name.Reviewed By: azzoliniDifferential Revision: D5948222fbshipit-source-id: aeda9cfc88bb64922bf7a9942b969e3c5066718a",1,Extract Method,,
dedf9fbe811aba215ab16f90d62fa7d4b9e0dc86,2021-05-06T00:54:20Z,https://github.com/pytorch/pytorch/commit/dedf9fbe811aba215ab16f90d62fa7d4b9e0dc86,[package] factor out `PackageExporter._get_dependencies` (#57335)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/57335Mostly refactoring. The only behavioral change is that I have eliminatedthe `orig_source_file` argument to `save_source_string`. I think itdoesn't provide enough marginal value (since if you have the module nameyou can get the source file anyway).Differential Revision: D28114184Test Plan: Imported from OSSReviewed By: VitalyFedyuninPulled By: suofbshipit-source-id: b5e9eb4250dc84552befeef2dcf9e591b32899ae,1,Extract Method,,
df039e2998dbc0c9d1300bbc9bde5741d3a433b4,2018-03-29T02:23:20Z,https://github.com/pytorch/pytorch/commit/df039e2998dbc0c9d1300bbc9bde5741d3a433b4,"Unify handling of type_dispatched_args in gen_python_functions. (#6088)This is just to simplify the handling, there is no generated code difference.",1,Extract Method,,
df70e2fde57595e87bff55cb06af75aaa336b8a2,2021-03-26T18:17:46Z,https://github.com/pytorch/pytorch/commit/df70e2fde57595e87bff55cb06af75aaa336b8a2,"Refactor get analytical jacobian (#54049)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/54049The goal of this is to factor out the core logic of getting the analytical jacobian which is effectively doing `f(grad_out) = grad_out^T J = grad_input`. This allows us to test a lot of logic that was not possible before because now we can replace f with whatever we want in order to simulate potential issues that gradcheck is designed to catch.Edit: I realize a lot of things this PR was originally aiming to allow is actually possible with hooks, hence the tests have already been added in a earlier PR in the stack. But this is still slightly useful for reducing code duplication when adding the new fast gradcheck code (more details below)After this change, `get_analytical_jacobian` is only responsible for gathering a list of rows that are later combined into a single Jacobian tensor. This means we don't have to perform any checks for correctness of the dtypes/size at this stepWe factor out that logic into a separate function, `combine_jacobian_rows`, which handles the list of rows -> single Tensor step for each jacobian, and the error checking it entails. (This allows this code to be shared between the fast/slow versions.)Test Plan: Imported from OSSReviewed By: ailzhangDifferential Revision: D27307240Pulled By: soulitzerfbshipit-source-id: 65bb58cda000ed6f3114e5b525ac3cae8da5b878",1,Extract Method,,
df9634496837c65fbbb656560b3982e9bd66153a,2021-01-21T18:54:17Z,https://github.com/pytorch/pytorch/commit/df9634496837c65fbbb656560b3982e9bd66153a,[optimizer] refactor AdamW to use functional API (#50411)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/50411Test Plan: Imported from OSSReviewed By: izdebyDifferential Revision: D25932776Pulled By: wanchaolfbshipit-source-id: e8e1696b3390ba7909b36fd0107c58b892520432,1,Extract Method,,
e38f48ff11cbe0ec9a896fa28c29ff5ddc0f1e39,2023-03-07T05:07:08Z,https://github.com/pytorch/pytorch/commit/e38f48ff11cbe0ec9a896fa28c29ff5ddc0f1e39,Refactor unittest around dynamo.export wrt function signature (#95850)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/95850 Approved by: https://github.com/jansel,1,Extract Method,,
e7b34962326713aa65383c509c7939f2a007211b,2021-01-29T02:57:12Z,https://github.com/pytorch/pytorch/commit/e7b34962326713aa65383c509c7939f2a007211b,[Gradient Compression] Refactor default_hooks.py and powerSGD_hook.py by creating a util function that make a vanilla allreduce future (#51094)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/51094Address https://github.com/pytorch/pytorch/pull/50973#discussion_r564229818Original PR issue: Investigate Applying PowerSGD to Communication Hook for Gradient Compression #47202ghstack-source-id: 120619680Test Plan:buck test mode/dev-nosan caffe2/test/distributed:c10d -- test_powerSGD_ddp_comm_hook_ncclbuck test mode/dev-nosan caffe2/test/distributed:c10d -- test_default_ddp_comm_hooks_ncclReviewed By: rohan-varmaDifferential Revision: D26070147fbshipit-source-id: 8c9339f1511e8f24cc906b9411cfe4850a5a6d81,1,Extract Method,,
f29039677ddce3bbecb4f1034622845bf567466a,2021-03-31T23:24:49Z,https://github.com/pytorch/pytorch/commit/f29039677ddce3bbecb4f1034622845bf567466a,"Refactor get numerical jacobian (#54092)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/54092This is the first of several refactors to get numerical jacobian:This one just moves some logic around as to try to split the get_numerical_jacobian function into smaller more manageable functions:- compute_gradient is now no longer nested, but we have to pass in the parameters instead- iter_tensor extracts out the logic of iterating through different types of tensors (the code should be almost the exact same here except for instead of calling into the update jacobian function, we yield the arguments instead)Test Plan: Imported from OSSReviewed By: H-HuangDifferential Revision: D27354268Pulled By: soulitzerfbshipit-source-id: 73288e3c889ae31bb8bf77a0e3acb3e9020e09a3",1,Extract Method,,
f8e217a17e4d46bb461a04de42bd853d291d0c1f,2021-08-13T23:59:29Z,https://github.com/pytorch/pytorch/commit/f8e217a17e4d46bb461a04de42bd853d291d0c1f,"refactor fx2trt example script so it can be imported as a library (#63262)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/63262  Just create a `__main__` guard.  Test Plan: run linter, sandcastle tests  Reviewed By: 842974287  Differential Revision: D30263617  fbshipit-source-id: 8044ce5d815b043c3778591384cb13d9a89d0048",1,Extract Method,,
f98ab184452e748d7b79629bbd079fcbb909d838,2020-11-19T20:27:23Z,https://github.com/pytorch/pytorch/commit/f98ab184452e748d7b79629bbd079fcbb909d838,[pytorch][codegen] move is_abstract property to NativeFunction model (#48252)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/48252Moved to a shared place so that gen_variable_type.py can reuse it.Test Plan: Imported from OSSReviewed By: ezyangDifferential Revision: D25087808Pulled By: ljk53fbshipit-source-id: 1f32e506956fc4eb08734cfde0add47b3e666bd9,1,Extract Method,,
adc5510ecb658a19c838f7eec7cc225f1747be7e,2017-08-03T07:26:55Z,https://github.com/pytorch/pytorch/commit/adc5510ecb658a19c838f7eec7cc225f1747be7e,dynamic embeddingSummary: refactor get_categorical_limitReviewed By: xianjiecDifferential Revision: D5459389fbshipit-source-id: 14a7e07394db52fb090c6923e341c34576fcb6d6,1,Extract Method,,
b410d864c979dd0fcc2938c1453e2a9856fdd100,2019-11-20T05:31:58Z,https://github.com/pytorch/pytorch/commit/b410d864c979dd0fcc2938c1453e2a9856fdd100,"make python remote exception to rethrow when using remote reference to itself (#29930)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/29930Right now, python call remote exception rethrown is coupled with deserializtiaon.For owner ref, the setValue() and getValue() do not use serialization and deserialization, so when users create a ref to itself, and call ownerRef.to_here(), python call remote exception will not be rethrown.This diff is to move remote exception rethrown out of deserialization, and exception can be handled for ownerRef.localValue() or ownerRef.to_here()close #29924ghstack-source-id: 94210894Test Plan: unit testsDifferential Revision: D18541916fbshipit-source-id: 7cda93f623d52c740b3c1b1fa9a442f866984340",1,Extract Method,,
b45f2ff1ae5b8a7fb04f96a9d6de86df39c1dcb2,2018-05-16T18:03:04Z,https://github.com/pytorch/pytorch/commit/b45f2ff1ae5b8a7fb04f96a9d6de86df39c1dcb2,Remove CompiledFunction + clean up JIT tests (#7421),1,Extract Method,Rename Method,Move Method
c14b62fca2f348d0ab3b901698a841f2c72c3ac6,2018-04-18T22:07:03Z,https://github.com/pytorch/pytorch/commit/c14b62fca2f348d0ab3b901698a841f2c72c3ac6,Create FileBaton to synchronize distributed JIT C++ extension builds (#6684)* Create FileBaton to synchronize distributed JIT C++ extension builds* Move FileBaton to its own file* Autoformat code* Respect verbose flag in cpp_extension._prepare_ldflags,1,Extract Method,,
c5b4f60fc24611bea2346278d860310f98788e44,2020-07-25T20:24:51Z,https://github.com/pytorch/pytorch/commit/c5b4f60fc24611bea2346278d860310f98788e44,Move qconfig removal into convert() (#41930)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/41930As titleghstack-source-id: 108517079Test Plan: CIReviewed By: jerryzh168Differential Revision: D22698386fbshipit-source-id: 4f748c9bae4a0b615aa69c7cc8d8e451e5d26863,1,Extract Method,API Refactoring,
d6050582122c09e52e51b518f5af9be04e12e021,2017-12-18T20:46:13Z,https://github.com/pytorch/pytorch/commit/d6050582122c09e52e51b518f5af9be04e12e021,"Replace Variable.volatile with torch.no_grad() (#3970)This removes volatile from Variable. The functionality is mostlyreplaced by a global (thread-local) flag, which is controlled bytorch.set_grad_enabled() and the context manager torch.no_grad().In C++, the flag is exposed through GradMode::is_enabled() and GradMode::set_enabled()Fixes #3627",1,Extract Method,,
defd23b8b9e84550a672324288e7729aca164f61,2019-06-25T23:17:49Z,https://github.com/pytorch/pytorch/commit/defd23b8b9e84550a672324288e7729aca164f61,Clean up old uses of checkScript (#22002)Summary:This cleans up the `checkScript` API and some old tests that were hardcoding outputs. It also now runs the Python function when a string is passed in to verify the outputs.Pull Request resolved: https://github.com/pytorch/pytorch/pull/22002Differential Revision: D15924485Pulled By: driazatifbshipit-source-id: ee870c942d804596913601cb411adc31bd988558,1,Extract Method,Extract Class,Move Method
efefd1d7cf3736cfb5c494a5eb3b5b22ab949dc4,2018-07-10T17:20:24Z,https://github.com/pytorch/pytorch/commit/efefd1d7cf3736cfb5c494a5eb3b5b22ab949dc4,"Unify aten_dispatch and aten_schema into a single operator abstraction with human-readable schema. (#8885)Summary:This is a series of two commits that should probably be read separately. They are stacked on top of #9018 since the second commit requires it for correctness.Commit 1=======This commit is the first in a series that will clean up how we handle declaring operators and intrinsics in the JIT to make it more modular and readable. This introduces readable declarations that can be used to register operators and switches gen_jit_dispatch to generate this schema. A follow up PR will remove the dispatch keys like ""add-3"" and resolve ops directly based on the registered schema, further simplifying the generation process.* Switches schema over to parsed declarations, in the future this will allow something like:```  registry.register_intrinsic(""foo(Tensor a, Tensor b) -> Tensor"", [](Stack& stack) {    ...  })```This will allow the scalable registration of intrinsics for lists, tuples, and other ops, as long as meta-data for these ops (e.g. derivatives and size propagation routines).The declarations resemble those used by PythonArgParser but have been singificantly cleaned up to minimize the number of types that can appear in the declaration. We should strive to get the other parts of PyTorch switched over to this restricted declaration set when possible, but it is too much to do in a single PR. My hope is that eventually we will use a very similar language to describe declarations in C10, and this can serve as a guide for that.Parsing is done using the script lexer, so it is very robust to whitespace and extensible for future types.This removes the other way we encoded schema, and makes it easier to see what schema are registered.Current generated declarations: https://gist.github.com/zdevito/a96a17766fb3a098d69a91ee00abaaf6* Switches how we handle attempting to use an integer in the place of a fixed-sized int list, such as in conv (e.g. 'int[3] stride=1'). Now that we can statically distinguish between int and Tensor, we handle the expansion as an implicit conversion in the compiler. This allows us to simplify the interpreter since it no longer needs to handle the conversion itself.* Schema declarations have been changed so that they match the type system in the IR exactly. In particular, attribute_info which was used by liftConstantAttributes has been dropped and constant attributes are lifted purely based on the type of the input. Type conversions in compiler have been simplified due to this change.* Error highlighting in ErrorReport now only reports at most 20 lines of code, to make reading where an error occurred easier.Commit 2=======This commit unifies aten_dispatch and aten_schema into a single Operator object that both contains schema and implementation information. In the future we can use this object to also contain functionality like shape prop and autodiff needed by all operators. Operators are registered globally, and dispatch logic uses the schema information to figure out which variant to use. Descriptor keys, a frequent source of inscrutable debug errors, have been removed.* Introduce Operator, to replace TensorOp. Unlike TensorOp, we use Operator for all op implementations, including primitives that may occur in the graphs. The only exceptions are ops that are only known to the interpreter like jumps, and GraphExecutors where we need to record additional debug info.* Adds a global registry for Operator implementations. aten_dispatch.cpp turns into register_aten_ops.cpp, which registers all the Operators for aten with the operator registry. register_prim_ops.cpp now contains the implementations for primitive operators that used to be in the interpreter. This means that it is now safe to use `getOperation(node)` to lookup the true interpreter function for the node, which will simplify const-propagation passes.* Remove addInterpreterOpHandler in favor of global operator registry.* Instead of descriptors, we match Node arguments directly against FunctionSchema describing expected inputs in `matchSchema`. `matchSchema` knows how parse both attributes and positional inputs from a node and match it to the appropriate registered operator. Debug error messages when we try to run an invalid operator are significantly improved: they now automatically display the schema for the op with the same name that are registered.* Merge aten_schema into regsiter_aten_ops. Each Operator takes a string schema which is parsed to determine when to dispatch to that op.* Cleans up gen_jit_dispatch.py now that we do not need to write out descriptors.  In particular, skip_scalar_overloads can be removed since Richard's code sorts declarations to put Tensor, Tensor declarations first.* remove matchSchemaAndLiftConstantAttributes and use emitBuiltinCall instead to remove code duplication* refactor stack manipulation functions into a separate header file.Pull Request resolved: https://github.com/pytorch/pytorch/pull/8885Reviewed By: jamesr66aDifferential Revision: D8751048Pulled By: zdevitofbshipit-source-id: 312aabfbf88307c5f6ab947b6caf691468b94557",1,Extract Method,,
0897df18a314f7a74dce9fcd065d6d7e4cab47d7,2021-06-09T16:45:16Z,https://github.com/pytorch/pytorch/commit/0897df18a314f7a74dce9fcd065d6d7e4cab47d7,Refactor Foreach Tests: Unary Functions (#58960)  Summary: Related issue: https://github.com/pytorch/pytorch/issues/58833  __changes__ - slowpath tests: pass every dtype&device tensors and compare the behavior with regular functions including inplace - check of #cudaLaunchKernel - rename `ForeachUnaryFuncInfo` -> `ForeachFuncInfo`: This change is mainly for the future binary/pointwise test refactors  cc: ngimel ptrblck mcarilli  Pull Request resolved: https://github.com/pytorch/pytorch/pull/58960  Reviewed By: ejguan  Differential Revision: D28926135  Pulled By: ngimel  fbshipit-source-id: 4eb21dcebbffffaf79259e31961626e0707fb8d1,1,Extract Method,Rename Variable,
0df239e55082ab947e07161468b61f324eb6bed5,2021-04-22T10:52:09Z,https://github.com/pytorch/pytorch/commit/0df239e55082ab947e07161468b61f324eb6bed5,"[FX] Make arg normalization a method on Node and not a pass (also augment tests to be exhaustive) (#55992)Summary:Commandeered from https://github.com/pytorch/pytorch/pull/54563Primary changes from first PR:1. Refactored primary `normalize_function` logic into `operator_schemas.py` so that non-FX users can use it.2. Refactored tests a bit, and added a path to call `normalize_function` directly.3. Moved check for `boolean_dispatch` so that `torch.lu` also gets properly handled.Pull Request resolved: https://github.com/pytorch/pytorch/pull/55992Reviewed By: mruberryDifferential Revision: D27774396Pulled By: Chilleefbshipit-source-id: 7f65632e1d608e4abd55aec5ccbfdc3f67f52b8e",1,Extract Method,,
483490cc2503d08dc1e4e52fdd86fa5b941eb363,2016-12-30T18:15:21Z,https://github.com/pytorch/pytorch/commit/483490cc2503d08dc1e4e52fdd86fa5b941eb363,Move PixelShuffle implementation to functional,1,Extract Method,,
4fae5a6721c0120d69b987181ba800b1aac301b1,2020-03-23T18:53:18Z,https://github.com/pytorch/pytorch/commit/4fae5a6721c0120d69b987181ba800b1aac301b1,Move module graph creation to testing utils (#34917)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/34917Test Plan: Imported from OSSDifferential Revision: D20539338Pulled By: eellisonfbshipit-source-id: 5c46c0ce50e5bcccf5abee264f432ded7d36d040,1,Extract Method,,
8769fec03fcf9318f19da538b5d488d2f97ecbaa,2018-07-18T20:36:22Z,https://github.com/pytorch/pytorch/commit/8769fec03fcf9318f19da538b5d488d2f97ecbaa,Move clamp into ATen (#9506)Summary:Glue component of https://github.com/pytorch/pytorch/pull/9319Important to unblock wanchaolPull Request resolved: https://github.com/pytorch/pytorch/pull/9506Reviewed By: wanchaolDifferential Revision: D8879437Pulled By: cpuhrschfbshipit-source-id: 16ea8a93f3f5df2695180b3a30a583834b7004f1,1,Extract Method,Rename Method,Move Method
8f18cdf2b8561df6c50e80be322b526c6ed07eea,2020-03-27T01:53:56Z,https://github.com/pytorch/pytorch/commit/8f18cdf2b8561df6c50e80be322b526c6ed07eea,[Autograd Testing] Few refactors to test_autograd.py (#35443)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/35443Addressing Wanchao's comments fromhttps://github.com/pytorch/pytorch/pull/35268.ghstack-source-id: 100944390Test Plan: waitforbuildbotDifferential Revision: D20662292fbshipit-source-id: d98bf27106e858fe81e0f7755639c7da0f322913,1,Extract Method,Rename Class,Move Class
7cf938c78ff0e38a231a7cb3a2a7fa412bb47966,2022-10-14T14:05:29Z,https://github.com/scikit-learn/scikit-learn/commit/7cf938c78ff0e38a231a7cb3a2a7fa412bb47966,API Remove `sklearn.metrics.manhattan_distances` option `sum_over_features` (#24630),1,Extract Method,,
d40d993199e2a627690fdd9b44a3d5b9e5331563,2020-05-12T18:23:00Z,https://github.com/scikit-learn/scikit-learn/commit/d40d993199e2a627690fdd9b44a3d5b9e5331563,CLN Refactors _encode into two functions (#17101),1,Extract Method,,
d4a3ac4252401a20368c405976ff3db6f30995ac,2020-02-18T10:05:14Z,https://github.com/scikit-learn/scikit-learn/commit/d4a3ac4252401a20368c405976ff3db6f30995ac,MAINT split partial dependence and visualization (#16453),1,Extract Method,,
b69d5fa818f27686fa186c4e556ae909a2f0644f,2016-09-18T23:04:09Z,https://github.com/scikit-learn/scikit-learn/commit/b69d5fa818f27686fa186c4e556ae909a2f0644f,remove lambda for flake8 linting,1,Extract Method,,
9cbceb32c100703d8f2e374b571974a523e42d8a,2016-02-06T23:45:24Z,https://github.com/scikit-learn/scikit-learn/commit/9cbceb32c100703d8f2e374b571974a523e42d8a,MAINT split test_ridge.test_dense_sparse with generator,1,Extract Method,,
6d4bcda876506d1dda06865165dfcfb2de8527ff,2015-06-05T17:14:45Z,https://github.com/scikit-learn/scikit-learn/commit/6d4bcda876506d1dda06865165dfcfb2de8527ff,"ENH refactor OVO decision function, use it in SVC for sklearn-like decision_function shape",1,Extract Method,,
bcd7e9b19c90f10a662c86f4cbce38b814b93779,2015-05-29T10:45:08Z,https://github.com/scikit-learn/scikit-learn/commit/bcd7e9b19c90f10a662c86f4cbce38b814b93779,refactoring to DRY.,1,Extract Method,,
8e0dc6b7b0df7fc81a6ecb7b968d9a564cb92250,2014-12-16T10:35:54Z,https://github.com/scikit-learn/scikit-learn/commit/8e0dc6b7b0df7fc81a6ecb7b968d9a564cb92250,Refactored LDA module (first working version).,1,Extract Method,,
30ebaa8a4603c5b9d19f125ae00a9e8739b823ba,2014-12-05T13:07:17Z,https://github.com/scikit-learn/scikit-learn/commit/30ebaa8a4603c5b9d19f125ae00a9e8739b823ba,Major changes 1. Refactored node splitting into a private function called _split_node. 2. Added copy argument to copy the data once and for all. 3. Removed n_samples_ attribute in CFNode. 4. Removed X and added linear_sum as an argument to the constructor of _CFSubcluster.,1,Extract Method,,
f7549fd2bae3f404b0b6aabfdf4fb4f5b4413227,2014-07-20T08:40:04Z,https://github.com/scikit-learn/scikit-learn/commit/f7549fd2bae3f404b0b6aabfdf4fb4f5b4413227,Refactor input validation.,1,Extract Method,,
1775095e18141a9686fe3031698304677a91f598,2014-07-05T07:35:26Z,https://github.com/scikit-learn/scikit-learn/commit/1775095e18141a9686fe3031698304677a91f598,Merge pull request #3344 from ihaque/remove_dup_fit  Remove duplicate GaussianNB.fit() code,1,Extract Method,,
42920cd8bd242f8cdec537270644840d8d1486ae,2014-05-20T10:50:40Z,https://github.com/scikit-learn/scikit-learn/commit/42920cd8bd242f8cdec537270644840d8d1486ae,Refactoring increasing_bool set into _check_increasing method,1,Extract Method,,
815af6846589f2a225afa1b3fd5e7d12108f0090,2014-03-10T12:45:39Z,https://github.com/scikit-learn/scikit-learn/commit/815af6846589f2a225afa1b3fd5e7d12108f0090,Done refactoring and necessary changes for multiouput constant strategy. Added tests and updated the documentation.,1,Extract Method,,
3aa9158a27f50c4152775329ec357e254c1eceb1,2013-08-25T09:33:37Z,https://github.com/scikit-learn/scikit-learn/commit/3aa9158a27f50c4152775329ec357e254c1eceb1,MISC: refactor Ward and linkage in same object,1,Extract Method,,
49954dc5b4ced7b28273814fd1b42d49bed5e5af,2013-08-25T09:28:33Z,https://github.com/scikit-learn/scikit-learn/commit/49954dc5b4ced7b28273814fd1b42d49bed5e5af,MISC: refactor Ward and linkage in same object,1,Extract Method,,
211944aaebac9cb0bcfa88eae4b9718e39929fda,2013-08-15T13:45:17Z,https://github.com/scikit-learn/scikit-learn/commit/211944aaebac9cb0bcfa88eae4b9718e39929fda,Move estimate_bandwidth test to its own function.,1,Extract Method,,
c9f3e0183324c8fff9855ccf413d37f59f90ed09,2013-07-28T08:45:43Z,https://github.com/scikit-learn/scikit-learn/commit/c9f3e0183324c8fff9855ccf413d37f59f90ed09,Refactor loss_func and score_func warnings in grid_search,1,Extract Method,,
b892db98c26307ed8fa126072f84c6a20bd9270c,2013-07-22T14:21:41Z,https://github.com/scikit-learn/scikit-learn/commit/b892db98c26307ed8fa126072f84c6a20bd9270c,COSMIT refactor random forests  Very little subclass-specific stuff left in base classes.  Also fix faulty import in forest tests.,1,Extract Method,,
aeeda9fc3a5047dd51c9b61b3633605674ac647a,2013-07-12T14:56:39Z,https://github.com/scikit-learn/scikit-learn/commit/aeeda9fc3a5047dd51c9b61b3633605674ac647a,COSMIT refactor document frequency implementations,1,Extract Method,,
d4494a05e0cd2715719185dda03b01d9728f53bf,2013-07-04T10:39:23Z,https://github.com/scikit-learn/scikit-learn/commit/d4494a05e0cd2715719185dda03b01d9728f53bf,Extract SVD-based solver.,1,Extract Method,,
4d8f5e807bc816623ff317aaf3f7737610b91a22,2013-07-04T10:39:23Z,https://github.com/scikit-learn/scikit-learn/commit/4d8f5e807bc816623ff317aaf3f7737610b91a22,Extract dense_cholesky solver (kernel case).,1,Extract Method,,
38463c1e2dbf9b9655e1fd697c5d27d45c25e8a9,2013-07-04T10:39:23Z,https://github.com/scikit-learn/scikit-learn/commit/38463c1e2dbf9b9655e1fd697c5d27d45c25e8a9,Extract dense_cholesky solver (linear case).,1,Extract Method,,
3c91661b6688d6697b63e514f1accc9be0b78593,2013-07-04T10:39:23Z,https://github.com/scikit-learn/scikit-learn/commit/3c91661b6688d6697b63e514f1accc9be0b78593,Extract sparse_cg and lsqr solvers.,1,Extract Method,,
8e9719d690021acf7024eb2483160979d471aebf,2013-05-12T07:14:18Z,https://github.com/scikit-learn/scikit-learn/commit/8e9719d690021acf7024eb2483160979d471aebf,COSMIT refactor roc_curve and precision_recall_curve,1,Extract Method,,
d562b461cfc27b0be82a646396ad6e4a867600e1,2013-04-24T11:34:23Z,https://github.com/scikit-learn/scikit-learn/commit/d562b461cfc27b0be82a646396ad6e4a867600e1,ENH refactor and further speed up CountVectorizer,1,Extract Method,,
980600b67ee81876ee45218cfdbc99d638652a36,2012-12-21T13:48:00Z,https://github.com/scikit-learn/scikit-learn/commit/980600b67ee81876ee45218cfdbc99d638652a36,ENH refactor matrix generation BaseRandomProjectiona and subclass,1,Extract Method,,
e8d21a798fc7a7aa3deefad554e98a84756884ea,2012-12-11T08:33:11Z,https://github.com/scikit-learn/scikit-learn/commit/e8d21a798fc7a7aa3deefad554e98a84756884ea,ENH Move parameter checking to fit,1,Extract Method,,
fad7143c863f5de69b5af6950254bc8333859228,2012-11-28T00:02:06Z,https://github.com/scikit-learn/scikit-learn/commit/fad7143c863f5de69b5af6950254bc8333859228,COSMIT refactor input validation code; skip some issparse calls,1,Extract Method,,
0d0d3e7a5389f6ef53bd6e5a556ef3f09c0d160c,2012-08-15T14:23:51Z,https://github.com/scikit-learn/scikit-learn/commit/0d0d3e7a5389f6ef53bd6e5a556ef3f09c0d160c,Refactored fast_pinv without lapack calls,1,Extract Method,,
598dbff146d91ac9a58f316b625356cdd903fcf6,2012-05-11T09:21:01Z,https://github.com/scikit-learn/scikit-learn/commit/598dbff146d91ac9a58f316b625356cdd903fcf6,P3K : Refactored test cases to use setUp,1,Extract Method,,
0f21fce652e133f837628112ee58f9360d7d795b,2012-03-12T15:20:02Z,https://github.com/scikit-learn/scikit-learn/commit/0f21fce652e133f837628112ee58f9360d7d795b,cleanup of arg check and doc update,1,Extract Method,,
d1a87f91152e88f616e5192ce3af64e0d4f17d55,2012-02-13T10:03:10Z,https://github.com/scikit-learn/scikit-learn/commit/d1a87f91152e88f616e5192ce3af64e0d4f17d55,COSMIT refactor SGD with Dataset factory function,1,Extract Method,,
b8d134dc45145637817d9eea0e67daaefc691368,2012-02-06T06:37:26Z,https://github.com/scikit-learn/scikit-learn/commit/b8d134dc45145637817d9eea0e67daaefc691368,Removed single k-means run to it's own function to enable optional parallelisation later.,1,Extract Method,,
81f3d12e2f52517d88debf682c02b57b2052a99e,2011-11-28T10:21:50Z,https://github.com/scikit-learn/scikit-learn/commit/81f3d12e2f52517d88debf682c02b57b2052a99e,Refactor MCD robust covariance estimator: it is easier to regularize.,1,Extract Method,,
882fa668669732aa5346591c03a9598cbea8f110,2011-08-12T01:49:18Z,https://github.com/scikit-learn/scikit-learn/commit/882fa668669732aa5346591c03a9598cbea8f110,"removed function kernel, switched to string for picklability",1,Extract Method,,
cdcc8eae2584b5f08091c44e1bb9ed0edc043342,2011-06-06T21:58:42Z,https://github.com/scikit-learn/scikit-learn/commit/cdcc8eae2584b5f08091c44e1bb9ed0edc043342,Refactor MultinomialNB: separate prior estimation and feature counting,1,Extract Method,,
8f76efdf35b6974831b2ccaa5dd106565c6e1c32,2011-05-08T13:37:38Z,https://github.com/scikit-learn/scikit-learn/commit/8f76efdf35b6974831b2ccaa5dd106565c6e1c32,split some tests to make them more atomic,1,Extract Method,,
1ee7f992b4af0ab2454c50c54ab4db1fd23493ec,2011-04-24T11:04:01Z,https://github.com/scikit-learn/scikit-learn/commit/1ee7f992b4af0ab2454c50c54ab4db1fd23493ec,"COSMIT: DPGMM: Move bound computing to functions  This localizes the code (helpful for later optimizations). Also, because the cv_type resolution is done outside the loop, it gives a small performance gain.",1,Extract Method,,
a4c34b877901c6a174fea1a9a5a0c05163f7a9d8,2010-10-31T23:54:42Z,https://github.com/scikit-learn/scikit-learn/commit/a4c34b877901c6a174fea1a9a5a0c05163f7a9d8,extract label extraction logics,1,Extract Method,,
ddbc0432924cbd27f2667b7bcca238f722db5cda,2010-10-31T21:15:00Z,https://github.com/scikit-learn/scikit-learn/commit/ddbc0432924cbd27f2667b7bcca238f722db5cda,refactored test_metrics to handle the binary case explictly and make room for the multiclass case,1,Extract Method,,
2a03d3b247b412d3830e0e2a7219183b356d8255,2010-06-10T12:26:38Z,https://github.com/scikit-learn/scikit-learn/commit/2a03d3b247b412d3830e0e2a7219183b356d8255,Refactoring in gmm module.  Squash init method into fit (you can still call init by calling fit with niter=0),1,Extract Method,,
3b39b906183ed08d9961908eb73104aeea345d11,2023-08-31T12:17:26Z,https://github.com/huggingface/transformers/commit/3b39b906183ed08d9961908eb73104aeea345d11,[`TokenizerFast`] `can_save_slow_tokenizer` as a property for when `vocab_file`'s folder was removed (#25626)  * pad token should be None by default  * fix tests  * nits  * check if isfile vocabfile  * add warning if sp model folder was deleted  * save SPM when missing folder for sloz  * update the ` can_save_slow_tokenizer`  to be a property  * first batch  * second batch  * missing one,1,Extract Method,,
e95bcaeef0bd6b084b7615faae411a14d50bcfee,2023-08-31T09:47:53Z,https://github.com/huggingface/transformers/commit/e95bcaeef0bd6b084b7615faae411a14d50bcfee,fix ds z3 checkpointing when  `stage3_gather_16bit_weights_on_model_save=False` (#25817)  * fix ds z3 checkpointing when  `stage3_gather_16bit_weights_on_model_save=False`  * refactoring,1,Extract Method,,
7ec9128e5a77980b17d5158241c4a182536d5668,2022-06-14T15:22:21Z,https://github.com/huggingface/transformers/commit/7ec9128e5a77980b17d5158241c4a182536d5668,FX function refactor (#17625)  * Function refactor  * Update src/transformers/utils/fx.py  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>,1,Extract Method,,
daecae1f1ce02d2dab23742d24f7a66a7d20cb79,2022-05-02T14:40:37Z,https://github.com/huggingface/transformers/commit/daecae1f1ce02d2dab23742d24f7a66a7d20cb79,[Trainer] Move logic for checkpoint loading into separate methods for easy overriding (#17043),1,Extract Method,,
12bfa97a4373b7b883ee0de4f2c9c53918d81cf1,2022-04-13T11:50:15Z,https://github.com/huggingface/transformers/commit/12bfa97a4373b7b883ee0de4f2c9c53918d81cf1,[from_pretrained] refactor find_mismatched_keys (#16706),1,Extract Method,,
83206ca6a8c79ffb8937b45742d81205c52c3e96,2021-04-14T18:06:59Z,https://github.com/huggingface/transformers/commit/83206ca6a8c79ffb8937b45742d81205c52c3e96, [deepspeed] test on one node 2 gpus max (#11237)  * test on one node 2 gpus max  * fix the other place  * refactor  * fix  * cleanup  * more exact version,1,Extract Method,,
0f360d3d1c606d6d79cdf1efa53c3d719249573d,2020-09-03T15:49:14Z,https://github.com/huggingface/transformers/commit/0f360d3d1c606d6d79cdf1efa53c3d719249573d,move wandb/comet logger init to train() to allow parallel logging (#6850)  * move wandb/comet logger init to train() to allow parallel logging  * Setup wandb/comet loggers on first call to log(),1,Extract Method,,
f98d0ef2a237f546aee949e2b3577c0e59422a5e,2020-04-10T14:20:18Z,https://github.com/huggingface/transformers/commit/f98d0ef2a237f546aee949e2b3577c0e59422a5e,"Big cleanup of `glue_convert_examples_to_features` (#3688)  * Big cleanup of `glue_convert_examples_to_features`  * Use batch_encode_plus  * Cleaner wrapping of glue_convert_examples_to_features for TF  @lysandrejik  * Cleanup syntax, thanks to @mfuntowicz  * Raise explicit error in case of user error",1,Extract Method,,
2ee410560e45ae3c619dc1e0b0fc4d257c48e18a,2020-04-06T08:37:05Z,https://github.com/huggingface/transformers/commit/2ee410560e45ae3c619dc1e0b0fc4d257c48e18a,"[Generate, Test] Split generate test function into beam search, no beam search (#3601)  * split beam search and no beam search test  * fix test  * clean generate tests",1,Extract Method,Rename Method,
56301bd9e8adf38bb8214e92acdb487234edff4b,2019-10-09T12:48:40Z,https://github.com/huggingface/transformers/commit/56301bd9e8adf38bb8214e92acdb487234edff4b,Extract method,1,Extract Method,,
99b90edab1c144ba92ff59e50a2811936a09550c,2019-07-05T15:09:35Z,https://github.com/huggingface/transformers/commit/99b90edab1c144ba92ff59e50a2811936a09550c,cleaning up run_glue example,1,Extract Method,,
3ff2ec5eb38edab190c4bad278e9a2cc76f4ef7f,2018-11-02T13:42:05Z,https://github.com/huggingface/transformers/commit/3ff2ec5eb38edab190c4bad278e9a2cc76f4ef7f,Move command-line argparse arguments into main() function,1,Extract Method,,
75cf60d9fe3528b03dc490313ad1a48905fa4c51,2020-03-18T01:51:00Z,https://github.com/tensorflow/tensorflow/commit/75cf60d9fe3528b03dc490313ad1a48905fa4c51,Refactoring: Extract base test class to lite_v2_test_util module (NFC)PiperOrigin-RevId: 301499331Change-Id: Ib99e2fd5f94def257a8c0de8c85e1cebfbc9ce53,1,Extract Class,,
da861da63df724339e0148ff43192de05770a3c8,2018-06-20T00:10:22Z,https://github.com/tensorflow/tensorflow/commit/da861da63df724339e0148ff43192de05770a3c8,Refactor loader.load function into a class that splits the graph loading and variable restoration steps.PiperOrigin-RevId: 201268712,1,Extract Class,,
916c0aab83ed3a5b5c6ffa42c3071f59ed0f7934,2018-06-15T18:35:23Z,https://github.com/tensorflow/tensorflow/commit/916c0aab83ed3a5b5c6ffa42c3071f59ed0f7934,Refactor loader.load function into a class that splits the graph loading and variable restoration steps.PiperOrigin-RevId: 200747752,1,Extract Class,,
62a70dd873bc8488b10df5ad55254119173a5d0c,2018-06-05T18:58:16Z,https://github.com/tensorflow/tensorflow/commit/62a70dd873bc8488b10df5ad55254119173a5d0c,Extend and refactor reader_ops_testPiperOrigin-RevId: 199335030,1,Extract Class,,
b6ece81d39ac852e8e310d9b738d560ca7d21b2b,2017-12-14T19:23:45Z,https://github.com/tensorflow/tensorflow/commit/b6ece81d39ac852e8e310d9b738d560ca7d21b2b,Splits _SharedEmbeddingColumn into a separate class and some bug fixes.PiperOrigin-RevId: 179070001,1,Extract Class,,
000c934b98cfd3e454c56707d7f85b7c2375776d,2017-11-06T23:18:55Z,https://github.com/tensorflow/tensorflow/commit/000c934b98cfd3e454c56707d7f85b7c2375776d,Refactor eager benchmarks to subclass Benchmark.PiperOrigin-RevId: 174770787,1,Extract Class,,
6a89eb72333bdf45cc67d6740d45bd9c7ac6d236,2017-05-23T17:33:49Z,https://github.com/tensorflow/tensorflow/commit/6a89eb72333bdf45cc67d6740d45bd9c7ac6d236,Move partial run tests into new PartialRunTest classPiperOrigin-RevId: 156879382,1,Extract Class,,
52203802b972f5af3663e629e808d427f515ce63,2017-01-26T22:22:21Z,https://github.com/tensorflow/tensorflow/commit/52203802b972f5af3663e629e808d427f515ce63,Separates app logic from serving logic. This change further simplifies the reuse of TensorBoard's WSGI app.* Refactor TensorBoard serving logic into a separate class* The new class exposes a wsgi app function for reuse in a WSGI serving stackChange: 145720685,1,Extract Class,,
905fcf5f13cb6480a5b0aed9e8b42af321bb2b9e,2017-01-10T04:01:24Z,https://github.com/tensorflow/tensorflow/commit/905fcf5f13cb6480a5b0aed9e8b42af321bb2b9e,"Refactor intializer functions as initializer classes. This is purely a refactoring change and does not affect any API.This is done for the following reasons:- Initializers were previously functions that returned functions, which is conceptually a callable class.- Inner functions were previously making unsafe access to their outer scope, which is against Python style and caused problems in at least one case.- Having classes allows us to serialize initializers: given an initializer instance we can retrieve its constructor arguments values, which can be used to reinstantiate the same initializer. Previously these values could not be recovered.- Some initializers required a class structure in any case (e.g. RandomWalk).Change: 144038994",1,Extract Class,,
569cd85032befb04b12c657acc5204c96f4e4c41,2016-11-24T01:37:38Z,https://github.com/tensorflow/tensorflow/commit/569cd85032befb04b12c657acc5204c96f4e4c41,Split _BinaryLogisticHead from _MultiClassHead.Combine train and eval loss fn (since they're always the same).Change: 140088698,1,Extract Class,,
8eff2d62f232abece68949af95efddc91689206f,2016-11-23T00:39:19Z,https://github.com/tensorflow/tensorflow/commit/8eff2d62f232abece68949af95efddc91689206f,Split _BinaryLogisticHead from _MultiClassHead.Change: 139971064,1,Extract Class,,
748112200eb8954d4d5996838e2be2e5c550d421,2016-09-19T17:00:43Z,https://github.com/tensorflow/tensorflow/commit/748112200eb8954d4d5996838e2be2e5c550d421,Removed is_chief handling from MonitoredSession by abstracting out SessionCreator.Moved graph writing to the checkpoint saver hook.Change: 133596696,1,Extract Class,,
323b57de58194202ba619a1301762f1e39189a6a,2016-07-29T02:58:07Z,https://github.com/tensorflow/tensorflow/commit/323b57de58194202ba619a1301762f1e39189a6a,Split TSAN-incompatible saver unit test into a separate target.Change: 128770169,1,Extract Class,,
fabcd8ac0a7c6d4bc1e8bf01c60deb02814c4c64,2022-03-31T16:07:42Z,https://github.com/keras-team/keras/commit/fabcd8ac0a7c6d4bc1e8bf01c60deb02814c4c64,Arrange unit test in an own class IncreasingBatchSizeAdapterTest,1,Extract Class,,
2dc80bac1428e72421a90dd118a3659f2fe60695,2022-01-20T02:48:20Z,https://github.com/keras-team/keras/commit/2dc80bac1428e72421a90dd118a3659f2fe60695,Move reshaping layers from the `core` directory to the `reshaping` directory.  PiperOrigin-RevId: 422954739,1,Extract Class,,
ebd0f08c715129094cece5a7ba5be321ba8aac61,2017-09-08T22:46:59Z,https://github.com/keras-team/keras/commit/ebd0f08c715129094cece5a7ba5be321ba8aac61,Refactor image preprocessing iterators to subclass Sequence. (#7853)  * Refactor image preprocessing iterators to subclass Sequence.  * Add more tests for image preprocessing Sequences,1,Extract Class,,
59f9894ff7a00df6e6f14c5bec781493b3684d2d,2017-09-08T20:22:22Z,https://github.com/keras-team/keras/commit/59f9894ff7a00df6e6f14c5bec781493b3684d2d,Refactor image preprocessing iterators to subclass Sequence.,1,Extract Class,,
0e18e345b0168ff31d08a062714f0a3e556afaca,2016-06-05T17:24:54Z,https://github.com/keras-team/keras/commit/0e18e345b0168ff31d08a062714f0a3e556afaca,"Refactor ImageDataGenerator, add directory support",1,Extract Class,,
59e345501e9eb13b6b50f98d2b78a8cc7c453538,2015-06-25T11:25:03Z,https://github.com/keras-team/keras/commit/59e345501e9eb13b6b50f98d2b78a8cc7c453538,refactored regularizers to be objects of a given class,1,Extract Class,Extract Variable,
97f23268c2567721b1aa858a286c30d739170eef,2015-06-21T00:09:08Z,https://github.com/keras-team/keras/commit/97f23268c2567721b1aa858a286c30d739170eef,Refactor test_lossweights into unit test,1,Extract Class,,
2084c1604dcf8850d3f35052a78b2288c268432a,2015-06-07T23:13:48Z,https://github.com/keras-team/keras/commit/97f23268c2567721b1aa858a286c30d739170eef,Refactor models.Sequential,1,Extract Class,,
04a11f365fb9c479e235b8b57280fc80892cd28c,2022-04-12T19:36:31Z,https://github.com/keras-team/keras/commit/04a11f365fb9c479e235b8b57280fc80892cd28c,Reduce the complexity of the base layer by pulling out the logic related to handling call function args to a separate class.  PiperOrigin-RevId: 441262175,1,Extract Class,Rename Variable,
23c40e68de2cffa77c92ae48cca1f81913756d2a,2018-08-21T23:41:37Z,https://github.com/keras-team/keras/commit/23c40e68de2cffa77c92ae48cca1f81913756d2a,"Refactoring: Made an abstract class for all the cropping layers. (#10888)  * Made an abstract class for all the cropping layers.  * Added the rank in the config of _Cropping.  * Made self.cropping be a tuple of tuple in all cases (1d, 2d and 3d).  * Removed the rank argument in _Cropping, allowing to remove the overwrides of get_config.",1,Extract Class,Rename Variable,
149cd09221a15730f1294f0dc55cb743b40616e2,2023-06-14T14:00:14Z,https://github.com/pytorch/pytorch/commit/149cd09221a15730f1294f0dc55cb743b40616e2,"Refactor and improve AOTAutograd tests (#103197)  This is in preparation for the new ""custom_op_compile_check"" utility, which will call the refactored testing API as a subroutine.  Here are the improvements to the AOTAutograd tests that this PR makes: - we use torch.autograd.grad instead of .backward(), which makes it so that we stop destructively modifying the inputs - we get rid of the difficult-to-understand sentinel=42 logic and replace it with something more sane - We create some helper functions and add some code comments - We improve error messages  Test Plan: - wait for CI Pull Request resolved: https://github.com/pytorch/pytorch/pull/103197 Approved by: https://github.com/bdhirsh, https://github.com/soulitzer, https://github.com/Chillee",1,Extract Class,,
2296ee08fab40c63cd24a5f4e97639e89eb6ab2d,2023-06-02T18:40:05Z,https://github.com/pytorch/pytorch/commit/2296ee08fab40c63cd24a5f4e97639e89eb6ab2d,[PT2][Quant][BE] Test refactor to be organize them better (#102704)  Collected most of the test modules under TestHelperModules. This allows reuse of modules when possible. Probably we can refactor a bit more but left some qat related helper modules in their respective tests  Differential Revision: [D46267687](https://our.internmc.facebook.com/intern/diff/D46267687/) Pull Request resolved: https://github.com/pytorch/pytorch/pull/102704 Approved by: https://github.com/andrewor14,1,Extract Class,,
2dab368d26c39a95458b30e696fab47054416f03,2021-07-21T20:30:36Z,https://github.com/pytorch/pytorch/commit/2dab368d26c39a95458b30e696fab47054416f03,Refactor generate_ci_workflows (#61879)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/61879  Refactor generate_ci_workflows to support CI dispatcher. This is the first step to refactor the workflow into a dataclass with some validation and OOP.  Verified that the output is the same:  ``` .github/scripts/generate_ci_workflows.py git status ```  Test Plan: Imported from OSS  Reviewed By: seemethere  Differential Revision: D29808365  Pulled By: zhouzhuojie  fbshipit-source-id: b8c5fd43f4bd6e17e06f3925a1a509084b790d95,1,Extract Class,,
442ec1dd4ed58c4589deb343ef235a909c19ceb7,2020-06-18T20:24:30Z,https://github.com/pytorch/pytorch/commit/442ec1dd4ed58c4589deb343ef235a909c19ceb7,"[test] split remaining quantization tests out of test_jit (#40144)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/40144as title, split remaining quantization tests out of test_jit to reducethe size of test_jitTest Plan: Imported from OSSDifferential Revision: D22085034Pulled By: wanchaolfbshipit-source-id: 0c8639da01ffc3e6a72e6f470837786c73a6b3f0",1,Extract Class,,
4e033b0040dfa4c991bf750c450216edf393c65c,2019-10-22T00:12:15Z,https://github.com/pytorch/pytorch/commit/4e033b0040dfa4c991bf750c450216edf393c65c,"split TestLogging, TestDict, TestListSummary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/28038Test Plan: Imported from OSSDifferential Revision: D17954441Pulled By: suofbshipit-source-id: 4703fb577adea3aa00fabb13c577b055e9ab4d7c",1,Extract Class,,
57eb8bd28864713e63f82172329aa891c719a6c6,2017-08-31T15:46:30Z,https://github.com/pytorch/pytorch/commit/57eb8bd28864713e63f82172329aa891c719a6c6,"Frontend refactor, and some documentation.- BC BREAKING: export now also takes a mandatory file-ish argument, specifying  the file to export the protobuf to.  I rewrote the tests to use BytesIO to  get out the string so they could parse it again.- BC BREAKING: export no longer returns the tensors that were computed.  To  get these, use the internal _export function.- Multiple inputs to models are now supported by passing a tuple to input.  (Old API of a single Variable still works.)- Keyword arguments to models are now supported via kwargs keyword arg.- Renamed embed_params to export_params, and it now defaults to True.- Toffee tests now live in their own test_toffee.py file.  I had to  rename a pile of expect files for this.- Removed defunct torch.toffee imports from autograd to solve module import  cycle.- Helper function _with_file_like to abstract over opening file-ish arguments,  taken from torch.save()Signed-off-by: Edward Z. Yang <ezyang@fb.com>",1,Extract Class,,
5bd43a7af86cd660d3b5bd91fad9c79d8b903c21,2018-08-01T05:57:01Z,https://github.com/pytorch/pytorch/commit/5bd43a7af86cd660d3b5bd91fad9c79d8b903c21,Refactor Seq2SeqModelCaffe2EnsembleDecoder (#10035)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/10035This is an initial diff which refactors some of the components in the Seq2SeqModelCaffe2EnsembleDecoder class.Reviewed By: jmp84Differential Revision: D9026372fbshipit-source-id: 449635208f24494209ae2fb78a19fca872970ea8,1,Extract Class,,
5dee15401c7730ae2a0e49e774c9da2d067527b7,2021-08-24T17:24:29Z,https://github.com/pytorch/pytorch/commit/5dee15401c7730ae2a0e49e774c9da2d067527b7,[pruner] refactor `ActivationReconstruction` forward hooks (#63158)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/63158  Combined functionality for `ActivationReconstruction` for both Linear and Conv2d in one class. The only difference between the old classes was the size and indexing of the reconstructed tensor -- that logic can be generalized by iterating over the size of `output`. ghstack-source-id: 136467465  Test Plan: `buck test mode/dev-nosan //caffe2/test:ao -- TestBasePruner`  https://pxl.cl/1MSSv  Reviewed By: raghuramank100  Differential Revision: D30282765  fbshipit-source-id: 08a1e4e0650511019fff85cf52b41dd818b0c7f8,1,Extract Class,,
76b72bd80d3dfbf1fef1b2214de097e38a964a89,2023-05-13T09:28:32Z,https://github.com/pytorch/pytorch/commit/76b72bd80d3dfbf1fef1b2214de097e38a964a89,"Rewrite frame state to use a struct for shapes, splitting scalar and size, prep for stride (#101250)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/101250 Approved by: https://github.com/ezyang",1,Extract Class,,
773a8eede437de972311b21824694e4fb120f6a2,2021-08-04T01:51:29Z,https://github.com/pytorch/pytorch/commit/773a8eede437de972311b21824694e4fb120f6a2,[profiler][refactor] Refactor the usage of legacy profiler implementation (#61931)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/61931  This PR consolidates the profiling code around a new C++ implementation (profiler_kineto.h/cpp) and uses it unconditionally from torch.autograd.profiler/torch.profiler: 1. Always use profiler_kineto.h/cpp as the C++ implementation 2. Simplify profiler.py to remove unneeded parts depending on legacy impl 3. Move some of the legacy logic into profiler_legacy.py (to be fully deleted later)  Test Plan: USE_KINETO=1 USE_CUDA=1 USE_MKLDNN=1 BLAS=MKL BUILD_BINARY=1 python setup.py develop install --cmake python test/test_profiler.py -v USE_KINETO=0 USE_CUDA=1 USE_MKLDNN=1 BLAS=MKL BUILD_BINARY=1 python setup.py develop install --cmake python test/test_profiler.py -v  Imported from OSS  Reviewed By: gdankel  Differential Revision: D29801599  fbshipit-source-id: 9794d29f2af38dddbcd90dbce4481fc8575fa29e,1,Extract Class,,
785676ccb042dd0d1bd2ffb032642356a0bf9a95,2023-04-26T00:18:12Z,https://github.com/pytorch/pytorch/commit/785676ccb042dd0d1bd2ffb032642356a0bf9a95,"[dynamo 3.11] refactor cpython function defs out of eval_frame.c (#99947)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/99947 Approved by: https://github.com/voznesenskym, https://github.com/albanD",1,Extract Class,,
7d39608a297eb21292cc9104c2939b657f6d59ef,2021-06-22T03:44:23Z,https://github.com/pytorch/pytorch/commit/7d39608a297eb21292cc9104c2939b657f6d59ef,"split TestAsserts by functionality (#58919)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/58919  Instead of having one large TestAsserts test case, we split of tests for self-contained functionality like container or complex checking into separate test cases. That makes it a lot easier to keep an overview over what is tested.  Test Plan: Imported from OSS  Reviewed By: anjali411  Differential Revision: D29259407  Pulled By: mruberry  fbshipit-source-id: 9769cb6d56c1a3790280542db398cb247986b09a",1,Extract Class,,
984a2397bac64fb5d25b52717ec3aa0765b6c11a,2023-05-02T17:11:02Z,https://github.com/pytorch/pytorch/commit/984a2397bac64fb5d25b52717ec3aa0765b6c11a,"Refactor OutputGraph (#99987)  This PR splits OutputGraph into two classes: - SubgraphTracer (handles FX-tracing) - OutputGraph (handles Dynamo-specific output graph logic, like tracking graph inputs, compiling the graph, and executing it).  The motivation behind this is in the next PR up in the stack. TL;DR is: in order to do higher-order operators, we need nested SubgraphTracer, one for each level of nesting of the higher-order operators.  I'm happy to flatten the stack into a single PR, but this separate made it easier for me to test. Lmk if you want the stack flattened.  Test Plan: - existing tests  Pull Request resolved: https://github.com/pytorch/pytorch/pull/99987 Approved by: https://github.com/anijain2305, https://github.com/voznesenskym",1,Extract Class,,
a78467f3df4bbf60671a16f95600a572f9d0df04,2022-11-29T12:47:48Z,https://github.com/pytorch/pytorch/commit/a78467f3df4bbf60671a16f95600a572f9d0df04,"Refactoring to share vectorization code for int8/uint8. (#89650)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/89650 Approved by: https://github.com/jgong5, https://github.com/lezcano, https://github.com/peterbell10",1,Extract Class,,
b8d7a28e1afc12c77f67edaa9f8154ef0bb13f55,2023-04-27T21:42:40Z,https://github.com/pytorch/pytorch/commit/b8d7a28e1afc12c77f67edaa9f8154ef0bb13f55,"refactor test_sdpa into two test classes to account for failure modes (#100121)  ### Summary This PR creates a new TestSDPAFailureModes test class in order to better seperate what each test is trying to do. Pull Request resolved: https://github.com/pytorch/pytorch/pull/100121 Approved by: https://github.com/malfet, https://github.com/ngimel",1,Extract Class,,
ba5686f8c537f9ce070db1dbb187fae34521b789,2020-12-02T15:47:13Z,https://github.com/pytorch/pytorch/commit/ba5686f8c537f9ce070db1dbb187fae34521b789,Refactor argument fields in FunctionSchema to Arguments (#48182)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/48182I'm planning to add a bunch more argument fields followinghttps://github.com/pytorch/pytorch/pull/45890#discussion_r503646917 andit will be a lot more convenient if the arguments get to livein their own dedicated struct.  Type checker will tell you ifI've done it wrong.  No change to output.Signed-off-by: Edward Z. Yang <ezyang@fb.com>Test Plan: Imported from OSSReviewed By: ljk53Differential Revision: D25057897Pulled By: ezyangfbshipit-source-id: dd377181dad6ab0c894d19d83408b7812775a691,1,Extract Class,,
dc7d8a889e7173446130344a3a1871e849b7a433,2020-12-01T02:29:04Z,https://github.com/pytorch/pytorch/commit/dc7d8a889e7173446130344a3a1871e849b7a433,caffe2: refactor context to allow being typed (#48340)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/48340This changes the context managed classes from using a decorator to define them to using inheritance. Inheritance allows the python static type checking to work correctly.```context.define_context()class Bar(object): ...context.define_context(allow_default=True)class Foo(object): ...```becomes```class Foo(context.Managed): ...class Bar(context.DefaultManaged): ...```Behavior differences:* arg_name has been removed since it's not used anywhere* classes need to call `super()` in `__enter__/__exit__` methods if they override (none do)This also defines a context.pyi file to add types for python3. python2 support should not be affectedTest Plan:ci  buck test //caffe2/caffe2/python:context_test //caffe2/caffe2/python:checkpoint_testReviewed By: dongyuzhengDifferential Revision: D25133469fbshipit-source-id: 16368bf723eeb6ce3308d6827f5ac5e955b4e29a,1,Extract Class,,
e096d2db5a62d5d676809f66b8b416047be80e3e,2023-01-12T14:16:49Z,https://github.com/pytorch/pytorch/commit/e096d2db5a62d5d676809f66b8b416047be80e3e,"[BC-Breaking] Separate `stream_id`, `device_index`, and `device_type` in `pack` and `unpack` for `Streams` (#81596)  #75854  A naive attempt at working around the limitations of using a single 64-bit integer to pack `stream_id`, `device_index`, and `device_type`.  Stills needs sanity checks, testing, and minimization of BC-breaking changes.  Currently a Holder for the `StreamData3` struct is used for `IValue` compatibility. While doing this seems to work for `ivalue.h` and `ivalue_inl.h`, this doesn't seem to be naively working for the JIT CUDA stream wrapper? (Something about ambiguous calls if an `intrusive_ptr` to `c10::ivalue::StreamData3Holder` is used as the return type for `pack()`. It turns out that the methods required to access the fields for rematerializing a CUDA Stream are basically already present anyway, so `pack` is simply removed in the wrapper for now and the methods to access the required fields are called directly.  CC @ptrblck  Pull Request resolved: https://github.com/pytorch/pytorch/pull/81596 Approved by: https://github.com/ezyang",1,Extract Class,,
ee2729890c32c77ec1948d81ad1080585e232468,2023-02-02T19:41:48Z,https://github.com/pytorch/pytorch/commit/ee2729890c32c77ec1948d81ad1080585e232468,Refactor dynamo register_backend/BACKENDS (#93389)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/93389 Approved by: https://github.com/voznesenskym,1,Extract Class,,
f2f7fdba05159e90b75b780cef29a0640a1f475c,2021-02-28T07:14:40Z,https://github.com/pytorch/pytorch/commit/f2f7fdba05159e90b75b780cef29a0640a1f475c,[quant][graphmode][fx][test][refactor] Refactoring binary op tests to split int8 and float16 tests (#52807)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/52807Test Plan: Imported from OSSReviewed By: vkuzoDifferential Revision: D26655617fbshipit-source-id: c36edef09f522fe4c8eb0a8872add80c8dae4938,1,Extract Class,,
ffcbd1c2dede82775cbd074e0c06ea5a451fa144,2023-05-03T02:00:11Z,https://github.com/pytorch/pytorch/commit/ffcbd1c2dede82775cbd074e0c06ea5a451fa144,Move tracked nn_modules from OutputGraph to TracingContext (#100457)  Lint  Pull Request resolved: https://github.com/pytorch/pytorch/pull/100457 Approved by: https://github.com/anijain2305,1,Extract Class,,
db3349faa393f18953bd4fb973f33d56171cb784,2017-09-27T18:16:44Z,https://github.com/pytorch/pytorch/commit/db3349faa393f18953bd4fb973f33d56171cb784,Support class decorator syntax; remove instance compilation.Signed-off-by: Edward Z. Yang <ezyang@fb.com>,1,Extract Class,,
0147a408c3acf5d3adabaf39ddf94c9799c85c80,2023-03-03T09:00:48Z,https://github.com/pytorch/pytorch/commit/0147a408c3acf5d3adabaf39ddf94c9799c85c80,Refactor inductor collectives around base class (#95920)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/95920 Approved by: https://github.com/wanchaol,1,Extract Class,,
1dba81f56dc33b44d7b0ecc92a039fe32ee80f8d,2023-06-20T02:40:54Z,https://github.com/pytorch/pytorch/commit/1dba81f56dc33b44d7b0ecc92a039fe32ee80f8d,"Abstract FX->ONNX translation through FxOnnxInterpreter (#102810)  # Summary by author  * Previous to this PR, FX-to-ONNX conversion logic was sprinkled in several functions, files and class, such as `_export_fx_to_onnx`, `export_fx_to_onnxscript`, `_export_fx_node_to_onnxscript` and `OnnxDispatcher` class[1]. Although each had its specific role in the lowering of FX, they all are part of the same lowering process. * A `FxOnnxInterpreter` class, similar to but not derived from `torch.fx.Interpreter`, is introduced to drive the FX Graph -> ONNX Graph process. All functions and utilities from previous bullet were either moved under this class with minor refactoring.   * One of the main changes is that each FX node now have their own entry point, providing lower complexity. It also provides isolation among them.   *  Why refactored as class and not as a bunch of functions? ONNX Exporter adopted Object Oriented paradigm since its origin, so this refactoring should not be seen as any break of paradigm. This is just a continuation of a previous design decision. Example of other classes include `Exporter`, `ExportOptions`, `ExportOutput`, `ExportOutputSerializer`, `ProtobufExportOutputSerializer`, `FXGraphExtractor`, `ResolvedExportOptions`, `Analysis`, `Diagnostic`, `DiagnosticContext`, `Decompose`, `Functionalize`, `MovePlaceholderToFront`, `RemoveInputMutation`, `ReplaceGetAttrWithPlaceholder`, `ShapeInferenceWithFakeTensor`, `OnnxRegistry`, `OnnxDispatcher`, just to name a few.   * `torch.fx.Interpreter` was not used because its API only passes the node name (aka `target`) instead of the actual `torch.fx.Node` object to the node implementations. This is not sufficient as the ONNX conversion process needs to inspect the node to extract type, name and other info from the node. * This PR renames `OnnxDispatch` (without functionality changes) to `OnnxFunctionDispatcher` for clarity. ONNX word was too overloaded in this context. * This PR also moved the `passes` and `serialization` handling from the `_export_fx_to_onnx` util and moved them to `Exporter.export`, where they are consumed. Passes are not the goal of this PR, so it was moved to a temporary function called `pre_export_passes` (mainly the content of `_export_fx_to_onnx` without serialization and fx -> onnx call). * This PR also removed a bug in which new registry (and dispatcher, that wouldnt be a problem) were created for each pass was. That would be an issue with custom operators because only the original registry would have a reference to the custom operator.  Below is a summarized structure of the export process:  ```python class Exporter     def export(self) -> ExportOutput:         # 1) Trace torch.nn.Module into torch.fx.GraphModule         graph_module = self.options.fx_tracer.generate_fx()          # 2) Adapt input and output types to match ONNX graph         updated_model_args = self.options.fx_tracer.input_adapter.apply()          # 3) Run pre-export passes         graph_module = pre_export_passes()          # 4) Dispatch each FX node to an ONNX operator implementation         #  Model level FX -> ONNX.         fx_interpreter = fx_onnx_interpreter.FxOnnxInterpreter()         fx_interpreter.run()          # 5) Serialize graph to ONNX ModelProto.         onnx_model = onnxscript_graph.to_model_proto(self.options.opset_version)          # 6 Create ExportOutput         return torch.onnx.ExportOutput()  class FxOnnxInterpreter:  # NOT a torch.fx.Interpreter     def run(self, node: torch.fx.Node):         with torch.utils._mode_utils.no_dispatch():             for node in self.graph_module.graph.nodes:                run_node(node)    def run_node(node):         if node.op == ""placeholder"":             self.placeholder(node)         elif node.op == ""get_attr"":             self.get_attr(node)         elif node.op == ""call_function"":             self.call_function(node)         elif node.op == ""call_method"":             self.call_method(node)         elif node.op == ""call_module"":             self.call_module(node)         elif node.op == ""output"":             self.output(node)         else:             raise RuntimeError(                 f""Found node type not defined in torch.fx: {node.op}""             )     def placeholder(self, node: torch.fx.Node):         pass     def call_function(self, node: torch.fx.Node):         pass     def output(self, node: torch.fx.Node):         pass     def call_method(self, node: torch.fx.Node):         pass     def call_module(self, node: torch.fx.Node):         pass     def get_attr(self, node: torch.fx.Node):         pass  class OnnxFunctionDispatcher:     def dispatch(         self,         node: torch.fx.Node,         onnx_args: Sequence[Optional[Union[_TensorLike, str, int, float, bool, list]]],         onnx_kwargs: Dict[str, _type_utils.Argument],         diagnostic_context: diagnostics.DiagnosticContext,     ) -> Union[""onnxscript.OnnxFunction"", ""onnxscript.TracedOnnxFunction""]:         pass      def get_aten_name(  # promoted to public API         self, node: torch.fx.Node, diagnostic_context: diagnostics.DiagnosticContext     ) -> str:         pass      def get_function_overloads(  # promoted to public API         self,         node: torch.fx.Node,         aten_name: str,         diagnostic_context: diagnostics.DiagnosticContext,     ) -> Set[Union[""onnxscript.OnnxFunction"", ""onnxscript.TracedOnnxFunction""]]:         pass ```  Before this PR, that was the structure of the code:  ```python # torch/onnx/_internal/exporter.py class Exporter: def export(self) -> ExportOutput:     graph_module = self.options.fx_tracer.generate_fx(     self.options, self.model, self.model_args, self.model_kwargs         )      updated_model_args = self.options.fx_tracer.input_adapter.apply(         *self.model_args, **self.model_kwargs     )      return self.options.fx_tracer._export_fx_to_onnx(         self.options, graph_module, updated_model_args     )  # torch/onnx/_internal/exporter.py class FXGraphExtractor     def _export_fx_to_onnx() -> ExportOutput: `# Ignore the fact it lives inside FXGraphExtractor. It was a temporary thing         # Run all passes         # ...         with torch.utils._mode_utils.no_dispatch():             onnxscript_graph = passes.export_fx_to_onnxscript()              # Run input adapter             # ...              # Run output adapter             # ...          # Export TorchScript graph to ONNX ModelProto.         onnx_model = onnxscript_graph.to_model_proto(options.opset_version)          # Create ExportOutput         return torch.onnx.ExportOutput()  # torch/onnx/_internal/fx/passes/fx_to_onnxscript.py def export_fx_to_onnxscript():      # Initialize the ONNX graph     onnxscript_graph = graph_building.TorchScriptGraph()     tracer = graph_building.TorchScriptTracingEvaluator(onnxscript_graph)      for node in fx_module_with_metadata.graph.nodes:         _export_fx_node_to_onnxscript()      return onnxscript_graph  # torch/onnx/_internal/fx/passes/fx_to_onnxscript.py def _export_fx_node_to_onnxscript():     if node.op == ""placeholder"":         # ...     elif node.op == ""call_function"":         symbolic_fn = options.onnx_dispatcher.dispatch()          with evaluator.default_as(tracer):             output = symbolic_fn(*onnx_args, **onnx_kwargs)     elif node.op == ""output"":         # ...     elif node.op == ""call_method"":         # ...     elif node.op == ""call_module"":         # ...     elif node.op == ""get_attr"":         # ...     else:         raise RuntimeError(f""Found node type not defined in torch.fx: {node.op}"")  # torch/onnx/_internal/fx/function_dispatcher.py class OnnxDispatcher:     @_beartype.beartype     def dispatch() -> Union[""onnxscript.OnnxFunction"", ""onnxscript.TracedOnnxFunction""]:         # ONNX Script lookup only ``` [1] Note that the main functionalities in the fx -> onnx is orchestrated by functions in different files (see below).  Although the main loop that drives the dispatching is executed by a well-defined function (`export_fx_to_onnxscript`), this is not the entry point of the export process. The entry point is a utility function called `_export_fx_to_onnx`, which calls `export_fx_to_onnxscript`, that in turn will call another utility called `_export_fx_node_to_onnxscript`. Lastly, `_export_fx_node_to_onnxscript` implements *all* FX nodes in a huge monolithic block. the ""call_function"" segment of such block consumes `OnnxDispatcher`, completing the cycle.  ```bash _export_fx_to_onnx                         torch/onnx/_internal/exporter.py _export_fx_node_to_onnxscript      torch/onnx/_internal/fx/fx_to_onnxscript.py export_fx_to_onnxscript                  torch/onnx/_internal/fx/fx_to_onnxscript.py OnnxDispatcher                              torch/onnx/_internal/fx/onnxfunction_dispatcher.py ``` Pull Request resolved: https://github.com/pytorch/pytorch/pull/102810 Approved by: https://github.com/wschin, https://github.com/BowenBao",1,Extract Class,Rename Method,Rename Variable
2089a9bd487513e76bfcdfd07ea9e80fa30d7594,2023-05-03T03:10:22Z,https://github.com/pytorch/pytorch/commit/2089a9bd487513e76bfcdfd07ea9e80fa30d7594,"Refactor minifier tests to be more compact (#100471)  Mostly burning in more assumptions based on commonality on the tests, so writing new tests takes less code.  Signed-off-by: Edward Z. Yang <ezyang@meta.com>  Pull Request resolved: https://github.com/pytorch/pytorch/pull/100471 Approved by: https://github.com/voznesenskym",1,Extract Class,,
25b7bffed1d28b98471315aaf404195435c89dbb,2010-12-10T18:56:33Z,https://github.com/scikit-learn/scikit-learn/commit/25b7bffed1d28b98471315aaf404195435c89dbb,extract the randomized SVD implementation as a toplevel class able to handle sparse data as well,1,Extract Class,,
75fa2b13a451591b9a5b11e72ae25be43aac764f,2010-10-26T05:51:54Z,https://github.com/scikit-learn/scikit-learn/commit/75fa2b13a451591b9a5b11e72ae25be43aac764f,Move common sparse code to SparseBaseLibLinear.,1,Extract Class,,
0f37104fe99479183dc4b1b0815191e8bb8308e8,2010-09-28T10:40:58Z,https://github.com/scikit-learn/scikit-learn/commit/0f37104fe99479183dc4b1b0815191e8bb8308e8,"Refactoring in the svm module.  Created a svm folder and moved relevant sources there. This should not affect the API, since we are maintaining an __init__ file which handles the imports.",1,Extract Class,,
b2423f98e354386e8c46d6f3d8e0769b21fc54eb,2010-09-09T08:19:33Z,https://github.com/scikit-learn/scikit-learn/commit/b2423f98e354386e8c46d6f3d8e0769b21fc54eb,ENH : adding example + refactor in covariance module,1,Extract Class,,
2c57f5598e1c49fc8d90e66cf5bdcf9ed4ac24eb,2010-08-18T19:27:11Z,https://github.com/scikit-learn/scikit-learn/commit/2c57f5598e1c49fc8d90e66cf5bdcf9ed4ac24eb,More refactoring and bugfixing with liblinear.  Created base class BaseLibLinear to share methods between sparse & dense implementations and logisitic.  fixed some bugs in the logisitic implementation.,1,Extract Class,,
263a4544ddb43c67e330d03a7a38d55e7b90d131,2010-08-18T08:30:29Z,https://github.com/scikit-learn/scikit-learn/commit/263a4544ddb43c67e330d03a7a38d55e7b90d131,More refactoring and bugfixing with liblinear.  Created base class BaseLibLinear to share methods between sparse & dense implementations and logisitic.  fixed some bugs in the logisitic implementation.,1,Extract Class,,
d2fbad45d98c5c0ed0eda18cdb2d4c2985385282,2010-01-05T15:07:35Z,https://github.com/scikit-learn/scikit-learn/commit/d2fbad45d98c5c0ed0eda18cdb2d4c2985385282,"Refactoring of EM into classes David Cournapeau <david@ar.media.kyoto-u.ac.jp> | 2006-07-14 16:26:45 +0900 (Fri, 14 Jul 2006)  From: cdavid <cdavid@cb17146a-f446-4be1-a4f7-bd7c5bb65646>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@71 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8",1,Extract Class,,
60db81ff60c4b06271bebd1f331d21d66b3fefad,2022-10-05T13:31:33Z,https://github.com/huggingface/transformers/commit/60db81ff60c4b06271bebd1f331d21d66b3fefad,"Making camembert independent from roberta, clean (#19337)  Co-authored-by: Mustapha AJEGHRIR <mustapha.ajeghrir@kleegroup.com>",1,Extract Class,,
8d4bb020565e404d9eb814150280147e4963a2ee,2020-12-10T20:57:39Z,https://github.com/huggingface/transformers/commit/8d4bb020565e404d9eb814150280147e4963a2ee,Refactor FLAX tests (#9034),1,Extract Class,,
420104a88654b0cf1b8600d042cd1f3c90ec5a59,2023-04-11T21:23:32Z,https://github.com/pytorch/pytorch/commit/420104a88654b0cf1b8600d042cd1f3c90ec5a59,"Replace _dynamo.config with an object instead of module (#96455)  Summary:     Replace _dynamo.config with an object instead of module      Current usage patterns of setting and reading fields on config will work     unchanged.      Only changes needed going forward:     1. import torch._dynamo.config will not work. However, just doing        import torch._dynamo is sufficient to access dynamo config        as torch._dynamo.config.      2. Files inside of _dynamo folder need to access config via        from torch._dynamo.config_util import config instead of        from torch._dynamo import config. Because _dynamo/__init__.py        imports some of the files so it would be circular import.  Test Plan:  Reviewers:  Subscribers:  Tasks:  Tags:  Fixes #ISSUE_NUMBER  Pull Request resolved: https://github.com/pytorch/pytorch/pull/96455 Approved by: https://github.com/williamwen42",1,Encapsulate Record,,
262a5a450f1bbb4f19c2ae58e6be40a7252bf26d,2020-04-19T12:02:25Z,https://github.com/tensorflow/tensorflow/commit/262a5a450f1bbb4f19c2ae58e6be40a7252bf26d,refactoring: early return 'if else' -> 'if',1,Expression,,
a5ea8041e34a171f6fa5d1b7970433b53f3b0ad6,2020-04-07T06:17:08Z,https://github.com/tensorflow/tensorflow/commit/a5ea8041e34a171f6fa5d1b7970433b53f3b0ad6,refactoring: early return 'if else' -> 'if',1,Expression,,
864e290d1776895d7877777b8368ca8bc6fc22a3,2018-08-29T08:56:35Z,https://github.com/tensorflow/tensorflow/commit/864e290d1776895d7877777b8368ca8bc6fc22a3,"Make tf.transpose emit simpler graph when possibleIf not given an explicit 'perm' parameter, tf.transpose currentlyemits a graph that dynamically calculates it from the rank of theinput tensor. This is completely unnecessary when the rank of theinput can be statically determined at graph construction time.Modify tf.transpose to emit 'perm' as a single Const node wheneverpossible.",1,Expression,,
e24cf471b5b51a822b78e01ebab00ac74d333fa7,2023-04-04T19:27:41Z,https://github.com/keras-team/keras/commit/e24cf471b5b51a822b78e01ebab00ac74d333fa7,Minor code cleanup to improve readability of `is_functional_model_init_params()`.  PiperOrigin-RevId: 521834459,1,Expression,,
318c1204ac5a6f1250874a2eebee7e6af6efe7dc,2022-08-18T00:19:48Z,https://github.com/keras-team/keras/commit/318c1204ac5a6f1250874a2eebee7e6af6efe7dc,Refactor internal keras code to remove deprecated call to tf.concat() with scalars.  PiperOrigin-RevId: 468332095,1,Expression,,
c216e4cd9fc9fbb4478bae603d7e9242d7f9ff35,2022-03-22T19:48:25Z,https://github.com/keras-team/keras/commit/c216e4cd9fc9fbb4478bae603d7e9242d7f9ff35,update adamw.py,1,Expression,,
8fc8a1681332cc4c8b05260b20ee54fa1589e3d2,2018-10-20T14:45:52Z,https://github.com/keras-team/keras/commit/8fc8a1681332cc4c8b05260b20ee54fa1589e3d2,Refactor theno_backend to shorten linelength (#11391)  * Refactor theno_backend to shorten linelength  A variety of different changes to ensure linelength falls within 85 charicter linelength  Part of issue #11383  * Fixup Syntax in Theano Backend  Syntax fixes for incorrect line breaks.  * Fixup Linter Warnings  * Attempt to Fix Failing CTC Cost Tests  Change the ctc cost function to try and make the `test_ctc` pass again.  * fixed shaddowig of log_probs  * Fix up bad closing brackets  * Extract Variables dont' Wrap Lines  Update some of the refactorings to get line lengths under control by extracting sub-expressions to their own variables ratther than wrapping long lines. This should hopefully make things a little easier to read.  * Fixup Broken For Loop  * Fix Mixup with `add` and `append`  Python lists `append` not `add` :-/,1,Expression,,
beda1bc5132e6fef10a6853b34f48fefc6dc67c3,2017-12-21T19:54:09Z,https://github.com/keras-team/keras/commit/beda1bc5132e6fef10a6853b34f48fefc6dc67c3,ImageDataGenerator: Allow specifying width/height_shift_range in pixels (#8830)  * allow specifying width/height_shift_range in pixels  * Simplify logic,1,Expression,,
0f1302eeaed3b10ab6db493c1c33797a6ec46866,2023-01-09T23:23:27Z,https://github.com/pytorch/pytorch/commit/0f1302eeaed3b10ab6db493c1c33797a6ec46866,"Refactor stack_trace preservation for node meta preservation (#90803)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/90803 Approved by: https://github.com/jerryzh168, https://github.com/albanD",1,Expression,,
36fe31f537eaa667498c37bac4514ce90470b40c,2023-01-30T23:30:43Z,https://github.com/pytorch/pytorch/commit/36fe31f537eaa667498c37bac4514ce90470b40c,"[Reland] Refactor stack_trace preservation for node meta preservation (#90803) (#92400)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/90803 Approved by: https://github.com/jerryzh168, https://github.com/albanD ghstack-source-id: 5848cca08ef5d6f8868f4f79d8bc29711e9a52c2  Fixes #ISSUE_NUMBER  Pull Request resolved: https://github.com/pytorch/pytorch/pull/92400 Approved by: https://github.com/jerryzh168",1,Expression,,
381b3d8f4b25487499f17fc99b2b8413a82b3ccf,2021-04-13T17:02:07Z,https://github.com/pytorch/pytorch/commit/381b3d8f4b25487499f17fc99b2b8413a82b3ccf,"Refactor get numerical jacobian to calculate wrt all outputs at once (#54378)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/54378### For release notes`torch.autograd.gradcheck.get_numerical_jacobian` (not part of the public api) is being deprecated.In the future, user code relying on this function will break because, among other changes, `get_numerical_jacobian` now returns `List[Tuple[torch.Tensor]]` instead of `List[torch.Tensor]`.(more details if necessary)For a `fn` that takes in M inputs and N outputs we now return a list of M N-tuples of jacobians where `output[i][j]` would represent the numerical jacobian w.r.t. to the ith input and the jth output. Previously `get_numerical_jacobian` returned a list of tensors where each tensor represents the jacobian w.r.t. to each of the M inputs and a specific output. Finally, the function passed in as the parameter `fn` should expect to handle individual parameters, where previously `fn` is required to expect its parameters wrapped in a tuple. --- end --This PR addresses the comment here https://github.com/pytorch/pytorch/pull/53857#discussion_r595429639, to reduce the run-time of old gradcheck's get numerical jacobian by a factor of num_outputs. However, because very few ops actually return multiple outputs, there is not too much real speed up here.The main benefit of doing this change as part of the refactor is that it helps us isolate the possible bugs that are specific to switching `get numerical jacobian` to run in a per output way vs all outputs at once. Much of the logic implemented here will be the same for the fast gradcheck case, so knowing for certain that everything should pass after this stage will make the next step much simpler.The get_numerical_jacobian api is also being used in common_nn. So we update the callsite there as well.Test Plan: Imported from OSSReviewed By: jbschlosserDifferential Revision: D27728720Pulled By: soulitzerfbshipit-source-id: ee0f90b4f26ddc5fdbe949c4965eaa91c9ed0bb8",1,Expression,,
3bbf0683a1d56d8edc03822ccf3e38445322b4f8,2023-05-17T01:29:31Z,https://github.com/pytorch/pytorch/commit/3bbf0683a1d56d8edc03822ccf3e38445322b4f8,[inductor] Refactor RNG operators (#100064)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/100064 Approved by: https://github.com/ngimel,1,Expression,,
5084ff3b9b85eb2380428515461e8b2bffc0fd5f,2017-06-20T18:47:10Z,https://github.com/pytorch/pytorch/commit/5084ff3b9b85eb2380428515461e8b2bffc0fd5f,"improve blob sharingSummary:Since D5193393 introduced a ""token"" system for memonger that prevents sharing of blobs across parallel branches, we can be more aggressive in blob sharing. Thus, this removes the tracking of 'unused free blobs' and just relies on the token system.For forward-only resnet50, this reduces the number of shared blobs to 5 (optimal accorsing to akirillov's calculation).This requires careful testing, so I will not land it soon.Reviewed By: asaadaldienDifferential Revision: D5208985fbshipit-source-id: 2e520c4ea2351a2ec327b6c5f2e3af24234d1c9a",1,Expression,,
5854923c171d07d9daaf53d9a958c47c04985049,2023-04-05T22:06:10Z,https://github.com/pytorch/pytorch/commit/5854923c171d07d9daaf53d9a958c47c04985049,Extract ExtraMeta symbolic shape fields into a dedicated SymbolicShap?(#98399)  …eMeta  This modularizes ExtraMeta to bring down its creation cost when it is needed for other functions than syn shape handling.  Change-Id: Ife59b201b0c4fd75090fe8be5171a6dd73a10d10  Fixes #ISSUE_NUMBER  Pull Request resolved: https://github.com/pytorch/pytorch/pull/98399 Approved by: https://github.com/ezyang,1,Expression,,
7078ad5b8cd023bb7ad631427ad8891ddd69090d,2023-01-12T21:32:05Z,https://github.com/pytorch/pytorch/commit/7078ad5b8cd023bb7ad631427ad8891ddd69090d,"Reland ""AOT Autograd refactor + cleanup, handle intermediate views of bases, use view replay, fix non-tensor input handling"" (#92076)  Original PR: https://github.com/pytorch/pytorch/pull/89532  Pull Request resolved: https://github.com/pytorch/pytorch/pull/92076 Approved by: https://github.com/janeyx99, https://github.com/albanD",1,Expression,,
780b24b27ce320fdf8877ac12bfc7527379c550d,2023-06-14T16:14:52Z,https://github.com/pytorch/pytorch/commit/780b24b27ce320fdf8877ac12bfc7527379c550d,[DDP] Refactor _DDPSink to take DDP weakref (#103304)  This will make future PRs to support DDP static graph multi forward cleaner.  Differential Revision: [D46584545](https://our.internmc.facebook.com/intern/diff/D46584545/) Pull Request resolved: https://github.com/pytorch/pytorch/pull/103304 Approved by: https://github.com/awgu,1,Expression,,
89145e602b91064a87c7f57bfe58364c145f69bd,2019-04-09T16:10:42Z,https://github.com/pytorch/pytorch/commit/89145e602b91064a87c7f57bfe58364c145f69bd,"Namedtuple return for gels, triangular_solve, and test refactor (#17195)Summary:Partial fix of: https://github.com/pytorch/pytorch/issues/394- `gels` and `triangular_solve` now returns namedtuple- refactor test for namedtuple API for better coverage and maintainabilityPull Request resolved: https://github.com/pytorch/pytorch/pull/17195Differential Revision: D14851875Pulled By: ezyangfbshipit-source-id: 9b2cba95564269d2c3a15324ba48751d68ed623c",1,Expression,,
b820493cf1b0dda2840cd861b8f8e04dc3c6e582,2021-07-23T19:29:04Z,https://github.com/pytorch/pytorch/commit/b820493cf1b0dda2840cd861b8f8e04dc3c6e582,[skip ci] Refactor CIFlow init logic (#62102)  Summary: This PR refactors the CIWorkflow post_init step to best account for how CIFlow interacts with everything.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/62102  Test Plan: This PR did NOT garner any workflow changes. I ran mypy and flake8 on the changed file locally with no issues.  Reviewed By: jbschlosser  Differential Revision: D29883275  Pulled By: janeyx99  fbshipit-source-id: 6c5c1fc1878159e0de1bf8d9bd0cb32aa47af49a,1,Expression,,
b8de1cf0073908913dad890a4f48fa06090636b4,2023-02-08T17:31:38Z,https://github.com/pytorch/pytorch/commit/b8de1cf0073908913dad890a4f48fa06090636b4,[functorch][nn] Refactor NN stateless APIs by swapping module tensors (#92536)  - Fixes #92295 - Resolves #86708 - Resolves #92153 - Closes #92401 - Closes #92218  - Requires #91579  Refactor NN stateless APIs by swapping module tensors.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/92536 Approved by: https://github.com/jbschlosser,1,Expression,,
cfe73648093e30e5650560a6ac74aa59b3b19484,2021-03-26T05:27:30Z,https://github.com/pytorch/pytorch/commit/cfe73648093e30e5650560a6ac74aa59b3b19484,"ns for fx: move shadow activations linear test to new API (#53819)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/53819Moves the linear tests for shadow activations to new API.In order to do so, adds logic for fp32 to fp32 dtype cast,which is an identity.Test Plan:```python test/test_quantization.py TestFXNumericSuiteCoreAPIsModels.test_compare_shadow_activations_linear```Imported from OSSReviewed By: hx89Differential Revision: D26982734fbshipit-source-id: b6203228abf3cdf74ab0638468a6df77658aa662",1,Expression,,
fc53472ce4ace149567fa87a0dc180a83ab4bbcc,2023-04-13T19:20:01Z,https://github.com/pytorch/pytorch/commit/fc53472ce4ace149567fa87a0dc180a83ab4bbcc,"Move/Fix FakeTensor logic for detecting multiple fake modes (#97186)  This was leftover for when we had more logic in the FakeTensor and not FakeTensorMode, and wasn't firing correctly. It also makes more sense for it to be in the other validation function.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/97186 Approved by: https://github.com/bdhirsh",1,Expression,,
a949245a8694eef39789d8346362e2cec7d59966,2018-07-23T20:58:32Z,https://github.com/pytorch/pytorch/commit/a949245a8694eef39789d8346362e2cec7d59966,"Switch interpreter to use IValue's primitive int/floats (#9718)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/9718This patch switches the interpreter to use IValue's primitive numbers rather than tensors for computing on integers and floats. In addition to preparing the interpreter for first-class support of other types, this cleans up the handling of primitive numbers, making it possible to just use the normal operator overloading dispatch to find the right implementation for numbers. As a result of this change, a lot of other functionality needed to be updated since it was the first time we use non-tensors in a lot of places in the code base.Notes:* Fixes code_template.py so that multi-line strings are indented correctly when used on a standalone line* Cast operators (`int(x)`) now are functional. Some tests have addition conversions to integers becausewe no longer allow implicit tensor -> integer conversions following the same convention as in python* prim::ListConstruct/createList has been added to the interpreter for creating lists and this hasreplaced aten::stack for integers lists* gen_jit_dispatch.py has been refactored so that non-tensor types use operators on IValues to extractthe primitives* IValue gains a .to<T> method that is the equivalent of tensor_as but for IValue instead of at::Tensor* `constant_as<T>` is switched over to using IValues's `.to<T>` method, to make conversion from constant->IValue->C++ typemore consistent. This functionality combined with `toIValue(Value*)` replaces the `tensor_as` and `as_tensor` family of functions.* conditional expressions (if, loop) and operators related to them are now computed on integers rather than tensors* IValue gains constructors for constructing from at::Scalar and converting to it. However, IValue itself will always storethe scalars as a double or int64.* To align with python 3 syntax, TK_INT, TK_FLOAT, and TK_BOOL have been removed from the parser, and int/float/bool are just treated as special identifiers in the compiler,along with print. These are represented as special sugared values with a `call` method implemented. For int/float/bool this implements casting behavior.* Dropped shared_from_this from Type/Module. They were not needed and they making debugging harder because they internally throw/catch exceptions.* Shape propagation has been updated to support running nodes that include floating point primitive types, this required some refactoring of internal functions.* TensorToNum and NumToTensor have actual implementations as operators now* regster_prim_ops now contains implementations of math operators for float/int primitive types, and for mixed (prim <+> tensor) versions. This removes the need for special handling in compiler.cpp* Primitive math is now entirely handled by letting the compiler choose the right overloads. This removes tons of special casing in the compiler.* incorporates eellison's change to allow casting from return values. Due to the addition of primitive support, the code need slight modifications, so I just pre-merged it here.* stack.h gains generic vararg versions of push/pop that know how to convert to/from C++ types:```at::Tensor a;at::Scalar b;pop(stack, a, b);at::Tensor c = a + b;push(stack, c);```apaszkePull Request resolved: https://github.com/pytorch/pytorch/pull/9584Reviewed By: apaszkeDifferential Revision: D8910546Pulled By: zdevitofbshipit-source-id: 0f3e60d4d22217f196a8f606549430e43b7e7e30",1,Expression,,
35be57970143236d74661f2415d66d496aab5476,2023-03-29T23:08:03Z,https://github.com/pytorch/pytorch/commit/35be57970143236d74661f2415d66d496aab5476,"Refactor TENSOR_MATCH guards to check dim (for NT support) (#97896)  Tweaks the TENSOR_MATCH guard logic to avoid saving sizes / strides for the case of dynamic shapes. Instead, the dim() is stored, which is enough for both dense tensors and NTs.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/97896 Approved by: https://github.com/ezyang",1,Expression,Rename Method,
93d75568c7070942a59337dd83194c2fd5221adb,2023-04-13T22:47:03Z,https://github.com/pytorch/pytorch/commit/93d75568c7070942a59337dd83194c2fd5221adb,"[ONNX] Refactor ShapeInferenceWithFakeTensor to fill  metavalue into the original gm (#98760)  From https://github.com/pytorch/pytorch/pull/97494#discussion_r1160068456, the passes should modify gm inplace, but before this PR, `ShapeInferenceWithFakeTensor` utilizes Transform.transform() to make a copy of the gm, and rely on the assumption that the topological order of two graphs should be the same. This PR addresses the issue by saving another metavalue `static_shape` into gm for op_level_debug, instead of overwriting `val`.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/98760 Approved by: https://github.com/BowenBao",1,Expression,Rename Variable,Rename Method
ae79f95cb899f2e767d1b98a08e248bedbe20439,2023-01-30T22:57:20Z,https://github.com/pytorch/pytorch/commit/ae79f95cb899f2e767d1b98a08e248bedbe20439,"[quant][fx][pt2e][refactor] Refactor prepare.py for upcoming quantize_pt2e changes (#92641)  Summary: Changes node.meta[""target_dtype_info""] to store observer/fake_quant constructors instead of (dtype, is_dynamic), so that in the future user can provide configure this by themselves, follow up refactors: (1). generalized structure for ""target_dtype_info"": right now, we have ""input_act_obs_or_fq_ctr"", ""weight_obs_or_fq_ctr"", ""bias_obs_or_fq_ctr"", ""output_obs_or_fq_ctr"" this works OK for current use cases, and users are using a different config to specify which input is weight and which input is bias, to generalize it we should just expose an api that allow users to specify either a dictionary from input_index to obs_or_fq_ctr, and output_index to obs_or_fq_ctr, e.g. e.g. out1, (out2, out3) = op(arg0, (arg1, arg2)) ""input_act_obs_or_fq_ctr"" = {0: obs1, 1: obs2} ""output_act_obs_or_fq_ctr"" = {0: obs3, 1: obs4} note that this would not allow configuring obs/fq for nested structures  or have a config that mimics the structure of arguments and output, e.g. out1, (out2, out3) = op(arg0, (arg1, arg2)), we can have ""input_act_obs_or_fq_ctr"" = (obs1, (obs2, obs3)) ""output_act_obs_or_fq_ctr"" = (obs4, (obs5, obs6))  (2). use these observer/fq directly for inserting observers instead of using qconfig (3). clean up the TODOs in the code base  Test Plan: python test/test_quantization.py TestQuantizeFx  Reviewers:  Subscribers:  Tasks:  Tags: Pull Request resolved: https://github.com/pytorch/pytorch/pull/92641 Approved by: https://github.com/jcaip",1,Expression,Extract Method,
c3b5ea2fa8bf23792ebaf309d6d0c564ea7685dd,2012-11-08T09:39:22Z,https://github.com/scikit-learn/scikit-learn/commit/c3b5ea2fa8bf23792ebaf309d6d0c564ea7685dd,MISC lars_path: cleaner code in degenerate case,1,Expression,,
83cf11c398d13cb19921a3f4442b0169927fdf74,2011-06-18T08:34:35Z,https://github.com/scikit-learn/scikit-learn/commit/83cf11c398d13cb19921a3f4442b0169927fdf74,COSMIT: Minor refactor in lars_path  This will make LarsCV easier,1,Expression,,
063edbc39d954515a3610ff61ea659f0573ab842,2021-02-08T17:43:02Z,https://github.com/tensorflow/tensorflow/commit/063edbc39d954515a3610ff61ea659f0573ab842,Simplify shape inference in Keras resize_images,1,Expression,,
47b0fb64a5e19ee6ca793cff0b91ed84e8aae978,2020-09-10T17:49:29Z,https://github.com/tensorflow/tensorflow/commit/47b0fb64a5e19ee6ca793cff0b91ed84e8aae978,python cleanup and more tests,1,Expression,,
feb0a771284df62a5162f24cb1eefde7134186c7,2020-09-03T22:43:43Z,https://github.com/tensorflow/tensorflow/commit/feb0a771284df62a5162f24cb1eefde7134186c7,Remove some unnecessary `if...else...` statement; Wrap the return valuewith an ndarray converter.,1,Expression,,
17227b0d7ac43b0065d972c65153994d45b3f3a5,2020-04-28T17:08:55Z,https://github.com/tensorflow/tensorflow/commit/17227b0d7ac43b0065d972c65153994d45b3f3a5,Simplify Model.run_eagerly logic for eager-only Model class.PiperOrigin-RevId: 308845109Change-Id: Ie2e30b8c675405c9db74290386da086bbac09a7c,1,Expression,,
ebd54f18065d93fe2fab3e1fda6b0b53cf7cb9af,2020-04-19T12:05:08Z,https://github.com/tensorflow/tensorflow/commit/ebd54f18065d93fe2fab3e1fda6b0b53cf7cb9af,refactoring: early return 'if else' -> 'if',1,Expression,,
3dbef88320ff06d14d1fab11cbb80f638925651c,2020-04-16T04:19:26Z,https://github.com/tensorflow/tensorflow/commit/3dbef88320ff06d14d1fab11cbb80f638925651c,refactoring: early return 'if else' syntax -> 'if' syntax,1,Expression,,
54f7845248570bff8858e9c13c7ce6f48b609b7c,2020-04-16T04:15:17Z,https://github.com/tensorflow/tensorflow/commit/54f7845248570bff8858e9c13c7ce6f48b609b7c,refactoring: early return 'if else' syntax -> 'if' syntax,1,Expression,,
bb23a5963df47db53966cb89c79187c9102daa37,2020-01-08T13:22:05Z,https://github.com/tensorflow/tensorflow/commit/bb23a5963df47db53966cb89c79187c9102daa37,Simplify tf.keras.backend.bias_add,1,Expression,,
77ae78b06991f53d86553f3e48f7034895adf466,2018-10-31T15:25:36Z,https://github.com/tensorflow/tensorflow/commit/77ae78b06991f53d86553f3e48f7034895adf466,simplify logic as requested in code review,1,Expression,,
443084eeaff33764271ea025119b1d8c151d6694,2018-10-12T18:15:00Z,https://github.com/tensorflow/tensorflow/commit/443084eeaff33764271ea025119b1d8c151d6694,Simplify implementation of shared weights support to not depend on string names.Instead we just ensure that all consumers of a target tensor use the inserted FakeQuant tensor instead.PiperOrigin-RevId: 216891274,1,Expression,,
6d02ee8e581bf5211f362b80175122e3782fb37a,2018-09-28T19:49:38Z,https://github.com/tensorflow/tensorflow/commit/6d02ee8e581bf5211f362b80175122e3782fb37a,Simplify batch_dot logicRemove dead logical branch.PiperOrigin-RevId: 214980627,1,Expression,,
c09e01232ace0a5657828c9c47de942751c94949,2018-08-27T20:09:39Z,https://github.com/tensorflow/tensorflow/commit/c09e01232ace0a5657828c9c47de942751c94949,Simplify logic that defaults to the default graph when no graph is passed into saved_models.utils.get_tensor_from_tensor_infoPiperOrigin-RevId: 210417762,1,Expression,,
e12a33cd193dcd32d236e7f67e27b31d40f0fb10,2018-06-22T14:34:41Z,https://github.com/tensorflow/tensorflow/commit/e12a33cd193dcd32d236e7f67e27b31d40f0fb10,CLN: remove redundant if...else,1,Expression,,
3bb161433069ea5012f1f5be97fbbd8d0784213d,2018-04-17T02:26:17Z,https://github.com/tensorflow/tensorflow/commit/3bb161433069ea5012f1f5be97fbbd8d0784213d,"Remove conditional scope logic now that ""current_arg_scope"" exists in contrib",1,Expression,,
93e5eaad37467be2516bd49e4ead080522ef6c3a,2017-05-30T22:20:53Z,https://github.com/tensorflow/tensorflow/commit/93e5eaad37467be2516bd49e4ead080522ef6c3a,"Refactoring of layer name autogeneration, to remove a graph serialization warning.PiperOrigin-RevId: 157520123",1,Expression,,
a2d5ea96d28a9efd97e2a582247d56ec58d2ca63,2023-03-29T17:21:46Z,https://github.com/keras-team/keras/commit/a2d5ea96d28a9efd97e2a582247d56ec58d2ca63,"Update training_utils.py  simplified logic a but. the first check will always return true because even (None,) != None.",1,Expression,,
b7449e59ba5e6617461f9974206b3af15e3ba475,2022-04-25T20:37:33Z,https://github.com/keras-team/keras/commit/b7449e59ba5e6617461f9974206b3af15e3ba475,"Refactor saving code to use `CallFunctionSpec`.  Creating tf.functions for layer calls requires argument manipulation with the `training` arg in order to ensure that layers have both `training=True` and `training=False` traces. `CallFunctionSpec` already contains methods for argument manipulation, so delete the duplicate functions.  This also resolves a long-standing issue where the `fullargspec` of the loaded call function contains multiple `training` arguments in the positional and keyword arguments.  PiperOrigin-RevId: 444357094",1,Expression,,
0c0390bf431ab441581c44a1d84ba8a3bc1768b4,2022-03-25T14:22:07Z,https://github.com/keras-team/keras/commit/0c0390bf431ab441581c44a1d84ba8a3bc1768b4,update adamw.py,1,Expression,,
d3f5bec982c568b4d61681753d9524c0e7994f53,2022-03-24T20:15:38Z,https://github.com/keras-team/keras/commit/d3f5bec982c568b4d61681753d9524c0e7994f53,update adamw.py,1,Expression,,
78566bdf0b70bb4aef0f8d08a2e990e8a4e9389b,2022-03-24T20:13:04Z,https://github.com/keras-team/keras/commit/78566bdf0b70bb4aef0f8d08a2e990e8a4e9389b,update adamw.py,1,Expression,,
3c3a204eb6ad6883e5817f9c2a4360dcd3800564,2022-02-12T18:14:34Z,https://github.com/keras-team/keras/commit/3c3a204eb6ad6883e5817f9c2a4360dcd3800564,"Simplify the conditional logic check for KPL.  Since KPL is only targeted for v2, we don't need to worry about the keras.learning_phase(), and should be safe to do if/else check on `training`.  Also consolidate some of augmentation logic into self-contained method, so that we can easily refactor them later if needed.  PiperOrigin-RevId: 428223342",1,Expression,,
a3678aa8dda7bb679067799c672a564edf65ec2c,2021-10-13T02:43:15Z,https://github.com/keras-team/keras/commit/a3678aa8dda7bb679067799c672a564edf65ec2c,Refactored model.summary and fixed tests,1,Expression,,
6096ded90df902e1f8a21f666748a03100d140c0,2019-01-09T23:57:18Z,https://github.com/keras-team/keras/commit/6096ded90df902e1f8a21f666748a03100d140c0,Simplify identity initializer with zero padding (#11986),1,Expression,,
c4b8049ce41a34d9b1133795d34fb8fa439939c0,2018-09-25T12:13:33Z,https://github.com/keras-team/keras/commit/c4b8049ce41a34d9b1133795d34fb8fa439939c0,refactor lagacy/interfaces (#11219)  if -> elif,1,Expression,,
672a873ffb344dfa030103cad69bdbc948184e8e,2018-08-08T14:08:33Z,https://github.com/keras-team/keras/commit/672a873ffb344dfa030103cad69bdbc948184e8e,Some code refactoring using `transpose_shape` in tensorflow_backend.py. Part 3 (#10860)  ### Summary  Some code refactoring.  ### Related Issues  ### PR Overview  - [ ] This PR requires new unit tests [y/n] (make sure tests are included) - [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date) - [x] This PR is backwards compatible [y/n] - [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet),1,Expression,,
359e7627b46e850688c95cf6d1de48b77f9df901,2018-08-08T14:07:41Z,https://github.com/keras-team/keras/commit/359e7627b46e850688c95cf6d1de48b77f9df901,"Some code refactoring using `transpose_shape` in tensorflow_backend.py. Part 2 (#10859)  ### Summary Some refactoring.  ### Related Issues  ### PR Overview  There was a bug in the code in the `channels_last` part:  `x += reshape(bias, (1, 1, 1, bias_shape[0]))`  The new shape should be of size 5, here it is only 4. My refactoring fixes this.  - [ ] This PR requires new unit tests [y/n] (make sure tests are included) - [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date) - [x] This PR is backwards compatible [y/n] - [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)",1,Expression,,
9aed521e6650384533f69d7b46c0210b45ae9391,2018-08-08T14:04:46Z,https://github.com/keras-team/keras/commit/9aed521e6650384533f69d7b46c0210b45ae9391,Some code refactoring using `transpose_shape` in tensorflow_backend.py. (#10858)  ### Summary  I was able to simplify this piece of code with the function `transpose_shape`.  ### Related Issues  ### PR Overview  - [ ] This PR requires new unit tests [y/n] (make sure tests are included) - [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date) - [x] This PR is backwards compatible [y/n] - [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet),1,Expression,,
8f4e4f2a0b543f3d74327cb04113f65cd5d11c62,2018-08-08T14:02:40Z,https://github.com/keras-team/keras/commit/8f4e4f2a0b543f3d74327cb04113f65cd5d11c62,Refactoring of the cropping layers. (#10865)  ### Summary  The computing of the output shape for cropping layers can be done in a single function. Maybe we could use subclassing later on?  ### Related Issues  ### PR Overview  - [ ] This PR requires new unit tests [y/n] (make sure tests are included) - [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date) - [x] This PR is backwards compatible [y/n] - [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet),1,Expression,,
e94e2cc5761e1a516f70e1706498b85cf9287297,2018-08-07T18:04:21Z,https://github.com/keras-team/keras/commit/e94e2cc5761e1a516f70e1706498b85cf9287297,Removed some code in the cropping layer by making use of slices. (#10864),1,Expression,,
9118ea65f40874e915dd1299efd1cc3a7ca2c333,2018-03-03T22:19:52Z,https://github.com/keras-team/keras/commit/9118ea65f40874e915dd1299efd1cc3a7ca2c333,Cleanup fit_genenerator for validation (#9537)  * Made Sequence iterable  * Made it python2 compliant  * clean fit_generator  * keep mp specs  * Fix tests and expl,1,Expression,,
3a5a090b231a67b6531cc2da3c40ee4dc34801c2,2018-02-02T18:44:12Z,https://github.com/keras-team/keras/commit/3a5a090b231a67b6531cc2da3c40ee4dc34801c2,Simplify with from six.moves import input (#9216)  * Simplify with from six.moves import input  [Use feature detection instead of version detection](https://docs.python.org/3/howto/pyporting.html#use-feature-detection-instead-of-version-detection)  * with patch('__builtin__.input') as mock:  * Update io_utils_test.py  * with patch('six.moves.input') as mock:  * with patch('input') as mock:  * get_input() ? input()  * get_input() in the script  * get_input() in the test  * six.moves.input() in the script  * six.moves.input in the test,1,Expression,,
d72c2b383e8fb5b13fe710a3343e54cb93d18eef,2018-01-08T17:16:27Z,https://github.com/keras-team/keras/commit/d72c2b383e8fb5b13fe710a3343e54cb93d18eef,Removed unnecessary check. (#9000),1,Expression,,
63c48ff2044ae754084dbf5afeded86efeb7184a,2018-01-04T18:15:38Z,https://github.com/keras-team/keras/commit/63c48ff2044ae754084dbf5afeded86efeb7184a,[Requests for Contributions] Refactoring _standardize_input_data to make it faster. With explanations and benchmarks. (#8920)  * Refactoring _standardize_input_data to make it faster. For loops replaced with list comprehensions and changed the starting point of the final for loop depending on the check_batch_axis argument.  * Corrected some bad formatting.  * Some blank lines are restored.  * Blank spaces this time.  * Fixing pep8.  * Pep8 again and again.  * Changed len(array.shape) into array.ndim.　Fixed bug name not defined.,1,Expression,,
0c41cefc883f1a56994a0a0eba2648dc643be9ca,2017-11-15T05:53:42Z,https://github.com/keras-team/keras/commit/0c41cefc883f1a56994a0a0eba2648dc643be9ca,Replace float ops with faster integer ops (#8488)  * Replace float ops with faster integer ops  * Replace float ops with faster integer ops  * pep8  * pep8,1,Expression,,
a3d41bb88640d034947c68cb75d2e89c54706ec8,2017-11-01T19:14:24Z,https://github.com/keras-team/keras/commit/a3d41bb88640d034947c68cb75d2e89c54706ec8,Simplify reporthook-related logic (#8327)  * Simplify reporthook-related logic  * More of the same,1,Expression,,
3077f277daa5f71a3d51f5217d367e08ab09a550,2017-10-28T00:19:22Z,https://github.com/keras-team/keras/commit/3077f277daa5f71a3d51f5217d367e08ab09a550,Simplify _to_tensor() (#8272),1,Expression,,
4a9f551a7a532c744dcb0fa90699ca3262d10bc0,2017-10-02T22:08:49Z,https://github.com/keras-team/keras/commit/4a9f551a7a532c744dcb0fa90699ca3262d10bc0,Enable accuracy reporting during training in examples/mnist_siamese_graph.py (#7997)  * 1. Enable accuracy reporting during training. 2. Simplify compute_accuracy()  * Fix PEP8 errors,1,Expression,,
9eb32b0a78254f7f29e1945fc8b1c9682effd2f5,2017-08-22T20:44:13Z,https://github.com/keras-team/keras/commit/9eb32b0a78254f7f29e1945fc8b1c9682effd2f5,Refactor applications input shape management,1,Expression,,
1fe9ed7b55f2ad42b4e697f2e0a471f0ff71b210,2017-04-07T18:47:34Z,https://github.com/keras-team/keras/commit/1fe9ed7b55f2ad42b4e697f2e0a471f0ff71b210,Small refactor of losses/updates.,1,Expression,,
5f94aef6685289c5451f24bcfdb2ab24e2bc87df,2017-03-05T01:00:01Z,https://github.com/keras-team/keras/commit/5f94aef6685289c5451f24bcfdb2ab24e2bc87df,Simplify tests.,1,Expression,,
72c7716902da61379aea15a059983ee0de843208,2016-12-21T23:59:03Z,https://github.com/keras-team/keras/commit/72c7716902da61379aea15a059983ee0de843208,refactored convert_kernel (#4720),1,Expression,,
9bf55395f14e5ba02a937825dff08484ee5b5006,2016-11-01T23:51:54Z,https://github.com/keras-team/keras/commit/9bf55395f14e5ba02a937825dff08484ee5b5006,Simplify 1D pooling implementation,1,Expression,,
075c34d037ec564aa9c923a653c2cc3135c99510,2015-12-08T06:44:56Z,https://github.com/keras-team/keras/commit/075c34d037ec564aa9c923a653c2cc3135c99510,Removed comment and sum mode,1,Expression,,
f2e4e2ddcef7aab7c6dd3d66b91a2ec62240a57d,2015-12-04T21:35:47Z,https://github.com/keras-team/keras/commit/f2e4e2ddcef7aab7c6dd3d66b91a2ec62240a57d,clean up code,1,Expression,,
560cb94519ad5a5eed3adc323a9e1ad3cf0690e9,2015-07-01T00:59:34Z,https://github.com/keras-team/keras/commit/560cb94519ad5a5eed3adc323a9e1ad3cf0690e9,Callback refactor,1,Expression,,
824f9f5e80ee96891fc07413eaf2df5f7e5737da,2015-06-19T19:30:23Z,https://github.com/keras-team/keras/commit/824f9f5e80ee96891fc07413eaf2df5f7e5737da,refactored weighting in models.py,1,Expression,,
7d0ed02cc17ac57e35562526d7998735dee6368f,2015-12-08T06:45:17Z,https://github.com/keras-team/keras/commit/7d0ed02cc17ac57e35562526d7998735dee6368f,refactored tf backend pooling,1,Expression,,
7bee9a18d83899ce6dfd50c4883afc678139f4ad,2018-12-02T14:35:34Z,https://github.com/keras-team/keras/commit/7bee9a18d83899ce6dfd50c4883afc678139f4ad,Remove reduce sum impl in batch dot (#11768)  * remove reduce_sum impl  * pep8  * relax test,1,Expression,,
7113063a93ef8d77c6d7d21a2756c1ac802d83de,2018-01-16T22:16:45Z,https://github.com/keras-team/keras/commit/7113063a93ef8d77c6d7d21a2756c1ac802d83de,"cifar10_resnet: Simplify and improve logic (#8955)  * Change shear intensity from radians to degrees  * Improve logic  * improve logic  * improve logic  * Update cifar10_resnet.py  * rename j to res_unit  * add comments  * Put back conversion to int, needed for Python3.  * pep8  * Improve first layer and first stage logic, break long lines  * renamings",1,Expression,Rename Method,
0c0e5c574e2b47d251ac4537633842d03a265cdb,2023-04-12T11:59:08Z,https://github.com/pytorch/pytorch/commit/0c0e5c574e2b47d251ac4537633842d03a265cdb,"[inductor] Consolidate constant_args and cpp_constant_args (#98742)  Summary: Refactor code to simplify the logic. Support convolution as an extern call in CudaWrapperCodeGen.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/98742 Approved by: https://github.com/jgong5, https://github.com/jansel",1,Expression,,
1c5073fb4bb7fdb73b4137e4fcf9bc7345ab4b9a,2019-04-16T17:50:48Z,https://github.com/pytorch/pytorch/commit/1c5073fb4bb7fdb73b4137e4fcf9bc7345ab4b9a,"Adding pin_memory kwarg to zeros, ones, empty, ... tensor constructors (#18952)Summary:Make it possible to construct a pinned memory tensor without creating a storage first and without calling pin_memory() function. It is also faster, as copy operation is unnecessary.Supported functions:```pythontorch.rand_like(t, pin_memory=True)torch.randn_like(t, pin_memory=True)torch.empty_like(t, pin_memory=True)torch.full_like(t, 4, pin_memory=True)torch.zeros_like(t, pin_memory=True)torch.ones_like(t, pin_memory=True)torch.tensor([10,11], pin_memory=True)torch.randn(3, 5, pin_memory=True)torch.rand(3, pin_memory=True)torch.zeros(3, pin_memory=True)torch.randperm(3, pin_memory=True)torch.empty(6, pin_memory=True)torch.ones(6, pin_memory=True)torch.eye(6, pin_memory=True)torch.arange(3, 5, pin_memory=True)```Part of the bigger: `Remove Storage` plan.Now compatible with both torch scripts: `  _1 = torch.zeros([10], dtype=6, layout=0, device=torch.device(""cpu""), pin_memory=False)`and`  _1 = torch.zeros([10], dtype=6, layout=0, device=torch.device(""cpu""))`Same checked for all similar functions `rand_like`, `empty_like` and othersIt is fixed version of #18455Pull Request resolved: https://github.com/pytorch/pytorch/pull/18952Differential Revision: D14801792Pulled By: VitalyFedyuninfbshipit-source-id: 8dbc61078ff7a637d0ecdb95d4e98f704d5450ba",1,Expression,,
1fa4908ac037a4216c0d445c0712e17418c5e1c0,2019-12-06T05:54:40Z,https://github.com/pytorch/pytorch/commit/1fa4908ac037a4216c0d445c0712e17418c5e1c0,Refactor test_quantization.py and enable `test_nested` (#30475)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/30475attTest Plan:python test/test_quantization.pyImported from OSSDifferential Revision: D18795727fbshipit-source-id: c9942c5361e0a34e91a08b8fc27405799db7ff4f,1,Expression,,
207883600554ed9f0940c37c7bbf2141ebdf2c8b,2021-04-23T02:42:20Z,https://github.com/pytorch/pytorch/commit/207883600554ed9f0940c37c7bbf2141ebdf2c8b,"Clean up raise exception logic (#55656)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/55656### For release notesWhat: - All errors that are silenced by ""raise_exception=False"" are now GradcheckError (which inherits from RuntimeError).Why: - Due to a refactor of gradcheckWorkaround: - If you catch for 'RuntimeError' with `except RuntimeError`, since GradcheckError inherits from RuntimeError, no changes are necessary. However if you explicitly check for the errors type via `type(error)`, you'll need to update your code to check for `GradcheckError` instead.Factors out all the logic handling involving `fail_test`, `raise_exception` into 1) a wrapper around gradcheck that uses try/except 2) gradcheck_helper that always raises exception.This allows us to avoid having to write the `if not x: return False` logic that is scattered throughout gradcheck currently.Test Plan: Imported from OSSReviewed By: albanDDifferential Revision: D27920809Pulled By: soulitzerfbshipit-source-id: 253aef6d9a3b147ee37a6e37a4ce06437981929a",1,Expression,,
2293ab4e53229e8729e0a89478b97f146e224362,2021-06-21T02:41:16Z,https://github.com/pytorch/pytorch/commit/2293ab4e53229e8729e0a89478b97f146e224362,[quant][graphmode][fx] Refactor convert for linear to use get_static_module_mapping and get_dynamic_module_mapping (#60151)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/60151  Test Plan: ``` python test/test_quantization.py TestQuantizeFx python test/test_quantization.py TestQuantizeFxOps ```  Imported from OSS  Reviewed By: vkuzo  Differential Revision: D29188264  fbshipit-source-id: d2b77ffcf4b7446fc6c43248e43218092d2a6aea,1,Expression,,
24a5d006f271f8536f88917f8394187ab9babaf5,2023-03-30T17:05:27Z,https://github.com/pytorch/pytorch/commit/24a5d006f271f8536f88917f8394187ab9babaf5,"[dynamo 3.11] Refactor create_instruction (#96499)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/96499 Approved by: https://github.com/jansel, https://github.com/albanD",1,Expression,,
298e0e0d573a90ed516f32051151c32e9b309c0f,2020-10-08T17:54:24Z,https://github.com/pytorch/pytorch/commit/298e0e0d573a90ed516f32051151c32e9b309c0f,Refactor gather_ranges_to_dense from Python to C++ (#46021)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/46021Refactor gather_ranges_to_dense from Python to C++https://www.internalfb.com/intern/tasks/?t=71935517Test Plan:General build/test:```buck build -c python.helpers=true fbcode/caffe2buck test -c python.helpers=true fbcode/caffe2```Specific Test:```buck test mode/dev-nosan //caffe2/torch/fb/sparsenn:test -- 'test_gather_ranges_to_dense \(caffe2\.torch\.fb\.sparsenn\.tests\.sparsenn_operators_test\.SparseNNOperatorsTest\)'```Reviewed By: houseroadDifferential Revision: D23858186fbshipit-source-id: 8bce7c279275c8ff7316901b455e1d1dd7e36b13,1,Expression,,
2f5fef5912233aafe023d73b51813634a980a33a,2023-06-14T02:04:54Z,https://github.com/pytorch/pytorch/commit/2f5fef5912233aafe023d73b51813634a980a33a,"Refactor tests for dynamic shapes (#103542)  First, infra improvements: new combinator `expectedFailureDynamic` which subsumes expectedFailure calls in test_dynamic_shapes.py. It's just nicer to have these right with the test. Implementation in torch/_dynamo/testing.py and it works by putting an attr on the test, which is then converted into a real expectedFailure when we actually generate the dynamic shapes test class  Next, some housekeeping: * test/dynamo/test_unspec.py accidentally was running mostly statically due to the `assume_static_by_default` config flip. Don't assume static by default and xfail some tests which regressed in that time. * New test file test/dynamo/test_config.py, for testing permutations of configuration options. `test_dynamic_shapes` got moved there.  Finally, grinding through tests in a way that will make them more compatible with dynamic by default: * If the test explicitly requires dynamic_shapes=False, remove that patch (and probably xfail it) * If the test checks dynamic_shapes internally, remove that test and patch the test so it ALWAYS runs with dynamic_shapes (this is not coverage loss because we're going to switch the default)  Signed-off-by: Edward Z. Yang <ezyang@meta.com>  Pull Request resolved: https://github.com/pytorch/pytorch/pull/103542 Approved by: https://github.com/anijain2305",1,Expression,,
30ec06c140b0428d591e2f5007bc8046d1bdf7c4,2018-02-23T23:03:31Z,https://github.com/pytorch/pytorch/commit/30ec06c140b0428d591e2f5007bc8046d1bdf7c4,"Merge Variable and Tensor classes (#5225)This replaces the torch.Tensor constructors with factories that produceVariables. Similarly, functions on the torch module (e.g. torch.randn)now return Variables.To keep the PR to a reasonable size, I've left most of the unused tensorcode. Subsequent PRs will remove the dead code, clean-up calls totorch.autograd.Variable, and rename Variable to Tensor everywhere.There are some breaking changes because Variable and Tensors hadslightly different semantics. There's a list of those changes here: https://github.com/pytorch/pytorch/wiki/Breaking-Changes-from-Variable-and-Tensor-merge",1,Expression,,
31f311a816c026bbfca622d6121d6a7fab44260d,2023-04-17T00:34:18Z,https://github.com/pytorch/pytorch/commit/31f311a816c026bbfca622d6121d6a7fab44260d,"[PT2E][Quantization] Refactor Quantizer and QNNPACKQuantizer (#99063)  This diff renames quantization spec/config and operator config. It moves these datastructures to base quantizer. Base quantizer API now has get_supported_operators that returns list of patterns that a quantizer quantizes. There are two choices being debated for how to convey to user what a particular quantizer will quantize.  1. Modules. We just convey what nn.Modules will be quantized. Of course that does not mean that equivalent functional variants wont be quantized, however for simplifity we just use nn.Module. If certain ops are quatnzied in fused manner then that will considered internal details. Pros and cons of this approach pros:   - Simple. Only nn Modules are listed.   - User does not have to see fusion patterns. Cons:   - confusing perhaps because it is not clear if supported = nn.Conv2d also     means that the quantizer supported functional.conv2d   - Hiding fusion pattern means user has no say in not fusing. Meaning if     conv2d + relu is fused and user configures to quantize only conv, quantizer     will also quantize the following relu as if conv2d + relu are fused.  2. Patterns. Be explicit about what is supported and enumerate all possible compbinations. Pros:   - it is very clear what quantizer will do. no surprises. Cons:   - It is not simple to parse.   - It can be argued taht fusion is internal detail of the quantizer. So some     quantizer implementation may chose to expose fusion patterns, while others     may not and may not even provide any configurability.  One option is to move set_supported_operators/modules out of base quantizer and let each quantizer define its own way of communicating what is supported. Issue with this is that when we want to ""Compose"" multiple quantizers there is no way for user to define the order of composition if user does not know what a quantizer supports. For exampl quantizer A may quantizer conv + relu while B only conv, but B's implementation is fast. In that case you may compose (B, A) such B quantizes conv and A quantizes relu. Not knowning what A and B support, makes such composition harder  Differential Revision: [D44895547](https://our.internmc.facebook.com/intern/diff/D44895547/)  **NOTE FOR REVIEWERS**: This PR has internal Meta-specific changes or comments, please review them on [Phabricator](https://our.internmc.facebook.com/intern/diff/D44895547/)! Pull Request resolved: https://github.com/pytorch/pytorch/pull/99063 Approved by: https://github.com/jerryzh168",1,Expression,,
3e2ea32dabddd62347633b9cee0d91badb4130fc,2023-05-19T17:30:52Z,https://github.com/pytorch/pytorch/commit/3e2ea32dabddd62347633b9cee0d91badb4130fc,[BE]: Enable ruff rule TRY302 and apply fixes (#101874)  Removes useless try statements and unreachable code. Pull Request resolved: https://github.com/pytorch/pytorch/pull/101874 Approved by: https://github.com/malfet,1,Expression,,
3f5d768b561e3edd17e93fd4daa7248f9d600bb2,2023-04-27T01:18:09Z,https://github.com/pytorch/pytorch/commit/3f5d768b561e3edd17e93fd4daa7248f9d600bb2,Refactors/improvements in _inductor/fx_passes (#100063)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/100063 Approved by: https://github.com/devashishshankar,1,Expression,,
431344f2d0ffef68689acfface75cc1607726949,2023-05-23T15:54:49Z,https://github.com/pytorch/pytorch/commit/431344f2d0ffef68689acfface75cc1607726949,"[inductor] Refactor generate_kernel_call (#102018)  Summary: Refactor generate_kernel_call to support codegen call to Triton kernel  Pull Request resolved: https://github.com/pytorch/pytorch/pull/102018 Approved by: https://github.com/jansel, https://github.com/jgong5",1,Expression,,
510339c07b9f2ef1a478a46bb2ed0b2c78463eeb,2022-12-14T01:13:19Z,https://github.com/pytorch/pytorch/commit/510339c07b9f2ef1a478a46bb2ed0b2c78463eeb,[FSDP][2/N] Refactor state dict hook registration (#90777)  This PR includes some follow-ups from the previous PR to clean up the code. Pull Request resolved: https://github.com/pytorch/pytorch/pull/90777 Approved by: https://github.com/rohan-varma,1,Expression,,
5b0f40048899e398d286fe7b55f297991f93ba2c,2020-10-20T01:40:28Z,https://github.com/pytorch/pytorch/commit/5b0f40048899e398d286fe7b55f297991f93ba2c,Replace list(map(...)) constructs by list comprehensions (#46461)Summary:As discussed in https://github.com/pytorch/pytorch/issues/46392 this makes the code more readable and possibly more performant.It also fixes a bug detected by this where the argument order of `map` was confused: https://github.com/Flamefire/pytorch/commit/030a24906e3b5a1c8e7768e0444973d63d818fde#diff-5bb26bd3a23ee3bb540aeadcc0385df2a4e48de39f87ed9ea76b21990738fe98L1537-R1537Fixes https://github.com/pytorch/pytorch/issues/46392Pull Request resolved: https://github.com/pytorch/pytorch/pull/46461Reviewed By: ailzhangDifferential Revision: D24367015Pulled By: ezyangfbshipit-source-id: d55a67933cc22346b00544c9671f09982ad920e7,1,Expression,,
5f77be8bbef5b7e8f1a02525e93ac43e48884aa7,2023-06-13T03:31:41Z,https://github.com/pytorch/pytorch/commit/5f77be8bbef5b7e8f1a02525e93ac43e48884aa7,"Refactor OptimizeIndexing (#100549)  This PR decouples the logic necessary to compute bounds on variables from the logic that uses this info to perform the strenght analysis on int64 variables. While doing so, it tries to minimize the number of attributes of the class in favour of local variables.  This class is now accessible from any `LoopBody` object.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/100549 Approved by: https://github.com/eellison",1,Expression,,
60a3b7425dde97fe8b46183c154a9c3b24f0c733,2023-02-05T09:24:12Z,https://github.com/pytorch/pytorch/commit/60a3b7425dde97fe8b46183c154a9c3b24f0c733,"Small refactor of shape guards to allow for 1:1 code_parts (#93894)  By moving guard string assembly into dynamo's default behavior and letting code_parts do the work, we can have much better shape guard failures.  Before this fix, the guard failure in the test would look like:  ``` 'x.size()[1] == x.size()[0] and x.stride()[0] == x.[264 chars]!= 1' != 'x.size()[0] < 3' - x.size()[1] == x.size()[0] and x.stride()[0] == x.size()[0] and x.stride()[1] == 1 and x.storage_offset() == 0 and y.size()[0] == x.size()[0] and y.size()[1] == x.size()[0] and y.stride()[0] == x.size()[0] and y.stride()[1] == 1 and y.storage_offset() == 0 and x.size()[0] < 3 and x.size()[0] != 0 and x.size()[0] != 1 + x.size()[0] < 3 ``` now it is ``` ""x.size()[0] < 3"" ```  Pull Request resolved: https://github.com/pytorch/pytorch/pull/93894 Approved by: https://github.com/ezyang",1,Expression,,
662a8cf74db7b16f53ea92010308c4f039fac40a,2023-03-28T22:19:44Z,https://github.com/pytorch/pytorch/commit/662a8cf74db7b16f53ea92010308c4f039fac40a,"[FSDP][8/N] Simplify addr padding internals (#97796)  This is a follow-up to the last PR to greatly simplify the approach. This should be much cleaner.  **Details** Let `N` denote the number of original parameters flattened into a given flat parameter with `M` extra padding tensors. - `_numels_with_padding`: length `N + M` - `_is_padding_mask`: length `N + M` - `_numels`, `_param_infos`, `_shapes`, `_fqns`, `_param_extensions`: length `N`  `_shard_param_indices` and `_shard_param_offsets` were used to determine (1) if a given original parameter is in the local shard and if so, then (2) what is its offset in the _sharded_ flat parameter, and (3) how many numel are in the _sharded_ flat parameter.  This PR reworks how to achieve (1), (2), and (3) to allow for simplifying the previously mentioned data structures. In particular, it saves one extra tuple `_shard_param_infos: Tuple[_ShardParamInfo, ...]` of length `N` where each `_ShardParamInfo` entry gives exactly the needed info. For example, the offset into the sharded flat parameter is now pre-computed, so we do not need to do `offset = 0; offset += numel_in_shard` over a `for` loop each time now.  For optimizer state dict, `FSDPParamInfo.param_indices` now maps to the indexes with respect to the length `N` data structures, not the length `N + M` ones. The only purpose of `param_indices` is to be able to index into `flat_param._shard_param_infos[i]` to get the contained info to flatten the unsharded original parameter optimizer state and extract the part in the local shard.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/97796 Approved by: https://github.com/rohan-varma",1,Expression,,
6630d98ae58ffaeb503f803f556ff571a30ff5c9,2021-08-07T02:13:42Z,https://github.com/pytorch/pytorch/commit/6630d98ae58ffaeb503f803f556ff571a30ff5c9,"Refactor codegen file sharding (#62184)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/62184  File sharding is currently implemented twice, once for VariableType and once for TraceType. This refactors the implementation into `FileManager` and also changes it so template substitution is only done once and shared between the sharded file and the ""Everything"" file.  Test Plan: Imported from OSS  Reviewed By: bdhirsh  Differential Revision: D29962050  Pulled By: albanD  fbshipit-source-id: 7858c3ca9f6e674ad036febd2d1a4ed2323a2861",1,Expression,,
74b7a6c75e698378882d30958908073407f97fb3,2023-06-09T15:44:46Z,https://github.com/pytorch/pytorch/commit/74b7a6c75e698378882d30958908073407f97fb3,Move tensor grouping to ATen (#100007)  rel: #94344 Pull Request resolved: https://github.com/pytorch/pytorch/pull/100007 Approved by: https://github.com/janeyx99,1,Expression,,
79474a192873df89883005e50df8a41de18d8594,2020-10-29T04:21:12Z,https://github.com/pytorch/pytorch/commit/79474a192873df89883005e50df8a41de18d8594,"[pytorch] simplify tensor options logic in pybinding codegen (#46976)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/46976Technically, it's not semantic preserving, e.g.: emition of'requires_grad' is no longer gated by 'has_tensor_return' - there is noguarantee that is_like_or_new_function should all have tensor return.But the output is identical so there might be some invariant - couldalso add assertion to fail loudly when it's broken.Test Plan: Imported from OSSReviewed By: ezyangDifferential Revision: D24589211Pulled By: ljk53fbshipit-source-id: 47c7e43b080e4e67a526fde1a8a53aae99df4432",1,Expression,,
796e3596014b0f684645aa58cb0fbd806a65b070,2019-05-20T18:16:36Z,https://github.com/pytorch/pytorch/commit/796363147f881271e120c4da6f32e097733c4f35,Refactor builtin opsSummary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/20666Pulled By: driazatiDifferential Revision: D15404419fbshipit-source-id: c52bfa408c3caabb0a14779308686cf27fed349b,1,Expression,,
7d28f1c81d51e069c36c05ab2172e0d7aef7e1e3,2021-01-12T23:17:20Z,https://github.com/pytorch/pytorch/commit/7d28f1c81d51e069c36c05ab2172e0d7aef7e1e3,[quant][refactor] Minor refactor of some typos (#50304)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/50304Does not include any functional changes -- purely for fixing minor typos in the `fuser_method_mappings.py`Test Plan: Imported from OSSReviewed By: jerryzh168Differential Revision: D25857248Pulled By: z-a-ffbshipit-source-id: 3f9b864b18bda8096e7cd52922dc21be64278887,1,Expression,,
8710dc8d5a09204391ebcaaed9839c1d885bdc44,2023-03-28T16:50:36Z,https://github.com/pytorch/pytorch/commit/8710dc8d5a09204391ebcaaed9839c1d885bdc44,[inductor] Refactor cpp_wrapper to be an attribute of GraphLowering (#97709)  Summary: to prepare for further AOT Inductor changes  <!-- copilot:summary --> ### <samp>🤖 Generated by Copilot at 7dff885</samp>  This pull request adds support for AOT compilation and C++ wrapper code generation for inductor models. It modifies the `GraphLowering` class in `torch/_inductor/graph.py` and the `compile_fx` function in `torch/_inductor/compile_fx.py` to enable this feature.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/97709 Approved by: https://github.com/jansel,1,Expression,,
93ac8c4aeb60e3c11afb61ef78336f27697b8890,2022-12-16T23:12:49Z,https://github.com/pytorch/pytorch/commit/93ac8c4aeb60e3c11afb61ef78336f27697b8890,[dynamo] Refactor how autocast parameters are binded (#90953)  Summary: Use `inspect.signature` for unified args handling  Test Plan: `test_dynamo`  Differential Revision: D42078621  Pull Request resolved: https://github.com/pytorch/pytorch/pull/90953 Approved by: https://github.com/brad-mengchi,1,Expression,,
a33d8133a52c7453958b70facc40bd7448d5d88d,2023-02-25T02:23:40Z,https://github.com/pytorch/pytorch/commit/a33d8133a52c7453958b70facc40bd7448d5d88d,"Slight cleanup of VariableBuilder giant if condition (#95471)  Some of these changes are semantics preserving, some are not. Please review carefully.  * Use `istype(x, y)` over `type(x) is y` * Use istype over isinstance in frozenset. If the user subclassed the type in question, we must treat it as a user defined class as it may have custom behavior * The `isinstance(value, (int, float))` condition for `wrap_unspecialized_primitive` is dead-ish; direct int/float values are caught earlier istype check. Technically however, if you subclassed int/float it would pass through, however this is almost assuredly not intended behavior  Signed-off-by: Edward Z. Yang <ezyang@meta.com>  Pull Request resolved: https://github.com/pytorch/pytorch/pull/95471 Approved by: https://github.com/Skylion007",1,Expression,,
aceceb3d5c4f8b0632c01b75d6c51c08609cb131,2021-04-13T20:20:01Z,https://github.com/pytorch/pytorch/commit/aceceb3d5c4f8b0632c01b75d6c51c08609cb131,"Reland #50999 (Added pow() on CPU for float16 & bfloat16) (#55280)Summary:#### Reason for relandingLine 1607 of `torch/testing/_internal/common_methods_invocations.py` of https://github.com/pytorch/pytorch/issues/50999  had `dtype` instead of `dtype=torch.bool`, so 4 of the 9 sample inputs for `bool` had incorrect dtype. This bug was caught by https://github.com/pytorch/pytorch/issues/54949.1. Added support for pow() on CPU for `float16` (`Half`) and `bfloat16` types.Both `pow(Tensor, Scalar)` and `pow(Tensor, Tensor)` are now supported for the aforementioned types.However autograd isn't supported for `Float16` on CPU yet, as `log_vml_cpu` can't be enabled for it.2. heitorschueroff added `pow_tensor_scalar_optimized_kernel` to refactor & simplify `PowKernel.cpp`.It provides a common path for all the complex types & floating point types (except Float16, due to lack of complete AVX2 vectorization support for it).  It replaced code that had previously been duplicated for (float, double) and complex types,so PowKernel.cpp looks a lot cleaner now.3. Enabled (unskipped) some tests for `erf`, `erfc`,`erfinv`, `tan` and `linalg.vector.norm` which were being skipped earlier due to `pow()` not having been implemented for `float16` & `bfloat16`.4. Added an OpInfo for `pow()` & enabled some test cases for `pow()`.5. Extended the coverage of existing tests for `pow` in `test_binary_ufuncs.py` in order to enable comparison with `numpy`, even with discontiguous tensors, and added a test to ensure that a runtime error is raised for `pow`'s inplace variant if resizing the base tensor is required during its invocation.6. Added `float16` & `bfloat16` to `square`'s dtype lists in its `UnaryUfuncInfo`.7. Removed redundant `dtypesIfCPU` and `dtypesIfCUDA` from `OpInfo`s where they are equal to `dtypes`.Pull Request resolved: https://github.com/pytorch/pytorch/pull/55280Reviewed By: jbschlosserDifferential Revision: D27591772Pulled By: heitorschuerofffbshipit-source-id: c7420811b32595bb3353149a61e54a73f2eb352b",1,Expression,,
c9222b7471a5452704c63beba30426e478c6b10e,2020-10-28T16:38:05Z,https://github.com/pytorch/pytorch/commit/c9222b7471a5452704c63beba30426e478c6b10e,"Implement clip_ranges operator for PyTorchTest Plan:unit test for correctness```buck test caffe2/torch/fb/sparsenn:test -- test_clip_rangesParsing buck files: finished in 1.6 secCreating action graph: finished in 18.9 secBuilding: finished in 15.0 sec (100%) 9442/9442 jobs, 1 updated  Total time: 35.6 secMore details at https://www.internalfb.com/intern/buck/build/66fb17de-859e-4d01-89bf-5c5de2950693Tpx test run coordinator for Facebook. See https://fburl.com/tpx for details.Running with tpx session id: 80f5e0c2-7db2-48a4-b148-25dd34651682Trace available for this run at /tmp/tpx-20201026-123217.050766/trace.logStarted reporting to test run: https://our.intern.facebook.com/intern/testinfra/testrun/4503599665041422    ?ListingSuccess: caffe2/torch/fb/sparsenn:test - main (14.912)    ?Pass: caffe2/torch/fb/sparsenn:test - test_clip_ranges (caffe2.torch.fb.sparsenn.tests.sparsenn_operators_test.SparseNNOperatorsTest) (14.098)Summary  Pass: 1  ListingSuccess: 1Finished test run: https://our.intern.facebook.com/intern/testinfra/testrun/4503599665041422```new  benchmark perf test```# ----------------------------------------# PyTorch/Caffe2 Operator Micro-benchmarks# ----------------------------------------# Tag : short# Benchmarking PyTorch: clip_ranges# Mode: JIT# Name: clip_ranges_LENGTH6_M1_N2_MAX_LENGTH1_dtypetorch.int32_cpu# Input: LENGTH: 6, M: 1, N: 2, MAX_LENGTH: 1, dtype: torch.int32, device: cpuForward Execution Time (us) : 155.765# Benchmarking PyTorch: clip_ranges# Mode: JIT# Name: clip_ranges_LENGTH7_M1_N2_MAX_LENGTH2_dtypetorch.int32_cpu# Input: LENGTH: 7, M: 1, N: 2, MAX_LENGTH: 2, dtype: torch.int32, device: cpuForward Execution Time (us) : 156.248# Benchmarking PyTorch: clip_ranges# Mode: JIT# Name: clip_ranges_LENGTH8_M1_N2_MAX_LENGTH3_dtypetorch.int32_cpu# Input: LENGTH: 8, M: 1, N: 2, MAX_LENGTH: 3, dtype: torch.int32, device: cpuForward Execution Time (us) : 156.634# Benchmarking PyTorch: clip_ranges# Mode: JIT# Name: clip_ranges_LENGTH9_M1_N2_MAX_LENGTH4_dtypetorch.int32_cpu# Input: LENGTH: 9, M: 1, N: 2, MAX_LENGTH: 4, dtype: torch.int32, device: cpuForward Execution Time (us) : 155.408# Benchmarking PyTorch: clip_ranges# Mode: JIT# Name: clip_ranges_LENGTH10_M1_N2_MAX_LENGTH5_dtypetorch.int32_cpu# Input: LENGTH: 10, M: 1, N: 2, MAX_LENGTH: 5, dtype: torch.int32, device: cpuForward Execution Time (us) : 165.168```Compare with the old implementation, there are **around 300us gain**```# ----------------------------------------# PyTorch/Caffe2 Operator Micro-benchmarks# ----------------------------------------# Tag : short# Benchmarking PyTorch: clip_ranges# Mode: JIT# Name: clip_ranges_LENGTH6_M1_N2_MAX_LENGTH1_dtypetorch.int32_cpu# Input: LENGTH: 6, M: 1, N: 2, MAX_LENGTH: 1, dtype: torch.int32, device: cpuForward Execution Time (us) : 443.012# Benchmarking PyTorch: clip_ranges# Mode: JIT# Name: clip_ranges_LENGTH7_M1_N2_MAX_LENGTH2_dtypetorch.int32_cpu# Input: LENGTH: 7, M: 1, N: 2, MAX_LENGTH: 2, dtype: torch.int32, device: cpuForward Execution Time (us) : 446.480# Benchmarking PyTorch: clip_ranges# Mode: JIT# Name: clip_ranges_LENGTH8_M1_N2_MAX_LENGTH3_dtypetorch.int32_cpu# Input: LENGTH: 8, M: 1, N: 2, MAX_LENGTH: 3, dtype: torch.int32, device: cpuForward Execution Time (us) : 444.064# Benchmarking PyTorch: clip_ranges# Mode: JIT# Name: clip_ranges_LENGTH9_M1_N2_MAX_LENGTH4_dtypetorch.int32_cpu# Input: LENGTH: 9, M: 1, N: 2, MAX_LENGTH: 4, dtype: torch.int32, device: cpuForward Execution Time (us) : 445.511# Benchmarking PyTorch: clip_ranges# Mode: JIT# Name: clip_ranges_LENGTH10_M1_N2_MAX_LENGTH5_dtypetorch.int32_cpu# Input: LENGTH: 10, M: 1, N: 2, MAX_LENGTH: 5, dtype: torch.int32, device: cpuForward Execution Time (us) : 450.468```Reviewed By: MarcioPortoDifferential Revision: D24546110fbshipit-source-id: e6c9b38e911f177f97961ede5bf375107f240363",1,Expression,,
e085acc9f36e3988af24413e444b6a8ab2e3bba1,2023-04-06T17:22:35Z,https://github.com/pytorch/pytorch/commit/e085acc9f36e3988af24413e444b6a8ab2e3bba1,"Cleanup Copy.cu logic (#97071)  Some of the logic specific to the cudaMallocAsync allocator related to peer access is placed outside of the allocator itself. This PR refactors, documents, and encapsulates it, while maintaining the same behavior.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/97071 Approved by: https://github.com/ngimel, https://github.com/eellison",1,Expression,,
f36f3cce9adfc24b3a662b16545416b9b4df719a,2019-02-02T05:31:13Z,https://github.com/pytorch/pytorch/commit/f36f3cce9adfc24b3a662b16545416b9b4df719a,Simplify layer_norm_op_testSummary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/16570Reviewed By: ezyangDifferential Revision: D13883913fbshipit-source-id: 7437d3cbc00c0de92bb01562c620cb658aa9f0d3,1,Expression,,
f9ce5932673753d329e4aac741ba5efd0bfd2354,2023-03-21T05:59:33Z,https://github.com/pytorch/pytorch/commit/f9ce5932673753d329e4aac741ba5efd0bfd2354,"Extend aot autograd dedup guards to params, stop using positions (#96774)  The purpose of this PR is to remove reliance on argument positions in dedup guards, AND extend the functionality to params.  A version of this PR was stamped prior https://github.com/pytorch/pytorch/pull/95831 - but was kinda gross, because it was based on an underlying PR that did way too much with source names.  This PR leaves most of that alone, in favor of just reusing the same name standardization logic that dynamo module registration does.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/96774 Approved by: https://github.com/ezyang",1,Expression,,
f9d25e8e724206218d276c3fccc6310c69b265b5,2016-09-26T22:38:52Z,https://github.com/pytorch/pytorch/commit/f9d25e8e724206218d276c3fccc6310c69b265b5,Refactor nn (require specifying parameters explicitly),1,Expression,,
fa66a1498eb1fac5b36811d5c1d6ba1540ffc824,2019-11-07T23:51:23Z,https://github.com/pytorch/pytorch/commit/fa66a1498eb1fac5b36811d5c1d6ba1540ffc824,Simplify _calculate_fan_in_and_fan_out (#29370)Summary:The code checking `if dimensions == 2` is not neededbecause the case of a 2D tensor (Linear) is already handledby the statement:`receptive_field_size = 1`and this conditional:`if tensor.dim() > 2:`Pull Request resolved: https://github.com/pytorch/pytorch/pull/29370Differential Revision: D18372987Pulled By: albanDfbshipit-source-id: fcb4dddbc76b9f4414c6d88c0aa2fb4435bf3385,1,Expression,,
fb1e6835cc15e3f6536d2223c0e86ce02ffec757,2021-09-20T17:34:45Z,https://github.com/pytorch/pytorch/commit/fb1e6835cc15e3f6536d2223c0e86ce02ffec757,simplify `torch.meshgrid`'s shape computation (#62905)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/62905  Reviewed By: mruberry  Differential Revision: D31021274  Pulled By: dagitses  fbshipit-source-id: c219389bdc543e9592f7b1c707acfbf752ee6f34,1,Expression,,
fc6f2f6e4e0bd3b5d442f912fea62155bffd85c6,2023-04-25T19:31:00Z,https://github.com/pytorch/pytorch/commit/fc6f2f6e4e0bd3b5d442f912fea62155bffd85c6,"[spmd] simplify data parallel tests (#99901)  As titled Pull Request resolved: https://github.com/pytorch/pytorch/pull/99901 Approved by: https://github.com/awgu, https://github.com/mrshenli",1,Expression,,
ff2e29144c9d3d8d86c3edf56cb280bd895d83c0,2020-05-27T22:29:24Z,https://github.com/pytorch/pytorch/commit/ff2e29144c9d3d8d86c3edf56cb280bd895d83c0,Refactor backward compatibility tests to use override_qengines decorator (#38838)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/38838Test Plan: Imported from OSSDifferential Revision: D21676032Pulled By: durumufbshipit-source-id: 5cbe56e0d72d322f540bccffb60bcdbb15385ee8,1,Expression,,
ff9e34fb35dca3a4768e9e02a73b42e892346d6a,2023-04-12T11:59:08Z,https://github.com/pytorch/pytorch/commit/ff9e34fb35dca3a4768e9e02a73b42e892346d6a,"[inductor] Consolidata kernel and cpp_kernel for wrapper codegen (#98741)  Summary: refactor to simplify the wrapper codegen logic  Pull Request resolved: https://github.com/pytorch/pytorch/pull/98741 Approved by: https://github.com/jgong5, https://github.com/jansel, https://github.com/ngimel",1,Expression,,
c79a13b7b6cd352ae88b14e209c0c42bdaa206d1,2019-09-11T19:00:22Z,https://github.com/pytorch/pytorch/commit/c79a13b7b6cd352ae88b14e209c0c42bdaa206d1,Simply code generation - phase 1 (#25961)Summary:remove special casing in YAML rendererPull Request resolved: https://github.com/pytorch/pytorch/pull/25961Differential Revision: D17322658Pulled By: kostmofbshipit-source-id: 2e44e075d97262790c7a5773abf0afa70e0b24cb,1,Expression,,
348dcf51e54e8dea7ea7807fb9bd446b4e307bbb,2023-04-06T15:59:55Z,https://github.com/pytorch/pytorch/commit/348dcf51e54e8dea7ea7807fb9bd446b4e307bbb,"[inductor] Combine CppWrapperCodeGen and CppAotWrapperCodeGen (#98088)  Summary: Make CppAotWrapperCodeGen generate kernels and wrapper in one file, which unifies the codegen for AOT and non-AOT mode. There will be more refactoring for the AOT part.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/98088 Approved by: https://github.com/jgong5, https://github.com/jansel",1,Expression,Rename Method,
40df6e164777e834b5f5b50e066632ed40bd25ef,2023-05-05T17:00:42Z,https://github.com/pytorch/pytorch/commit/40df6e164777e834b5f5b50e066632ed40bd25ef,"[ONNX] Simplify repeat_intereleave export for scalar-valued 'repeat' (#100575)  This PR simplifies the ONNX export of torch.repeat_interleave when 'repeat' is a scalar value (so each index in the input is repeated the same number of times). (Issue #100438)  Here is a before/after of a simple model export: ```python # Model + export code import torch  class RepeatInterleaveModel(torch.nn.Module):     def forward(self, x):         return x.repeat_interleave(2, dim=-1)  args = (torch.rand((2, 2, 16)),) model = RepeatInterleaveModel() torch.onnx.export(model, args, ""repeat_interleave.onnx"", opset_version=17) ```  **Before (static shapes)** ![repeat_interleave onnx(1)](https://user-images.githubusercontent.com/46343317/236014996-00726832-1e76-4fb4-950d-4b54cc5cc20c.png)  ----- **Before (dynamic shapes, second graph is Loop body)** <p float=""left"">   <img src=""https://user-images.githubusercontent.com/46343317/236029895-20b0ae0a-240f-466d-bb01-e619ec5967ad.png"" width=""45%"" />   <img src=""https://user-images.githubusercontent.com/46343317/236029915-e67b808a-029b-4997-bc05-1ce59eec409a.png"" width=""47%"" /> </p>  ----- **After (for both static and dynamic shapes)** <img src=""https://user-images.githubusercontent.com/46343317/236015235-633811cb-09a2-435d-a293-1b2bcb7dea50.png"" width=""66%"" />  -----  This PR also fixes a bug where the exporter throws an expection when the input has dynamic shapes and the 'dim' parameter is not specified to torch.repeat_interleave. Also adds a new testcase to cover this. (Issue #100429)  Fixes #100438 and #100429  Pull Request resolved: https://github.com/pytorch/pytorch/pull/100575 Approved by: https://github.com/BowenBao",1,Expression,,
7d40cce26729e7befa5fcc1e41f2493d8f113054,2017-09-27T05:51:00Z,https://github.com/pytorch/pytorch/commit/7d40cce26729e7befa5fcc1e41f2493d8f113054,Simplify glu symbolic,1,Expression,Inline Variable,
9a622f4cd9318d69896462823891588ef0bf719c,2021-05-20T01:55:52Z,https://github.com/pytorch/pytorch/commit/9a622f4cd9318d69896462823891588ef0bf719c,"refactor ASGD to use functional API (#58410)  Summary: Functional API is used in large scale distributed training to enable multithreaded training instead of multiprocess, as it gives more optimal resource utilization and efficiency.  In this PR, we provide code migration and refactoring for functional API for ASGD algorithm.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/58410  Reviewed By: ailzhang  Differential Revision: D28546702  Pulled By: iramazanli  fbshipit-source-id: 4f62b6037d53f35b19f98340e88af2ebb6243a4f",1,Expression,Extract Method,
cbac56e2445e6e9fea906d28889b47595b2611c0,2023-02-22T22:33:58Z,https://github.com/pytorch/pytorch/commit/cbac56e2445e6e9fea906d28889b47595b2611c0,"[BE] Simplify `Source.is_nn_module`; add some types (#95292)  I am still reading Dynamo source code...  This is an easy PR to simplify `Source.is_nn_module()` to reuse `GuardSource.is_nn_module()` instead of having the `in (...)` check implemented twice. While simplifying that, I thought I might as well add some type annotations for `Source` methods. Pull Request resolved: https://github.com/pytorch/pytorch/pull/95292 Approved by: https://github.com/ezyang",1,Expression,API Refactoring,
cc628293bf6e65720b23d5e66b30c31e2ed0d037,2023-04-26T18:46:57Z,https://github.com/pytorch/pytorch/commit/cc628293bf6e65720b23d5e66b30c31e2ed0d037,"simplify method_def generation (#100059)  simplify method_def generation  Summary: This removes some duplication. This was originally done to streamline a subsequent change, but that change turned out to be misguided. Nevertheless, this is a nice simplification.  Test Plan: This should change the code gen by removing some redundant parentheses. Rely on CI.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/100059 Approved by: https://github.com/ezyang",1,Expression,Inline Variable,
c927f5a87134ddebe3ede0b47fedeafed0b1592f,2022-06-01T06:36:19Z,https://github.com/scikit-learn/scikit-learn/commit/c927f5a87134ddebe3ede0b47fedeafed0b1592f,MNT Simplify comparison in PCA (#23502),1,Expression,,
ffbb1b4a0bbb58fdca34a30856c6f7faace87c67,2020-07-02T12:16:56Z,https://github.com/scikit-learn/scikit-learn/commit/ffbb1b4a0bbb58fdca34a30856c6f7faace87c67,MNT Collapse an unnecessary enclosed if statement (#17766)  Co-authored-by: Thomas J. Fan <thomasjpfan@gmail.com>,1,Expression,,
70829b34df8a1d98a15250f041102c6c0b10e2d1,2020-01-30T21:11:41Z,https://github.com/scikit-learn/scikit-learn/commit/70829b34df8a1d98a15250f041102c6c0b10e2d1,MNT Small check sample weight refactor (#16324),1,Expression,,
b7b0ba6a3cf2a31297785e037999d88db40b90df,2019-08-01T07:23:23Z,https://github.com/scikit-learn/scikit-learn/commit/b7b0ba6a3cf2a31297785e037999d88db40b90df,MAINT Simplify liblinear helpers set_problem and csr_set_probl?(#14533),1,Expression,,
ee59a0c4878e27873e6a910866596f762441a71d,2014-03-10T12:46:06Z,https://github.com/scikit-learn/scikit-learn/commit/ee59a0c4878e27873e6a910866596f762441a71d,Refactored the code and added quotes,1,Expression,,
fedff321ceff946886776ed3b1f74d62c937b1ed,2013-12-19T06:47:36Z,https://github.com/scikit-learn/scikit-learn/commit/fedff321ceff946886776ed3b1f74d62c937b1ed,COSMIT: simplify code,1,Expression,,
3c257fd08807c41724e037314af9cafb4fbc52f2,2013-08-03T07:03:22Z,https://github.com/scikit-learn/scikit-learn/commit/3c257fd08807c41724e037314af9cafb4fbc52f2,ENH : simplify ProabilisticPCA covariance_ computation + misc in pca.py,1,Expression,,
27e2b6ecf8196a1e75c9cae440feded25f9f289b,2013-07-24T16:47:52Z,https://github.com/scikit-learn/scikit-learn/commit/27e2b6ecf8196a1e75c9cae440feded25f9f289b,Simplified GraphLassoCV code.  Benchmarked GraphLassoCV with different combination of warm-restart. Removed any code that did not provide a significant speedup.  Corrected some docstrings at the same time.,1,Expression,,
109f2fb630e45b3214429ae4c8bdac034066236d,2013-07-08T11:49:25Z,https://github.com/scikit-learn/scikit-learn/commit/109f2fb630e45b3214429ae4c8bdac034066236d,OPTIM + ENH simplify mix string and number check,1,Expression,,
ef60f35d368c885e3520e33772dc7a7c92bcaed3,2012-12-21T09:33:48Z,https://github.com/scikit-learn/scikit-learn/commit/ef60f35d368c885e3520e33772dc7a7c92bcaed3,ENH Simplify estimator type checking in GridSearchCV.,1,Expression,,
e1972fa325db4ed4ebe9842759c2342162ea77ef,2012-12-21T09:33:48Z,https://github.com/scikit-learn/scikit-learn/commit/e1972fa325db4ed4ebe9842759c2342162ea77ef,"ENH make cross_val_score work, some refactoring in GridSearchCV",1,Expression,,
04b31e23ef8a7fd8945f00b536daa682bbae4f58,2012-10-11T20:30:55Z,https://github.com/scikit-learn/scikit-learn/commit/04b31e23ef8a7fd8945f00b536daa682bbae4f58,ENH simplify as suggested by @larsmans.,1,Expression,,
38c3c3020712873a8b3059076e7c3649f847b5b2,2012-07-20T13:18:16Z,https://github.com/scikit-learn/scikit-learn/commit/38c3c3020712873a8b3059076e7c3649f847b5b2,COSMIT refactor input validation code and tests,1,Expression,,
10a551ec1f4d5db4402a594f8d0de1218502ed2c,2011-09-08T17:30:36Z,https://github.com/scikit-learn/scikit-learn/commit/10a551ec1f4d5db4402a594f8d0de1218502ed2c,moved the min_split test to beginning of recursive_split,1,Expression,,
165125f324c2b4125daba3c9a6778220afc8fd7b,2011-09-01T13:05:15Z,https://github.com/scikit-learn/scikit-learn/commit/165125f324c2b4125daba3c9a6778220afc8fd7b,Refactored construct to subsample dimensions.,1,Expression,,
fecf08560cd9843b569279dd6f665c987890af4c,2023-08-24T14:18:39Z,https://github.com/huggingface/transformers/commit/fecf08560cd9843b569279dd6f665c987890af4c,[`from_pretrained`]  Simpler code for peft (#25726)  * refactor complicated from pretrained for peft  * nits  * more nits  * Update src/transformers/modeling_utils.py  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * make tests happy  * fixup after merge  ---------  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>,1,Expression,,
f1a6df3210695fa7311b4e8905c520cb738decbb,2022-09-09T15:44:56Z,https://github.com/huggingface/transformers/commit/f1a6df3210695fa7311b4e8905c520cb738decbb,Generate: Simplify is_pad_token_not_equal_to_eos_token_id (#18933),1,Expression,,
c55d6e4e10ce2d9c37e5f677f0842b04ef8b73f3,2022-08-24T16:12:42Z,https://github.com/huggingface/transformers/commit/c55d6e4e10ce2d9c37e5f677f0842b04ef8b73f3,examples/run_summarization_no_trainer: fixed incorrect param to hasattr (#18720)  * fixed incorrect param to hasattr  * simplified condition checks  * code cleanup,1,Expression,,
ee04b698223bc3279e0ce97bdd9d00aaa5d9cc38,2021-02-27T01:01:01Z,https://github.com/huggingface/transformers/commit/ee04b698223bc3279e0ce97bdd9d00aaa5d9cc38,[examples] better model example (#10427)  * refactors  * typo,1,Expression,,
33b74228397a112961c891234e60286102d516a3,2021-01-11T14:39:28Z,https://github.com/huggingface/transformers/commit/33b74228397a112961c891234e60286102d516a3,[trainer] remove `--model_parallel` (#9451)  * fix bad merge - dropped code  * remove --model_parallel  * Deal with TrainingArguments  * Use a private attr and fix batch sizes  * fix _n_gpu  * add is_parallel helper wrapper  * fix attribute  * introduce a new attribute is_model_parallel  * docs  * docs  * Put back init False and rearrange doc  * Ignore non-init args in HFArgumentParser  Co-authored-by: Sylvain Gugger <sylvain.gugger@gmail.com>,1,Expression,,
5e069633943c7fa2a348fb7c1ec63e7bed238ef4,2020-06-17T18:48:06Z,https://github.com/huggingface/transformers/commit/5e069633943c7fa2a348fb7c1ec63e7bed238ef4,Some changes to simplify the generation function (#5031)  * moving logits post-processing out of beam search  * moving logits post-processing out of beam search  * first step cache  * fix_Encoder_Decoder  * patrick_version_postprocess  * add_keyword_arg,1,Expression,,
a139d1a1602ee72ca98d5e0412efbd68f746d2c8,2020-06-08T21:08:04Z,https://github.com/huggingface/transformers/commit/a139d1a1602ee72ca98d5e0412efbd68f746d2c8,[cleanup] consolidate some prune_heads logic (#4799),1,Expression,,
c6d9d5394e6bf461f09e5f3e9b08e333961e590b,2018-12-05T16:53:09Z,https://github.com/huggingface/transformers/commit/c6d9d5394e6bf461f09e5f3e9b08e333961e590b,Simplifying code for easier understanding.,1,Expression,,
d69876b2f1caec3e77387b3aa3006a2d2ca3dc7c,2023-02-02T14:22:26Z,https://github.com/pytorch/pytorch/commit/d69876b2f1caec3e77387b3aa3006a2d2ca3dc7c,"Refactor to allow reuse of SchedulerNode.allocate (#93328)  Paves the way for ExternKernelSchedulerNode to also be able to use the buffer inplace logic, needed for Collective ops.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/93328 Approved by: https://github.com/jansel",1,Collapse Hierarchy,,
7750cae722e0c490ad67f191bba25dea187975af,2019-07-10T19:08:50Z,https://github.com/pytorch/pytorch/commit/7750cae722e0c490ad67f191bba25dea187975af,Refactor and improve randperm tests.Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/22121Test Plan: Imported from OSSDifferential Revision: D16153794Pulled By: li-royfbshipit-source-id: 4dbfa6cfcc79f6d431918a6646664215fa9ea0b9,1,Change Reference to Value,,
a11e3aa7a1f1dd872f4eab48100b58e1275a191b,2021-02-08T19:42:16Z,https://github.com/tensorflow/tensorflow/commit/a11e3aa7a1f1dd872f4eab48100b58e1275a191b,refactor ParallelInterleaveBenchmark,1,API Refactoring,,
32acc39360dba8f4eb44e4e4bedc3666e8cbf96d,2020-10-21T00:13:32Z,https://github.com/tensorflow/tensorflow/commit/32acc39360dba8f4eb44e4e4bedc3666e8cbf96d,"Refactor Keras SavedModel loading implementation.Before this CL, Keras rebuilds from a SavedModel by overwriting steps in the internal loader, so that the loader calls a different function to load Keras layers and models. Other objects and variables are loaded using the core loading functions.With load_partial added in cl/333129134, Keras objects and core objects can be loaded in separate steps. The Keras objects are loaded first, which are passed as inputs to load_partial, which will then load the other nodes in the SavedModel.PiperOrigin-RevId: 338167915Change-Id: I4d46d844552cf10d5d3cdcd32bcec60cc529c31e",1,API Refactoring,,
aecc2160715c43e26e7b1eaa7e67ccc7094c28bb,2020-08-21T22:26:04Z,https://github.com/tensorflow/tensorflow/commit/aecc2160715c43e26e7b1eaa7e67ccc7094c28bb,Refactor DistributeVariable saveable object to extend from SaveableObject instead of ResourceVariableSaveable. This allows us move to a single type of DistributedVariable with attached policies.PiperOrigin-RevId: 327884662Change-Id: I4f3030f4a19248dfd7e9d3281a971e637735bc5f,1,API Refactoring,,
6d8eafa78834e197a04086a928d9bb3e1339a9aa,2019-09-23T20:02:12Z,https://github.com/tensorflow/tensorflow/commit/6d8eafa78834e197a04086a928d9bb3e1339a9aa,Removed unused name argument from execute.record_gradientPiperOrigin-RevId: 270741677,1,API Refactoring,,
fc4f7eb6963aca828774136159f4bc8a4e3c98da,2019-09-16T21:57:38Z,https://github.com/tensorflow/tensorflow/commit/fc4f7eb6963aca828774136159f4bc8a4e3c98da,remove fusd param,1,API Refactoring,,
a6cd5f9f28c45c576b1210a76c1d964f50506db8,2019-09-07T02:43:48Z,https://github.com/tensorflow/tensorflow/commit/a6cd5f9f28c45c576b1210a76c1d964f50506db8,clean up copy_function since all the places are taking false valuePiperOrigin-RevId: 267718819,1,API Refactoring,,
8d52e1c6460d7e0809afd1883b6f2eb21403b1f5,2019-07-31T21:26:29Z,https://github.com/tensorflow/tensorflow/commit/8d52e1c6460d7e0809afd1883b6f2eb21403b1f5,Move default protocol parameter to a platforms library.PiperOrigin-RevId: 260998356,1,API Refactoring,,
c015d55b6dfd7b1cc4296d54c00d95a56d5599ed,2019-07-23T16:34:59Z,https://github.com/tensorflow/tensorflow/commit/c015d55b6dfd7b1cc4296d54c00d95a56d5599ed,Move two tests from contrib to core.PiperOrigin-RevId: 259552437,1,API Refactoring,,
e0d9dfd54b0f2f4a2a6637268aa176d1701ee8e9,2019-06-28T04:01:27Z,https://github.com/tensorflow/tensorflow/commit/e0d9dfd54b0f2f4a2a6637268aa176d1701ee8e9,tf.distribute clean ups.PiperOrigin-RevId: 255533911,1,API Refactoring,,
c903fc2338f05a485fe4c4f5a269a37f0ef2ec12,2019-04-18T03:36:54Z,https://github.com/tensorflow/tensorflow/commit/c903fc2338f05a485fe4c4f5a269a37f0ef2ec12,Remove confusing unused output_gen field.PiperOrigin-RevId: 244119314,1,API Refactoring,,
471993acd6e05729b0ec19d2200d08f3ccacfd53,2019-04-14T02:58:00Z,https://github.com/tensorflow/tensorflow/commit/471993acd6e05729b0ec19d2200d08f3ccacfd53,"tf.distribute.Strategy.reduce: Remove default value for axis argument for Strategy V2, but keep for Strategy V1.Change all callers to specify the argument, so their code continues to work with Strategy V2.For now most of the callers use axis=None. If this continues to remain the most common case, we can consider adding back the default in the future.PiperOrigin-RevId: 243462195",1,API Refactoring,,
1f3c5d317b25d5fb6a4d825198c743ceeaf63d42,2019-03-26T11:19:14Z,https://github.com/tensorflow/tensorflow/commit/1f3c5d317b25d5fb6a4d825198c743ceeaf63d42,removed k1 and k2 as default parameter,1,API Refactoring,,
301b21e8846b79663c762312ca9805e92099429e,2019-03-26T11:12:43Z,https://github.com/tensorflow/tensorflow/commit/301b21e8846b79663c762312ca9805e92099429e,removed k1 and k2 as default parameter,1,API Refactoring,,
72c6be901e50b8402ad8f3f08c76910b63aa8ee9,2019-02-14T16:42:48Z,https://github.com/tensorflow/tensorflow/commit/72c6be901e50b8402ad8f3f08c76910b63aa8ee9,"[XLA:Python] Refactor XLA client to support multiple platforms in the same process.Use device ordinals when naming devices for execution, buffer placement, infeed, and outfeed. A replica is a property of a computation, and computations may have different numbers of replicas. Different numbers of replicas may be mapped onto a particular topology of devices differently, so a replica number does not uniquely name a device.PiperOrigin-RevId: 233962949",1,API Refactoring,,
755b142a1a3d903faa802ed7e468f06ed797a7fe,2019-01-25T19:00:32Z,https://github.com/tensorflow/tensorflow/commit/755b142a1a3d903faa802ed7e468f06ed797a7fe,"Refactor bare ConcreteFunction supportIt gets its own proto. This fixes keyword argument naming, which is determined in get_concrete_function rather than in the Function where the ConcreteFunction was originally created.Also de-duplicates ConcreteFunction metadata in the proto format to fix loading a bare concrete function which is also a Function component.PiperOrigin-RevId: 230932074",1,API Refactoring,,
ea680ae952681ed88738b91deb5463d178b42c43,2018-11-29T00:12:34Z,https://github.com/tensorflow/tensorflow/commit/ea680ae952681ed88738b91deb5463d178b42c43,"Remove ""return_same_structure"" argument from while_loop_v2.PiperOrigin-RevId: 223254267",1,API Refactoring,,
1023a54b03751d859468905403e2ae7f4faf4e60,2018-11-16T18:13:49Z,https://github.com/tensorflow/tensorflow/commit/1023a54b03751d859468905403e2ae7f4faf4e60,Remove the input flattening as required in the new APIPiperOrigin-RevId: 221811903,1,API Refactoring,,
84ace0358526bb51c04a3bef4b3072b93b9d1bec,2018-10-09T18:16:32Z,https://github.com/tensorflow/tensorflow/commit/84ace0358526bb51c04a3bef4b3072b93b9d1bec,Improves tf.function prototype.Specifically: - renames from def_function - returns an object with well-defined methods - doesn't force-retrace twice - uses the python descriptor API ( https://docs.python.org/3/howto/descriptor.html )   to remove the need for a tf.methodPiperOrigin-RevId: 216388957,1,API Refactoring,,
35f3046a326daea0179d024044636f2fcbb45f4a,2018-10-02T12:18:28Z,https://github.com/tensorflow/tensorflow/commit/35f3046a326daea0179d024044636f2fcbb45f4a,Export endpoint for the version of the `regex_replace` function that calls StaticRegexReplace.PiperOrigin-RevId: 215371291,1,API Refactoring,,
0c6c46dad147769f4b09b9a92e04630bcca82e74,2018-09-06T21:25:51Z,https://github.com/tensorflow/tensorflow/commit/0c6c46dad147769f4b09b9a92e04630bcca82e74,Remove unused parent_name argument from _UnreadVariable.__init__.PiperOrigin-RevId: 211869673,1,API Refactoring,,
38f811077dd52820eaa3d5c684f41142de01c7eb,2018-08-23T08:23:03Z,https://github.com/tensorflow/tensorflow/commit/38f811077dd52820eaa3d5c684f41142de01c7eb,CLN: remove negative_to_zero argument,1,API Refactoring,,
dc27aecb5b3a259bd35d928c643ee1a548279c3a,2017-10-18T02:06:38Z,https://github.com/tensorflow/tensorflow/commit/dc27aecb5b3a259bd35d928c643ee1a548279c3a,Remove thread ordering with sleep statements from coordinator_test.PiperOrigin-RevId: 172550053,1,API Refactoring,,
d4ea993cae51a25c16368bb9d034986f182f78f1,2017-10-04T00:53:41Z,https://github.com/tensorflow/tensorflow/commit/d4ea993cae51a25c16368bb9d034986f182f78f1,Removes unnecessary eager-mode call to convert_to_tensor in record_gradient.PiperOrigin-RevId: 170944265,1,API Refactoring,,
c55a2e18a82dd744ad31c665f21dcba8b99f2977,2017-10-02T22:03:46Z,https://github.com/tensorflow/tensorflow/commit/c55a2e18a82dd744ad31c665f21dcba8b99f2977,Remove deprecated is_training from resnet_arg_scope.PiperOrigin-RevId: 170759260,1,API Refactoring,,
2ed48e89c341937caf1e1036f897c42988e561f9,2017-09-27T23:39:44Z,https://github.com/tensorflow/tensorflow/commit/2ed48e89c341937caf1e1036f897c42988e561f9,[tf.data] Remove deprecated arguments from future `tf.data.Dataset.map()`.PiperOrigin-RevId: 170271834,1,API Refactoring,,
8e868cf6a13de06e1ce299ca761e87f00480e539,2017-05-31T22:01:24Z,https://github.com/tensorflow/tensorflow/commit/8e868cf6a13de06e1ce299ca761e87f00480e539,Remove unused arguments to call_cpp_shape_fn.PiperOrigin-RevId: 157640125,1,API Refactoring,,
498f3f6cac1b903252d1c8e400e8adf5bd1c7d98,2017-04-18T17:16:55Z,https://github.com/tensorflow/tensorflow/commit/498f3f6cac1b903252d1c8e400e8adf5bd1c7d98,"Move weights to be the second argument in tf.bincount.This matches np.bincount(x, weights, minlength).Change: 153476565",1,API Refactoring,,
4b57da4ced14a9d892cb8a4d92bf9d3ec911b27a,2017-04-18T17:16:55Z,https://github.com/tensorflow/tensorflow/commit/4b57da4ced14a9d892cb8a4d92bf9d3ec911b27a,"Move weights to be the second argument in tf.bincount.This matches np.bincount(x, weights, minlength).Change: 153476565",1,API Refactoring,,
1d3908c00fc3e1f8889cd0eeb021e276714232b0,2017-04-10T15:49:19Z,https://github.com/tensorflow/tensorflow/commit/1d3908c00fc3e1f8889cd0eeb021e276714232b0,"Remove obsolete use of validate_indices from embedding_ops.pyvalidate_indices is ignored, so it shouldn't appear in new code.Change: 152691948",1,API Refactoring,,
2dca3420ff04a4bd1e520e895845c9b7fda22972,2017-04-07T05:18:26Z,https://github.com/tensorflow/tensorflow/commit/2dca3420ff04a4bd1e520e895845c9b7fda22972,Remove superfluous mode argument.Change: 152467334,1,API Refactoring,,
57fba1aa11a9196dc24e5ee5116dd54f048297de,2017-02-15T20:00:42Z,https://github.com/tensorflow/tensorflow/commit/57fba1aa11a9196dc24e5ee5116dd54f048297de,Refactor state_saving_rnn_estimator.py to use inheritance from Estimator.Change: 147626256,1,API Refactoring,,
3b168a56042ce5dcef4ce57db89e40c2ef6a839f,2017-01-31T00:03:25Z,https://github.com/tensorflow/tensorflow/commit/3b168a56042ce5dcef4ce57db89e40c2ef6a839f,"Refactor samplers in tf.contrib.seq2seq1. Sampler now has two step calls: sample (which just return sample_ids),  and next_inputs (which accepts sample_ids, but also old state and returns  a possibly updated state).  The updated state change is necessary for  TopK / beam search samplers.2. Added a CustomSampler class that helps build samplers from simple helper fns.In the near future, it'll be easy to add a ScheduledEmbeddingSampler and a standard EmbeddingSampler(because all we need to provide is a new sampler method).For now, everything's still part of the Sampler interface; but it's possible thatSampler will go away in favor of BasicSamplingDecoder simply doing all the necessary workand calling its own sample() and next_inputs() methods.Change: 146051886",1,API Refactoring,,
2a6bd09d05881d3160885a386b3ac1fb7cf6a6e1,2016-12-14T05:35:34Z,https://github.com/tensorflow/tensorflow/commit/2a6bd09d05881d3160885a386b3ac1fb7cf6a6e1,Refactor KMeansClustering estimator from inheritance to composition and update users to use input_fn instead of x/batch_size.Change: 141978044,1,API Refactoring,,
a8f6a4f1b7c805ca3721052b3d75d09b02b2af05,2016-08-05T22:24:06Z,https://github.com/tensorflow/tensorflow/commit/a8f6a4f1b7c805ca3721052b3d75d09b02b2af05,Remove arbitrary float restrictions for constant_ and random_uniform_initializerconstant_initializer clearly makes sense for any type.random_uniform_initializer also should work for integers now thatrandom_uniform works for integers.Change: 129489215,1,API Refactoring,,
40e6aa7c2a2074230cf3942b9c5409a5c4641840,2016-08-05T19:36:41Z,https://github.com/tensorflow/tensorflow/commit/40e6aa7c2a2074230cf3942b9c5409a5c4641840,Refactor/consolidate internal/external gen_docs_combinedChange: 129470667,1,API Refactoring,,
838ba8f227eb9e7637ebf367310f14bca3b7be37,2016-06-16T17:51:43Z,https://github.com/tensorflow/tensorflow/commit/838ba8f227eb9e7637ebf367310f14bca3b7be37,Remove n_classes argument from LinearRegressor constructor.Change: 125077307,1,API Refactoring,,
af206f2a0f18b3736cc565f3f44068bd00a31663,2016-06-09T08:45:48Z,https://github.com/tensorflow/tensorflow/commit/af206f2a0f18b3736cc565f3f44068bd00a31663,Removed `dynamic_shape` argument,1,API Refactoring,,
d17ec785a85417f34adff9c311e82e8359855c12,2016-06-01T22:05:53Z,https://github.com/tensorflow/tensorflow/commit/d17ec785a85417f34adff9c311e82e8359855c12,Remove dual and primal_loss variables from variables dict created in auxiliary test method make_dense_variable_dict. These 2 variables are nowhere used in SDCASolver. Right now this auxiliary method is more confusing than helpful.Change: 123799466,1,API Refactoring,,
6f74cd15a60821211444acfedc8e5e68782a6fcf,2016-02-26T22:24:22Z,https://github.com/tensorflow/tensorflow/commit/6f74cd15a60821211444acfedc8e5e68782a6fcf,"Refactor DirectoryWatcher to take in a path provider as input.This will allow us to watchings things that aren't local files on disk, such asGCS directories.Change: 115708990",1,API Refactoring,,
c977e835bd92ffa4f28ffd48f424a88cdc19db89,2016-02-09T07:10:02Z,https://github.com/tensorflow/tensorflow/commit/c977e835bd92ffa4f28ffd48f424a88cdc19db89,Adding a batch_size to predict method to split into smaller mini-batches if required,1,API Refactoring,,
d823be2a619f57f68da8c6202800c0ce15c07a9d,2023-07-23T10:55:22Z,https://github.com/keras-team/keras/commit/d823be2a619f57f68da8c6202800c0ce15c07a9d,Refactor test cases to improve unit test quality,1,API Refactoring,,
5a1e63990a92f643d4fd45796d371a3565b37058,2016-07-14T22:05:48Z,https://github.com/keras-team/keras/commit/5a1e63990a92f643d4fd45796d371a3565b37058,Refactor batch norm,1,API Refactoring,,
2db93975c4d994ab52f918d0b78d63bc176ed6f6,2021-12-22T21:43:53Z,https://github.com/keras-team/keras/commit/2db93975c4d994ab52f918d0b78d63bc176ed6f6,Migrate _checkpoint_dependencies to _trackable_children  PiperOrigin-RevId: 417879104,1,API Refactoring,,
35e10e91172c2fb716d5a6ec489ae71e0f488ca3,2018-01-05T17:21:30Z,https://github.com/keras-team/keras/commit/35e10e91172c2fb716d5a6ec489ae71e0f488ca3,Refactor `_standardize_input_data` to make it faster (#8971),1,API Refactoring,,
e11ebd48eaade842210235cd7f4401ac45ea13a6,2022-02-09T16:52:28Z,https://github.com/keras-team/keras/commit/e11ebd48eaade842210235cd7f4401ac45ea13a6,Remove axis argument - it will always be 0 when called by predict,1,API Refactoring,,
970488e8a9376753cefe5e9b147558e35474e714,2017-10-25T23:06:12Z,https://github.com/keras-team/keras/commit/970488e8a9376753cefe5e9b147558e35474e714,"Simplify, clarify, sync style examples/mnist_net2net.py (#8167)  * Simplify, clarify, sync style examples/mnist_net2net.py  * Pass globals as arguments into functions  * Pass epochs as arguments into functions  * Remove default epochs value",1,API Refactoring,Rename Variable,
8824bdb910c162b23251401f55e5ac6888ef43d9,2015-06-03T14:31:14Z,https://github.com/keras-team/keras/commit/8824bdb910c162b23251401f55e5ac6888ef43d9,cleanup constructors,1,API Refactoring,,
8830c53135dcad4825e2f8805c78523931c3bbed,2017-04-18T18:34:24Z,https://github.com/keras-team/keras/commit/8830c53135dcad4825e2f8805c78523931c3bbed,Refactor add_weight to align it with get_variable,1,API Refactoring,,
06af7618e730d890108ce2a022cb0588388ccb05,2021-06-02T05:00:49Z,https://github.com/pytorch/pytorch/commit/06af7618e730d890108ce2a022cb0588388ccb05,[quant][graphmode][fx][refactor] Remove Quantizer class from convert (QuantizeHandler) (#59040)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/59040  To remove Quantizer class and split prepare and convert functions to different files  Test Plan: python test/test_quantization.py TestQuantizeFx python test/test_quantization.py TestQuantizeFxOps  Imported from OSS  Reviewed By: vkuzo  Differential Revision: D28724870  fbshipit-source-id: c0f748711b825cd46bdfcc05c054c77a41e8207a,1,API Refactoring,,
0d7a986da1cd1d9de886fb687de728eebf54200f,2018-11-16T19:50:29Z,https://github.com/pytorch/pytorch/commit/0d7a986da1cd1d9de886fb687de728eebf54200f,"Change hip filename extension to .hip (#14036)Summary:xw285cornell- To make hip files to have unique filename extension we change hip files from _hip.cc to .hip (it's the only blessing option other than .cu in hipcc https://github.com/ROCm-Developer-Tools/HIP/blob/3d51a1fb0105e2f2312d2523c20e0034339f6ada/bin/hipcc#L552).- Change to use host compiler to compile .cc|.cpp files. Previously we use hcc to compile them which is unnecessary- Change the hipify script to not replace ""gpu"" with ""hip"" in the filename of the generated hipified files. Previously we do this because hcc has a bug when linking files that have same filename. We have now changed to use host linker to do linking so this is unnecessary anymore.Pull Request resolved: https://github.com/pytorch/pytorch/pull/14036Reviewed By: xw285cornellDifferential Revision: D13091813Pulled By: bddppqfbshipit-source-id: ea3d887751d8abb39d75f5d5104aa66ce66b9ee0",1,API Refactoring,,
1288c4fd79983883b2f72e830d326b70040b00c4,2018-03-23T03:32:13Z,https://github.com/pytorch/pytorch/commit/1288c4fd79983883b2f72e830d326b70040b00c4,refactor epoch_limiter (#2389)* refactor epoch_limiter* fix test,1,API Refactoring,,
17a01c7c7bb26307cc850b3c14800e758d96aa36,2020-03-26T14:57:48Z,https://github.com/pytorch/pytorch/commit/17a01c7c7bb26307cc850b3c14800e758d96aa36,"feature: deterministic random_split (#34043)Summary:## 🚀 FeatureOption to provide a seed (random_state) for random_split() like the sklearn API https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html.## MotivationUseful for deterministic sampling & reproducible data generation (easily, without affecting the PRNG for other uses).See https://github.com/pytorch/pytorch/issues/32467Pull Request resolved: https://github.com/pytorch/pytorch/pull/34043Differential Revision: D20605678Pulled By: ezyangfbshipit-source-id: 12b10bf72cd8a0d4264ae4d326064f806945d011",1,API Refactoring,,
183b04da3ec339700d5099a3b2819bfd7d74f255,2020-06-07T07:16:09Z,https://github.com/pytorch/pytorch/commit/183b04da3ec339700d5099a3b2819bfd7d74f255,"[pytorch] remove tracing logic from gen_variable_factories.py (#39514)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/39514For methods in `variable_factories.h`, we set `AutoNonVariableTypeMode` guard before dispatching, which also disables tracing as side effort, so we need replicate the tracing logic.Now as we have created separate TraceType, we should be able to remove tracing from `variable_factories.h`.Example of old code:```inline at::Tensor arange(at::Scalar start, at::Scalar end, at::Scalar step, const at::TensorOptions & options = {}) {  #if !defined(PYTORCH_DISABLE_TRACING)  torch::jit::Node* node = nullptr;  std::shared_ptr<jit::tracer::TracingState> tracer_state;  if (jit::tracer::isTracing()) {    tracer_state = jit::tracer::getTracingState();    at::Symbol op_name;    op_name = jit::Symbol::fromQualString(""aten::arange"");    node = tracer_state->graph->create(op_name, /*num_outputs=*/0);    jit::tracer::recordSourceLocation(node);    jit::tracer::addInputs(node, ""start"", start);    jit::tracer::addInputs(node, ""end"", end);    jit::tracer::addInputs(node, ""step"", step);    jit::tracer::addInputs(node, ""options"", options);    tracer_state->graph->insertNode(node);    jit::tracer::setTracingState(nullptr);  }  #endif  at::Tensor tensor = ([&]() {    at::AutoNonVariableTypeMode non_var_type_mode(true);    return at::arange(start, end, step, at::TensorOptions(options));  })();  at::Tensor result =    autograd::make_variable(std::move(tensor), /*requires_grad=*/options.requires_grad());  #if !defined(PYTORCH_DISABLE_TRACING)  if (tracer_state) {    jit::tracer::setTracingState(std::move(tracer_state));    jit::tracer::addOutput(node, result);  }  #endif  return result;}```Example of new code:```inline at::Tensor arange(at::Scalar start, at::Scalar end, at::Scalar step, const at::TensorOptions & options = {}) {  at::Tensor tensor = ([&]() {    at::AutoNonVariableTypeMode non_var_type_mode(true);    return at::arange(start, end, step, at::TensorOptions(options));  })();  at::Tensor result =    autograd::make_variable(std::move(tensor), /*requires_grad=*/options.requires_grad());  return result;}```ghstack-source-id: 105407617Test Plan: CIDifferential Revision: D21880936fbshipit-source-id: 19a4330eed5bc1ee956ad1c638a9658e7a1ce283",1,API Refactoring,,
1b5c843a9c2b8e96398245b3a794df74d923f94d,2017-11-03T14:11:14Z,https://github.com/pytorch/pytorch/commit/1b5c843a9c2b8e96398245b3a794df74d923f94d,cleaner logic on sparse feature hashingReviewed By: kennyhorrorDifferential Revision: D6195525fbshipit-source-id: f687ac3d4914c3dbb0d35679e3a3d3a64a71ac53,1,API Refactoring,,
1cf8f7a43944ee39e977769d26bc2d5f40abcd40,2021-05-21T03:34:47Z,https://github.com/pytorch/pytorch/commit/1cf8f7a43944ee39e977769d26bc2d5f40abcd40,[quant][fx][graphmode][refactor] Remove qconfig_map from Quantizer (#58455)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/58455  Test Plan: python test/test_quantization.py TestQuantizeFx python test/test_quantization.py TestQuantizeFxOps  Imported from OSS  Reviewed By: vkuzo  Differential Revision: D28497967  fbshipit-source-id: 421ce3d86fadd3d92f4120b850b0167270509189,1,API Refactoring,,
261eb46ddd3f80000441748fe4c2e7e5927ae5f1,2023-02-28T17:54:26Z,https://github.com/pytorch/pytorch/commit/261eb46ddd3f80000441748fe4c2e7e5927ae5f1,"[dtensor] refactor get_coordiniate (#95457)  This refactor get_coordinate to return a optional[list] instead of directly the coordinate on dim, this is so that we can check if the rank is inside the mesh easily  Differential Revision: [D43643579](https://our.internmc.facebook.com/intern/diff/D43643579) Pull Request resolved: https://github.com/pytorch/pytorch/pull/95457 Approved by: https://github.com/XilunWu",1,API Refactoring,,
30d687522d708fb3e4041e378d4f4ce420a86157,2020-10-19T22:18:57Z,https://github.com/pytorch/pytorch/commit/30d687522d708fb3e4041e378d4f4ce420a86157,[reland][quant][eagermode] Move custom_module registration to prepare/convert_custom_config_dict (#46293) (#46364)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/46364Test Plan:Imported from OSSImported from OSSReviewed By: vkuzoDifferential Revision: D24322747fbshipit-source-id: 4801ba1835fc805bf767fe9810b9edfa2ceeefb4,1,API Refactoring,,
36895e2dd2a004482ef051f77d474c6ffc467717,2017-10-16T17:05:18Z,https://github.com/pytorch/pytorch/commit/36895e2dd2a004482ef051f77d474c6ffc467717,"update the comments, move the expect check logic into the helper function",1,API Refactoring,,
3ad797c93724d2bc402f85d8f5b57d5661915eaf,2020-10-14T19:00:34Z,https://github.com/pytorch/pytorch/commit/3ad797c93724d2bc402f85d8f5b57d5661915eaf,[quant][eagermode] Move custom_module registration to prepare/convert_custom_config_dict (#46293)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/46293Test Plan: Imported from OSSReviewed By: raghuramank100Differential Revision: D24290811fbshipit-source-id: 7d2aee98e1946c2a4268efb94443f1e5daaa793e,1,API Refactoring,,
3b1a5a1b8adf77fdfe8864464db3de1d9f2f21f6,2018-09-19T16:58:15Z,https://github.com/pytorch/pytorch/commit/3b1a5a1b8adf77fdfe8864464db3de1d9f2f21f6,Refactor tests part 2 (#11811)Summary:Followup to the [first refactor](https://github.com/pytorch/pytorch/pull/11350). Increase coverage of testsPull Request resolved: https://github.com/pytorch/pytorch/pull/11811Reviewed By: houseroadDifferential Revision: D9923074Pulled By: ajyufbshipit-source-id: 0f899bb9e9a75bf7ed939e06cc9b028daa7f6bd9,1,API Refactoring,,
3d7c22a2ced626f906a9c43d56e15f42d4698877,2020-09-04T22:19:37Z,https://github.com/pytorch/pytorch/commit/3d7c22a2ced626f906a9c43d56e15f42d4698877,[ONNX] Enable new scripting passes for functionalization and remove_mutation (#43791)Summary:Duplicate of https://github.com/pytorch/pytorch/issues/41413This PR initiates the process of updating the torchsciprt backend interface used by ONNX exporter.Replace jit lower graph pass by freeze module passEnable ScriptModule tests for ONNX operator tests (ORT backend) and model tests by default.Replace jit remove_inplace_ops pass with remove_mutation and consolidation all passes for handling inplace ops.Pull Request resolved: https://github.com/pytorch/pytorch/pull/43791Reviewed By: houseroadDifferential Revision: D23421872Pulled By: bzinodevfbshipit-source-id: a98710c45ee905748ec58385e2a232de2486331b,1,API Refactoring,Extract Method,
45c6fa0007cc3eda6fa187c1c2a587eba5b0008d,2019-06-27T00:03:25Z,https://github.com/pytorch/pytorch/commit/45c6fa0007cc3eda6fa187c1c2a587eba5b0008d,Refactor Tests for Multiple ONNX Opsets (#20036)Summary:Refactor tests for https://github.com/pytorch/pytorch/pull/19294.Pull Request resolved: https://github.com/pytorch/pytorch/pull/20036Reviewed By: zrpherculeDifferential Revision: D16016593Pulled By: houseroadfbshipit-source-id: eaae324e347679acf3d0ac1c14be03919f54496e,1,API Refactoring,,
49903a5cd5dc39b44466b7fa78dfa5a29e21a038,2020-10-14T17:41:07Z,https://github.com/pytorch/pytorch/commit/49903a5cd5dc39b44466b7fa78dfa5a29e21a038,[quant][graphmode][fx] Move custom_module_class config to prepare/convert_custom_config_dict (#46251)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/46251Test Plan: Imported from OSSReviewed By: raghuramank100Differential Revision: D24290810fbshipit-source-id: 7a96f04a0f33f0315943ac18ef2d08e4f5a5d1c0,1,API Refactoring,,
50e6ee3ca2c6b5e1a55a0505630cdcb37b1c3efb,2021-06-02T04:40:08Z,https://github.com/pytorch/pytorch/commit/50e6ee3ca2c6b5e1a55a0505630cdcb37b1c3efb,[quant][graphmode][fx][refactor] Remove Quantizer class from quantize_node (#59039)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/59039  To remove Quantizer class and split prepare and convert functions to different files  Test Plan: python test/test_quantization.py TestQuantizeFx python test/test_quantization.py TestQuantizeFxOps  Imported from OSS  Reviewed By: vkuzo  Differential Revision: D28724874  fbshipit-source-id: bd984716b2da1d6879c3e92fa827574783a41567,1,API Refactoring,,
591fffc5245e1ce8b00cf2a778d5874e43655d53,2020-07-02T14:09:21Z,https://github.com/pytorch/pytorch/commit/591fffc5245e1ce8b00cf2a778d5874e43655d53,"Type-annotate serialization.py (#40862)Summary:Move Storage class from __init__.pyi.in to types.py and make it a protocol, since this is not a real classExpose `PyTorchFileReader` and `PyTorchFileWriter` native classesIgnore function attributes, as there are yet no good way to type annotate those, see https://github.com/python/mypy/issues/2087Pull Request resolved: https://github.com/pytorch/pytorch/pull/40862Differential Revision: D22344743Pulled By: malfetfbshipit-source-id: 95cdb6f980ee79383960f306223e170c63df3232",1,API Refactoring,,
67115b226a159e562aff5fe35a93e55c0d67972b,2020-06-07T18:07:31Z,https://github.com/pytorch/pytorch/commit/67115b226a159e562aff5fe35a93e55c0d67972b,[quant][graphmode] Dynamic Quant Do not depend on input shapes (#39412)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/39412This PR introduces changes to enable running the weight observer standalone in the graphIt extracts the nodes from the graph that correspond to the observed weight value and adds all the related nodes to a new subgraphThe subgraph is then executed using GraphFunctionTest Plan:python test/test_quantization.py TestGraphMostPostTrainingStaticpython test/test_quantization.py TestQuantizeDynamicScriptImported from OSSDifferential Revision: D21872940fbshipit-source-id: 55f1dcc2caef193531e2b807c8e56288b9794520,1,API Refactoring,,
69080e9e7e102327ea16110a0ff1785790037c72,2020-09-01T04:40:05Z,https://github.com/pytorch/pytorch/commit/69080e9e7e102327ea16110a0ff1785790037c72,"simplify profile text output by displaying only top-level ops statistics (#42262)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/42262Test Plan:Imported from OSS```==================================================================================================================================================================================TEST-----------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------------------------------------Name                           Self CPU total %  Self CPU total   CPU total %      CPU total        CPU time avg     Number of Calls  Input Shapes-----------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------------------------------------aten::add_                     3.61%            462.489us        3.61%            462.489us        462.489us        1                [[3, 20], [3, 20], []]aten::slice                    1.95%            249.571us        1.95%            250.018us        250.018us        1                [[3, 80], [], [], [], []]aten::lstm                     1.89%            242.534us        22.41%           2.872ms          2.872ms          1                [[5, 3, 10], [], [], [], [], [], [], [], []]aten::lstm                     1.68%            215.852us        18.18%           2.330ms          2.330ms          1                [[5, 3, 10], [], [], [], [], [], [], [], []]aten::lstm                     1.68%            215.767us        18.49%           2.370ms          2.370ms          1                [[5, 3, 10], [], [], [], [], [], [], [], []]aten::lstm                     1.60%            205.014us        20.15%           2.582ms          2.582ms          1                [[5, 3, 10], [], [], [], [], [], [], [], []]aten::lstm                     1.55%            198.213us        18.53%           2.375ms          2.375ms          1                [[5, 3, 10], [], [], [], [], [], [], [], []]aten::addmm                    0.95%            122.359us        1.01%            129.857us        129.857us        1                [[80], [3, 20], [20, 80], [], []]aten::stack                    0.29%            36.745us         0.63%            80.179us         80.179us         1                [[], []]aten::add_                     0.28%            35.694us         0.28%            35.694us         35.694us         1                [[3, 20], [3, 20], []]-----------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------------------------------------Self CPU time total: 12.817ms-----------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------------------------------------Name                           Self CPU total %  Self CPU total   CPU total %      CPU total        CPU time avg     Number of Calls  Input Shapes-----------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------------------------------------aten::mul                      11.45%           1.467ms          12.88%           1.651ms          11.006us         150              [[3, 20], [3, 20]]aten::lstm                     8.41%            1.077ms          97.76%           12.529ms         2.506ms          5                [[5, 3, 10], [], [], [], [], [], [], [], []]aten::addmm                    7.65%            979.982us        11.38%           1.459ms          29.182us         50               [[80], [3, 20], [20, 80], [], []]aten::sigmoid_                 6.78%            869.295us        9.74%            1.249ms          8.327us          150              [[3, 20]]aten::add_                     5.82%            745.801us        5.82%            745.801us        14.916us         50               [[3, 20], [3, 20], []]aten::slice                    5.58%            715.532us        6.61%            847.445us        4.237us          200              [[3, 80], [], [], [], []]aten::unsafe_split             4.24%            544.015us        13.25%           1.698ms          33.957us         50               [[3, 80], [], []]aten::tanh                     3.11%            398.881us        6.05%            775.024us        15.500us         50               [[3, 20]]aten::empty                    3.04%            389.055us        3.04%            389.055us        1.319us          295              [[], [], [], [], [], []]aten::sigmoid                  2.96%            379.686us        2.96%            379.686us        2.531us          150              [[3, 20], [3, 20]]-----------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------------------------------------Self CPU time total: 12.817ms==================================================================================================================================================================================TEST==================================================================================================================================================================================This report only display top-level ops statistics-----------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------------------------------------Name                           Self CPU total %  Self CPU total   CPU total %      CPU total        CPU time avg     Number of Calls  Input Shapes-----------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------------------------------------aten::lstm                     1.89%            242.534us        22.41%           2.872ms          2.872ms          1                [[5, 3, 10], [], [], [], [], [], [], [], []]aten::lstm                     1.68%            215.852us        18.18%           2.330ms          2.330ms          1                [[5, 3, 10], [], [], [], [], [], [], [], []]aten::lstm                     1.68%            215.767us        18.49%           2.370ms          2.370ms          1                [[5, 3, 10], [], [], [], [], [], [], [], []]aten::lstm                     1.60%            205.014us        20.15%           2.582ms          2.582ms          1                [[5, 3, 10], [], [], [], [], [], [], [], []]aten::lstm                     1.55%            198.213us        18.53%           2.375ms          2.375ms          1                [[5, 3, 10], [], [], [], [], [], [], [], []]-----------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------------------------------------Self CPU time total: 12.817ms==================================================================================================================================================================================This report only display top-level ops statistics-----------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------------------------------------Name                           Self CPU total %  Self CPU total   CPU total %      CPU total        CPU time avg     Number of Calls  Input Shapes-----------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------------------------------------aten::lstm                     8.41%            1.077ms          97.76%           12.529ms         2.506ms          5                [[5, 3, 10], [], [], [], [], [], [], [], []]-----------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------------------------------------Self CPU time total: 12.817msTotal time based on python measurements:  13.206msCPU time measurement python side overhead: 3.03%```Reviewed By: ilia-cherDifferential Revision: D22830328Pulled By: ilia-cherfbshipit-source-id: c9a71be7b23a8f84784117c788faa43caa96f545",1,API Refactoring,,
6d14f7a2141bcb90e218250820751e44742066c8,2019-08-13T16:33:07Z,https://github.com/pytorch/pytorch/commit/6d14f7a2141bcb90e218250820751e44742066c8,"Simplify tests that should cover all possible devices (#23824)Summary:This PR introduce `pytorchtest.test_all_device_types()` decorator which helps to write CPU, CUDA tests faster, iterating single test through all available devicesSimple `test_var_mean_some_dims`  becomes```test_var_mean_some_dims (__main__.TestTorch) ... oktest_var_mean_some_dims_cpu (__main__.TestTorch) ... oktest_var_mean_some_dims_cuda (__main__.TestTorch) ... ok``````pythonclass pytorchtest():    """"""Allows to generate and run per-device unittests.    This decorator class allows to generate and run per-device unittest.    Example:    class _TestTorchMixin(pytorchtest):        pytorchtest.test_all_device_types()        def test_zeros_like(self, device):            expected = torch.zeros((100, 100,), device=device)    Will execute:        test_zeros_like (__main__.TestTorch) ... skipped 'Look at test_zeros_like_cpu, test_zeros_like_cuda results.'        test_zeros_like_cpu (__main__.TestTorch) ... ok        test_zeros_like_cuda (__main__.TestTorch) ... ok    To work properly, test class should be inherited from the `pytorchtest`.    test_all_device_types decorator does not guarantee proper functionality in    combination with other decorators.    Please do not extend this decorator to support other cases (such as dtype,    layouts, etc) without consulting with bigger group. Devices is the special    case as build flags control additions/removals (see    https://github.com/pytorch/pytorch/pull/23824 for the reference).    """"""```Pull Request resolved: https://github.com/pytorch/pytorch/pull/23824Differential Revision: D16716959Pulled By: VitalyFedyuninfbshipit-source-id: ba39af0f9bce2c4a64da421bbc24d6a1c1d9139d",1,API Refactoring,Rename Method,
75bf5f2b59148ea8b6a3844248bcc645dd80e0c8,2020-10-15T06:25:48Z,https://github.com/pytorch/pytorch/commit/75bf5f2b59148ea8b6a3844248bcc645dd80e0c8,"[JIT] Improve class type annotation inference (#45940)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/45940**Summary**In `try_ann_to_type`, if an annotation has an attribute named`__torch_script_class__`, it is assumed to be a TorchScript class thathas already been scripted. However, if it is a class that extendsanother class, this code path causes a crash because it looks up theJIT type for the class by name in the compilation unit. This JIT typeobviously cannot exist because inheritance is not supported.This commit fixes this by looking up the qualified name of a classin torch.jit._state._script_class in order to ascertain whether it hasalready been scripted (instead of looking for a `__torch_script_class__`attribute on the class object.**Test Plan**This commit adds a unit test consisting of the code sample from theissue that reported this problem.**Fixes**This commit fixes #45860.Test Plan: Imported from OSSReviewed By: anjali411Differential Revision: D24310027Pulled By: SplitInfinityfbshipit-source-id: 9f8225f3316fd50738d98e3544bf5562b16425b6",1,API Refactoring,,
76c964dfb0955e459047eddceea27b0301737a42,2020-05-07T05:32:45Z,https://github.com/pytorch/pytorch/commit/76c964dfb0955e459047eddceea27b0301737a42,Reland [quant][tests] Enable tests to run on all qengine backends (#37943)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/37943Refactor tests to use supported_qenginesTest Plan:python test/test_quantization.pyImported from OSSDifferential Revision: D21435514fbshipit-source-id: 8004ef2535e1cc65036f331c00af27ded1c04a6b,1,API Refactoring,,
771a9debbe8cc1bbc41e1f9b8759971ae20f09d2,2023-05-03T03:23:32Z,https://github.com/pytorch/pytorch/commit/771a9debbe8cc1bbc41e1f9b8759971ae20f09d2,[PT2E][Quant] Refactor quantizer and qnnpack qantizer code to support dqlinear config (#99399)  This diff introduces a few refactors:  - Move observer creation to utils.py. - Use quantization spec to supply args to observers. - Use annotation function registration corresponding QuantizationConfig. This   will be later used in dynamic quantized linear.  Differential Revision: [D45073790](https://our.internmc.facebook.com/intern/diff/D45073790/) Pull Request resolved: https://github.com/pytorch/pytorch/pull/99399 Approved by: https://github.com/jerryzh168,1,API Refactoring,,
7b243a4d4684bf79bb236def8711bd589db0563f,2020-08-25T00:57:09Z,https://github.com/pytorch/pytorch/commit/7b243a4d4684bf79bb236def8711bd589db0563f,[quant][graphmode[fx][test][refactor] Refactor tests for graph mode quantization on fx (#43445)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/43445changed the interface for checkGraphModule to make the arguments more explicitas requested in https://github.com/pytorch/pytorch/pull/43437Test Plan:TestQuantizeFxImported from OSSReviewed By: vkuzoDifferential Revision: D23280586fbshipit-source-id: 5b5859e326d149a5aacb1d15cbeee69667cc9109,1,API Refactoring,,
7e81d72d1226f47b21446ef9dd30b5eedcd3b85c,2019-12-18T05:53:25Z,https://github.com/pytorch/pytorch/commit/7e81d72d1226f47b21446ef9dd30b5eedcd3b85c,remove unnecessary arg from create_script_module (#31017)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/31017This arg is now derivable from another one. So we don't need to passbothTest Plan: Imported from OSSDifferential Revision: D18904111Pulled By: suofbshipit-source-id: ea74ea9c2ae83d9e0e6977b0eb6629f53545e2e4,1,API Refactoring,,
7fe6e8e5a20bf1d279a296184b1ee6c28d86763d,2021-04-27T14:51:54Z,https://github.com/pytorch/pytorch/commit/7fe6e8e5a20bf1d279a296184b1ee6c28d86763d,Refactor C->C to C->R twice (#55692)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/55692### Release notesget_numerical_jacobian and get_analytical_jacobian only support `grad_out=1` and `fn` no longer accepts functions that return complex outputTest Plan: Imported from OSSReviewed By: H-HuangDifferential Revision: D28004614Pulled By: soulitzerfbshipit-source-id: 9592c9c69584b4035b39be62252f138dce39d3b5,1,API Refactoring,,
8372c5dc687d622c7d2e0d411f61cd2720fc1052,2023-03-29T16:55:49Z,https://github.com/pytorch/pytorch/commit/8372c5dc687d622c7d2e0d411f61cd2720fc1052,"Refactor dynamic dims api, stateless internals, higher level export API (#96699)  The purpose of this API is to execute a few large components of work:  1) Refactor all the internals of plumbing dynamic dimension information after dynamo to be stateless 2) Decouple allocation controls around dynamic dimensions from verification 3) For (2), for allocation, create an enum that dictates whether we are in DUCK (default today), STATIC (aka assume_static_default in the past), or DYNAMIC (aka user constrained, do not duck shape) 4) For (2), for verification, we separate out the list of dynamic ranges entirely from allocation. This means shape_env does not tracking for what we verify on, and instead, it is the callers job to invoke produce_guards() with the various things they want verified, specifically, with the valid ranges. We do use constrain ranges to refine value ranges when doing analysis. 5) We have decided, therefore, as an extension of (4) to double down on ""late"" checks versus ""eager"" checks, primarily because the mechanisms for gathering what actually matters happens during guards, and should be a purview of the caller seeking guards, not the shape env. However, for dynamo, these structures are essentially one and the same.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/96699 Approved by: https://github.com/avikchaudhuri, https://github.com/ezyang",1,API Refactoring,,
858d4a6a04261a32a05de7ce9df88c5dfe9661e3,2019-07-22T19:02:34Z,https://github.com/pytorch/pytorch/commit/858d4a6a04261a32a05de7ce9df88c5dfe9661e3,"Cleanup API and remove 'experimental' warning (#23000)Summary:This fixes ASAN test issues with https://github.com/pytorch/pytorch/pull/21786 seen at https://circleci.com/api/v1.1/project/github/pytorch/pytorch/2212325/output/105/0?file=true and lands it again.This cleans up the `torch.utils.tensorboard` API to remove all kwargs usage (which isn't clear to the  user) and removes the ""experimental"" warning in prep for our 1.2 release.We also don't need the additional PyTorch version checks now that we are in the codebase itself.cc yf225, lanpa, natalialunovaPull Request resolved: https://github.com/pytorch/pytorch/pull/23000Reviewed By: sanekmelnikovDifferential Revision: D16349734Pulled By: orionrfbshipit-source-id: 604a9cad56868a55e08b509a0c6f42b84f68de95",1,API Refactoring,,
87d57dc5f5f6ea38c3cc6ed012b0553ad97ab2ce,2018-08-01T16:37:52Z,https://github.com/pytorch/pytorch/commit/87d57dc5f5f6ea38c3cc6ed012b0553ad97ab2ce,"Simplified Operator (#10080)Summary:zdevito explained that the attributed versions of `Operator`s are no longer necessary. This PR does two things:1. Removes all code associated with attributed operators,2. Adds a second kind of state to `Operator` where it is constructed with an `Operation` directly instead of an `OperationCreator`. This will be useful to test custom operators which don't require a node (you can just retrieve it directly).Now rebased on top of https://github.com/pytorch/pytorch/pull/9801zdevitoPull Request resolved: https://github.com/pytorch/pytorch/pull/10080Differential Revision: D9113668Pulled By: goldsboroughfbshipit-source-id: 1276a191c7cf89da1c38488769f2105ce2664750",1,API Refactoring,,
8868a4f20be52704df23d96bda8f600d349a6b9f,2019-04-21T18:03:09Z,https://github.com/pytorch/pytorch/commit/8868a4f20be52704df23d96bda8f600d349a6b9f,Move non_differentiable_arg_names from autograd functions to differentiability_info. (#19519)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/19519ghimport-source-id: 74e603688b2e4ed33f6c46c7da9d009336140e74Differential Revision: D15021378Pulled By: gchananfbshipit-source-id: e366a914c67a90ba0552b67d0bf5b347edbaf189,1,API Refactoring,,
8b5732e8adf87785b1adae7ceac1260499bb9b2e,2020-06-18T22:50:41Z,https://github.com/pytorch/pytorch/commit/8b5732e8adf87785b1adae7ceac1260499bb9b2e,Move `torch.cuda` annotations inline (#40075)Summary:Also enable `torch.cuda` typecheckingPull Request resolved: https://github.com/pytorch/pytorch/pull/40075Differential Revision: D22121275Pulled By: malfetfbshipit-source-id: dbecef09911334e8f3d87f5ecab66349da9f2325,1,API Refactoring,,
8f5631b8594e16f20e81e68d35b9c761482d551e,2021-10-04T02:55:08Z,https://github.com/pytorch/pytorch/commit/8f5631b8594e16f20e81e68d35b9c761482d551e,"Refactor functional api vectorized jacobian to use batched grad parameter (#65566)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/65566  This doesn't simplify vectorized jacobian computation, but is good to consolidate logic and helps us to test the logic  Test Plan: Imported from OSS  Reviewed By: albanD  Differential Revision: D31236257  Pulled By: soulitzer  fbshipit-source-id: 00ca0aa6519bed5f9ee2c7be4daa8872af5e92cd",1,API Refactoring,,
91f10a1de1e44e6f4243e9ddf2615c0c2fa0df46,2020-01-24T23:44:58Z,https://github.com/pytorch/pytorch/commit/91f10a1de1e44e6f4243e9ddf2615c0c2fa0df46,[quant][graphmode][refactor] Better API for fold_convbn (#32380)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/32380We'll clone the module first and then fold conv bn and return a newmoduleTest Plan:.Imported from OSSDifferential Revision: D19508033fbshipit-source-id: 328e91a2c9420761c904a7f2b62dab4cfaaa31ac,1,API Refactoring,,
95556f40757957b12be4f7c3bdc8d5e9e7a7d8c5,2017-10-18T12:14:19Z,https://github.com/pytorch/pytorch/commit/95556f40757957b12be4f7c3bdc8d5e9e7a7d8c5,add ignored_keys param to load_state_dict (#3159)* add ignored_keys param to load_state_dict* remove ignored_keys in favour of a strict param* raise KeyError only if strict is enables,1,API Refactoring,,
9ec1727ea689fb936959b42db5ad382a5eaf4fc8,2019-11-15T17:52:24Z,https://github.com/pytorch/pytorch/commit/9ec1727ea689fb936959b42db5ad382a5eaf4fc8,"Makes test_type_promotion generic (#29417)Summary:Test type promotion was already running on CUDA with its own (tiny) version of a generic test framework. This PR makes it use the actual generic test framework.In addition, the tests previously set the default dtype (and did not reset it). A new decorator replaces the previous style and resets the default dtype after each test. This is still not thread-safe, but at least there's a comment to that effect now.Pull Request resolved: https://github.com/pytorch/pytorch/pull/29417Differential Revision: D18514545Pulled By: mruberryfbshipit-source-id: 5aad43481ae71124cba99fb2e4a946894f591d68",1,API Refactoring,,
c1415a0a72a09e16a93bb1900eb1a8541bb448d6,2021-09-17T17:31:58Z,https://github.com/pytorch/pytorch/commit/c1415a0a72a09e16a93bb1900eb1a8541bb448d6,[Reland] [Model Averaging] Simplify PostLocalSGD Optimizer API (#65197)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/65197  1. The constructor accepts a local optimizer instance instead of the inputs of local optimizer constructor and the class type. 2. The parameters are read from local optimizer's param_groups instead of a separate input.  Proposal: https://github.com/pytorch/pytorch/issues/59699 ghstack-source-id: 138307226  Test Plan: buck test mode/dev-nosan //caffe2/test/distributed:distributed_nccl_spawn -- test_post_localSGD_optimizer_parity  Reviewed By: rohan-varma  Differential Revision: D31007439  fbshipit-source-id: bbb0526e6763ef76775b85088571506b3942c722,1,API Refactoring,,
c2d28fb87498d506f71f03d33c188b6b46e718d3,2016-12-21T04:43:37Z,https://github.com/pytorch/pytorch/commit/c2d28fb87498d506f71f03d33c188b6b46e718d3,RNNs API simplificationSummary:This is a first step in improving our RNN story. It provides a wrapper around current RecurrentNetworkOp implementation which infers most of the redundant parameters and makes API much simpler.Also in order to support general step nets I added an extra argument to the RecurrentNetworkOp.Future work:1. Inferring step net output and internal blobs (scratches) sizes and type2. Avoid accessing blobs by names in c++ part3. Remove requirement for inputs / output 1:1 correspondence in the step net4. Make python API support networks with operators like Sum being on the boarder of the Cell net (currently there is an issue with such networks where gradient blobs which are on the side are not explicitly created).Differential Revision: D4268503fbshipit-source-id: f8a66491c2b55daa730caeed7e9f2b3921541b49,1,API Refactoring,,
e7564b076c13325fba1704d9d07844a26041f10f,2020-10-19T16:26:52Z,https://github.com/pytorch/pytorch/commit/e7564b076c13325fba1704d9d07844a26041f10f,Refactor scalar list APIs to use overloads (#45673)Summary:Refactor foreach APIs to use overloads in case of scalar list inputs.Tested via unit tests.Pull Request resolved: https://github.com/pytorch/pytorch/pull/45673Reviewed By: heitorschueroffDifferential Revision: D24053424Pulled By: izdebyfbshipit-source-id: 35976cc50b4acfe228a32ed26cede579d5621cde,1,API Refactoring,,
f29e75c4dcc3454d50849f3a4670c6ae1d4d3142,2021-05-24T21:57:45Z,https://github.com/pytorch/pytorch/commit/f29e75c4dcc3454d50849f3a4670c6ae1d4d3142,[reland][quant][fx][graphmode][refactor] Remove qconfig_map from Quantizer (#58455) (#58756)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/58756  Test Plan: python test/test_quantization.py TestQuantizeFx python test/test_quantization.py TestQuantizeFxOps  Imported from OSS  Imported from OSS  Reviewed By: supriyar  Differential Revision: D28607564  fbshipit-source-id: 979cf165941bb3a9044d03077a170b5ea64dc36a,1,API Refactoring,,
f32c9bd5e9263c214381cdbf5923ae2331966e02,2019-05-09T21:07:36Z,https://github.com/pytorch/pytorch/commit/f32c9bd5e9263c214381cdbf5923ae2331966e02,"Refactor core DistributedDataParallel tests (#20235)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/20235The tests expected to only run for CUDA models. In a future commit weneed to update this to work for CPU models as well. Therefore, we canno longer rely on only integers being passed for device identifiers.With this change we pass both the materialized list of devices to use(as `torch.Device` objects), as well as an optional list of integers.The latter is specified to exercise the code in theDistributedDataParallel constructor that turns a list of integers intoCUDA devices, IFF it is used to wrap a single-device CUDA module.This commit also groups together the 'str' and non-'str' tests. Theseused to test passing the list of devices as integers or as`torch.Device` instances. These are now executed from the same test.Reviewed By: mrshenliDifferential Revision: D15245429fbshipit-source-id: 5797ba9db33d2c26db8e7493c91bb52f694285ac",1,API Refactoring,,
f7c736e1e7d3161304a3e93c3e36c55dcb5ebd05,2023-05-23T05:48:23Z,https://github.com/pytorch/pytorch/commit/f7c736e1e7d3161304a3e93c3e36c55dcb5ebd05,"[quant][pt2e] Add observer_or_fake_quant_ctr to QuantizationSpec (#101920)  Summary: This is the second refactor to align the annotation API with design, next step is to change prepare_pt2e to consume QuantizationSpec object directly  Test Plan: ``` buck2 test mode/optcaffe2/test:quantization_pt2e -- --exact 'caffe2/test:quantization_pt2e - test_resnet18_with_quantizer_api (quantization.pt2e.test_quantize_pt2e.TestQuantizePT2EModels)' ```  Reviewed By: kimishpatel  Differential Revision: D45927416  Pull Request resolved: https://github.com/pytorch/pytorch/pull/101920 Approved by: https://github.com/andrewor14",1,API Refactoring,,
a782858285ec4393a4b7c5fb48ea558ee0959e2e,2017-09-12T01:41:32Z,https://github.com/pytorch/pytorch/commit/a782858285ec4393a4b7c5fb48ea558ee0959e2e,Move go_token_id out of beam search constructor.Summary: This is will allow the same decoder to handle different go tokens.Differential Revision: D5801811fbshipit-source-id: ddd309963c97e32c728b15d2ccd4ba0c4ad5ebbe,1,API Refactoring,Move Statement,
a9a9d362e2634deec56e207e0836ead3a54fbc76,2019-09-23T18:50:50Z,https://github.com/pytorch/pytorch/commit/a9a9d362e2634deec56e207e0836ead3a54fbc76,"Makes test_indexing.py device generic (#26634)Summary:- Makes test_indexing.py device generic- Removes test_indexing_cuda.pyNote: a couple tests in test_indexing.py were already CPU and CUDA tests, meaning these tests were run multiple times when CUDA was available. Genericizing test_indexing.py corrects this and lets these tests be run on other device types, like XLA, too.Pull Request resolved: https://github.com/pytorch/pytorch/pull/26634Differential Revision: D17529001Pulled By: mruberryfbshipit-source-id: e71ba28d947749255a0aceeb7b77a42c4811439d",1,API Refactoring,,
b82658810e544fd4c935b0cf73906741ffabc2d8,2020-03-10T03:35:26Z,https://github.com/pytorch/pytorch/commit/b82658810e544fd4c935b0cf73906741ffabc2d8,Split deserialize from _run_function in RPC internal.py (#34494)Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/34494Differential Revision: D20347463Test Plan: Imported from OSSPulled By: mrshenlifbshipit-source-id: e6fd886622f26c46bb83ac118e67abb2f5b296b9,1,API Refactoring,,
bc328d01e595ddf8d926e301784137c5182474f1,2019-01-07T23:12:25Z,https://github.com/pytorch/pytorch/commit/bc328d01e595ddf8d926e301784137c5182474f1,simplify conv dnnlowp ops by not allowing fp32 in/out (#15758)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/15758DNNLOWP Conv operators became very complex due to many options. This diff simplifies them by not allowing fp32 in/out. This is OK for Conv operators because Conv operators are usually used in deep networks where quantizing and dequantizing using separate operators is not much overhead.Reviewed By: csummerseaDifferential Revision: D13587341fbshipit-source-id: e88c919dae79d1c5b7d787ea539edf5bcb064afc,1,API Refactoring,,
cab7d94d47c35d3a3c3929a726dea11b705c5264,2020-07-03T09:44:01Z,https://github.com/pytorch/pytorch/commit/cab7d94d47c35d3a3c3929a726dea11b705c5264,[PyTorch Numeric Suite] Remove unnecessary Logger in input arguments (#40890)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/40890Remove unnecessary Logger in input arguments and simplify the API.ghstack-source-id: 107110487Test Plan:buck test mode/dev caffe2/test:quantization -- 'test_compare_weights_lstm_dynamic'buck test mode/dev caffe2/test:quantization -- 'test_compare_model_stub_lstm_dynamic'buck test mode/dev caffe2/test:quantization -- 'test_compare_model_outputs_lstm_dynamic'buck test mode/dev caffe2/test:quantization -- 'test_compare_weights_conv_static'buck test mode/dev caffe2/test:quantization -- 'test_compare_weights_linear_static'buck test mode/dev caffe2/test:quantization -- 'test_compare_weights_linear_dynamic'buck test mode/dev caffe2/test:quantization -- 'test_compare_model_stub_conv_static'buck test mode/dev caffe2/test:quantization -- 'test_compare_model_stub_linear_static'buck test mode/dev caffe2/test:quantization -- 'test_compare_model_stub_submodule_static'buck test mode/dev caffe2/test:quantization -- 'test_compare_model_stub_functional_static'buck test mode/dev caffe2/test:quantization -- 'test_compare_model_stub_linear_dynamic'buck test mode/dev caffe2/test:quantization -- 'test_compare_model_outputs_conv_static'buck test mode/dev caffe2/test:quantization -- 'test_compare_model_outputs_linear_static'buck test mode/dev caffe2/test:quantization -- 'test_compare_model_outputs_functional_static'buck test mode/dev caffe2/test:quantization -- 'test_compare_model_outputs_linear_dynamic'Differential Revision: D22345477fbshipit-source-id: d8b4eb3d6cb3049aa3296dead8ba29bf5467bd1c,1,API Refactoring,,
e9adbbba8258f6c7ad11d2e9943d93fca57697ee,2018-04-07T15:09:31Z,https://github.com/pytorch/pytorch/commit/e9adbbba8258f6c7ad11d2e9943d93fca57697ee,refactor reduce arg to _Loss superclass (#6371),1,API Refactoring,,
ec2c974bd51b9677f9925eafc25cd15add8883c6,2020-02-04T16:39:23Z,https://github.com/pytorch/pytorch/commit/ec2c974bd51b9677f9925eafc25cd15add8883c6,"Simplify some TH codegen by moving code out of the switch and killing dead code. (#32888)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/32888This kills ~1500 lines of generated code by doing the following:1) Stop binding _th_clone, which isn't used anymore.2) Move allocation code out of the switch, because it doesn't need to be there, example:Now:```auto dispatch_scalar_type = infer_scalar_type(self);auto result_ = c10::make_intrusive<TensorImpl, UndefinedTensorImpl>(c10::Storage(scalarTypeToTypeMeta(dispatch_scalar_type), 0, allocator(), true),DispatchKey::CPUTensorId).release();auto result = Tensor(c10::intrusive_ptr<TensorImpl, UndefinedTensorImpl>::reclaim(result_));switch (dispatch_scalar_type) {    case ScalarType::Bool: {        ...    case ScalarType::Byte: {	    ...```Before:```auto dispatch_scalar_type = infer_scalar_type(self);switch(dispatch_scalar_type) {    case ScalarType::Bool: {       	auto result_ = c10::make_intrusive<TensorImpl, UndefinedTensorImpl>(caffe2::TypeMeta::Make<bool>(), 0, allocator(), true),DispatchKey::CPUTensorId).release();        auto result = Tensor(c10::intrusive_ptr<TensorImpl, UndefinedTensorImpl>::reclaim(result_));    case ScalarType::Byte: {        auto result_ = c10::make_intrusive<TensorImpl, UndefinedTensorImpl>(caffe2::TypeMeta::Make<byte>(), 0, allocator(), true),DispatchKey::CPUTensorId).release();        auto result = Tensor(c10::intrusive_ptr<TensorImpl, UndefinedTensorImpl>::reclaim(result_));```Note there's one extra lookup from ScalarType -> TypeMeta, but that can go away once we are able to put everything in a dispatch macro.3) Prepare for more moves out of the switch by using dispatch_scalar_type where we would have used an explicit ScalarType::NameMore moves are currently blocked by ""real"" types needing to map scalar_type -> C++ type.  Dispatch macros can solve that, but I'll need to wrap the actual TH calls in templates so the entirething can be done via dispatch.4) Kill some codegen that isn't used anymore: ALLOC_WRAP, is_actual_return_long.Test Plan: Imported from OSSDifferential Revision: D19672613Pulled By: gchananfbshipit-source-id: 753f480842d11757e10182e43b471bd3abaa5446",1,API Refactoring,,
0824b919ec37d461660e2ebef811242ba7292981,2021-07-01T00:20:05Z,https://github.com/pytorch/pytorch/commit/0824b919ec37d461660e2ebef811242ba7292981,[BE] move general script out of .circleci/ into tools/ (#60973)  Summary: Second step in https://github.com/pytorch/pytorch/issues/60373.  Pull Request resolved: https://github.com/pytorch/pytorch/pull/60973  Reviewed By: samestep  Differential Revision: D29499385  Pulled By: walterddr  fbshipit-source-id: 22df22f78f6b9af6221917a10188218773245009,1,API Refactoring,,
1a52ca02ef1ae77204a0a2f254c8bedbbd81cb41,2017-07-18T17:27:39Z,https://github.com/pytorch/pytorch/commit/1a52ca02ef1ae77204a0a2f254c8bedbbd81cb41,Always return indices from MaxPool autograd functions to simplify implementation;The callers (in functional.py) will filter out the return instead.,1,API Refactoring,Expression,
1b4586ee202696594e01d724eab22410cb58b4a6,2021-06-01T19:42:28Z,https://github.com/pytorch/pytorch/commit/1b4586ee202696594e01d724eab22410cb58b4a6,[quant][gx][graphmode][refactor] Remove modules from Quantizer (#59030)  Summary: Pull Request resolved: https://github.com/pytorch/pytorch/pull/59030  Trying to remove Quantizer class and split prepare and convert code  Test Plan: python test/test_quantization.py TestQuantizeFx python test/test_quantization.py TestQuantizeFxOps  Imported from OSS  Reviewed By: vkuzo  Differential Revision: D28724875  fbshipit-source-id: d6610c1d5eb7755331252be9e348a230abf4175c,1,API Refactoring,,
27d1daab45dc19953345b3c44185952116c249ad,2019-06-03T17:55:51Z,https://github.com/pytorch/pytorch/commit/27d1daab45dc19953345b3c44185952116c249ad,"Export ONNX Dropout for opset 10 (#20710)Summary:Remove Dropout from the opset 10 blacklist.ONNX Dropout was modified in opset 10, but only the output ""mask"" was modified, which is not exported in pytorch opset 9. So we can still fallback on the opset 9 op.Pull Request resolved: https://github.com/pytorch/pytorch/pull/20710Differential Revision: D15571248Pulled By: houseroadfbshipit-source-id: 15267eb63308a29a435261034b2f07324db1dea6",1,API Refactoring,,
7743ed850231781097fe4388fbe6d299cbb4a2c6,2019-02-11T21:31:06Z,https://github.com/pytorch/pytorch/commit/7743ed850231781097fe4388fbe6d299cbb4a2c6,"Don't keep unnecessary saved_inputs alive (#16583)Summary:Fixes #16577.This greatly improves memory efficiency of certain ops like Dropout2d. Previously, they were implemented as `input * mask` where mask never requires_grad, but we didn't use that knowledge in forward, and (in case of a in-place dropout) kept input.clone() for the backward, when it would simply get ignored.This patch tries to address this situation by emitting some guards for stores like this, but only if they are as simple, as checking if a single value requires_grad.Interestingly, the same optimizations apply to methods like bmm, baddmm, etc., but _not to mm nor addmm_, because of how their derivatives are defined. Apparently they unnecessarily use `mat1` to compute the derivative of `mat1` just to improve the error message in case `mat1` was sparse. I'd like to apply this optimization to that case, but I don't want to loose the nicer error message, so if anyone has any ideas for solutions, please let me know...Full list of operators affected by this patch:* _nnpack_spatial_convolution* addbmm* addcdiv* addcmul* addmv* addr* baddbmm* bmm* cross* div* dot* fmod* ger* index_add_* mul* mv* scatter_add_Pull Request resolved: https://github.com/pytorch/pytorch/pull/16583Differential Revision: D13900881Pulled By: gchananfbshipit-source-id: dd0aeb2ab58c4b6aa95b37b46d3255b3e014291c",1,API Refactoring,Move Statement,
c9593bc0e15b661dc90286eeaf503f31a3c9df78,2023-05-05T22:31:12Z,https://github.com/pytorch/pytorch/commit/c9593bc0e15b661dc90286eeaf503f31a3c9df78,"[ONNX] Refactor diagnose_call message_formatter signature (#100299)  Pull Request resolved: https://github.com/pytorch/pytorch/pull/100299 Approved by: https://github.com/justinchuby, https://github.com/thiagocrepaldi",1,API Refactoring,,
d705083c2b4677af40cb34f3ffff4233377777ef,2020-10-13T15:24:07Z,https://github.com/pytorch/pytorch/commit/d705083c2b4677af40cb34f3ffff4233377777ef,"Refactor dispatcher and native to use Signature structure. (#45990)Summary:Pull Request resolved: https://github.com/pytorch/pytorch/pull/45990In #45890 we introduced the concept of a CppSignature, which bundledup all of the information necessary to declare a C++ signature forthe cpp API.  This PR introduces analogous concepts for dispatcherand native: DispatcherSignature and NativeSignature.The three interfaces are not particularly well coupled right now,but they do have some duck typing coincidences:- defn() which renders the C++ definition ""bool f(int x)""- decl() which renders the C++ declaration ""bool f(int x = 2)""- type() which renders the C++ function type ""bool(int)""Maybe at some point we'll introduce a Protocol, or a supertype.Many other methods (like arguments()) have varying types.  Thesesignatures also have some helper methods that forward back to realimplementations in the api modules.  Something to think about iswhether or not we should attempt to reduce boilerplate here ornot; I'm not too sure about it yet.The net effect is we get to reduce the number of variables wehave to explicitly write out in the codegen, since now these are allbundled together into a signature.  Something extra special happensin BackendSelect, where we now dynamically select between dispatcher_sigand native_sig as ""how"" the backend select is implemented.A little bit of extra cleanup:- Some places where we previously advertised Sequence, we now advertise  a more informative Tuple.- defn() may take an optional positional parameter overriding the entire  name, or a kwarg-only prefix parameter to just add a prefix to the  name.Signed-off-by: Edward Z. Yang <ezyang@fb.com>Test Plan: Imported from OSSReviewed By: smessmerDifferential Revision: D24223100Pulled By: ezyangfbshipit-source-id: f985eced08af4a60ba9641d125d0f260f8cda9eb",1,API Refactoring,,
bdb11e716a3affc6c7aa50f0a27776b721da2396,2018-08-14T19:41:30Z,https://github.com/pytorch/pytorch/commit/bdb11e716a3affc6c7aa50f0a27776b721da2396,"Split the dependence of ONNX from test_operators.py (#10151)Summary:Now, run `python test/onnx/test_operators.py --no-onnx`, we won't introduce any onnx python dependence. (No onnx/protobuf python packages needs to be installed)The major changes:- output pbtxt from C++ exporter directly, so the floating format may be slightly different. (This should be fine, since it's just to guard ONNX exporting.)- ONNX python packages are only imported if we run the ONNX related checks. Those checks are disabled when using `--no-onnx` flag.Pull Request resolved: https://github.com/pytorch/pytorch/pull/10151Reviewed By: jamesr66aDifferential Revision: D9130706Pulled By: houseroadfbshipit-source-id: ea28cf5db8399929179698ee535137f209e9ce6f",1,API Refactoring,,
8cf87a30bbd5cbd6444c6f3ed380a3d2b5f67461,2021-08-13T22:00:21Z,https://github.com/scikit-learn/scikit-learn/commit/8cf87a30bbd5cbd6444c6f3ed380a3d2b5f67461,MNT Replace `@property` on predict methods with `@available_if` (#20667)  Co-authored-by: Guillaume Lemaitre <g.lemaitre58@gmail.com>,1,API Refactoring,,
de1262c35e2aa4ee062d050281ee576ce9e35c94,2021-05-06T01:38:17Z,https://github.com/scikit-learn/scikit-learn/commit/de1262c35e2aa4ee062d050281ee576ce9e35c94,CLN Remove **kwargs in Neighbors estiamtors (#20013),1,API Refactoring,,
1f91b873e420fcfb5f1d84b821d27ab54bd76144,2021-04-08T22:17:49Z,https://github.com/scikit-learn/scikit-learn/commit/1f91b873e420fcfb5f1d84b821d27ab54bd76144,TST Remove redundant max iter in sklearn/linear_model/tests (#14622)  Co-authored-by: Thomas J. Fan <thomasjpfan@gmail.com>,1,API Refactoring,,
cd673475bde70e87255ccd9b6f35687ce59b4b67,2020-10-14T16:42:56Z,https://github.com/scikit-learn/scikit-learn/commit/cd673475bde70e87255ccd9b6f35687ce59b4b67,CLN Refactors find binning threshold (#18395),1,API Refactoring,Rename Variable,
5e010c44a08904c63895e33d1238fab936dc39a3,2020-08-05T19:10:05Z,https://github.com/scikit-learn/scikit-learn/commit/5e010c44a08904c63895e33d1238fab936dc39a3,MNT remove pre-dispatch and verbose from CalibratedClassifierCV (#18030),1,API Refactoring,,
993a0a3ab741d845d756ac0c399eba59a8eec89f,2020-07-11T21:27:16Z,https://github.com/scikit-learn/scikit-learn/commit/993a0a3ab741d845d756ac0c399eba59a8eec89f,ENH remove default y value in sklearn.kernel_ridge.KernelRidge.fit (#17906),1,API Refactoring,,
d2735911c2f636e0c83db5617afddc62b72ee770,2020-07-06T12:15:10Z,https://github.com/scikit-learn/scikit-learn/commit/d2735911c2f636e0c83db5617afddc62b72ee770,MNT Removed arguments from matplotlib.use() (#17774),1,API Refactoring,,
493f167c769b7a8bc9dc32f869ef44e627fc762c,2020-06-17T19:09:13Z,https://github.com/scikit-learn/scikit-learn/commit/493f167c769b7a8bc9dc32f869ef44e627fc762c,Replace *kwargs with named arguments in make_column_transformer (#17623),1,API Refactoring,,
6df781b0c34be916306857e8cb52a4bcac63a6ae,2020-06-07T17:40:10Z,https://github.com/scikit-learn/scikit-learn/commit/6df781b0c34be916306857e8cb52a4bcac63a6ae,ENH Replace *args with named arguments in make_union (#17472)  Co-authored-by: Thomas J. Fan <thomasjpfan@gmail.com> Co-authored-by: IQRA MUHAMMAD <iqra@iqra.local>,1,API Refactoring,,
e91902298f1521783a824bc1a6a8d1d7653a416a,2020-06-04T18:43:15Z,https://github.com/scikit-learn/scikit-learn/commit/e91902298f1521783a824bc1a6a8d1d7653a416a,MNT remove deprecated presort param (#17446),1,API Refactoring,,
f42cf8a2bc9194391bbf693eec41c0c5321bf12a,2020-05-25T21:48:50Z,https://github.com/scikit-learn/scikit-learn/commit/f42cf8a2bc9194391bbf693eec41c0c5321bf12a,MNT Replace kwargs by named args for resample (#17324),1,API Refactoring,,
d03dfa2778f9614aea896197ca404fb42851ee94,2020-05-15T22:28:02Z,https://github.com/scikit-learn/scikit-learn/commit/d03dfa2778f9614aea896197ca404fb42851ee94,MNT Removed name parameter from private check generators (#17224),1,API Refactoring,,
8abe0a822ea4fb35f705518fcd293e7d3eef835e,2020-05-14T13:21:01Z,https://github.com/scikit-learn/scikit-learn/commit/8abe0a822ea4fb35f705518fcd293e7d3eef835e,MNT Replaced kwargs by named args for train_test_split (#17216),1,API Refactoring,,
2d03d781a9f6333f1e3e1be452e37c3340396881,2020-04-17T17:44:09Z,https://github.com/scikit-learn/scikit-learn/commit/2d03d781a9f6333f1e3e1be452e37c3340396881,MNT simplify xfail check marking logic (#16949)  Co-Authored-By: Roman Yurchak <rth.yurchak@gmail.com>,1,API Refactoring,,
6cd77c2c50792127d71cccc8a1296cb8ee178960,2020-04-15T16:11:26Z,https://github.com/scikit-learn/scikit-learn/commit/6cd77c2c50792127d71cccc8a1296cb8ee178960,API make feature_extraction's constructors' params kwonly (#16866),1,API Refactoring,,
725ca8f32e1877881064886a422d8dc35449d7fe,2019-12-26T13:03:24Z,https://github.com/scikit-learn/scikit-learn/commit/725ca8f32e1877881064886a422d8dc35449d7fe,MAINT Remove redundant sample_weights check in DummyClassifier (#15510)  Co-authored-by: Sallie Walecka <sallie.walecka@gmail.com>,1,API Refactoring,,
d847557e180f796fcbce95dd38099f819c5ce577,2019-11-07T03:59:54Z,https://github.com/scikit-learn/scikit-learn/commit/d847557e180f796fcbce95dd38099f819c5ce577,MNT Remove pos_label in plot_roc_auc_curve (#15555),1,API Refactoring,,
dbe45918b29e42a8cbeb65fe9868c3dd0a12ca56,2019-11-05T10:05:03Z,https://github.com/scikit-learn/scikit-learn/commit/dbe45918b29e42a8cbeb65fe9868c3dd0a12ca56,MNT remove unnecessary constructor parameter **kwargs. (#15525),1,API Refactoring,,
b8a4da8baa1137f173e7035f104067c7d2ffde22,2019-11-02T22:47:52Z,https://github.com/scikit-learn/scikit-learn/commit/b8a4da8baa1137f173e7035f104067c7d2ffde22,"Remove support for positional arguments in SGDClassifier.set_params() (#15481)  Positional arguments are not supported by SGDClassifier's parent class BaseEstimator.set_params(), so passing them raises an error.",1,API Refactoring,,
266bfe85c0c1dc4fbadcea08e20a84952d8139f1,2019-09-10T00:04:55Z,https://github.com/scikit-learn/scikit-learn/commit/266bfe85c0c1dc4fbadcea08e20a84952d8139f1,MAINT Removed redundant parameters of 2 classes (#14796),1,API Refactoring,,
3d9fefce4e44550b632c6994a44c2fa8bea99c02,2019-08-25T02:53:18Z,https://github.com/scikit-learn/scikit-learn/commit/3d9fefce4e44550b632c6994a44c2fa8bea99c02,MAINT Remove redundant parameters in examples (#14792),1,API Refactoring,,
8f9a027b384e3365131c6fa1575557921251f2d1,2019-08-24T21:51:47Z,https://github.com/scikit-learn/scikit-learn/commit/8f9a027b384e3365131c6fa1575557921251f2d1,removed redundant tol paramtere from examples (#14765),1,API Refactoring,,
538a2f51ab9c445cc6a8dc714f814c2783d4e0c7,2019-08-14T20:41:15Z,https://github.com/scikit-learn/scikit-learn/commit/538a2f51ab9c445cc6a8dc714f814c2783d4e0c7,MAINT Removes unused keyword in BaseSGD (#14655),1,API Refactoring,,
92af3dabbb5f3381a656f7727171f332b8928e05,2019-08-13T20:09:07Z,https://github.com/scikit-learn/scikit-learn/commit/92af3dabbb5f3381a656f7727171f332b8928e05,MAINT simplify check_is_fitted to use any fitted attributes (#14545),1,API Refactoring,,
f13c9c07527413145894fbb72d561db491d3a281,2019-08-07T17:38:41Z,https://github.com/scikit-learn/scikit-learn/commit/f13c9c07527413145894fbb72d561db491d3a281,"CLN remove redundant default parameters in examples and tests (#14590)  remove redundant 'fit_intercept=True' in examples and tests along with some instances of other redundant parameters (max_iter=100, C=1 and alpha=1.0)",1,API Refactoring,,
228109cd5c12c0c3374e37f13b48d7382d15a5a7,2019-08-02T20:11:46Z,https://github.com/scikit-learn/scikit-learn/commit/228109cd5c12c0c3374e37f13b48d7382d15a5a7,MAINT Remove tolerance paramter from Perceptron (#14558),1,API Refactoring,,
38fd24ac1e9c7048a32c673a7827afd4501f0050,2019-08-02T18:04:10Z,https://github.com/scikit-learn/scikit-learn/commit/38fd24ac1e9c7048a32c673a7827afd4501f0050,EXA Remove redundant tol parameter for SGDClassifier (#14556),1,API Refactoring,,
b271e205701cbe1b6d220b51619e381cc7d0c805,2019-05-29T09:50:11Z,https://github.com/scikit-learn/scikit-learn/commit/b271e205701cbe1b6d220b51619e381cc7d0c805,DEP remove positive parameter for lars solver (#13863),1,API Refactoring,,
75967ef20ee1010e3fe05cda6c2866c3446f1f87,2019-05-14T17:48:58Z,https://github.com/scikit-learn/scikit-learn/commit/75967ef20ee1010e3fe05cda6c2866c3446f1f87,DEP remove deprecated parameters in EllipticEnvelope (#13818),1,API Refactoring,,
91e019df5e86bb3b1db8c283c3bdc4a7ef1ce74b,2019-05-09T02:19:40Z,https://github.com/scikit-learn/scikit-learn/commit/91e019df5e86bb3b1db8c283c3bdc4a7ef1ce74b,DEP remove precomputed parameter in t_sne.trustworthiness (#13820),1,API Refactoring,,
2b7a69baca0aeb6837600b5029be89d47bdcd086,2019-05-09T00:21:54Z,https://github.com/scikit-learn/scikit-learn/commit/2b7a69baca0aeb6837600b5029be89d47bdcd086,DEP remove the batch_size parameter from pariwise_distance_argmin (#13822),1,API Refactoring,,
b52bae49b1c74d9c4f09a21963c63e980c356fb3,2015-10-21T18:41:40Z,https://github.com/scikit-learn/scikit-learn/commit/b52bae49b1c74d9c4f09a21963c63e980c356fb3,"refactor mlp optimization methods into _fit_lbfgs and _fit_sgd, add Ctrl+C stop option for SGD",1,API Refactoring,,
5db2adf93ce1625bc112767c44c0e2385e91524a,2015-10-21T08:24:23Z,https://github.com/scikit-learn/scikit-learn/commit/5db2adf93ce1625bc112767c44c0e2385e91524a,MAINT Removed deprecated stuff.,1,API Refactoring,,
459cb9ba3da4afef6373166dc83cd14acf1a0aff,2015-10-05T15:19:57Z,https://github.com/scikit-learn/scikit-learn/commit/459cb9ba3da4afef6373166dc83cd14acf1a0aff,Remove warm start,1,API Refactoring,,
46edeec1117a71dfa5433391745754f93110128e,2015-10-01T22:07:01Z,https://github.com/scikit-learn/scikit-learn/commit/46edeec1117a71dfa5433391745754f93110128e,COSMIT some refactoring in NMF  * de-indent loop * move regularization calculations out of loop,1,API Refactoring,,
ceeef700372a4aa3ec26b102561f6248a179c375,2015-09-21T09:42:07Z,https://github.com/scikit-learn/scikit-learn/commit/ceeef700372a4aa3ec26b102561f6248a179c375,ENH refactor NMF and add CD solver,1,API Refactoring,,
81de81a01a19635649371347564fdc7448ae0211,2015-07-16T17:21:24Z,https://github.com/scikit-learn/scikit-learn/commit/81de81a01a19635649371347564fdc7448ae0211,ENH implement LYRL2004 train/test split of rcv1,1,API Refactoring,,
4c6ad90d2a91d439a46bc7e50828d396f10a7c8c,2015-05-16T09:13:31Z,https://github.com/scikit-learn/scikit-learn/commit/4c6ad90d2a91d439a46bc7e50828d396f10a7c8c,Remove interquartile_scale parameter,1,API Refactoring,,
e5957928d3536dfb4b2771af433854e91594d9fb,2015-05-15T21:48:34Z,https://github.com/scikit-learn/scikit-learn/commit/e5957928d3536dfb4b2771af433854e91594d9fb,Remove 'copy' parameter form RobustScaler functions,1,API Refactoring,,
2638fe59d5b6e1fe225c0a952bb4e6eed189a589,2015-03-19T15:30:39Z,https://github.com/scikit-learn/scikit-learn/commit/2638fe59d5b6e1fe225c0a952bb4e6eed189a589,Use immutable default arguments throughtout repo  Replace mutable default arguments in examples  Replace mutable default arguments in sklearn/manifold/t_sne.py  Replace mutable default arguments in sklearn/metrics/pairwise.py,1,API Refactoring,,
81acb94e2d6fe1bdfac1e413a222e9f37295f2c9,2015-03-18T22:46:33Z,https://github.com/scikit-learn/scikit-learn/commit/81acb94e2d6fe1bdfac1e413a222e9f37295f2c9,Merge pull request #4411 from ragv/maint_remove_n_iterations  MAINT remove the deprecated n_iterations param,1,API Refactoring,,
88759ba187c550ea6d41ba73e261fd809a0b94ec,2015-03-18T22:44:24Z,https://github.com/scikit-learn/scikit-learn/commit/88759ba187c550ea6d41ba73e261fd809a0b94ec,MAINT remove the deprecated n_iterations param,1,API Refactoring,,
f79ac7c187f5b6775d2a8947f8c71ff70e90cbe6,2014-12-26T23:47:32Z,https://github.com/scikit-learn/scikit-learn/commit/f79ac7c187f5b6775d2a8947f8c71ff70e90cbe6,MAINT: Remove deprecation warnings in enet_path and lasso_path,1,API Refactoring,,
7ed6c5f326ba0635d6290aa2dd59e2d2d2f3e244,2014-12-05T13:07:16Z,https://github.com/scikit-learn/scikit-learn/commit/7ed6c5f326ba0635d6290aa2dd59e2d2d2f3e244,OPT: Remove unwanted calls to np.asarray for self.centroids_,1,API Refactoring,,
373e641c5264274b157fd5f3f9de7844558a2d34,2014-11-25T16:23:00Z,https://github.com/scikit-learn/scikit-learn/commit/373e641c5264274b157fd5f3f9de7844558a2d34,MAINT refactor gradient boosting code  Fixes gh-3790,1,API Refactoring,,
dc3b00dfc082f68efc1af0db8ae3ed0c1e5a874b,2014-09-19T03:37:34Z,https://github.com/scikit-learn/scikit-learn/commit/dc3b00dfc082f68efc1af0db8ae3ed0c1e5a874b,Removed n_jobs parameter from the fit method and added it to the constructor,1,API Refactoring,,
7f4c974d6b58802a654daaf1f19555f35cac6751,2014-09-17T10:14:26Z,https://github.com/scikit-learn/scikit-learn/commit/7f4c974d6b58802a654daaf1f19555f35cac6751,Sample weights for gradient boosting  Exponential loss for classification + predict_proba refactoring,1,API Refactoring,,
4fe04e20c277e9b8499a965e3221ad1a704ffd2f,2014-07-22T14:57:40Z,https://github.com/scikit-learn/scikit-learn/commit/4fe04e20c277e9b8499a965e3221ad1a704ffd2f,Refactor fit_intercept case,1,API Refactoring,,
b12d1ac48739e44dde67b6afd1fee8edb8ad6288,2014-07-17T12:53:06Z,https://github.com/scikit-learn/scikit-learn/commit/b12d1ac48739e44dde67b6afd1fee8edb8ad6288,Remove deprecated 'score_func' and 'loss_func' parameters from sklearn.metrics.scorer.check_scoring. Amend the code in all the other places they were used.,1,API Refactoring,,
7d905b8c5aed33040a4c8af7ed336437395433b6,2014-07-17T09:23:28Z,https://github.com/scikit-learn/scikit-learn/commit/7d905b8c5aed33040a4c8af7ed336437395433b6,Remove deprecated 'Gram' and 'Xy' parameters from OrthogonalMatchingPursuit.fit,1,API Refactoring,,
0a953a1187c812b8294869f38afa4732e03e1435,2014-07-17T08:59:42Z,https://github.com/scikit-learn/scikit-learn/commit/0a953a1187c812b8294869f38afa4732e03e1435,"Remove deprecated 'copy_Gram', 'copy_Xy' and 'copy_X' parameters",1,API Refactoring,,
7b69ace3e1698bd94f28a864e129d3a8bd229bc3,2014-07-17T08:47:07Z,https://github.com/scikit-learn/scikit-learn/commit/7b69ace3e1698bd94f28a864e129d3a8bd229bc3,Remove deprecated 'precompute_gram' parameter,1,API Refactoring,,
e107e1f5f675d9eb2c0e96a131b2ff332d845e61,2014-07-16T16:53:36Z,https://github.com/scikit-learn/scikit-learn/commit/e107e1f5f675d9eb2c0e96a131b2ff332d845e61,Remove deprecated 'class_weight' parameter from RidgeClassifierCV.fit,1,API Refactoring,,
802c0a6275d9fc41ecf7b1934dd9895529116556,2014-07-16T16:26:41Z,https://github.com/scikit-learn/scikit-learn/commit/802c0a6275d9fc41ecf7b1934dd9895529116556,Remove deprecated 'mode' parameter from sklearn.manifold.spectral_embedding,1,API Refactoring,,
cf8201249c37880d92719301a14d068be1c0339b,2014-07-04T19:37:23Z,https://github.com/scikit-learn/scikit-learn/commit/cf8201249c37880d92719301a14d068be1c0339b,"Remove duplicate GaussianNB.fit() code  This code is substantially duplicated by partial_fit(), so just call partial_fit().",1,API Refactoring,,
ae7a4ad0a936870b24efeb6075f5a29dd103e50e,2014-06-05T10:44:35Z,https://github.com/scikit-learn/scikit-learn/commit/ae7a4ad0a936870b24efeb6075f5a29dd103e50e,Remove unused param precompute from MultiTask models,1,API Refactoring,,
d0f6052a7c0eb8df48b0dd867c2799aa9bd729fa,2014-05-26T15:33:47Z,https://github.com/scikit-learn/scikit-learn/commit/d0f6052a7c0eb8df48b0dd867c2799aa9bd729fa,Merge pull request #3199 from mjbommar/isotonic-out-of-bounds-2  Handling out-of-bounds in IsotonicRegression (clean PR #3147),1,API Refactoring,,
0abe21eaacc147c7be33c73bce80444bb017d48e,2014-03-12T12:33:42Z,https://github.com/scikit-learn/scikit-learn/commit/0abe21eaacc147c7be33c73bce80444bb017d48e,MAINT remove some deprecated stuff,1,API Refactoring,,
0a000e0b2bd20bec2c2787f78d56c83c4d35aafa,2014-01-16T03:43:16Z,https://github.com/scikit-learn/scikit-learn/commit/0a000e0b2bd20bec2c2787f78d56c83c4d35aafa,Replace '_fit_estimator' by '_cross_val_score',1,API Refactoring,,
4d5ce3540c68d7903fdcc39b60a4f93b6ea7aef5,2013-10-20T13:58:05Z,https://github.com/scikit-learn/scikit-learn/commit/4d5ce3540c68d7903fdcc39b60a4f93b6ea7aef5,Remove unused outliers parameter,1,API Refactoring,,
a2d95d3e8306d544208930d87a208565201a2b49,2013-10-13T15:31:17Z,https://github.com/scikit-learn/scikit-learn/commit/a2d95d3e8306d544208930d87a208565201a2b49,Merge branch 'refactor-squared-norms',1,API Refactoring,,
b62b0d3dc5fedaf3e0ab1b38886e3cbd492393d8,2013-08-26T07:43:09Z,https://github.com/scikit-learn/scikit-learn/commit/b62b0d3dc5fedaf3e0ab1b38886e3cbd492393d8,tree export_graphviz: remove unused close parameter and close the file if out_file is a string,1,API Refactoring,,
cf397fb26f3365357d912e5fc478610b7d2de403,2013-08-25T09:28:35Z,https://github.com/scikit-learn/scikit-learn/commit/cf397fb26f3365357d912e5fc478610b7d2de403,ENH Removed copy option and deprecation on new functions and classes,1,API Refactoring,,
a82b31547dab9daa401adbe70d4ad18c06cd4442,2013-08-08T08:00:22Z,https://github.com/scikit-learn/scikit-learn/commit/a82b31547dab9daa401adbe70d4ad18c06cd4442,MAINT remove deprecated parameters (the easy cases),1,API Refactoring,,
202e6ee8fb4a151d05cbb28161757093174cb387,2013-07-25T17:19:21Z,https://github.com/scikit-learn/scikit-learn/commit/202e6ee8fb4a151d05cbb28161757093174cb387,replaced kmeans_kwargs with some useful k-means parameters,1,API Refactoring,,
08e5c35ce54b6deeb7548534a868d906c722c760,2013-07-25T17:19:20Z,https://github.com/scikit-learn/scikit-learn/commit/08e5c35ce54b6deeb7548534a868d906c722c760,removed svd_kwargs argument,1,API Refactoring,,
784486126fa6c7f929271f2dc4034e55568f7b34,2013-07-22T10:56:05Z,https://github.com/scikit-learn/scikit-learn/commit/784486126fa6c7f929271f2dc4034e55568f7b34,"Cleaned up tests, and removed unused multilabel parameter in decision_function_ovr",1,API Refactoring,,
e83056f0a611979dfb7c5caae6863a39b81947f1,2013-07-04T10:39:23Z,https://github.com/scikit-learn/scikit-learn/commit/e83056f0a611979dfb7c5caae6863a39b81947f1,Remove copy option.,1,API Refactoring,,
c849b320ae10925bd86e8b6922c68494078e7a90,2013-06-13T17:58:15Z,https://github.com/scikit-learn/scikit-learn/commit/c849b320ae10925bd86e8b6922c68494078e7a90,MAINT remove deprecated gprime handling from FastICA + refactoring  Test coverage up from 88% to 99%.,1,API Refactoring,,
eb755db13af05d708dc06bc5e18e26f70b55e9e2,2013-06-03T07:08:20Z,https://github.com/scikit-learn/scikit-learn/commit/eb755db13af05d708dc06bc5e18e26f70b55e9e2,ENH remove pos_label argument with multilabel binary indicator format,1,API Refactoring,,
1bf52ec373941a8f2a2c879648c9bfce1cdd84fa,2013-04-25T13:28:24Z,https://github.com/scikit-learn/scikit-learn/commit/1bf52ec373941a8f2a2c879648c9bfce1cdd84fa,removed class_weight parameter from RidgeClassifier.fit(),1,API Refactoring,,
7a595b85b4e59aff7baf572bde21680c3af6b32c,2013-01-20T21:00:48Z,https://github.com/scikit-learn/scikit-learn/commit/7a595b85b4e59aff7baf572bde21680c3af6b32c,COSMIT: simplify parallel code in multiclass,1,API Refactoring,,
57b184b2dd3fafac265cace5918fa9470fff4b55,2012-09-02T21:16:51Z,https://github.com/scikit-learn/scikit-learn/commit/57b184b2dd3fafac265cace5918fa9470fff4b55,ENH: simplify dict learning with gram and reg_param handling,1,API Refactoring,,
d1e34dda5b5c9df05569a0feed4eb14c87a5de0b,2012-05-06T20:42:38Z,https://github.com/scikit-learn/scikit-learn/commit/d1e34dda5b5c9df05569a0feed4eb14c87a5de0b,CLEAN sparse_encode: remove unused arguments  And use the ones that should,1,API Refactoring,,
33f758d4e833634cbd8fe2c045856c5f75b98c1c,2012-05-04T21:16:01Z,https://github.com/scikit-learn/scikit-learn/commit/33f758d4e833634cbd8fe2c045856c5f75b98c1c,"COSMIT removed unused ""verbose"" option in dbscan",1,API Refactoring,,
dbaabfac2515e37a4674de499a05e5889bf4626d,2012-03-18T16:10:42Z,https://github.com/scikit-learn/scikit-learn/commit/dbaabfac2515e37a4674de499a05e5889bf4626d,ENH refactoring of dot-file export,1,API Refactoring,,
db7d0d29cf1168f4d4a13ef1d370104f434235a5,2012-03-11T13:16:30Z,https://github.com/scikit-learn/scikit-learn/commit/db7d0d29cf1168f4d4a13ef1d370104f434235a5,refactoring for multi-class,1,API Refactoring,,
d429b68d0b9c41c57e5ec0b44cf1ea45fb5d4156,2012-02-15T10:25:04Z,https://github.com/scikit-learn/scikit-learn/commit/d429b68d0b9c41c57e5ec0b44cf1ea45fb5d4156,"feature_extraction/text.py: 'ignore' removed as a default, class param instead with a default of 'strict'",1,API Refactoring,,
f6deb73249d2ece162b6a75011080ebc1c3022b5,2012-02-09T14:13:19Z,https://github.com/scikit-learn/scikit-learn/commit/f6deb73249d2ece162b6a75011080ebc1c3022b5,removed pure python codes and beam pruning options,1,API Refactoring,,
3922816a373b698110524a70f3f5004e87960a12,2012-02-05T12:35:34Z,https://github.com/scikit-learn/scikit-learn/commit/3922816a373b698110524a70f3f5004e87960a12,refactor SGD regression input validation + doc fixes,1,API Refactoring,,
c716902ec85e1d3ff7d2d687a6879e526f9382c0,2012-01-14T12:51:18Z,https://github.com/scikit-learn/scikit-learn/commit/c716902ec85e1d3ff7d2d687a6879e526f9382c0,"- removed unnecessary **kwargs specification in fit and _do_mstep methods - addad trailing underscores to estimated quantities.   e.g. self.startprob_, self.transmat_, self.emissionprob_ etc",1,API Refactoring,,
aad9a42a6ebaeccf2fd47d44b6d574650e936f7c,2011-12-21T17:44:30Z,https://github.com/scikit-learn/scikit-learn/commit/aad9a42a6ebaeccf2fd47d44b6d574650e936f7c,ENH: Removed X and z varaibles from dpmm cladd (should not ship the data),1,API Refactoring,,
c4decfbd97d1d208cf81d7c3d21bca2ace86a041,2011-12-20T15:58:32Z,https://github.com/scikit-learn/scikit-learn/commit/c4decfbd97d1d208cf81d7c3d21bca2ace86a041,Replace unmaintainable test  closes https://github.com/scikit-learn/scikit-learn/issues/485,1,API Refactoring,,
9cef7eb0dd23cd57883c581e9fd840649121207f,2011-12-19T10:27:03Z,https://github.com/scikit-learn/scikit-learn/commit/9cef7eb0dd23cd57883c581e9fd840649121207f,Merge pull request #477 from jakevdp/gmm-fix  remove unused return_log keyword in GMM,1,API Refactoring,,
f43c524415c2377459e5b70825bafba392cce12e,2011-11-28T10:23:26Z,https://github.com/scikit-learn/scikit-learn/commit/f43c524415c2377459e5b70825bafba392cce12e,Remove `correction` and `reweighting` parameters from the API.,1,API Refactoring,,
541528c955839e3a8e40eed0f530a6dfa7530474,2011-11-11T22:45:39Z,https://github.com/scikit-learn/scikit-learn/commit/541528c955839e3a8e40eed0f530a6dfa7530474,Remove C from NuSVR.,1,API Refactoring,,
3d58c49c060665fff77d4c9551ca32bf8ce9d6e2,2011-11-06T12:43:34Z,https://github.com/scikit-learn/scikit-learn/commit/3d58c49c060665fff77d4c9551ca32bf8ce9d6e2,refactored the init logic for MiniBatchKMeans,1,API Refactoring,,
8878ebe9da68882f445689be67627f17f317a1a7,2011-11-04T12:34:54Z,https://github.com/scikit-learn/scikit-learn/commit/8878ebe9da68882f445689be67627f17f317a1a7,ENH Sparse SVM: removed cache_size parameter from fit method. Is now part of constructur.,1,API Refactoring,,
895094dbd1fd52e660d5bc04221982473eeb360e,2011-11-03T13:42:53Z,https://github.com/scikit-learn/scikit-learn/commit/895094dbd1fd52e660d5bc04221982473eeb360e,"ENH: removed kernel cache from fit method of DenseLibSVM, added to __init__ of BaseLibSVM",1,API Refactoring,,
eab58773c6e66ed405e36213c9524750221ecfe3,2011-11-01T13:22:31Z,https://github.com/scikit-learn/scikit-learn/commit/eab58773c6e66ed405e36213c9524750221ecfe3,"Simplified tree module API.  Among other changes, the max_features parameter has been removed. It will be properly reincluded later when building randomized trees.",1,API Refactoring,,
b5429abd8d0344d2973b3ce815f066538ad1f8ca,2011-10-26T10:32:46Z,https://github.com/scikit-learn/scikit-learn/commit/b5429abd8d0344d2973b3ce815f066538ad1f8ca,Removed unused parameters in least_angle,1,API Refactoring,,
fbad80e86bfc1d28edd3b31aded2bb693aeedaaa,2011-10-14T16:05:24Z,https://github.com/scikit-learn/scikit-learn/commit/fbad80e86bfc1d28edd3b31aded2bb693aeedaaa,replaced ratio r with sampling with replacement,1,API Refactoring,,
31e9a5495d1b63da8222693c866e8eb57438f795,2011-09-30T10:21:54Z,https://github.com/scikit-learn/scikit-learn/commit/31e9a5495d1b63da8222693c866e8eb57438f795,"refactor SVMlight reader and writer  * use with block (PEP 343) for exception-safety * support file-likes and paths everywhere * don't use 'file' as a variable name, it's a Python built-in",1,API Refactoring,,
858b268ca24a2ab80891eb83dbc672f020c160f4,2011-09-20T15:06:16Z,https://github.com/scikit-learn/scikit-learn/commit/858b268ca24a2ab80891eb83dbc672f020c160f4,"refactor linear models to call as_float_array only from _center_data  coordinate_descent is the exception, since it plays tricks with X is X_init that I don't fully understand yet.",1,API Refactoring,,
61a3e001ba678cd07484b1491c48284ce4fb9260,2011-09-19T10:45:02Z,https://github.com/scikit-learn/scikit-learn/commit/61a3e001ba678cd07484b1491c48284ce4fb9260,removed sample_mask parameter,1,API Refactoring,,
66187d8533c56ae2e37e7ba448f32b52cd9438fe,2011-09-01T19:31:05Z,https://github.com/scikit-learn/scikit-learn/commit/66187d8533c56ae2e37e7ba448f32b52cd9438fe,Merge pull request #331 from JeanKossaifi/master  Removed parameter iid in cross_val_score and _cross_val_score,1,API Refactoring,,
7809dfe61f135a53d36e41c200cd624ea16a4fb0,2011-09-01T16:20:27Z,https://github.com/scikit-learn/scikit-learn/commit/7809dfe61f135a53d36e41c200cd624ea16a4fb0,Cross_val : Removed useless & tricky parameter iid,1,API Refactoring,,
dfb0646e9125a1eeb20e684f561238a48718b20d,2011-08-24T07:55:12Z,https://github.com/scikit-learn/scikit-learn/commit/dfb0646e9125a1eeb20e684f561238a48718b20d,Merge pull request #317 from agramfort/normalize_data  Normalize data and refactor of coordinate_descent.py,1,API Refactoring,,
8a329270961ea9d1ac64f64c04316aae852f9915,2011-08-23T17:07:08Z,https://github.com/scikit-learn/scikit-learn/commit/8a329270961ea9d1ac64f64c04316aae852f9915,Removed fit_params from dictionary learning objects,1,API Refactoring,,
ce9814bbe88edd9d5ef1b1d003d5e05656490a34,2011-08-23T13:37:40Z,https://github.com/scikit-learn/scikit-learn/commit/ce9814bbe88edd9d5ef1b1d003d5e05656490a34,Remove fit params from all objects.,1,API Refactoring,,
7eb38a730a355940bc2cc6937c3fde2e9f9f2860,2011-08-12T05:48:03Z,https://github.com/scikit-learn/scikit-learn/commit/7eb38a730a355940bc2cc6937c3fde2e9f9f2860,Removed default value of n_components=None in SparsePCA,1,API Refactoring,,
d7821520208c3760f8c3ecc88aa9b68dee4e0640,2011-08-12T05:48:02Z,https://github.com/scikit-learn/scikit-learn/commit/d7821520208c3760f8c3ecc88aa9b68dee4e0640,"Removed dict_init in MiniBatchSparsePCA, docstrings",1,API Refactoring,,
d4d6dfa7c1552e5f28bc3bb2b43a8ea9ac7a949f,2011-08-12T05:30:35Z,https://github.com/scikit-learn/scikit-learn/commit/d4d6dfa7c1552e5f28bc3bb2b43a8ea9ac7a949f,remove lobpcg from LocallyLinearEmbedding,1,API Refactoring,,
a42871383b8f1686c63d7db5f3a7a533b816a87e,2011-08-08T10:59:38Z,https://github.com/scikit-learn/scikit-learn/commit/a42871383b8f1686c63d7db5f3a7a533b816a87e,"PEP8, renaming, removed image size from params  renaming for consistency, tests for PatchExtractor",1,API Refactoring,,
8b4fe769c40e8abda7fbd6cbfeae6452cfecfd6c,2011-07-27T18:13:16Z,https://github.com/scikit-learn/scikit-learn/commit/8b4fe769c40e8abda7fbd6cbfeae6452cfecfd6c,cleanups & pep8,1,API Refactoring,,
3ffe86e4d10ec281d3dcdb1ba17c8fc50178326d,2011-07-21T18:05:56Z,https://github.com/scikit-learn/scikit-learn/commit/3ffe86e4d10ec281d3dcdb1ba17c8fc50178326d,remove n_init arg from MiniBatchKMeans signature,1,API Refactoring,,
2bd81d1d76ca4e6d39f15459b884af2264637034,2011-07-20T15:48:26Z,https://github.com/scikit-learn/scikit-learn/commit/2bd81d1d76ca4e6d39f15459b884af2264637034,remove verbose output from GMMHMM test,1,API Refactoring,,
9704604d728523030b5721ec8517f01914cd3f55,2011-07-05T19:07:38Z,https://github.com/scikit-learn/scikit-learn/commit/9704604d728523030b5721ec8517f01914cd3f55,"Refactor/simplify CountVectorizer  Less parameter passing, -1 method",1,API Refactoring,Move Method,
cdf7df988b0a4806b578421a49879f51ab32d111,2011-07-05T12:26:38Z,https://github.com/scikit-learn/scikit-learn/commit/cdf7df988b0a4806b578421a49879f51ab32d111,"pep8 feature_extraction.text + rm content word ""computer"" from stop list",1,API Refactoring,,
db08066bb9055dd6c75be55e1d54cab01d9b7f28,2011-07-01T15:26:04Z,https://github.com/scikit-learn/scikit-learn/commit/db08066bb9055dd6c75be55e1d54cab01d9b7f28,"more transform methods, split_sign",1,API Refactoring,,
4ebd82698b518a59ce43db569091a347e0b9d100,2011-06-29T09:45:31Z,https://github.com/scikit-learn/scikit-learn/commit/4ebd82698b518a59ce43db569091a347e0b9d100,Remove bogus sparse vectorizing tests,1,API Refactoring,,
75380499f8394b65ec7b3ffd87f9bffacd556270,2011-06-25T21:31:00Z,https://github.com/scikit-learn/scikit-learn/commit/75380499f8394b65ec7b3ffd87f9bffacd556270,Rename of cg -> dense_cg and 'default'-> 'dense_cholesky'.  Also added parameter solver to RidgeClassifier.,1,API Refactoring,,
3c3db66d562690ae340166fe232d50f862a94a7f,2011-05-16T12:58:13Z,https://github.com/scikit-learn/scikit-learn/commit/3c3db66d562690ae340166fe232d50f862a94a7f,Move cache_size out of model parameters.,1,API Refactoring,,
f3b6f57749d666fcdc1786ec4429e7a7857e406e,2011-02-17T09:23:32Z,https://github.com/scikit-learn/scikit-learn/commit/f3b6f57749d666fcdc1786ec4429e7a7857e406e,"ENH: Neighbors refactoring.  Heavy refactoring in kneighbors_graph: most of loops could be eliminated, cleaner implementation.  Also, thanks to the previous commit, most of the special cased n_neighbors=1 could be avoided.  API changes:     - barycenter_weights has been renamed to barycenters and accepts      now X as 2D array and 3D array Y. This way iteration happens      inside barycenters, rendering kneighbor_graph considerably      cleaner. Also, NeighborRegressor directly uses barycenters      instead of kneighbor_graph. Apart from being conceptually      clearer, this lets us drop keyword drop_first in kneighbor_graph,      making the output of kneighbor_graph more consistent.     - weight keyword was renamed to mode. This is in the spirit of some      scipy function (qr) that perform slightly different algorithms      based on that keyword.     - added keyword eps to control how much regularization is      needed. Better names, anyone ?     - dropped keyword drop_first. By default, the first is not used on      'distance' and 'barycenter', so that exactly n_neighbors are      nonzero on each row. This is what is expected in my opinion and      makes API simpler.",1,API Refactoring,,
7d39bddfb11f865f0093a8d5b51e48ba20894da3,2011-02-08T08:06:23Z,https://github.com/scikit-learn/scikit-learn/commit/7d39bddfb11f865f0093a8d5b51e48ba20894da3,Move cv parameter to constructor in RidgeCV.,1,API Refactoring,,
4152157ddd36b2ce1a880508526ad5c369412bd0,2011-02-01T18:28:09Z,https://github.com/scikit-learn/scikit-learn/commit/4152157ddd36b2ce1a880508526ad5c369412bd0,Remove references to y in preprocessing objects.,1,API Refactoring,,
5571f7e06955ba5971e5f3d34e44b83bfac7aa5f,2010-11-23T13:18:03Z,https://github.com/scikit-learn/scikit-learn/commit/5571f7e06955ba5971e5f3d34e44b83bfac7aa5f,Some LARS refactoring.,1,API Refactoring,,
1622c42d784db19fdc0e6d69ea4aabae24f00125,2010-11-18T10:05:36Z,https://github.com/scikit-learn/scikit-learn/commit/1622c42d784db19fdc0e6d69ea4aabae24f00125,"removed parameters `p` and `C` from OneClassSVM (dense and sparse). Completed parameter list of SVC, NuSVR, and OneClassSVM.",1,API Refactoring,,
dbdb8a641a67140dbcda93ff34d10b11f63dd119,2010-10-31T22:06:56Z,https://github.com/scikit-learn/scikit-learn/commit/dbdb8a641a67140dbcda93ff34d10b11f63dd119,remove n_symbols argument from MultinomialHMM.__init__,1,API Refactoring,,
002d02ac01ecd2f9faa0ce1638cf37ea9dc7ddac,2010-10-31T21:51:29Z,https://github.com/scikit-learn/scikit-learn/commit/002d02ac01ecd2f9faa0ce1638cf37ea9dc7ddac,clean up interfaces in hmm and gmm   * remove unused 'labels' property  * fix doctests  * clarify definition of MultinomialHMM.n_symbols,1,API Refactoring,,
85a1c4a5064f6e9e77910fcbb0c7864a7771b6bb,2010-10-21T08:28:22Z,https://github.com/scikit-learn/scikit-learn/commit/85a1c4a5064f6e9e77910fcbb0c7864a7771b6bb,Remove normalize option from TfidfTransformer.,1,API Refactoring,,
41d3f72b7930f87bcccc9e3478c752006cdc2316,2010-09-21T14:37:15Z,https://github.com/scikit-learn/scikit-learn/commit/41d3f72b7930f87bcccc9e3478c752006cdc2316,work in progress: refactoring the document classification dataset API to remove the feature extraction step,1,API Refactoring,,
971b5b6b25cc96cdc4c1dde33df6dfd3e11b72d9,2010-09-07T17:22:55Z,https://github.com/scikit-learn/scikit-learn/commit/971b5b6b25cc96cdc4c1dde33df6dfd3e11b72d9,Remove Y from fit in OneClassSVM.,1,API Refactoring,,
667e5089eed604c24a2f0402181d4047b22629fe,2010-08-31T17:14:28Z,https://github.com/scikit-learn/scikit-learn/commit/667e5089eed604c24a2f0402181d4047b22629fe,"ENH : continue refactoring of GLM module (doc, moving files, config etc.)",1,API Refactoring,,
15ab406f43968f84bccbf2096a5fbf5d0f2c8046,2010-08-21T00:00:58Z,https://github.com/scikit-learn/scikit-learn/commit/15ab406f43968f84bccbf2096a5fbf5d0f2c8046,finish merge of hmm_trainers with hmm and remove hmm_trainers,1,API Refactoring,,
7b9ecbf595e8ee5b0a879573df2c4f503b2381a7,2010-07-07T03:05:08Z,https://github.com/scikit-learn/scikit-learn/commit/7b9ecbf595e8ee5b0a879573df2c4f503b2381a7,removed ndim argument from gmm.rvs(),1,API Refactoring,,
d3e537f26a57c96c464cef0d361b476484e01021,2010-06-21T08:36:21Z,https://github.com/scikit-learn/scikit-learn/commit/d3e537f26a57c96c464cef0d361b476484e01021,GMM refactoring.  Removed ndim parameter from __init__ (it should be inferred from input in fit),1,API Refactoring,,
f4401dbfeca0bee8ff9e4a6754b294e9dc32ab5d,2010-05-04T10:41:00Z,https://github.com/scikit-learn/scikit-learn/commit/f4401dbfeca0bee8ff9e4a6754b294e9dc32ab5d,Refactor lasso coordinate descent code.,1,API Refactoring,,
b806b12f41220ebbe1a1097a0276a899d4120628,2010-03-15T11:01:12Z,https://github.com/scikit-learn/scikit-learn/commit/b806b12f41220ebbe1a1097a0276a899d4120628,SVM refactoring  From: Fabian Pedregosa <fabian.pedregosa@inria.fr>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@534 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8,1,API Refactoring,,
fcc11d22e5017857a0235220140d1278de6578a0,2010-03-01T14:33:21Z,https://github.com/scikit-learn/scikit-learn/commit/fcc11d22e5017857a0235220140d1278de6578a0,Neighbors module refactoring.  Some minor changes to conform to coding standards and expanded tests. This document describes how new classifiers should behave: https://sourceforge.net/apps/trac/scikit-learn/wiki/ApiDiscussion  From: Fabian Pedregosa <fabian.pedregosa@inria.fr>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@418 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8,1,API Refactoring,,
fad33963ff3bea8f669f8b97471b2fd8e3165556,2010-01-18T15:07:49Z,https://github.com/scikit-learn/scikit-learn/commit/fad33963ff3bea8f669f8b97471b2fd8e3165556,"Neighbors refactoring, predict method added.  Some unused arguments were erased, Neighbors.kneighbors returns now separate arrays for distance and point, which makes some computations much easier, since typically you are interested only in one these vectors (see for example Neighbors.predict).  Also renamed neighbors -> k, since neighbors is too similar to function kneighbors. Plus, k is the default parameter also in other packages (PyMVPA).  Some optimizations could still be made, both technical, like creating self.dist and self.ind as fixed-sized arrays (changing a bit of the C++ might be needed for this) and algorithmical, for example using kd-trees[1].  None of those are high-priority issues and probably won't be looked at before 0.2.  [1] http://en.wikipedia.org/wiki/Kd-tree  From: Fabian Pedregosa <fabian.pedregosa@inria.fr>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@349 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8",1,API Refactoring,,
efd31fb7c33e1f8e0e7a6214806f152463a1abdd,2010-01-06T11:11:04Z,https://github.com/scikit-learn/scikit-learn/commit/efd31fb7c33e1f8e0e7a6214806f152463a1abdd,Split tests for logresp python vs cython.  From: cdavid <cdavid@cb17146a-f446-4be1-a4f7-bd7c5bb65646>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@312 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8,1,API Refactoring,,
414eb0f654888c64b13ea29527dd38859105aece,2010-01-05T17:07:06Z,https://github.com/scikit-learn/scikit-learn/commit/414eb0f654888c64b13ea29527dd38859105aece,Prediction refactoring in progress.  From: fullung <fullung@cb17146a-f446-4be1-a4f7-bd7c5bb65646>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@187 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8,1,API Refactoring,,
394dd1f2276766c7d86f3fe2fbdb62606e57dc97,2010-01-05T13:46:04Z,https://github.com/scikit-learn/scikit-learn/commit/394dd1f2276766c7d86f3fe2fbdb62606e57dc97,"Extensive refactoring of mlp (still convergence probs with some optimization algs). Started work on srn, should commit a good deal more tonight (want to have a working srn with at least one training alg before the weekend).  From: fred.mailhot <fred.mailhot@cb17146a-f446-4be1-a4f7-bd7c5bb65646>  git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@24 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8",1,API Refactoring,,
30b3c46ff5a7c9761a800a9ab4bcf8cdb206727e,2023-08-18T11:26:27Z,https://github.com/huggingface/transformers/commit/30b3c46ff5a7c9761a800a9ab4bcf8cdb206727e,[`split_special_tokens`] Add support for `split_special_tokens` argument to encode (#25081)  * draft changes  * update and add tests  * styling for no  * move test  * path to usable model  * update test  * small update  * update bertbased tokenizers  * don'tuse kwargs for _tokenize  * don'tuse kwargs for _tokenize  * fix copies  * update  * update test for special tokenizers  * fixup  * skip two tests  * remove pdb breakpiont()  * wowo  * rewrite custom tests  * nits  * revert chang in target keys  * fix markup lm  * update documentation of the argument,1,API Refactoring,,
d6bf08f7f6f8bf5d6d94e9b10b7d8203906353ad,2023-08-17T15:00:32Z,https://github.com/huggingface/transformers/commit/d6bf08f7f6f8bf5d6d94e9b10b7d8203906353ad,"[`resize_embedding`] Introduce `pad_to_multiple_of` and guidance (#25088)  * fix  * revert cahnges and update resizing of embedding layer  * use wraning  * fixup  * more styling nits  * fix all tests that overload the embedding tests  * 👀👀 remove breakpoint  * remove useless overload + overload correctly where needed  * resize lm head with new vocab size  * reverse not necessary changes  * style  * fix CIs!  * fix last CI tests, adapt bark and Marian  * fixup",1,API Refactoring,,
d114a6b71f243054db333dc5a3f55816161eb7ea,2023-08-03T14:51:54Z,https://github.com/huggingface/transformers/commit/d114a6b71f243054db333dc5a3f55816161eb7ea,Add timeout parameter to load_image function (#25184)  * Add timeout parameter to load_image function.  * Remove line.  * Reformat code  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>  * Add parameter to docs.  ---------  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>,1,API Refactoring,,
a73b1d59a34ca8e30098b3e32a977a7928663559,2023-05-31T09:46:22Z,https://github.com/huggingface/transformers/commit/a73b1d59a34ca8e30098b3e32a977a7928663559,"accelerate deepspeed and gradient accumulation integrate (#23236)  * mixed precision support via accelerate  * fix issues  * fix for the sharded ddp case  * fix flax and tf failing tests  * `refactor the place to create `Accelerator` object  * move ddp prep to accelerate  * fix 😅  * resolving comments  * move fsdp handling to accelerate  * fixex  * fix saving  * shift torch dynamo handling to accelerate  * shift deepspeed integration and save & load utils to accelerate  * fix accelerate launcher support  * oops  * fix 🐛  * save ckpt fix  * Trigger CI  * nasty 🐛 😅  * as deepspeed needs grad_acc fixes, transfer grad_acc to accelerate  * make tests happy  * quality ? * loss tracked needs to account for grad_acc  * fixing the deepspeed tests  * quality ? * 😅😅😅  * tests 😡  * quality ? * Trigger CI  * resolve comments and fix the issue with the previous merge from branch  * Trigger CI  * accelerate took over deepspeed integration  ---------  Co-authored-by: Stas Bekman <stas@stason.org>",1,API Refactoring,,
b92abfa6e0b7053c8bede0647b69f0f1690e9cd0,2023-05-11T09:07:43Z,https://github.com/huggingface/transformers/commit/b92abfa6e0b7053c8bede0647b69f0f1690e9cd0,Add `top_k` argument to post-process of conditional/deformable-DETR (#22787)  * update min k_value of conditional detr post-processing  * feat: add top_k arg to post processing of deformable and conditional detr  * refactor: revert changes to deprecated methods  * refactor: move prob reshape to improve code clarity and reduce repetition,1,API Refactoring,,
78cda46f17548d8739c354a07b00b3f2996773c7,2023-04-18T16:36:56Z,https://github.com/huggingface/transformers/commit/78cda46f17548d8739c354a07b00b3f2996773c7,Generate: Add assisted generation (#22211)  * working mvp  * remove breakpoint  * fix commit  * standardize outputs  * tmp commit  * tests almost ready  * tmp commit  * skip a few models  * Add streaming; Docs and examples  * document limitations  * PR commits  * Amy PR comments,1,API Refactoring,,
ea7b0a539a92a79b829cfc7d41d28f33f993e820,2023-04-17T15:36:29Z,https://github.com/huggingface/transformers/commit/ea7b0a539a92a79b829cfc7d41d28f33f993e820,Use code on the Hub from another repo (#22698)  * initial work  * Add other classes  * Refactor code  * Move warning and fix dynamic pipeline  * Issue warning when necessary  * Add test,1,API Refactoring,,
871598be552c38537bc047a409b4a6840ba1c1e4,2023-04-04T13:05:04Z,https://github.com/huggingface/transformers/commit/871598be552c38537bc047a409b4a6840ba1c1e4,Implemented safetensors checkpoints save/load for Trainer (#22498)  * implemented safetensors save/load  * remove duplicated file  * added tests  * more tests  * style fix  * fix tf tests  * change to list comprehension  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * review fixes + safe load for sharded checkpoint  * style fix  * remove rogue import  * remove partial to avoid undefined exception  * use naming alias instead of safetensors.torch  * fix safe sharding in tests  * grammar  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * update docs  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * update docs  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * minor corrections  * style  ---------  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>,1,API Refactoring,,
330d8b991fee414e75098baa76b33b408d4a8b53,2023-03-21T10:16:07Z,https://github.com/huggingface/transformers/commit/330d8b991fee414e75098baa76b33b408d4a8b53,"replace_8bit_linear modules_to_not_convert default value fix (#22238)  * Fixed modules_to_not_convert default value  * Fixed modules_to_not_convert docstring  * Update src/transformers/utils/bitsandbytes.py  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>  * Update src/transformers/utils/bitsandbytes.py  Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>  * [""lm_head""] if modules_to_not_convert is None  ---------  Co-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com> Co-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>",1,API Refactoring,,
8788fd0ceb2cea986cd4ca14b4eb4be554e1404c,2023-01-25T14:46:10Z,https://github.com/huggingface/transformers/commit/8788fd0ceb2cea986cd4ca14b4eb4be554e1404c,Moving to cleaner tokenizer version or `oneformer`. (#21292)  Moving to cleaner tokenizer version.,1,API Refactoring,,
0f78529f982eceb79c5855d0466c287ec8a18df1,2022-11-17T12:34:46Z,https://github.com/huggingface/transformers/commit/0f78529f982eceb79c5855d0466c287ec8a18df1,Generate: general TF XLA constrastive search are now slow tests (#20277)  * move contrastive search test to slow,1,API Refactoring,,
70a058bc65ce8cd1ac429139fb2df65f548fd567,2022-10-11T16:54:41Z,https://github.com/huggingface/transformers/commit/70a058bc65ce8cd1ac429139fb2df65f548fd567,Added tokenize keyword arguments to feature extraction pipeline (#19382)  * Added tokenize keyword arguments to feature extraction pipeline  * Reverted truncation parameter  * Import numpy moved to top,1,API Refactoring,,
408b5e307b495b2c14e9c83ff1c62b944ff366af,2022-09-26T12:50:58Z,https://github.com/huggingface/transformers/commit/408b5e307b495b2c14e9c83ff1c62b944ff366af,Remove pos arg from Perceiver's Pre/Postprocessors (#18602)  * Remove pos arg from Perceiver's Pre/Postprocessors  * Revert the removed pos args in public methods,1,API Refactoring,,
0e0f1f4692b9dbbab56b1adf32e0911caeecaa34,2022-06-24T17:31:30Z,https://github.com/huggingface/transformers/commit/0e0f1f4692b9dbbab56b1adf32e0911caeecaa34,Use higher value for hidden_size in Flax BigBird test (#17822)  * Use higher value for hidden_size in Flax BigBird test  * remove 5e-5  Co-authored-by: ydshieh <ydshieh@users.noreply.github.com>,1,API Refactoring,,
39f8eafc1b6f00769240f714e2df5b2c5f111c32,2022-05-03T15:06:11Z,https://github.com/huggingface/transformers/commit/39f8eafc1b6f00769240f714e2df5b2c5f111c32,Remove device parameter from create_extended_attention_mask_for_decoder (#16894),1,API Refactoring,,
b4ddd2677c9072f39267c8b3bf9b33a7a52d108f,2022-04-18T09:58:24Z,https://github.com/huggingface/transformers/commit/b4ddd2677c9072f39267c8b3bf9b33a7a52d108f,TF generate refactor - XLA sample (#16713),1,API Refactoring,,
3f43d824b909ec92cde5311e9be016767c0fb11b,2022-04-06T17:19:34Z,https://github.com/huggingface/transformers/commit/3f43d824b909ec92cde5311e9be016767c0fb11b,TF generate refactor - Beam Search (#16374)  * refactor TF beam search  * refactored generate can now properly use attention masks  * add force bos/eos logit processors,1,API Refactoring,,
fbb454307dd60e071273ac741a6074ebccbc6d1a,2022-03-21T16:34:10Z,https://github.com/huggingface/transformers/commit/fbb454307dd60e071273ac741a6074ebccbc6d1a,[SegFormer] Remove unused attributes (#16285)  * Remove unused attributes  * Add link to blog and add clarification about input size  * Improve readability of the code  Co-authored-by: Niels Rogge <nielsrogge@Nielss-MacBook-Pro.local>,1,API Refactoring,,
94be424308e7877e86eea2108ad44ba7fe12f916,2022-03-21T16:17:52Z,https://github.com/huggingface/transformers/commit/94be424308e7877e86eea2108ad44ba7fe12f916,Added type hints for PyTorch T5 model (#16257)  * Added type hints for PyTorch T5 model  * removed a type hint  * ran make style,1,API Refactoring,,
1d94d575461a76cb1dcb3ebe6e85f1c85d1dafcd,2022-02-02T08:44:22Z,https://github.com/huggingface/transformers/commit/1d94d575461a76cb1dcb3ebe6e85f1c85d1dafcd,Add option to resize like torchvision's Resize (#15419)  * Add torchvision's resize  * Rename torch_resize to default_to_square  * Apply suggestions from code review  * Add support for default_to_square and tuple of length 1,1,API Refactoring,,
9b3aab2cce17e47aa2216f75f1675132d19f43d1,2021-07-12T15:15:54Z,https://github.com/huggingface/transformers/commit/9b3aab2cce17e47aa2216f75f1675132d19f43d1,"Pickle auto models (#12654)  * PoC, it pickles!  * Remove old method.  * Apply to every auto object",1,API Refactoring,,
ca33278fdbb83426dff7415f78cbf4070e873db0,2021-05-18T21:50:51Z,https://github.com/huggingface/transformers/commit/ca33278fdbb83426dff7415f78cbf4070e873db0,"FlaxGPT2 (#11556)  * flax gpt2  * combine masks  * handle shared embeds  * add causal LM sample  * style  * add tests  * style  * fix imports, docs, quality  * don't use cache  * add cache  * add cache 1st version  * make use cache work  * start adding test for generation  * finish generation loop compilation  * rewrite test  * finish  * update  * update  * apply sylvains suggestions  * update  * refactor  * fix typo  Co-authored-by: Patrick von Platen <patrick.v.platen@gmail.com>",1,API Refactoring,,
37ed3ab719f10dc00bf63ac343b441bf78bb1eee,2021-05-13T06:44:55Z,https://github.com/huggingface/transformers/commit/37ed3ab719f10dc00bf63ac343b441bf78bb1eee,Enable option for subword regularization in more tokenizers. (#11417)  * improve slow class tok usage at xlm rob  * add subword regularization for barthez  * improve barthez tok. test  * fix tokenizer tests  * add subword regularization for camembert  * add subword regularization for deberta v2 tokenizer  * add more doc to deberta v2 tokenizer  * add subword regularization for speech to text tok.  * fix sp_model_kwargs type in speech 2 text tok.  * add subword regularization for M2M100 tok.  * add more concrete type hints  * fix tests for m2m100 and s2t tok.  * add missing Any import  * fix syntax error in m2m100 tok.  * fix unpickle of m2m100 and s2t tok.  * fix test of m2m100 and s2t tok.  * improve unpickle of deberta v2 tok.  * add test for pickle of barthez & camembert  * fix pickle of barthez & camembert  * add test for deberta v2 tok. pickle  * fix m2m100 tok. pickle  * fix s2t tok. pickle  * add subword regularization to albert tok.  * refactor subword reg. test into TokenizerTesterMixin  improve albert tok. test  remove sample argument form albert tok.  check subword reg. using TokenizerTesterMixin  improve tok. tests  improve xlm roberta tok. tests  improve xlm roberta tok. tests  * add subword regularization for big bird t.  * improve xlm roberta tok. test  * add subword regularization for mbart50 tok.  * add subword regularization for pegasus tok.  * add subword regularization for reformer tok.  * add subword regularization for T5 tok.  * fix t5 tok. test formatting  * add subword regularization for xlm_proph. tok.  * add subword regularization for xlnet tok.  * add subword regularization for gert_gen tok.  * add typing to tokenizers  * add typing to xlm rob. tok  * add subword regularization for marian tok.  * add reverse tok. test  * fix marian tok test  * fix marian tok test  * fix casing in tok. tests  * fix style of tok. common test  * fix deberta v2 tok test  * add type annotations to tok. tests  * add type annotations to tok. __init__  * add typing to kokenizer  * add type annotations to tok. __init__  * don't specify the default when it's None  * fix barthez tok. doc  * move sentencepiece tok. tests to TokenizerTesterMixin  * fix unused imports  * fix albert tok. test  * add comment to sentencepiece test options  * fix Any import at big bird tok.  * fix Any import at xlm prophetnet tok.  * empty commit to trigger CI,1,API Refactoring,,
8c9b5fcbaf27cbf1aa781670d598cf74c07b7e88,2021-04-23T07:53:09Z,https://github.com/huggingface/transformers/commit/8c9b5fcbaf27cbf1aa781670d598cf74c07b7e88,[Flax] Big FlaxBert Refactor (#11364)  * improve flax  * refactor  * typos  * Update src/transformers/modeling_flax_utils.py  * Apply suggestions from code review  * Update src/transformers/modeling_flax_utils.py  * fix typo  * improve error tolerance  * typo  * correct nasty saving bug  * fix from pretrained  * correct tree map  * add note  * correct weight tying,1,API Refactoring,,
c503a1c15ec1b11e69a3eaaf06edfa87c05a2849,2021-03-04T20:27:12Z,https://github.com/huggingface/transformers/commit/c503a1c15ec1b11e69a3eaaf06edfa87c05a2849,[ProphetNet] Bart-like Refactor (#10501)  * first step to refactor  * make all fast tests pass  * make all slow tests pass  * save intermediate  * correct cache  * finish PR  * make fp16 work,1,API Refactoring,,
0203ad43bcd0b29423dec6ca1a58ed58300f0d61,2020-09-16T19:38:37Z,https://github.com/huggingface/transformers/commit/0203ad43bcd0b29423dec6ca1a58ed58300f0d61,[s2s] distributed eval cleanup (#7186),1,API Refactoring,,
a59bcefbb1cf834353bd1177f32edfbc95dd4279,2020-08-31T19:16:39Z,https://github.com/huggingface/transformers/commit/a59bcefbb1cf834353bd1177f32edfbc95dd4279,Split hp search methods (#6857)  * Split the run_hp_search by backend  * Unused import,1,API Refactoring,,
eb613b566acb90120afd8d90bc3660a18c12f140,2020-08-14T07:34:39Z,https://github.com/huggingface/transformers/commit/eb613b566acb90120afd8d90bc3660a18c12f140,Use hash to clean the test dirs (#6475)  * Use hash to clean the test dirs  * Use hash to clean the test dirs  * Use hash to clean the test dirs  * fix,1,API Refactoring,Extract Variable,
1429b920d44d610eaa0a6f48de43853da52e9c03,2020-08-10T09:31:20Z,https://github.com/huggingface/transformers/commit/1429b920d44d610eaa0a6f48de43853da52e9c03,refactor almost identical tests (#6339)  * refactor almost identical tests  * important to add a clear assert error message  * make the assert error even more descriptive than the original bt,1,API Refactoring,,
b2747af5434e5a5d8ab1d7e2789699d20d7a4ab8,2020-07-10T14:31:47Z,https://github.com/huggingface/transformers/commit/b2747af5434e5a5d8ab1d7e2789699d20d7a4ab8,Improvements to PretrainedConfig documentation (#5642)  * Update PretrainedConfig doc  * Formatting  * Small fixes  * Forgotten args and more cleanup,1,API Refactoring,,
989ae326b572b3729b78ac8ac1c6c5859c104af7,2020-07-07T08:48:06Z,https://github.com/huggingface/transformers/commit/989ae326b572b3729b78ac8ac1c6c5859c104af7,[Reformer] Adapt Reformer MaskedLM Attn mask (#5560)  * fix attention mask  * fix slow test  * refactor attn masks  * fix fp16 generate test,1,API Refactoring,,
3d3e605affb792b78c918aac48f6bc82cfbf7e3e,2020-06-18T20:30:24Z,https://github.com/huggingface/transformers/commit/3d3e605affb792b78c918aac48f6bc82cfbf7e3e,[cleanup] generate_beam_search comments (#5115),1,API Refactoring,,
07dd7c2fd8996fec2979555437dfeff0d38cbf28,2020-05-19T14:46:55Z,https://github.com/huggingface/transformers/commit/07dd7c2fd8996fec2979555437dfeff0d38cbf28,[cleanup] test_tokenization_common.py (#4390),1,API Refactoring,Rename Method,Rename Variable
33508ae310f101a2534d3e97ea23fda93e25ef38,2019-12-04T21:26:45Z,https://github.com/huggingface/transformers/commit/33508ae310f101a2534d3e97ea23fda93e25ef38,Remove `only_first`,1,API Refactoring,,
f5bcde0b2fcfab961580129ec27ac72f43eaa267,2019-09-30T20:04:55Z,https://github.com/huggingface/transformers/commit/f5bcde0b2fcfab961580129ec27ac72f43eaa267,[multiple-choice] Simplify and use tokenizer.encode_plus,1,API Refactoring,,
0c2ff348151cab8f245e352bb249d18b5623e3bc,2019-06-27T07:27:50Z,https://github.com/huggingface/transformers/commit/0c2ff348151cab8f245e352bb249d18b5623e3bc,extracting double hidden-state from xlnet,1,API Refactoring,,
